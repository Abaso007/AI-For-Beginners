<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7bd8dc72040e98e35e7225e34058cd4e",
  "translation_date": "2025-08-24T09:03:07+00:00",
  "source_file": "lessons/6-Other/22-DeepRL/lab/README.md",
  "language_code": "pt"
}
-->
# Treinar o Carro da Montanha para Escapar

Trabalho prático do [Currículo de IA para Iniciantes](https://github.com/microsoft/ai-for-beginners).

## Tarefa

O teu objetivo é treinar o agente de RL para controlar o [Mountain Car](https://www.gymlibrary.ml/environments/classic_control/mountain_car/) no Ambiente OpenAI.

## O Ambiente

O ambiente Mountain Car consiste num carro preso dentro de um vale. O teu objetivo é saltar para fora do vale e alcançar a bandeira. As ações que podes realizar são acelerar para a esquerda, para a direita ou não fazer nada. Podes observar a posição do carro ao longo do eixo x e a velocidade.

## Notebook Inicial

Começa o trabalho prático abrindo [MountainCar.ipynb](../../../../../../lessons/6-Other/22-DeepRL/lab/MountainCar.ipynb)

## Conclusão

Deverás aprender ao longo deste trabalho que adaptar algoritmos de RL a um novo ambiente é frequentemente bastante simples, porque o OpenAI Gym tem a mesma interface para todos os ambientes, e os algoritmos, como tal, não dependem muito da natureza do ambiente. Podes até reestruturar o código Python de forma a passar qualquer ambiente para o algoritmo de RL como um parâmetro.

**Aviso Legal**:  
Este documento foi traduzido utilizando o serviço de tradução por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precisão, esteja ciente de que traduções automáticas podem conter erros ou imprecisões. O documento original no seu idioma nativo deve ser considerado a fonte autoritativa. Para informações críticas, recomenda-se a tradução profissional humana. Não nos responsabilizamos por quaisquer mal-entendidos ou interpretações incorretas resultantes do uso desta tradução.