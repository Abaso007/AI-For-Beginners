<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "2f7b97b375358cb51a1e098df306bf73",
  "translation_date": "2025-08-24T08:59:55+00:00",
  "source_file": "lessons/4-ComputerVision/07-ConvNets/CNN_Architectures.md",
  "language_code": "pt"
}
-->
# Arquiteturas CNN Conhecidas

### VGG-16

VGG-16 √© uma rede que alcan√ßou 92,7% de precis√£o na classifica√ß√£o top-5 do ImageNet em 2014. Possui a seguinte estrutura de camadas:

![Camadas do ImageNet](../../../../../lessons/4-ComputerVision/07-ConvNets/images/vgg-16-arch1.jpg)

Como pode ver, a VGG segue uma arquitetura piramidal tradicional, que √© uma sequ√™ncia de camadas de convolu√ß√£o e pooling.

![Pir√¢mide do ImageNet](../../../../../lessons/4-ComputerVision/07-ConvNets/images/vgg-16-arch.jpg)

> Imagem de [Researchgate](https://www.researchgate.net/figure/Vgg16-model-structure-To-get-the-VGG-NIN-model-we-replace-the-2-nd-4-th-6-th-7-th_fig2_335194493)

### ResNet

ResNet √© uma fam√≠lia de modelos proposta pela Microsoft Research em 2015. A ideia principal da ResNet √© usar **blocos residuais**:

<img src="images/resnet-block.png" width="300"/>

> Imagem deste [artigo](https://arxiv.org/pdf/1512.03385.pdf)

A raz√£o para usar a passagem de identidade √© permitir que a camada preveja **a diferen√ßa** entre o resultado de uma camada anterior e a sa√≠da do bloco residual - da√≠ o nome *residual*. Esses blocos s√£o muito mais f√°ceis de treinar, e √© poss√≠vel construir redes com v√°rias centenas desses blocos (as variantes mais comuns s√£o ResNet-52, ResNet-101 e ResNet-152).

Pode tamb√©m pensar nesta rede como sendo capaz de ajustar a sua complexidade ao conjunto de dados. Inicialmente, quando come√ßa a treinar a rede, os valores dos pesos s√£o pequenos, e a maior parte do sinal passa pelas camadas de identidade. √Ä medida que o treino avan√ßa e os pesos se tornam maiores, a import√¢ncia dos par√¢metros da rede cresce, e a rede ajusta-se para acomodar o poder expressivo necess√°rio para classificar corretamente as imagens de treino.

### Google Inception

A arquitetura Google Inception leva esta ideia um passo adiante e constr√≥i cada camada da rede como uma combina√ß√£o de v√°rios caminhos diferentes:

<img src="images/inception.png" width="400"/>

> Imagem de [Researchgate](https://www.researchgate.net/figure/Inception-module-with-dimension-reductions-left-and-schema-for-Inception-ResNet-v1_fig2_355547454)

Aqui, √© importante destacar o papel das convolu√ß√µes 1x1, porque, √† primeira vista, elas n√£o fazem sentido. Por que precisar√≠amos passar pela imagem com um filtro 1x1? No entanto, √© necess√°rio lembrar que os filtros de convolu√ß√£o tamb√©m trabalham com v√°rios canais de profundidade (originalmente - cores RGB, em camadas subsequentes - canais para diferentes filtros), e a convolu√ß√£o 1x1 √© usada para misturar esses canais de entrada usando diferentes pesos trein√°veis. Tamb√©m pode ser vista como uma forma de downsampling (pooling) na dimens√£o dos canais.

Aqui est√° [um bom artigo](https://medium.com/analytics-vidhya/talented-mr-1x1-comprehensive-look-at-1x1-convolution-in-deep-learning-f6b355825578) sobre o assunto, e [o artigo original](https://arxiv.org/pdf/1312.4400.pdf).

### MobileNet

MobileNet √© uma fam√≠lia de modelos com tamanho reduzido, adequada para dispositivos m√≥veis. Use-os se tiver poucos recursos e puder sacrificar um pouco de precis√£o. A ideia principal por tr√°s deles √© a chamada **convolu√ß√£o separ√°vel por profundidade**, que permite representar filtros de convolu√ß√£o por uma composi√ß√£o de convolu√ß√µes espaciais e convolu√ß√µes 1x1 sobre os canais de profundidade. Isso reduz significativamente o n√∫mero de par√¢metros, tornando a rede menor em tamanho e tamb√©m mais f√°cil de treinar com menos dados.

Aqui est√° [um bom artigo sobre MobileNet](https://medium.com/analytics-vidhya/image-classification-with-mobilenet-cc6fbb2cd470).

## Conclus√£o

Nesta unidade, aprendeu o conceito principal por tr√°s das redes neurais de vis√£o computacional - redes convolucionais. Arquiteturas reais que alimentam classifica√ß√£o de imagens, dete√ß√£o de objetos e at√© redes de gera√ß√£o de imagens s√£o todas baseadas em CNNs, apenas com mais camadas e alguns truques adicionais de treino.

## üöÄ Desafio

Nos notebooks que acompanham, h√° notas no final sobre como obter maior precis√£o. Fa√ßa alguns experimentos para ver se consegue alcan√ßar uma precis√£o maior.

## [Question√°rio p√≥s-aula](https://ff-quizzes.netlify.app/en/ai/quiz/14)

## Revis√£o e Autoestudo

Embora as CNNs sejam mais frequentemente usadas para tarefas de Vis√£o Computacional, elas s√£o geralmente boas para extrair padr√µes de tamanho fixo. Por exemplo, se estivermos a lidar com sons, tamb√©m podemos querer usar CNNs para procurar padr√µes espec√≠ficos no sinal de √°udio - nesse caso, os filtros seriam unidimensionais (e essa CNN seria chamada de 1D-CNN). Al√©m disso, √†s vezes √© usada uma 3D-CNN para extrair caracter√≠sticas em espa√ßo multidimensional, como certos eventos que ocorrem em v√≠deos - a CNN pode capturar certos padr√µes de mudan√ßa de caracter√≠sticas ao longo do tempo. Fa√ßa uma revis√£o e autoestudo sobre outras tarefas que podem ser realizadas com CNNs.

## [Tarefa](lab/README.md)

Neste laborat√≥rio, a sua tarefa √© classificar diferentes ra√ßas de gatos e c√£es. Estas imagens s√£o mais complexas do que o conjunto de dados MNIST, t√™m dimens√µes maiores e h√° mais de 10 classes.

**Aviso Legal**:  
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precis√£o, √© importante ter em conta que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original na sua l√≠ngua nativa deve ser considerado a fonte autorit√°ria. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional realizada por humanos. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes incorretas decorrentes da utiliza√ß√£o desta tradu√ß√£o.