<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "bd10f434e444bce61b7f97eeb1ff6a55",
  "translation_date": "2025-08-24T08:55:35+00:00",
  "source_file": "lessons/5-NLP/19-NER/README.md",
  "language_code": "pt"
}
-->
# Reconhecimento de Entidades Nomeadas

At√© agora, temos nos concentrado principalmente em uma tarefa de PLN - classifica√ß√£o. No entanto, existem outras tarefas de PLN que podem ser realizadas com redes neurais. Uma dessas tarefas √© o **[Reconhecimento de Entidades Nomeadas](https://wikipedia.org/wiki/Reconhecimento_de_entidades_nomeadas)** (NER), que lida com o reconhecimento de entidades espec√≠ficas em um texto, como locais, nomes de pessoas, intervalos de data e hora, f√≥rmulas qu√≠micas, entre outros.

## [Question√°rio pr√©-aula](https://ff-quizzes.netlify.app/en/ai/quiz/37)

## Exemplo de Uso do NER

Suponha que queira desenvolver um chatbot de linguagem natural, semelhante √† Amazon Alexa ou ao Google Assistant. A forma como chatbots inteligentes funcionam √© *entendendo* o que o utilizador deseja, realizando a classifica√ß√£o de texto na frase de entrada. O resultado dessa classifica√ß√£o √© o chamado **intento**, que determina o que o chatbot deve fazer.

<img alt="Bot NER" src="images/bot-ner.png" width="50%"/>

> Imagem do autor

No entanto, um utilizador pode fornecer alguns par√¢metros como parte da frase. Por exemplo, ao perguntar sobre o tempo, ele pode especificar uma localiza√ß√£o ou uma data. Um bot deve ser capaz de compreender essas entidades e preencher os campos de par√¢metros adequadamente antes de executar a a√ß√£o. √â exatamente aqui que o NER entra em cena.

> ‚úÖ Outro exemplo seria [analisar artigos cient√≠ficos na √°rea m√©dica](https://soshnikov.com/science/analyzing-medical-papers-with-azure-and-text-analytics-for-health/). Um dos principais objetivos √© identificar termos m√©dicos espec√≠ficos, como doen√ßas e subst√¢ncias m√©dicas. Enquanto um pequeno n√∫mero de doen√ßas pode ser extra√≠do usando busca por subcadeias, entidades mais complexas, como compostos qu√≠micos e nomes de medicamentos, exigem uma abordagem mais sofisticada.

## NER como Classifica√ß√£o de Tokens

Os modelos de NER s√£o essencialmente **modelos de classifica√ß√£o de tokens**, porque para cada token de entrada precisamos decidir se ele pertence a uma entidade ou n√£o, e, se pertence, a qual classe de entidade.

Considere o seguinte t√≠tulo de artigo:

**Regurgita√ß√£o da v√°lvula tric√∫spide** e **carbonato de l√≠tio** **toxicidade** em um rec√©m-nascido.

As entidades aqui s√£o:

* Regurgita√ß√£o da v√°lvula tric√∫spide √© uma doen√ßa (`DIS`)
* Carbonato de l√≠tio √© uma subst√¢ncia qu√≠mica (`CHEM`)
* Toxicidade tamb√©m √© uma doen√ßa (`DIS`)

Note que uma entidade pode abranger v√°rios tokens. E, como neste caso, precisamos distinguir entre duas entidades consecutivas. Assim, √© comum usar duas classes para cada entidade - uma especificando o primeiro token da entidade (geralmente o prefixo `B-` √© usado, para **b**eginning/in√≠cio), e outra para a continua√ß√£o da entidade (`I-`, para **i**nner token/token interno). Tamb√©m usamos `O` como uma classe para representar todos os **o**utros tokens. Essa marca√ß√£o de tokens √© chamada de [marca√ß√£o BIO](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)) (ou IOB). Quando marcado, nosso t√≠tulo ficar√° assim:

Token | Tag
------|-----
Tric√∫spide | B-DIS
v√°lvula | I-DIS
regurgita√ß√£o | I-DIS
e | O
carbonato | B-CHEM
de | I-CHEM
l√≠tio | I-CHEM
toxicidade | B-DIS
em | O
um | O
rec√©m-nascido | O
. | O

Como precisamos construir uma correspond√™ncia um-para-um entre tokens e classes, podemos treinar um modelo de rede neural **muitos-para-muitos** da seguinte forma:

![Imagem mostrando padr√µes comuns de redes neurais recorrentes.](../../../../../lessons/5-NLP/17-GenerativeNetworks/images/unreasonable-effectiveness-of-rnn.jpg)

> *Imagem retirada [deste artigo](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) de [Andrej Karpathy](http://karpathy.github.io/). Os modelos de classifica√ß√£o de tokens NER correspondem √† arquitetura de rede mais √† direita nesta imagem.*

## Treinamento de Modelos NER

Como um modelo NER √© essencialmente um modelo de classifica√ß√£o de tokens, podemos usar RNNs, com as quais j√° estamos familiarizados, para essa tarefa. Nesse caso, cada bloco da rede recorrente retornar√° o ID do token. O seguinte notebook de exemplo mostra como treinar um LSTM para classifica√ß√£o de tokens.

## ‚úçÔ∏è Notebooks de Exemplo: NER

Continue o seu aprendizado no seguinte notebook:

* [NER com TensorFlow](../../../../../lessons/5-NLP/19-NER/NER-TF.ipynb)

## Conclus√£o

Um modelo NER √© um **modelo de classifica√ß√£o de tokens**, o que significa que ele pode ser usado para realizar a classifica√ß√£o de tokens. Esta √© uma tarefa muito comum em PLN, ajudando a reconhecer entidades espec√≠ficas em textos, incluindo locais, nomes, datas e muito mais.

## üöÄ Desafio

Complete o exerc√≠cio abaixo para treinar um modelo de reconhecimento de entidades nomeadas para termos m√©dicos e, em seguida, experimente-o em um conjunto de dados diferente.

## [Question√°rio p√≥s-aula](https://ff-quizzes.netlify.app/en/ai/quiz/38)

## Revis√£o e Autoestudo

Leia o artigo [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) e explore a se√ß√£o de Leituras Adicionais para aprofundar o seu conhecimento.

## [Exerc√≠cio](lab/README.md)

No exerc√≠cio desta li√ß√£o, ter√° de treinar um modelo de reconhecimento de entidades m√©dicas. Pode come√ßar treinando um modelo LSTM, como descrito nesta li√ß√£o, e depois avan√ßar para o uso do modelo transformer BERT. Leia [as instru√ß√µes](lab/README.md) para obter todos os detalhes.

**Aviso Legal**:  
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos pela precis√£o, esteja ciente de que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original na sua l√≠ngua nativa deve ser considerado a fonte autorit√°ria. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional realizada por humanos. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes incorretas decorrentes do uso desta tradu√ß√£o.