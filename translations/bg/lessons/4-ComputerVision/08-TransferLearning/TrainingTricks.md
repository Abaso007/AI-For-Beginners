<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ae074cd940fc2f4dc24fc07b66ccbd99",
  "translation_date": "2025-08-25T23:13:03+00:00",
  "source_file": "lessons/4-ComputerVision/08-TransferLearning/TrainingTricks.md",
  "language_code": "bg"
}
-->
# Трикове за обучение на дълбоки невронни мрежи

С увеличаването на дълбочината на невронните мрежи, процесът на тяхното обучение става все по-предизвикателен. Един от основните проблеми са така наречените [изчезващи градиенти](https://en.wikipedia.org/wiki/Vanishing_gradient_problem) или [експлодиращи градиенти](https://deepai.org/machine-learning-glossary-and-terms/exploding-gradient-problem#:~:text=Exploding%20gradients%20are%20a%20problem,updates%20are%20small%20and%20controlled.). [Тази статия](https://towardsdatascience.com/the-vanishing-exploding-gradient-problem-in-deep-neural-networks-191358470c11) предоставя добро въведение в тези проблеми.

За да направим обучението на дълбоки мрежи по-ефективно, могат да се използват няколко техники.

## Поддържане на стойностите в разумен интервал

За да направим числените изчисления по-стабилни, трябва да се уверим, че всички стойности в невронната мрежа са в разумен мащаб, обикновено [-1..1] или [0..1]. Това не е строго изискване, но природата на изчисленията с плаваща запетая е такава, че стойности с различни порядъци не могат да бъдат манипулирани точно заедно. Например, ако добавим 10<sup>-10</sup> и 10<sup>10</sup>, вероятно ще получим 10<sup>10</sup>, защото по-малката стойност ще бъде "конвертирана" към същия порядък като по-голямата, и така мантисата ще бъде загубена.

Повечето функции за активация имат нелинейности около [-1..1], и затова има смисъл да се скалират всички входни данни към интервала [-1..1] или [0..1].

## Инициализация на началните тегла

Идеално, искаме стойностите да останат в същия диапазон след преминаване през слоевете на мрежата. Затова е важно да инициализираме теглата така, че да запазим разпределението на стойностите.

Нормалното разпределение **N(0,1)** не е добра идея, защото ако имаме *n* входове, стандартното отклонение на изхода ще бъде *n*, и стойностите вероятно ще излязат извън интервала [0..1].

Често използваните инициализации са:

 * Равномерно разпределение -- `uniform`
 * **N(0,1/n)** -- `gaussian`
 * **N(0,1/√n_in)** гарантира, че за входове със средна стойност 0 и стандартно отклонение 1, същата средна стойност/стандартно отклонение ще остане
 * **N(0,√2/(n_in+n_out))** -- така наречената **Xavier инициализация** (`glorot`), която помага да се запазят сигналите в диапазона както при предно, така и при обратно разпространение

## Нормализация на партиди

Дори с правилна инициализация на теглата, те могат да станат произволно големи или малки по време на обучението, което ще изведе сигналите извън правилния диапазон. Можем да върнем сигналите обратно, като използваме една от техниките за **нормализация**. Въпреки че има няколко такива (нормализация на тегла, нормализация на слоеве), най-често използваната е нормализация на партиди.

Идеята на **нормализацията на партиди** е да се вземат предвид всички стойности в минипартидата и да се извърши нормализация (т.е. изваждане на средната стойност и делене на стандартното отклонение) въз основа на тези стойности. Тя се реализира като слой в мрежата, който извършва тази нормализация след прилагането на теглата, но преди функцията за активация. В резултат, вероятно ще видим по-висока крайна точност и по-бързо обучение.

Ето [оригиналната статия](https://arxiv.org/pdf/1502.03167.pdf) за нормализация на партиди, [обяснението в Wikipedia](https://en.wikipedia.org/wiki/Batch_normalization), и [добър въвеждащ блог пост](https://towardsdatascience.com/batch-normalization-in-3-levels-of-understanding-14c2da90a338) (и един [на руски](https://habrahabr.ru/post/309302/)).

## Dropout

**Dropout** е интересна техника, която премахва определен процент от случайни неврони по време на обучението. Тя също се реализира като слой с един параметър (процентът на невроните, които да се премахнат, обикновено 10%-50%), и по време на обучението занулява случайни елементи от входния вектор, преди да го предаде на следващия слой.

Въпреки че това може да звучи като странна идея, можете да видите ефекта от dropout върху обучението на класификатор за цифри MNIST в [`Dropout.ipynb`](../../../../../lessons/4-ComputerVision/08-TransferLearning/Dropout.ipynb) тетрадка. Тя ускорява обучението и ни позволява да постигнем по-висока точност за по-малко епохи.

Този ефект може да се обясни по няколко начина:

 * Може да се разглежда като случаен шоков фактор за модела, който го извежда от локалния минимум
 * Може да се разглежда като *имплицитно усредняване на модела*, защото можем да кажем, че по време на dropout обучаваме леко различен модел

> *Някои хора казват, че когато пиян човек се опитва да научи нещо, той ще го запомни по-добре на следващата сутрин, в сравнение с трезвен човек, защото мозъкът с някои нефункциониращи неврони се опитва по-добре да схване смисъла. Никога не сме тествали дали това е вярно.*

## Предотвратяване на пренасищане

Един от много важните аспекти на дълбокото обучение е способността да се предотврати [пренасищане](../../3-NeuralNetworks/05-Frameworks/Overfitting.md). Въпреки че може да е изкушаващо да се използва много мощен модел на невронна мрежа, винаги трябва да балансираме броя на параметрите на модела с броя на обучаващите примери.

> Уверете се, че разбирате концепцията за [пренасищане](../../3-NeuralNetworks/05-Frameworks/Overfitting.md), която въведохме по-рано!

Има няколко начина за предотвратяване на пренасищане:

 * Ранно спиране -- непрекъснато наблюдение на грешката върху валидиращия набор и спиране на обучението, когато грешката на валидиращия набор започне да се увеличава.
 * Явно разпадане на теглата / регуляризация -- добавяне на допълнителна санкция към функцията за загуба за високи абсолютни стойности на теглата, което предотвратява модела да получи много нестабилни резултати
 * Усредняване на модела -- обучение на няколко модела и след това усредняване на резултата. Това помага за минимизиране на вариацията.
 * Dropout (Имплицитно усредняване на модела)

## Оптимизатори / Алгоритми за обучение

Друг важен аспект на обучението е изборът на добър алгоритъм за обучение. Въпреки че класическият **градиентен спуск** е разумен избор, понякога може да бъде твърде бавен или да доведе до други проблеми.

В дълбокото обучение използваме **Стохастичен градиентен спуск** (SGD), който е градиентен спуск, приложен към минипартиди, случайно избрани от обучаващия набор. Теглата се коригират с тази формула:

w<sup>t+1</sup> = w<sup>t</sup> - η∇ℒ

### Моментум

При **моментум SGD**, запазваме част от градиента от предишните стъпки. Това е подобно на движението с инерция, когато получим удар в различна посока, траекторията ни не се променя веднага, а запазва част от оригиналното движение. Тук въвеждаме друг вектор v, който представлява *скоростта*:

* v<sup>t+1</sup> = γ v<sup>t</sup> - η∇ℒ
* w<sup>t+1</sup> = w<sup>t</sup>+v<sup>t+1</sup>

Тук параметърът γ показва степента, до която вземаме предвид инерцията: γ=0 съответства на класическия SGD; γ=1 е чисто уравнение за движение.

### Adam, Adagrad и др.

Тъй като във всеки слой умножаваме сигналите с някаква матрица W<sub>i</sub>, в зависимост от ||W<sub>i</sub>||, градиентът може или да намалее и да бъде близо до 0, или да нарасне безкрайно. Това е същността на проблема с експлодиращи/изчезващи градиенти.

Едно от решенията на този проблем е да използваме само посоката на градиента в уравнението и да игнорираме абсолютната стойност, т.е.

w<sup>t+1</sup> = w<sup>t</sup> - η(∇ℒ/||∇ℒ||), където ||∇ℒ|| = √∑(∇ℒ)<sup>2</sup>

Този алгоритъм се нарича **Adagrad**. Други алгоритми, които използват същата идея: **RMSProp**, **Adam**

> **Adam** се счита за много ефективен алгоритъм за много приложения, така че ако не сте сигурни кой да използвате - използвайте Adam.

### Ограничаване на градиента

Ограничаването на градиента е разширение на идеята по-горе. Когато ||∇ℒ|| ≤ θ, разглеждаме оригиналния градиент в оптимизацията на теглата, а когато ||∇ℒ|| > θ - разделяме градиента на неговата норма. Тук θ е параметър, в повечето случаи можем да вземем θ=1 или θ=10.

### Намаляване на скоростта на обучение

Успехът на обучението често зависи от параметъра за скорост на обучение η. Логично е да предположим, че по-големи стойности на η водят до по-бързо обучение, което е нещо, което обикновено искаме в началото на обучението, а след това по-малките стойности на η ни позволяват да фино настроим мрежата. Затова в повечето случаи искаме да намалим η в процеса на обучението.

Това може да се направи чрез умножаване на η с някакво число (например 0.98) след всяка епоха на обучението или чрез използване на по-сложен **график за скорост на обучение**.

## Различни архитектури на мрежи

Изборът на правилната архитектура на мрежата за вашия проблем може да бъде труден. Обикновено бихме избрали архитектура, която е доказала, че работи за нашата конкретна задача (или подобна). Ето [добър преглед](https://www.topbots.com/a-brief-history-of-neural-network-architectures/) на архитектури на невронни мрежи за компютърно зрение.

> Важно е да изберете архитектура, която ще бъде достатъчно мощна за броя на обучаващите примери, които имаме. Изборът на твърде мощен модел може да доведе до [пренасищане](../../3-NeuralNetworks/05-Frameworks/Overfitting.md).

Друг добър подход би бил да използвате архитектура, която автоматично се адаптира към необходимата сложност. До известна степен, архитектурите **ResNet** и **Inception** са самоадаптивни. [Повече за архитектури за компютърно зрение](../07-ConvNets/CNN_Architectures.md).

**Отказ от отговорност**:  
Този документ е преведен с помощта на AI услуга за превод [Co-op Translator](https://github.com/Azure/co-op-translator). Въпреки че се стремим към точност, моля, имайте предвид, че автоматизираните преводи може да съдържат грешки или неточности. Оригиналният документ на неговия роден език трябва да се счита за авторитетен източник. За критична информация се препоръчва професионален човешки превод. Ние не носим отговорност за недоразумения или погрешни интерпретации, произтичащи от използването на този превод.