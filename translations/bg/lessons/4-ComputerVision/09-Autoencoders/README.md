<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "0b306c04f5337b6e7430e5c0b16bb5c0",
  "translation_date": "2025-08-25T22:30:32+00:00",
  "source_file": "lessons/4-ComputerVision/09-Autoencoders/README.md",
  "language_code": "bg"
}
-->
# Автоенкодери

При обучението на CNNs (свързани невронни мрежи), един от проблемите е, че се нуждаем от много етикетирани данни. В случая на класификация на изображения, трябва да разделим изображенията в различни класове, което изисква ръчна работа.

## [Тест преди лекцията](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/109)

Въпреки това, може да искаме да използваме сурови (неетикетирани) данни за обучение на CNN за извличане на характеристики, което се нарича **самонаблюдавано обучение**. Вместо етикети, ще използваме тренировъчните изображения както като вход, така и като изход на мрежата. Основната идея на **автоенкодера** е, че ще имаме **енкодерна мрежа**, която преобразува входното изображение в някакво **латентно пространство** (обикновено това е вектор с по-малък размер), след което **декодерна мрежа**, чиято цел е да възстанови оригиналното изображение.

> ✅ Един [автоенкодер](https://wikipedia.org/wiki/Autoencoder) е "вид изкуствена невронна мрежа, използвана за изучаване на ефективни кодировки на неетикетирани данни."

Тъй като обучаваме автоенкодера да улавя възможно най-много информация от оригиналното изображение за точно възстановяване, мрежата се опитва да намери най-доброто **вграждане** на входните изображения, за да улови тяхното значение.

![Диаграма на Автоенкодер](../../../../../translated_images/autoencoder_schema.5e6fc9ad98a5eb6197f3513cf3baf4dfbe1389a6ae74daebda64de9f1c99f142.bg.jpg)

> Изображение от [Keras блог](https://blog.keras.io/building-autoencoders-in-keras.html)

## Сценарии за използване на автоенкодери

Докато възстановяването на оригинални изображения може да не изглежда полезно само по себе си, има няколко сценария, в които автоенкодерите са особено полезни:

* **Намаляване на размерността на изображенията за визуализация** или **обучение на вграждания на изображения**. Обикновено автоенкодерите дават по-добри резултати от PCA, защото вземат предвид пространствената природа на изображенията и йерархичните характеристики.
* **Премахване на шум**, т.е. премахване на шума от изображението. Тъй като шумът съдържа много ненужна информация, автоенкодерът не може да го побере в сравнително малкото латентно пространство и следователно улавя само важната част от изображението. При обучението на шумопремахващи мрежи започваме с оригинални изображения и използваме изображения с изкуствено добавен шум като вход за автоенкодера.
* **Суперрезолюция**, увеличаване на резолюцията на изображението. Започваме с изображения с висока резолюция и използваме изображението с по-ниска резолюция като вход за автоенкодера.
* **Генеративни модели**. След като обучим автоенкодера, декодерната част може да се използва за създаване на нови обекти, започвайки от случайни латентни вектори.

## Вариационни автоенкодери (VAE)

Традиционните автоенкодери намаляват размерността на входните данни, като идентифицират важните характеристики на входните изображения. Въпреки това, латентните вектори често нямат ясен смисъл. С други думи, ако вземем за пример набора от данни MNIST, определянето на това кои цифри съответстват на различни латентни вектори не е лесна задача, защото близките латентни вектори не е задължително да съответстват на едни и същи цифри.

От друга страна, за да обучим *генеративни* модели, е по-добре да имаме някакво разбиране за латентното пространство. Тази идея ни води до **вариационния автоенкодер** (VAE).

VAE е автоенкодер, който се учи да предсказва *статистическото разпределение* на латентните параметри, така нареченото **латентно разпределение**. Например, може да искаме латентните вектори да бъдат разпределени нормално с някаква средна стойност z<sub>mean</sub> и стандартно отклонение z<sub>sigma</sub> (и средната стойност, и стандартното отклонение са вектори с някаква размерност d). Енкодерът във VAE се учи да предсказва тези параметри, а декодерът взема случаен вектор от това разпределение, за да възстанови обекта.

В обобщение:

 * От входния вектор предсказваме `z_mean` и `z_log_sigma` (вместо да предсказваме стандартното отклонение директно, предсказваме неговия логаритъм)
 * Извличаме вектор `sample` от разпределението N(z<sub>mean</sub>,exp(z<sub>log\_sigma</sub>))
 * Декодерът се опитва да декодира оригиналното изображение, използвайки `sample` като входен вектор

 <img src="images/vae.png" width="50%">

> Изображение от [тази публикация](https://ijdykeman.github.io/ml/2016/12/21/cvae.html) на Исак Дайкман

Вариационните автоенкодери използват сложна функция за загуба, която се състои от две части:

* **Загуба от възстановяване** е функцията за загуба, която показва колко близко е възстановеното изображение до целевото (може да бъде Mean Squared Error или MSE). Това е същата функция за загуба като при нормалните автоенкодери.
* **KL загуба**, която гарантира, че разпределението на латентните променливи остава близко до нормалното разпределение. Тя се основава на понятието за [дивергенция на Кълбак-Лайблер](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained) - метрика за оценка на сходството между две статистически разпределения.

Едно важно предимство на VAE е, че те ни позволяват да генерираме нови изображения сравнително лесно, защото знаем от кое разпределение да извличаме латентни вектори. Например, ако обучим VAE с 2D латентен вектор върху MNIST, можем след това да променяме компонентите на латентния вектор, за да получим различни цифри:

<img alt="vaemnist" src="images/vaemnist.png" width="50%"/>

> Изображение от [Дмитрий Сошников](http://soshnikov.com)

Наблюдавайте как изображенията се преливат едно в друго, когато започнем да извличаме латентни вектори от различни части на латентното пространство. Можем също така да визуализираме това пространство в 2D:

<img alt="vaemnist cluster" src="images/vaemnist-diag.png" width="50%"/> 

> Изображение от [Дмитрий Сошников](http://soshnikov.com)

## ✍️ Упражнения: Автоенкодери

Научете повече за автоенкодерите в следните тетрадки:

* [Автоенкодери в TensorFlow](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb)
* [Автоенкодери в PyTorch](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoEncodersPyTorch.ipynb)

## Свойства на автоенкодерите

* **Специфични за данните** - те работят добре само с типа изображения, върху които са били обучени. Например, ако обучим мрежа за суперрезолюция върху цветя, тя няма да работи добре върху портрети. Това е така, защото мрежата може да създаде изображение с по-висока резолюция, като използва фините детайли от характеристиките, научени от тренировъчния набор от данни.
* **Със загуби** - възстановеното изображение не е същото като оригиналното. Характерът на загубата се определя от *функцията за загуба*, използвана по време на обучението.
* Работят с **неетикетирани данни**

## [Тест след лекцията](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/209)

## Заключение

В този урок научихте за различните видове автоенкодери, достъпни за AI учените. Научихте как да ги изграждате и как да ги използвате за възстановяване на изображения. Също така научихте за VAE и как да ги използвате за генериране на нови изображения.

## 🚀 Предизвикателство

В този урок научихте за използването на автоенкодери за изображения. Но те могат да се използват и за музика! Разгледайте проекта Magenta [MusicVAE](https://magenta.tensorflow.org/music-vae), който използва автоенкодери за изучаване на възстановяването на музика. Направете някои [експерименти](https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/Multitrack_MusicVAE.ipynb) с тази библиотека, за да видите какво можете да създадете.

## [Тест след лекцията](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/208)

## Преглед и самостоятелно обучение

За справка, прочетете повече за автоенкодерите в следните ресурси:

* [Изграждане на автоенкодери в Keras](https://blog.keras.io/building-autoencoders-in-keras.html)
* [Публикация в блога на NeuroHive](https://neurohive.io/ru/osnovy-data-science/variacionnyj-avtojenkoder-vae/)
* [Обяснение на вариационните автоенкодери](https://kvfrans.com/variational-autoencoders-explained/)
* [Условни вариационни автоенкодери](https://ijdykeman.github.io/ml/2016/12/21/cvae.html)

## Задача

В края на [тази тетрадка с TensorFlow](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb) ще намерите 'задача' - използвайте я като ваше домашно.

**Отказ от отговорност**:  
Този документ е преведен с помощта на AI услуга за превод [Co-op Translator](https://github.com/Azure/co-op-translator). Въпреки че се стремим към точност, моля, имайте предвид, че автоматизираните преводи може да съдържат грешки или неточности. Оригиналният документ на неговия роден език трябва да се счита за авторитетен източник. За критична информация се препоръчва професионален човешки превод. Не носим отговорност за недоразумения или погрешни интерпретации, произтичащи от използването на този превод.