{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generatyviniai tinklai\n",
    "\n",
    "Pasikartojantys neuroniniai tinklai (RNN) ir jų užtvarų ląstelių variantai, tokie kaip ilgos trumpos atminties ląstelės (LSTM) ir užtvarų pasikartojančios vienetai (GRU), suteikė mechanizmą kalbos modeliavimui, t. y. jie gali išmokti žodžių tvarką ir pateikti prognozes apie kitą žodį sekoje. Tai leidžia mums naudoti RNN **generatyvinėms užduotims**, tokioms kaip įprastas teksto generavimas, mašininis vertimas ir net vaizdų aprašymas.\n",
    "\n",
    "RNN architektūroje, kurią aptarėme ankstesniame skyriuje, kiekvienas RNN vienetas generavo kitą paslėptą būseną kaip išvestį. Tačiau mes taip pat galime pridėti kitą išvestį prie kiekvieno pasikartojančio vieneto, kuris leistų mums generuoti **seką** (kuri yra tokio pat ilgio kaip pradinė seka). Be to, galime naudoti RNN vienetus, kurie kiekviename žingsnyje nepriima įvesties, o tiesiog naudoja pradinį būsenos vektorių ir tada generuoja išvesties seką.\n",
    "\n",
    "Šiame užrašų knygelėje mes sutelksime dėmesį į paprastus generatyvinius modelius, kurie padeda mums generuoti tekstą. Paprastumo dėlei sukurkime **simbolių lygmens tinklą**, kuris generuoja tekstą raidė po raidės. Mokymo metu mums reikia paimti tam tikrą teksto korpusą ir padalyti jį į raidžių sekas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Building vocab...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "import numpy as np\n",
    "from torchnlp import *\n",
    "train_dataset,test_dataset,classes,vocab = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charakterių žodyno kūrimas\n",
    "\n",
    "Norint sukurti generatyvinį tinklą, veikiantį simbolių lygiu, tekstą reikia suskaidyti į atskirus simbolius, o ne žodžius. Tai galima padaryti apibrėžiant kitokį žodyną:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size = 82\n",
      "Encoding of 'a' is 1\n",
      "Character with code 13 is c\n"
     ]
    }
   ],
   "source": [
    "def char_tokenizer(words):\n",
    "    return list(words) #[word for word in words]\n",
    "\n",
    "counter = collections.Counter()\n",
    "for (label, line) in train_dataset:\n",
    "    counter.update(char_tokenizer(line))\n",
    "vocab = torchtext.vocab.vocab(counter)\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "print(f\"Vocabulary size = {vocab_size}\")\n",
    "print(f\"Encoding of 'a' is {vocab.get_stoi()['a']}\")\n",
    "print(f\"Character with code 13 is {vocab.get_itos()[13]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pažiūrėkime pavyzdį, kaip galime užkoduoti tekstą iš mūsų duomenų rinkinio:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  2,  3,  4,  5,  6,  3,  7,  8,  1,  9, 10,  3, 11,  2,  1,\n",
       "        12,  3,  7,  1, 13, 14,  3, 15, 16,  5, 17,  3,  5, 18,  8,  3,  7,  2,\n",
       "         1, 13, 14,  3, 19, 20,  8, 21,  5,  8,  9, 10, 22,  3, 20,  8, 21,  5,\n",
       "         8,  9, 10,  3, 23,  3,  4, 18, 17,  9,  5, 23, 10,  8,  2,  2,  8,  9,\n",
       "        10, 24,  3,  0,  1,  2,  2,  3,  4,  5,  9,  8,  8,  5, 25, 10,  3, 26,\n",
       "        12, 27, 16, 26,  2, 27, 16, 28, 29, 30,  1, 16, 26,  3, 17, 31,  3, 21,\n",
       "         2,  5,  9,  1, 23, 13, 32, 16, 27, 13, 10, 24,  3,  1,  9,  8,  3, 10,\n",
       "         8,  8, 27, 16, 28,  3, 28,  9,  8,  8, 16,  3,  1, 28,  1, 27, 16,  6])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def enc(x):\n",
    "    return torch.LongTensor(encode(x,voc=vocab,tokenizer=char_tokenizer))\n",
    "\n",
    "enc(train_dataset[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generatyvios RNN mokymas\n",
    "\n",
    "RNN mokysime generuoti tekstą tokiu būdu. Kiekviename žingsnyje imsime simbolių seką, kurios ilgis yra `nchars`, ir paprašysime tinklo sugeneruoti kitą išvesties simbolį kiekvienam įvesties simboliui:\n",
    "\n",
    "![Paveikslėlis, rodantis RNN generavimo pavyzdį su žodžiu 'HELLO'.](../../../../../lessons/5-NLP/17-GenerativeNetworks/images/rnn-generate.png)\n",
    "\n",
    "Priklausomai nuo konkretaus scenarijaus, galime norėti įtraukti specialius simbolius, tokius kaip *sekos pabaiga* `<eos>`. Mūsų atveju, mes tiesiog norime išmokyti tinklą generuoti begalinį tekstą, todėl kiekvienos sekos dydį nustatysime kaip `nchars` simbolių. Taigi, kiekvienas mokymo pavyzdys susidarys iš `nchars` įvesties ir `nchars` išvesties (kurios yra įvesties seka, paslinkta vienu simboliu į kairę). Minipartija susidarys iš kelių tokių sekų.\n",
    "\n",
    "Minipartijas generuosime taip: imsime kiekvieną naujienų tekstą, kurio ilgis yra `l`, ir iš jo sukursime visas galimas įvesties-išvesties kombinacijas (jų bus `l-nchars`). Jos sudarys vieną minipartiją, o minipartijų dydis kiekviename mokymo žingsnyje bus skirtingas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  1,  2,  ..., 28, 29, 30],\n",
       "         [ 1,  2,  2,  ..., 29, 30,  1],\n",
       "         [ 2,  2,  3,  ..., 30,  1, 16],\n",
       "         ...,\n",
       "         [20,  8, 21,  ...,  1, 28,  1],\n",
       "         [ 8, 21,  5,  ..., 28,  1, 27],\n",
       "         [21,  5,  8,  ...,  1, 27, 16]]),\n",
       " tensor([[ 1,  2,  2,  ..., 29, 30,  1],\n",
       "         [ 2,  2,  3,  ..., 30,  1, 16],\n",
       "         [ 2,  3,  4,  ...,  1, 16, 26],\n",
       "         ...,\n",
       "         [ 8, 21,  5,  ..., 28,  1, 27],\n",
       "         [21,  5,  8,  ...,  1, 27, 16],\n",
       "         [ 5,  8,  9,  ..., 27, 16,  6]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nchars = 100\n",
    "\n",
    "def get_batch(s,nchars=nchars):\n",
    "    ins = torch.zeros(len(s)-nchars,nchars,dtype=torch.long,device=device)\n",
    "    outs = torch.zeros(len(s)-nchars,nchars,dtype=torch.long,device=device)\n",
    "    for i in range(len(s)-nchars):\n",
    "        ins[i] = enc(s[i:i+nchars])\n",
    "        outs[i] = enc(s[i+1:i+nchars+1])\n",
    "    return ins,outs\n",
    "\n",
    "get_batch(train_dataset[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dabar apibrėžkime generatoriaus tinklą. Jis gali būti pagrįstas bet kuria pasikartojančia ląstele, kurią aptarėme ankstesniame skyriuje (paprasta, LSTM arba GRU). Mūsų pavyzdyje naudosime LSTM.\n",
    "\n",
    "Kadangi tinklas kaip įvestį naudoja simbolius, o žodyno dydis yra gana mažas, mums nereikia įterpimo sluoksnio – vieno karšto kodavimo įvestis gali tiesiogiai pereiti į LSTM ląstelę. Tačiau, kadangi kaip įvestį perduodame simbolių numerius, prieš perduodant juos į LSTM, turime juos užkoduoti vieno karšto kodavimu. Tai atliekama kviečiant funkciją `one_hot` vykdymo metu (`forward` pass). Išvesties koduotojas bus linijinis sluoksnis, kuris paslėptą būseną pavers vieno karšto kodavimo išvestimi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMGenerator(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.rnn = torch.nn.LSTM(vocab_size,hidden_dim,batch_first=True)\n",
    "        self.fc = torch.nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, s=None):\n",
    "        x = torch.nn.functional.one_hot(x,vocab_size).to(torch.float32)\n",
    "        x,s = self.rnn(x,s)\n",
    "        return self.fc(x),s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mokymosi metu norime turėti galimybę generuoti tekstą. Tam apibrėšime funkciją `generate`, kuri sukurs išvesties eilutę, kurios ilgis yra `size`, pradedant nuo pradinės eilutės `start`.\n",
    "\n",
    "Štai kaip tai veikia. Pirmiausia, visą pradinę eilutę perduosime per tinklą, gausime išvesties būseną `s` ir kitą numatomą simbolį `out`. Kadangi `out` yra vieno karšto kodavimo (one-hot encoded) formatu, naudojame `argmax`, kad gautume simbolio `nc` indeksą žodyne, o tada naudojame `itos`, kad nustatytume tikrąjį simbolį ir pridėtume jį prie rezultatų simbolių sąrašo `chars`. Šis simbolio generavimo procesas kartojamas `size` kartų, kad būtų sugeneruotas reikiamas simbolių skaičius.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(net,size=100,start='today '):\n",
    "        chars = list(start)\n",
    "        out, s = net(enc(chars).view(1,-1).to(device))\n",
    "        for i in range(size):\n",
    "            nc = torch.argmax(out[0][-1])\n",
    "            chars.append(vocab.get_itos()[nc])\n",
    "            out, s = net(nc.view(1,-1),s)\n",
    "        return ''.join(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dabar pradėkime mokymą! Mokymo ciklas beveik toks pat kaip ir visuose ankstesniuose pavyzdžiuose, tačiau vietoj tikslumo kas 1000 epochų spausdiname sugeneruotą tekstą.\n",
    "\n",
    "Ypatingą dėmesį reikia skirti tam, kaip apskaičiuojame nuostolį. Turime apskaičiuoti nuostolį, turėdami vieno karšto kodavimo išvestį `out` ir tikėtiną tekstą `text_out`, kuris yra simbolių indeksų sąrašas. Laimei, `cross_entropy` funkcija tikisi neapdorotos tinklo išvesties kaip pirmo argumento ir klasės numerio kaip antro, kas būtent ir atitinka mūsų situaciją. Ji taip pat automatiškai atlieka vidurkinimą pagal mini partijos dydį.\n",
    "\n",
    "Taip pat apribojame mokymą iki `samples_to_train` pavyzdžių, kad nereikėtų per ilgai laukti. Skatiname jus eksperimentuoti ir bandyti ilgesnį mokymą, galbūt kelias epochas (tokiu atveju reikėtų sukurti dar vieną ciklą aplink šį kodą).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss = 4.398899078369141\n",
      "today sr sr sr sr sr sr sr sr sr sr sr sr sr sr sr sr sr sr sr sr sr sr sr sr sr sr sr sr sr sr sr sr sr s\n",
      "Current loss = 2.161320447921753\n",
      "today and to the tor to to the tor to to the tor to to the tor to to the tor to to the tor to to the tor t\n",
      "Current loss = 1.6722588539123535\n",
      "today and the court to the could to the could to the could to the could to the could to the could to the c\n",
      "Current loss = 2.423795223236084\n",
      "today and a second to the conternation of the conternation of the conternation of the conternation of the \n",
      "Current loss = 1.702607274055481\n",
      "today and the company to the company to the company to the company to the company to the company to the co\n",
      "Current loss = 1.692358136177063\n",
      "today and the company to the company to the company to the company to the company to the company to the co\n",
      "Current loss = 1.9722288846969604\n",
      "today and the control the control the control the control the control the control the control the control \n",
      "Current loss = 1.8705692291259766\n",
      "today and the second to the second to the second to the second to the second to the second to the second t\n",
      "Current loss = 1.7626899480819702\n",
      "today and a security and a security and a security and a security and a security and a security and a secu\n",
      "Current loss = 1.5574463605880737\n",
      "today and the company and the company and the company and the company and the company and the company and \n",
      "Current loss = 1.5620026588439941\n",
      "today and the be that the be the be that the be the be that the be the be that the be the be that the be t\n"
     ]
    }
   ],
   "source": [
    "net = LSTMGenerator(vocab_size,64).to(device)\n",
    "\n",
    "samples_to_train = 10000\n",
    "optimizer = torch.optim.Adam(net.parameters(),0.01)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "net.train()\n",
    "for i,x in enumerate(train_dataset):\n",
    "    # x[0] is class label, x[1] is text\n",
    "    if len(x[1])-nchars<10:\n",
    "        continue\n",
    "    samples_to_train-=1\n",
    "    if not samples_to_train: break\n",
    "    text_in, text_out = get_batch(x[1])\n",
    "    optimizer.zero_grad()\n",
    "    out,s = net(text_in)\n",
    "    loss = torch.nn.functional.cross_entropy(out.view(-1,vocab_size),text_out.flatten()) #cross_entropy(out,labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i%1000==0:\n",
    "        print(f\"Current loss = {loss.item()}\")\n",
    "        print(generate(net))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Šis pavyzdys jau generuoja gana gerą tekstą, tačiau jį galima dar labiau patobulinti keliais būdais:\n",
    "\n",
    "* **Geresnė minibatch generacija**. Duomenų paruošimas mokymui buvo atliekamas generuojant vieną minibatch iš vieno pavyzdžio. Tai nėra idealu, nes minibatch dydžiai yra skirtingi, o kai kurie jų net negali būti sugeneruoti, nes tekstas yra trumpesnis nei `nchars`. Be to, maži minibatch nepakankamai apkrauna GPU. Protingiau būtų paimti didelį teksto fragmentą iš visų pavyzdžių, tada sugeneruoti visas įvesties-išvesties poras, jas sumaišyti ir sukurti vienodo dydžio minibatch.\n",
    "\n",
    "* **Daugiasluoksnis LSTM**. Verta išbandyti 2 ar 3 LSTM ląstelių sluoksnius. Kaip minėjome ankstesniame skyriuje, kiekvienas LSTM sluoksnis iš tekstų išskiria tam tikrus modelius, o simbolių lygio generatoriaus atveju galima tikėtis, kad žemesnis LSTM lygis bus atsakingas už skiemenų išskyrimą, o aukštesni lygiai - už žodžius ir jų kombinacijas. Tai galima paprastai įgyvendinti perduodant sluoksnių skaičiaus parametrą LSTM konstruktoriui.\n",
    "\n",
    "* Taip pat galite eksperimentuoti su **GRU vienetais** ir patikrinti, kurie veikia geriau, bei su **skirtingais paslėpto sluoksnio dydžiais**. Per didelis paslėpto sluoksnio dydis gali sukelti per didelį pritaikymą (pvz., tinklas išmoks tikslų tekstą), o per mažas dydis gali neduoti gero rezultato.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minkštas teksto generavimas ir temperatūra\n",
    "\n",
    "Ankstesnėje `generate` funkcijos apibrėžtyje mes visada pasirinkdavome simbolį su didžiausia tikimybe kaip kitą simbolį generuojamame tekste. Tai dažnai lėmė, kad tekstas \"kartodavosi\" tarp tų pačių simbolių sekų vėl ir vėl, kaip šiame pavyzdyje:\n",
    "```\n",
    "today of the second the company and a second the company ...\n",
    "```\n",
    "\n",
    "Tačiau, jei pažvelgsime į tikimybių pasiskirstymą kitam simboliui, gali būti, kad skirtumas tarp kelių didžiausių tikimybių nėra didelis, pvz., vienas simbolis gali turėti tikimybę 0.2, o kitas - 0.19 ir pan. Pavyzdžiui, ieškant kito simbolio sekoje '*play*', kitas simbolis gali būti tiek tarpas, tiek **e** (kaip žodyje *player*).\n",
    "\n",
    "Tai leidžia daryti išvadą, kad ne visada yra \"teisinga\" pasirinkti simbolį su didžiausia tikimybe, nes pasirinkus antrą pagal dydį tikimybę vis tiek galime gauti prasmingą tekstą. Protingiau yra **imti mėginius** iš tikimybių pasiskirstymo, kurį pateikia tinklo išvestis.\n",
    "\n",
    "Šis mėginių ėmimas gali būti atliekamas naudojant `multinomial` funkciją, kuri įgyvendina vadinamąjį **multinominį pasiskirstymą**. Funkcija, kuri įgyvendina šį **minkštą** teksto generavimą, apibrėžta žemiau:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Temperature = 0.3\n",
      "Today and a company and complete an all the land the restrational the as a security and has provers the pay to and a report and the computer in the stand has filities and working the law the stations for a company and with the company and the final the first company and refight of the state and and workin\n",
      "\n",
      "--- Temperature = 0.8\n",
      "Today he oniis its first to Aus bomblaties the marmation a to manan  boogot that pirate assaid a relaid their that goverfin the the Cappets Ecrotional Assonia Cition targets it annight the w scyments Blamity #39;s TVeer Diercheg Reserals fran envyuil that of ster said access what succers of Dour-provelith\n",
      "\n",
      "--- Temperature = 1.0\n",
      "Today holy they a 11 will meda a toket subsuaties, engins for Chanos, they's has stainger past to opening orital his thempting new Nattona was al innerforder advan-than #36;s night year his religuled talitatian what the but with Wednesday to Justment will wemen of Mark CCC Camp as Timed Nae wome a leaders\n",
      "\n",
      "--- Temperature = 1.3\n",
      "Today gpone 2.5 fech atcusion poor cocles toparsdorM.cht Line Pamage put 43 his calt lowed to the book, that has authh-the silia rruch ailing to'ory andhes beutirsimi- Aefffive heading offil an auf eacklets is charged evis, Gunymy oy) Mony has it after-sloythyor loveId out filme, the Natabl -Najuntaxiggs \n",
      "\n",
      "--- Temperature = 1.8\n",
      "Today plary, P.slan chly\\401 mardregationly #39;t 8.1Mide) closes ,filtcon alfly playin roven!\\grea.-QFBEP: Iss onfarchQ/itilia CCf Zivesigntwasta orce.-Peul-aw.uicrin of fuglinfsut aftaningwo, MIEX awayew Aice Woiduar Corvagiugge oppo esig ThusBratourid canthly-RyI.co lagitems\\eexciaishes.conBabntusmor I\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_soft(net,size=100,start='today ',temperature=1.0):\n",
    "        chars = list(start)\n",
    "        out, s = net(enc(chars).view(1,-1).to(device))\n",
    "        for i in range(size):\n",
    "            #nc = torch.argmax(out[0][-1])\n",
    "            out_dist = out[0][-1].div(temperature).exp()\n",
    "            nc = torch.multinomial(out_dist,1)[0]\n",
    "            chars.append(vocab.get_itos()[nc])\n",
    "            out, s = net(nc.view(1,-1),s)\n",
    "        return ''.join(chars)\n",
    "    \n",
    "for i in [0.3,0.8,1.0,1.3,1.8]:\n",
    "    print(f\"--- Temperature = {i}\\n{generate_soft(net,size=300,start='Today ',temperature=i)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mes pristatėme dar vieną parametrą, vadinamą **temperatūra**, kuris naudojamas nurodyti, kaip stipriai turėtume laikytis didžiausios tikimybės. Jei temperatūra yra 1.0, atliekame sąžiningą multinominį mėginių ėmimą, o kai temperatūra pasiekia begalybę - visos tikimybės tampa lygios, ir mes atsitiktinai pasirenkame kitą simbolį. Žemiau pateiktame pavyzdyje galime pastebėti, kad tekstas tampa beprasmiškas, kai temperatūra per daug padidėja, ir primena „ciklinį“ sunkiai generuojamą tekstą, kai ji artėja prie 0.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Atsakomybės apribojimas**:  \nŠis dokumentas buvo išverstas naudojant AI vertimo paslaugą [Co-op Translator](https://github.com/Azure/co-op-translator). Nors siekiame tikslumo, prašome atkreipti dėmesį, kad automatiniai vertimai gali turėti klaidų ar netikslumų. Originalus dokumentas jo gimtąja kalba turėtų būti laikomas autoritetingu šaltiniu. Kritinei informacijai rekomenduojama naudoti profesionalų žmogaus vertimą. Mes neprisiimame atsakomybės už nesusipratimus ar klaidingus interpretavimus, atsiradusius dėl šio vertimo naudojimo.\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16af2a8bbb083ea23e5e41c7f5787656b2ce26968575d8763f2c4b17f9cd711f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "coopTranslator": {
   "original_hash": "7673cd150d96c74c6d6011460094efb4",
   "translation_date": "2025-08-31T13:44:35+00:00",
   "source_file": "lessons/5-NLP/17-GenerativeNetworks/GenerativePyTorch.ipynb",
   "language_code": "lt"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}