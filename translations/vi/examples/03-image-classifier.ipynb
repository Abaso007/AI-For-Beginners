{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B·ªô ph√¢n lo·∫°i h√¨nh ·∫£nh ƒë∆°n gi·∫£n\n",
    "\n",
    "Notebook n√†y h∆∞·ªõng d·∫´n b·∫°n c√°ch ph√¢n lo·∫°i h√¨nh ·∫£nh b·∫±ng c√°ch s·ª≠ d·ª•ng m·ªôt m·∫°ng n∆°-ron ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán tr∆∞·ªõc.\n",
    "\n",
    "**Nh·ªØng g√¨ b·∫°n s·∫Ω h·ªçc:**\n",
    "- C√°ch t·∫£i v√† s·ª≠ d·ª•ng m·ªôt m√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán tr∆∞·ªõc\n",
    "- Ti·ªÅn x·ª≠ l√Ω h√¨nh ·∫£nh\n",
    "- D·ª± ƒëo√°n tr√™n h√¨nh ·∫£nh\n",
    "- Hi·ªÉu v·ªÅ ƒëi·ªÉm s·ªë ƒë·ªô tin c·∫≠y\n",
    "\n",
    "**Tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng:** Nh·∫≠n di·ªán c√°c ƒë·ªëi t∆∞·ª£ng trong h√¨nh ·∫£nh (nh∆∞ \"m√®o\", \"ch√≥\", \"xe h∆°i\", v.v.)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B∆∞·ªõc 1: Nh·∫≠p c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
    "\n",
    "H√£y nh·∫≠p c√°c c√¥ng c·ª• m√† ch√∫ng ta c·∫ßn. ƒê·ª´ng lo l·∫Øng n·∫øu b·∫°n ch∆∞a hi·ªÉu h·∫øt t·∫•t c·∫£ nh·ªØng ƒëi·ªÅu n√†y!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# TensorFlow for deep learning\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.applications import MobileNetV2\n",
    "    from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, decode_predictions\n",
    "    print(\"‚úÖ TensorFlow loaded successfully!\")\n",
    "    print(f\"   Version: {tf.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå Please install TensorFlow: pip install tensorflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B∆∞·ªõc 2: T·∫£i m√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán tr∆∞·ªõc\n",
    "\n",
    "Ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng **MobileNetV2**, m·ªôt m·∫°ng n∆°-ron ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán tr√™n h√†ng tri·ªáu h√¨nh ·∫£nh.\n",
    "\n",
    "ƒê√¢y ƒë∆∞·ª£c g·ªçi l√† **H·ªçc chuy·ªÉn giao** - s·ª≠ d·ª•ng m·ªôt m√¥ h√¨nh m√† ng∆∞·ªùi kh√°c ƒë√£ hu·∫•n luy·ªán!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üì¶ Loading pre-trained MobileNetV2 model...\")\n",
    "print(\"   This may take a minute on first run (downloading weights)...\")\n",
    "\n",
    "# Load the model\n",
    "# include_top=True means we use the classification layer\n",
    "# weights='imagenet' means it was trained on ImageNet dataset\n",
    "model = MobileNetV2(weights='imagenet', include_top=True)\n",
    "\n",
    "print(\"‚úÖ Model loaded!\")\n",
    "print(f\"   The model can recognize 1000 different object categories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B∆∞·ªõc 3: C√°c H√†m H·ªó Tr·ª£\n",
    "\n",
    "H√£y t·∫°o c√°c h√†m ƒë·ªÉ t·∫£i v√† chu·∫©n b·ªã h√¨nh ·∫£nh cho m√¥ h√¨nh c·ªßa ch√∫ng ta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_from_url(url):\n",
    "    \"\"\"\n",
    "    Load an image from a URL.\n",
    "    \n",
    "    Args:\n",
    "        url: Web address of the image\n",
    "        \n",
    "    Returns:\n",
    "        PIL Image object\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    return img\n",
    "\n",
    "\n",
    "def prepare_image(img):\n",
    "    \"\"\"\n",
    "    Prepare an image for the model.\n",
    "    \n",
    "    Steps:\n",
    "    1. Resize to 224x224 (model's expected size)\n",
    "    2. Convert to array\n",
    "    3. Add batch dimension\n",
    "    4. Preprocess for MobileNetV2\n",
    "    \n",
    "    Args:\n",
    "        img: PIL Image\n",
    "        \n",
    "    Returns:\n",
    "        Preprocessed image array\n",
    "    \"\"\"\n",
    "    # Resize to 224x224 pixels\n",
    "    img = img.resize((224, 224))\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    img_array = np.array(img)\n",
    "    \n",
    "    # Add batch dimension (model expects multiple images)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    # Preprocess for MobileNetV2\n",
    "    img_array = preprocess_input(img_array)\n",
    "    \n",
    "    return img_array\n",
    "\n",
    "\n",
    "def classify_image(img):\n",
    "    \"\"\"\n",
    "    Classify an image and return top predictions.\n",
    "    \n",
    "    Args:\n",
    "        img: PIL Image\n",
    "        \n",
    "    Returns:\n",
    "        List of (class_name, confidence) tuples\n",
    "    \"\"\"\n",
    "    # Prepare the image\n",
    "    img_array = prepare_image(img)\n",
    "    \n",
    "    # Make prediction\n",
    "    predictions = model.predict(img_array, verbose=0)\n",
    "    \n",
    "    # Decode predictions to human-readable labels\n",
    "    # top=5 means we get the top 5 most likely classes\n",
    "    decoded = decode_predictions(predictions, top=5)[0]\n",
    "    \n",
    "    # Convert to simpler format\n",
    "    results = [(label, float(confidence)) for (_, label, confidence) in decoded]\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"‚úÖ Helper functions ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B∆∞·ªõc 4: Ki·ªÉm tra tr√™n c√°c h√¨nh ·∫£nh m·∫´u\n",
    "\n",
    "H√£y th·ª≠ ph√¢n lo·∫°i m·ªôt s·ªë h√¨nh ·∫£nh t·ª´ internet!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample images to classify\n",
    "# These are from Unsplash (free stock photos)\n",
    "test_images = [\n",
    "    {\n",
    "        \"url\": \"https://images.unsplash.com/photo-1514888286974-6c03e2ca1dba?w=400\",\n",
    "        \"description\": \"A cat\"\n",
    "    },\n",
    "    {\n",
    "        \"url\": \"https://images.unsplash.com/photo-1552053831-71594a27632d?w=400\",\n",
    "        \"description\": \"A dog\"\n",
    "    },\n",
    "    {\n",
    "        \"url\": \"https://images.unsplash.com/photo-1511919884226-fd3cad34687c?w=400\",\n",
    "        \"description\": \"A car\"\n",
    "    },\n",
    "]\n",
    "\n",
    "print(f\"üß™ Testing on {len(test_images)} images...\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ph√¢n lo·∫°i M·ªói H√¨nh ·∫£nh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, img_data in enumerate(test_images, 1):\n",
    "    print(f\"\\nüì∏ Image {i}: {img_data['description']}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    try:\n",
    "        # Load image\n",
    "        img = load_image_from_url(img_data['url'])\n",
    "        \n",
    "        # Display image\n",
    "        display(img.resize((200, 200)))  # Show smaller version\n",
    "        \n",
    "        # Classify\n",
    "        results = classify_image(img)\n",
    "        \n",
    "        # Show predictions\n",
    "        print(\"\\nüéØ Top 5 Predictions:\")\n",
    "        for rank, (label, confidence) in enumerate(results, 1):\n",
    "            # Create a visual bar\n",
    "            bar_length = int(confidence * 50)\n",
    "            bar = \"‚ñà\" * bar_length\n",
    "            \n",
    "            print(f\"  {rank}. {label:20s} {confidence*100:5.2f}% {bar}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B∆∞·ªõc 5: Th·ª≠ v·ªõi h√¨nh ·∫£nh c·ªßa b·∫°n!\n",
    "\n",
    "Thay th·∫ø URL b√™n d∆∞·ªõi b·∫±ng b·∫•t k·ª≥ URL h√¨nh ·∫£nh n√†o b·∫°n mu·ªën ph√¢n lo·∫°i.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try your own image!\n",
    "# Replace this URL with any image URL\n",
    "custom_image_url = \"https://images.unsplash.com/photo-1472491235688-bdc81a63246e?w=400\"  # A flower\n",
    "\n",
    "print(\"üñºÔ∏è  Classifying your custom image...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    # Load and show image\n",
    "    img = load_image_from_url(custom_image_url)\n",
    "    display(img.resize((300, 300)))\n",
    "    \n",
    "    # Classify\n",
    "    results = classify_image(img)\n",
    "    \n",
    "    # Show results\n",
    "    print(\"\\nüéØ Top 5 Predictions:\")\n",
    "    print(\"-\" * 70)\n",
    "    for rank, (label, confidence) in enumerate(results, 1):\n",
    "        bar_length = int(confidence * 50)\n",
    "        bar = \"‚ñà\" * bar_length\n",
    "        print(f\"  {rank}. {label:20s} {confidence*100:5.2f}% {bar}\")\n",
    "    \n",
    "    # Highlight top prediction\n",
    "    top_label, top_confidence = results[0]\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"\\nüèÜ Best guess: {top_label} ({top_confidence*100:.2f}% confident)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    print(\"   Make sure the URL points to a valid image!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° ƒêi·ªÅu G√¨ V·ª´a X·∫£y Ra?\n",
    "\n",
    "1. **Ch√∫ng ta ƒë√£ t·∫£i m·ªôt m√¥ h√¨nh ƒë∆∞·ª£c hu·∫•n luy·ªán tr∆∞·ªõc** - MobileNetV2 ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán tr√™n h√†ng tri·ªáu h√¨nh ·∫£nh\n",
    "2. **Ch√∫ng ta ƒë√£ ti·ªÅn x·ª≠ l√Ω h√¨nh ·∫£nh** - Thay ƒë·ªïi k√≠ch th∆∞·ªõc v√† ƒë·ªãnh d·∫°ng ch√∫ng ph√π h·ª£p v·ªõi m√¥ h√¨nh\n",
    "3. **M√¥ h√¨nh ƒë√£ ƒë∆∞a ra d·ª± ƒëo√°n** - N√≥ xu·∫•t ra x√°c su·∫•t cho 1000 l·ªõp ƒë·ªëi t∆∞·ª£ng\n",
    "4. **Ch√∫ng ta ƒë√£ gi·∫£i m√£ k·∫øt qu·∫£** - Chuy·ªÉn ƒë·ªïi c√°c con s·ªë th√†nh nh√£n d·ªÖ hi·ªÉu\n",
    "\n",
    "### Hi·ªÉu V·ªÅ ƒêi·ªÉm T·ª± Tin\n",
    "\n",
    "- **90-100%**: R·∫•t t·ª± tin (g·∫ßn nh∆∞ ch·∫Øc ch·∫Øn ƒë√∫ng)\n",
    "- **70-90%**: T·ª± tin (c√≥ th·ªÉ ƒë√∫ng)\n",
    "- **50-70%**: T∆∞∆°ng ƒë·ªëi t·ª± tin (c√≥ th·ªÉ ƒë√∫ng)\n",
    "- **D∆∞·ªõi 50%**: Kh√¥ng t·ª± tin l·∫Øm (kh√¥ng ch·∫Øc ch·∫Øn)\n",
    "\n",
    "### T·∫°i sao d·ª± ƒëo√°n c√≥ th·ªÉ sai?\n",
    "\n",
    "- **G√≥c ho·∫∑c √°nh s√°ng b·∫•t th∆∞·ªùng** - M√¥ h√¨nh ƒë∆∞·ª£c hu·∫•n luy·ªán tr√™n c√°c b·ª©c ·∫£nh th√¥ng th∆∞·ªùng\n",
    "- **Nhi·ªÅu ƒë·ªëi t∆∞·ª£ng** - M√¥ h√¨nh mong ƒë·ª£i m·ªôt ƒë·ªëi t∆∞·ª£ng ch√≠nh\n",
    "- **ƒê·ªëi t∆∞·ª£ng hi·∫øm** - M√¥ h√¨nh ch·ªâ bi·∫øt 1000 danh m·ª•c\n",
    "- **H√¨nh ·∫£nh ch·∫•t l∆∞·ª£ng th·∫•p** - H√¨nh ·∫£nh m·ªù ho·∫∑c b·ªã v·ª° pixel s·∫Ω kh√≥ h∆°n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ C√°c b∆∞·ªõc ti·∫øp theo\n",
    "\n",
    "1. **Th·ª≠ c√°c h√¨nh ·∫£nh kh√°c:**\n",
    "   - T√¨m h√¨nh ·∫£nh tr√™n [Unsplash](https://unsplash.com)\n",
    "   - Nh·∫•p chu·ªôt ph·∫£i ‚Üí \"Sao ch√©p ƒë·ªãa ch·ªâ h√¨nh ·∫£nh\" ƒë·ªÉ l·∫•y URL\n",
    "\n",
    "2. **Th·ª≠ nghi·ªám:**\n",
    "   - ƒêi·ªÅu g√¨ x·∫£y ra v·ªõi ngh·ªá thu·∫≠t tr·ª´u t∆∞·ª£ng?\n",
    "   - N√≥ c√≥ th·ªÉ nh·∫≠n di·ªán c√°c ƒë·ªëi t∆∞·ª£ng t·ª´ c√°c g√≥c ƒë·ªô kh√°c nhau kh√¥ng?\n",
    "   - N√≥ x·ª≠ l√Ω nhi·ªÅu ƒë·ªëi t∆∞·ª£ng nh∆∞ th·∫ø n√†o?\n",
    "\n",
    "3. **T√¨m hi·ªÉu th√™m:**\n",
    "   - Kh√°m ph√° [b√†i h·ªçc v·ªÅ Th·ªã gi√°c M√°y t√≠nh](../lessons/4-ComputerVision/README.md)\n",
    "   - H·ªçc c√°ch hu·∫•n luy·ªán b·ªô ph√¢n lo·∫°i h√¨nh ·∫£nh c·ªßa ri√™ng b·∫°n\n",
    "   - Hi·ªÉu c√°ch ho·∫°t ƒë·ªông c·ªßa CNNs (M·∫°ng N∆°-ron T√≠ch ch·∫≠p)\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ Ch√∫c m·ª´ng!\n",
    "\n",
    "B·∫°n v·ª´a x√¢y d·ª±ng m·ªôt b·ªô ph√¢n lo·∫°i h√¨nh ·∫£nh s·ª≠ d·ª•ng m·∫°ng n∆°-ron ti√™n ti·∫øn!\n",
    "\n",
    "K·ªπ thu·∫≠t n√†y ƒëang ƒë∆∞·ª£c ·ª©ng d·ª•ng trong:\n",
    "- Google Photos (s·∫Øp x·∫øp ·∫£nh c·ªßa b·∫°n)\n",
    "- Xe t·ª± l√°i (nh·∫≠n di·ªán ƒë·ªëi t∆∞·ª£ng)\n",
    "- Ch·∫©n ƒëo√°n y t·∫ø (ph√¢n t√≠ch h√¨nh ·∫£nh X-quang)\n",
    "- Ki·ªÉm so√°t ch·∫•t l∆∞·ª£ng (ph√°t hi·ªán l·ªói)\n",
    "\n",
    "Ti·∫øp t·ª•c kh√°m ph√° v√† h·ªçc h·ªèi nh√©! üöÄ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Tuy√™n b·ªë mi·ªÖn tr·ª´ tr√°ch nhi·ªám**:  \nT√†i li·ªáu n√†y ƒë√£ ƒë∆∞·ª£c d·ªãch b·∫±ng d·ªãch v·ª• d·ªãch thu·∫≠t AI [Co-op Translator](https://github.com/Azure/co-op-translator). M·∫∑c d√π ch√∫ng t√¥i c·ªë g·∫Øng ƒë·∫£m b·∫£o ƒë·ªô ch√≠nh x√°c, xin l∆∞u √Ω r·∫±ng c√°c b·∫£n d·ªãch t·ª± ƒë·ªông c√≥ th·ªÉ ch·ª©a l·ªói ho·∫∑c kh√¥ng ch√≠nh x√°c. T√†i li·ªáu g·ªëc b·∫±ng ng√¥n ng·ªØ b·∫£n ƒë·ªãa n√™n ƒë∆∞·ª£c coi l√† ngu·ªìn th√¥ng tin ch√≠nh th·ª©c. ƒê·ªëi v·ªõi c√°c th√¥ng tin quan tr·ªçng, khuy·∫øn ngh·ªã s·ª≠ d·ª•ng d·ªãch v·ª• d·ªãch thu·∫≠t chuy√™n nghi·ªáp b·ªüi con ng∆∞·ªùi. Ch√∫ng t√¥i kh√¥ng ch·ªãu tr√°ch nhi·ªám cho b·∫•t k·ª≥ s·ª± hi·ªÉu l·∫ßm ho·∫∑c di·ªÖn gi·∫£i sai n√†o ph√°t sinh t·ª´ vi·ªác s·ª≠ d·ª•ng b·∫£n d·ªãch n√†y.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "coopTranslator": {
   "original_hash": "1d472141d9df46b751542b3c29f88677",
   "translation_date": "2025-10-03T11:49:28+00:00",
   "source_file": "examples/03-image-classifier.ipynb",
   "language_code": "vi"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}