<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "437c988596e751072e41a5aad3fcc5d9",
  "translation_date": "2025-08-25T20:47:57+00:00",
  "source_file": "lessons/7-Ethics/README.md",
  "language_code": "sw"
}
-->
# AI ya Kimaadili na ya Kuwajibika

U karibu kumaliza kozi hii, na natumai kwamba kufikia sasa unaelewa wazi kuwa AI inategemea mbinu kadhaa za kihisabati rasmi ambazo hutuwezesha kupata uhusiano katika data na kufundisha mifano kuiga baadhi ya tabia za binadamu. Katika hatua hii ya historia, tunachukulia AI kama chombo chenye nguvu sana cha kutoa mifumo kutoka kwa data, na kutumia mifumo hiyo kutatua matatizo mapya.

## [Jaribio la kabla ya somo](https://white-water-09ec41f0f.azurestaticapps.net/quiz/5/)

Hata hivyo, katika hadithi za kisayansi mara nyingi tunaona simulizi ambapo AI inahatarisha ubinadamu. Kwa kawaida, hadithi hizo huzunguka aina fulani ya uasi wa AI, ambapo AI huamua kupingana na wanadamu. Hii inaashiria kwamba AI ina aina fulani ya hisia au inaweza kufanya maamuzi yasiyotabirika na watengenezaji wake.

Aina ya AI tuliyojifunza katika kozi hii si chochote zaidi ya hesabu kubwa za matriki. Ni chombo chenye nguvu sana cha kutusaidia kutatua matatizo yetu, na kama chombo kingine chochote chenye nguvu - kinaweza kutumika kwa madhumuni mazuri au mabaya. Muhimu zaidi, kinaweza kutumiwa *vibaya*.

## Kanuni za AI ya Kuwajibika

Ili kuepuka matumizi mabaya ya AI kwa bahati mbaya au kwa makusudi, Microsoft inasisitiza [Kanuni Muhimu za AI ya Kuwajibika](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-77998-cacaste). Dhana zifuatazo zinaunga mkono kanuni hizi:

* **Haki** inahusiana na tatizo muhimu la *upendeleo wa mfano*, ambalo linaweza kusababishwa na kutumia data yenye upendeleo kwa mafunzo. Kwa mfano, tunapojaribu kutabiri uwezekano wa mtu kupata kazi ya msanidi programu, mfano unaweza kupendelea wanaume zaidi - kwa sababu tu seti ya data ya mafunzo ilionekana kuwa na upendeleo kwa wanaume. Tunahitaji kusawazisha data ya mafunzo kwa uangalifu na kuchunguza mfano ili kuepuka upendeleo, na kuhakikisha kwamba mfano unazingatia vipengele vinavyofaa zaidi.
* **Uaminifu na Usalama**. Kwa asili, mifano ya AI inaweza kufanya makosa. Mtandao wa neva hutoa uwezekano, na tunahitaji kuzingatia hilo tunapofanya maamuzi. Kila mfano una usahihi na kumbukumbu fulani, na tunahitaji kuelewa hilo ili kuzuia madhara yanayoweza kusababishwa na ushauri mbaya.
* **Faragha na Usalama** vina athari maalum za AI. Kwa mfano, tunapotumia data fulani kwa mafunzo ya mfano, data hii inakuwa kwa namna fulani "imeunganishwa" kwenye mfano. Kwa upande mmoja, hilo linaongeza usalama na faragha, lakini kwa upande mwingine - tunahitaji kukumbuka data ambayo mfano ulifundishwa nayo.
* **Ujumuishi** unamaanisha kwamba hatujengi AI ili kuchukua nafasi ya watu, bali kuimarisha watu na kufanya kazi yetu kuwa ya ubunifu zaidi. Pia inahusiana na haki, kwa sababu tunaposhughulika na jamii zisizowakilishwa vizuri, seti nyingi za data tunazokusanya zinaweza kuwa na upendeleo, na tunahitaji kuhakikisha kwamba jamii hizo zinajumuishwa na kushughulikiwa ipasavyo na AI.
* **Uwazi**. Hii inajumuisha kuhakikisha kwamba tunakuwa wazi kila wakati kuhusu matumizi ya AI. Pia, popote inapowezekana, tunataka kutumia mifumo ya AI ambayo inaweza *kufasiriwa*.
* **Uwajibikaji**. Wakati mifano ya AI inatoa maamuzi fulani, si mara zote wazi ni nani anayewajibika kwa maamuzi hayo. Tunahitaji kuhakikisha kwamba tunaelewa uwajibikaji wa maamuzi ya AI uko wapi. Katika hali nyingi tungependa kujumuisha wanadamu katika mchakato wa kufanya maamuzi muhimu, ili watu halisi wawajibike.

## Zana za AI ya Kuwajibika

Microsoft imeunda [Kisanduku cha Zana cha AI ya Kuwajibika](https://github.com/microsoft/responsible-ai-toolbox) ambacho kina seti ya zana:

* Dashibodi ya Ufasiri (InterpretML)
* Dashibodi ya Haki (FairLearn)
* Dashibodi ya Uchambuzi wa Makosa
* Dashibodi ya AI ya Kuwajibika inayojumuisha

   - EconML - chombo cha Uchambuzi wa Kisababishi, kinacholenga maswali ya "nini-ikiwa"
   - DiCE - chombo cha Uchambuzi wa Counterfactual kinachokuwezesha kuona ni vipengele vipi vinahitaji kubadilishwa ili kuathiri uamuzi wa mfano

Kwa maelezo zaidi kuhusu Maadili ya AI, tafadhali tembelea [somo hili](https://github.com/microsoft/ML-For-Beginners/tree/main/1-Introduction/3-fairness?WT.mc_id=academic-77998-cacaste) kwenye Mtaala wa Kujifunza Mashine unaojumuisha kazi za nyumbani.

## Mapitio na Kujisomea

Chukua [Njia hii ya Kujifunza](https://docs.microsoft.com/learn/modules/responsible-ai-principles/?WT.mc_id=academic-77998-cacaste) ili kujifunza zaidi kuhusu AI ya kuwajibika.

## [Jaribio la baada ya somo](https://white-water-09ec41f0f.azurestaticapps.net/quiz/6/)

**Kanusho**:  
Hati hii imetafsiriwa kwa kutumia huduma ya kutafsiri ya AI [Co-op Translator](https://github.com/Azure/co-op-translator). Ingawa tunajitahidi kuhakikisha usahihi, tafadhali fahamu kuwa tafsiri za kiotomatiki zinaweza kuwa na makosa au kutokuwa sahihi. Hati ya asili katika lugha yake ya awali inapaswa kuzingatiwa kama chanzo cha mamlaka. Kwa taarifa muhimu, tafsiri ya kitaalamu ya binadamu inapendekezwa. Hatutawajibika kwa kutoelewana au tafsiri zisizo sahihi zinazotokana na matumizi ya tafsiri hii.