<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "717775c4050ccbffbe0c961ad8bf7bf7",
  "translation_date": "2025-08-26T09:42:42+00:00",
  "source_file": "lessons/4-ComputerVision/08-TransferLearning/README.md",
  "language_code": "mo"
}
-->
# 預訓練網路與遷移學習

訓練 CNN 需要花費大量時間，並且需要大量數據。然而，大部分時間都花在學習網路用來從圖像中提取模式的最佳低層過濾器上。一個自然的問題是：我們是否可以使用在一個數據集上訓練好的神經網路，並將其適應於分類不同的圖像，而不需要完整的訓練過程？

## [課前測驗](https://ff-quizzes.netlify.app/en/ai/quiz/15)

這種方法被稱為**遷移學習**，因為我們將某些知識從一個神經網路模型轉移到另一個模型。在遷移學習中，我們通常從一個預訓練模型開始，該模型已經在一些大型圖像數據集（例如 **ImageNet**）上進行過訓練。這些模型已經能夠很好地從通用圖像中提取不同的特徵，在許多情況下，只需在這些提取的特徵上構建一個分類器就能取得不錯的結果。

> ✅ 遷移學習這個術語在其他學術領域（例如教育學）中也能找到，它指的是將一個領域的知識應用到另一個領域的過程。

## 預訓練模型作為特徵提取器

我們在上一節中討論的卷積網路包含多層，每一層都應該從圖像中提取一些特徵，從低層次的像素組合（例如水平/垂直線條或筆劃）開始，到更高層次的特徵組合，對應於像火焰的眼睛這樣的東西。如果我們在足夠大的通用和多樣化的圖像數據集上訓練 CNN，網路應該能夠學習提取這些常見特徵。

Keras 和 PyTorch 都包含了方便的函數，可以輕鬆加載一些常見架構的預訓練神經網路權重，這些模型大多數是在 ImageNet 圖像上訓練的。最常用的模型在之前課程的 [CNN 架構](../07-ConvNets/CNN_Architectures.md) 頁面中有描述。特別是，你可能會考慮使用以下模型之一：

* **VGG-16/VGG-19**：這些是相對簡單但仍能提供良好準確性的模型。通常使用 VGG 作為首次嘗試是一個不錯的選擇，可以看看遷移學習的效果如何。
* **ResNet**：這是一組由微軟研究院在 2015 年提出的模型。它們有更多的層，因此需要更多資源。
* **MobileNet**：這是一組縮小版的模型，適合移動設備。如果資源有限且可以接受稍微降低的準確性，可以使用它們。

以下是 VGG-16 網路從一張貓的圖片中提取的特徵示例：

![VGG-16 提取的特徵](../../../../../translated_images/features.6291f9c7ba3a0b951af88fc9864632b9115365410765680680d30c927dd67354.mo.png)

## 貓與狗數據集

在這個例子中，我們將使用 [貓與狗](https://www.microsoft.com/download/details.aspx?id=54765&WT.mc_id=academic-77998-cacaste) 數據集，這非常接近於真實的圖像分類場景。

## ✍️ 練習：遷移學習

讓我們在相應的筆記本中看看遷移學習的實際應用：

* [遷移學習 - PyTorch](../../../../../lessons/4-ComputerVision/08-TransferLearning/TransferLearningPyTorch.ipynb)
* [遷移學習 - TensorFlow](../../../../../lessons/4-ComputerVision/08-TransferLearning/TransferLearningTF.ipynb)

## 可視化對抗性貓

預訓練的神經網路在其「大腦」中包含了不同的模式，包括**理想的貓**（以及理想的狗、理想的斑馬等）。我們可以嘗試以某種方式**可視化這些圖像**。然而，這並不簡單，因為模式分散在網路的權重中，並且以層次結構組織。

我們可以採取的一種方法是從一張隨機圖像開始，然後嘗試使用**梯度下降優化**技術調整該圖像，使得網路認為它是一隻貓。

![圖像優化循環](../../../../../translated_images/ideal-cat-loop.999fbb8ff306e044f997032f4eef9152b453e6a990e449bbfb107de2493cc37e.mo.png)

然而，如果我們這樣做，最終會得到一些非常類似於隨機噪聲的東西。這是因為*有很多方法可以讓網路認為輸入圖像是一隻貓*，其中包括一些在視覺上沒有意義的方式。雖然這些圖像包含了許多典型的貓的模式，但它們並沒有被約束為視覺上有辨識度的圖像。

為了改善結果，我們可以在損失函數中添加另一個項，稱為**變異損失**。這是一個衡量圖像相鄰像素相似程度的指標。最小化變異損失可以使圖像更平滑，並消除噪聲，從而顯示出更具視覺吸引力的模式。以下是一些這樣的「理想」圖像的示例，它們被高概率分類為貓和斑馬：

![理想的貓](../../../../../translated_images/ideal-cat.203dd4597643d6b0bd73038b87f9c0464322725e3a06ab145d25d4a861c70592.mo.png) | ![理想的斑馬](../../../../../translated_images/ideal-zebra.7f70e8b54ee15a7a314000bb5df38a6cfe086ea04d60df4d3ef313d046b98a2b.mo.png)
-----|-----
*理想的貓* | *理想的斑馬*

類似的方法可以用來對神經網路進行所謂的**對抗性攻擊**。假設我們想要欺騙神經網路，讓一隻狗看起來像一隻貓。如果我們拿一張被網路識別為狗的狗的圖片，然後稍微調整它，使用梯度下降優化，直到網路開始將其分類為貓：

![狗的圖片](../../../../../translated_images/original-dog.8f68a67d2fe0911f33041c0f7fce8aa4ea919f9d3917ec4b468298522aeb6356.mo.png) | ![被分類為貓的狗的圖片](../../../../../translated_images/adversarial-dog.d9fc7773b0142b89752539bfbf884118de845b3851c5162146ea0b8809fc820f.mo.png)
-----|-----
*原始狗的圖片* | *被分類為貓的狗的圖片*

查看以下筆記本中的代碼以重現上述結果：

* [理想與對抗性貓 - TensorFlow](../../../../../lessons/4-ComputerVision/08-TransferLearning/AdversarialCat_TF.ipynb)

## 結論

通過遷移學習，你可以快速組建一個自定義對象分類任務的分類器，並實現高準確性。你可以看到，我們現在解決的更複雜的任務需要更高的計算能力，並且無法輕易在 CPU 上完成。在下一單元中，我們將嘗試使用更輕量化的實現來訓練相同的模型，使用較低的計算資源，並僅稍微降低準確性。

## 🚀 挑戰

在附帶的筆記本中，底部有關於遷移知識如何在某些相似的訓練數據（例如新的動物類型）上表現最佳的筆記。嘗試使用完全新類型的圖像進行實驗，看看你的遷移知識模型表現得如何。

## [課後測驗](https://ff-quizzes.netlify.app/en/ai/quiz/16)

## 回顧與自學

閱讀 [TrainingTricks.md](TrainingTricks.md)，以加深對其他訓練模型方法的了解。

## [作業](lab/README.md)

在這個實驗中，我們將使用真實的 [Oxford-IIIT](https://www.robots.ox.ac.uk/~vgg/data/pets/) 寵物數據集，其中包含 35 種貓和狗的品種，並構建一個遷移學習分類器。

**免責聲明**：  
本文檔已使用 AI 翻譯服務 [Co-op Translator](https://github.com/Azure/co-op-translator) 進行翻譯。我們致力於提供準確的翻譯，但請注意，自動翻譯可能包含錯誤或不準確之處。應以原始語言的文件作為權威來源。對於關鍵信息，建議尋求專業人工翻譯。我們對因使用此翻譯而引起的任何誤解或誤釋不承擔責任。