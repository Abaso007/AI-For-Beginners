{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‡§∏‡§∞‡§≤ ‡§á‡§Æ‡•á‡§ú ‡§ï‡•ç‡§≤‡§æ‡§∏‡§ø‡§´‡§æ‡§Ø‡§∞\n",
    "\n",
    "‡§Ø‡§π ‡§®‡•ã‡§ü‡§¨‡•Å‡§ï ‡§Ü‡§™‡§ï‡•ã ‡§è‡§ï ‡§™‡•ç‡§∞‡•Ä-‡§ü‡•ç‡§∞‡•á‡§Ç‡§° ‡§®‡•ç‡§Ø‡•Ç‡§∞‡§≤ ‡§®‡•á‡§ü‡§µ‡§∞‡•ç‡§ï ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§ï‡•á ‡§á‡§Æ‡•á‡§ú ‡§ï‡•ã ‡§µ‡§∞‡•ç‡§ó‡•Ä‡§ï‡•É‡§§ ‡§ï‡§∞‡§®‡§æ ‡§∏‡§ø‡§ñ‡§æ‡§§‡•Ä ‡§π‡•à‡•§\n",
    "\n",
    "**‡§Ü‡§™ ‡§ï‡•ç‡§Ø‡§æ ‡§∏‡•Ä‡§ñ‡•á‡§Ç‡§ó‡•á:**\n",
    "- ‡§™‡•ç‡§∞‡•Ä-‡§ü‡•ç‡§∞‡•á‡§Ç‡§° ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•ã ‡§≤‡•ã‡§° ‡§î‡§∞ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡•à‡§∏‡•á ‡§ï‡§∞‡•á‡§Ç\n",
    "- ‡§á‡§Æ‡•á‡§ú ‡§™‡•ç‡§∞‡•Ä‡§™‡•ç‡§∞‡•ã‡§∏‡•á‡§∏‡§ø‡§Ç‡§ó\n",
    "- ‡§á‡§Æ‡•á‡§ú ‡§™‡§∞ ‡§≠‡§µ‡§ø‡§∑‡•ç‡§Ø‡§µ‡§æ‡§£‡•Ä ‡§ï‡§∞‡§®‡§æ\n",
    "- ‡§ï‡•â‡§®‡•ç‡§´‡§ø‡§°‡•á‡§Ç‡§∏ ‡§∏‡•ç‡§ï‡•ã‡§∞ ‡§ï‡•ã ‡§∏‡§Æ‡§ù‡§®‡§æ\n",
    "\n",
    "**‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§æ ‡§Æ‡§æ‡§Æ‡§≤‡§æ:** ‡§á‡§Æ‡•á‡§ú ‡§Æ‡•á‡§Ç ‡§µ‡§∏‡•ç‡§§‡•Å‡§ì‡§Ç ‡§ï‡•Ä ‡§™‡§π‡§ö‡§æ‡§® ‡§ï‡§∞‡§®‡§æ (‡§ú‡•à‡§∏‡•á \"‡§¨‡§ø‡§≤‡•ç‡§≤‡•Ä\", \"‡§ï‡•Å‡§§‡•ç‡§§‡§æ\", \"‡§ï‡§æ‡§∞\" ‡§Ü‡§¶‡§ø)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‡§ö‡§∞‡§£ 1: ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï ‡§≤‡§æ‡§á‡§¨‡•ç‡§∞‡•á‡§∞‡•Ä ‡§Ü‡§Ø‡§æ‡§§ ‡§ï‡§∞‡•á‡§Ç\n",
    "\n",
    "‡§Ü‡§á‡§è ‡§â‡§® ‡§â‡§™‡§ï‡§∞‡§£‡•ã‡§Ç ‡§ï‡•ã ‡§Ü‡§Ø‡§æ‡§§ ‡§ï‡§∞‡•á‡§Ç ‡§ú‡§ø‡§®‡§ï‡•Ä ‡§π‡§Æ‡•á‡§Ç ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ ‡§π‡•à‡•§ ‡§Ö‡§ó‡§∞ ‡§Ü‡§™ ‡§á‡§®‡§Æ‡•á‡§Ç ‡§∏‡•á ‡§ï‡•Å‡§õ ‡§ï‡•ã ‡§Ö‡§≠‡•Ä ‡§™‡•Ç‡§∞‡•Ä ‡§§‡§∞‡§π ‡§∏‡•á ‡§®‡§π‡•Ä‡§Ç ‡§∏‡§Æ‡§ù‡§§‡•á ‡§π‡•à‡§Ç ‡§§‡•ã ‡§ö‡§ø‡§Ç‡§§‡§æ ‡§® ‡§ï‡§∞‡•á‡§Ç!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# TensorFlow for deep learning\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.applications import MobileNetV2\n",
    "    from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, decode_predictions\n",
    "    print(\"‚úÖ TensorFlow loaded successfully!\")\n",
    "    print(f\"   Version: {tf.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå Please install TensorFlow: pip install tensorflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‡§ö‡§∞‡§£ 2: ‡§™‡•ç‡§∞‡•Ä-‡§ü‡•ç‡§∞‡•á‡§Ç‡§° ‡§Æ‡•â‡§°‡§≤ ‡§≤‡•ã‡§° ‡§ï‡§∞‡•á‡§Ç\n",
    "\n",
    "‡§π‡§Æ **MobileNetV2** ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç‡§ó‡•á, ‡§ú‡•ã ‡§™‡§π‡§≤‡•á ‡§∏‡•á ‡§π‡•Ä ‡§≤‡§æ‡§ñ‡•ã‡§Ç ‡§õ‡§µ‡§ø‡§Ø‡•ã‡§Ç ‡§™‡§∞ ‡§™‡•ç‡§∞‡§∂‡§ø‡§ï‡•ç‡§∑‡§ø‡§§ ‡§è‡§ï ‡§®‡•ç‡§Ø‡•Ç‡§∞‡§≤ ‡§®‡•á‡§ü‡§µ‡§∞‡•ç‡§ï ‡§π‡•à‡•§\n",
    "\n",
    "‡§á‡§∏‡•á **‡§ü‡•ç‡§∞‡§æ‡§Ç‡§∏‡§´‡§∞ ‡§≤‡§∞‡•ç‡§®‡§ø‡§Ç‡§ó** ‡§ï‡§π‡§æ ‡§ú‡§æ‡§§‡§æ ‡§π‡•à - ‡§ï‡§ø‡§∏‡•Ä ‡§î‡§∞ ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§™‡•ç‡§∞‡§∂‡§ø‡§ï‡•ç‡§∑‡§ø‡§§ ‡§Æ‡•â‡§°‡§≤ ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§®‡§æ!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üì¶ Loading pre-trained MobileNetV2 model...\")\n",
    "print(\"   This may take a minute on first run (downloading weights)...\")\n",
    "\n",
    "# Load the model\n",
    "# include_top=True means we use the classification layer\n",
    "# weights='imagenet' means it was trained on ImageNet dataset\n",
    "model = MobileNetV2(weights='imagenet', include_top=True)\n",
    "\n",
    "print(\"‚úÖ Model loaded!\")\n",
    "print(f\"   The model can recognize 1000 different object categories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‡§ö‡§∞‡§£ 3: ‡§∏‡§π‡§æ‡§Ø‡§ï ‡§´‡§º‡§Ç‡§ï‡•ç‡§∂‡§®\n",
    "\n",
    "‡§Ü‡§á‡§è ‡§π‡§Æ‡§æ‡§∞‡•á ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§õ‡§µ‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡•ã ‡§≤‡•ã‡§° ‡§î‡§∞ ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§´‡§º‡§Ç‡§ï‡•ç‡§∂‡§® ‡§¨‡§®‡§æ‡§è‡§Ç‡•§\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_from_url(url):\n",
    "    \"\"\"\n",
    "    Load an image from a URL.\n",
    "    \n",
    "    Args:\n",
    "        url: Web address of the image\n",
    "        \n",
    "    Returns:\n",
    "        PIL Image object\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    return img\n",
    "\n",
    "\n",
    "def prepare_image(img):\n",
    "    \"\"\"\n",
    "    Prepare an image for the model.\n",
    "    \n",
    "    Steps:\n",
    "    1. Resize to 224x224 (model's expected size)\n",
    "    2. Convert to array\n",
    "    3. Add batch dimension\n",
    "    4. Preprocess for MobileNetV2\n",
    "    \n",
    "    Args:\n",
    "        img: PIL Image\n",
    "        \n",
    "    Returns:\n",
    "        Preprocessed image array\n",
    "    \"\"\"\n",
    "    # Resize to 224x224 pixels\n",
    "    img = img.resize((224, 224))\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    img_array = np.array(img)\n",
    "    \n",
    "    # Add batch dimension (model expects multiple images)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    # Preprocess for MobileNetV2\n",
    "    img_array = preprocess_input(img_array)\n",
    "    \n",
    "    return img_array\n",
    "\n",
    "\n",
    "def classify_image(img):\n",
    "    \"\"\"\n",
    "    Classify an image and return top predictions.\n",
    "    \n",
    "    Args:\n",
    "        img: PIL Image\n",
    "        \n",
    "    Returns:\n",
    "        List of (class_name, confidence) tuples\n",
    "    \"\"\"\n",
    "    # Prepare the image\n",
    "    img_array = prepare_image(img)\n",
    "    \n",
    "    # Make prediction\n",
    "    predictions = model.predict(img_array, verbose=0)\n",
    "    \n",
    "    # Decode predictions to human-readable labels\n",
    "    # top=5 means we get the top 5 most likely classes\n",
    "    decoded = decode_predictions(predictions, top=5)[0]\n",
    "    \n",
    "    # Convert to simpler format\n",
    "    results = [(label, float(confidence)) for (_, label, confidence) in decoded]\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"‚úÖ Helper functions ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‡§ö‡§∞‡§£ 4: ‡§®‡§Æ‡•Ç‡§®‡§æ ‡§õ‡§µ‡§ø‡§Ø‡•ã‡§Ç ‡§™‡§∞ ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§£ ‡§ï‡§∞‡•á‡§Ç\n",
    "\n",
    "‡§ö‡§≤‡•ã ‡§á‡§Ç‡§ü‡§∞‡§®‡•á‡§ü ‡§∏‡•á ‡§ï‡•Å‡§õ ‡§õ‡§µ‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡•ã ‡§µ‡§∞‡•ç‡§ó‡•Ä‡§ï‡•É‡§§ ‡§ï‡§∞‡§®‡•á ‡§ï‡•Ä ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample images to classify\n",
    "# These are from Unsplash (free stock photos)\n",
    "test_images = [\n",
    "    {\n",
    "        \"url\": \"https://images.unsplash.com/photo-1514888286974-6c03e2ca1dba?w=400\",\n",
    "        \"description\": \"A cat\"\n",
    "    },\n",
    "    {\n",
    "        \"url\": \"https://images.unsplash.com/photo-1552053831-71594a27632d?w=400\",\n",
    "        \"description\": \"A dog\"\n",
    "    },\n",
    "    {\n",
    "        \"url\": \"https://images.unsplash.com/photo-1511919884226-fd3cad34687c?w=400\",\n",
    "        \"description\": \"A car\"\n",
    "    },\n",
    "]\n",
    "\n",
    "print(f\"üß™ Testing on {len(test_images)} images...\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡•á‡§ï ‡§õ‡§µ‡§ø ‡§ï‡•ã ‡§µ‡§∞‡•ç‡§ó‡•Ä‡§ï‡•É‡§§ ‡§ï‡§∞‡•á‡§Ç\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, img_data in enumerate(test_images, 1):\n",
    "    print(f\"\\nüì∏ Image {i}: {img_data['description']}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    try:\n",
    "        # Load image\n",
    "        img = load_image_from_url(img_data['url'])\n",
    "        \n",
    "        # Display image\n",
    "        display(img.resize((200, 200)))  # Show smaller version\n",
    "        \n",
    "        # Classify\n",
    "        results = classify_image(img)\n",
    "        \n",
    "        # Show predictions\n",
    "        print(\"\\nüéØ Top 5 Predictions:\")\n",
    "        for rank, (label, confidence) in enumerate(results, 1):\n",
    "            # Create a visual bar\n",
    "            bar_length = int(confidence * 50)\n",
    "            bar = \"‚ñà\" * bar_length\n",
    "            \n",
    "            print(f\"  {rank}. {label:20s} {confidence*100:5.2f}% {bar}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‡§ö‡§∞‡§£ 5: ‡§Ö‡§™‡§®‡•Ä ‡§ñ‡•Å‡§¶ ‡§ï‡•Ä ‡§õ‡§µ‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡•ã ‡§Ü‡§ú‡§º‡§Æ‡§æ‡§è‡§Ç!\n",
    "\n",
    "‡§®‡•Ä‡§ö‡•á ‡§¶‡§ø‡§è ‡§ó‡§è URL ‡§ï‡•ã ‡§ï‡§ø‡§∏‡•Ä ‡§≠‡•Ä ‡§õ‡§µ‡§ø URL ‡§∏‡•á ‡§¨‡§¶‡§≤‡•á‡§Ç ‡§ú‡§ø‡§∏‡•á ‡§Ü‡§™ ‡§µ‡§∞‡•ç‡§ó‡•Ä‡§ï‡•É‡§§ ‡§ï‡§∞‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç‡•§\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try your own image!\n",
    "# Replace this URL with any image URL\n",
    "custom_image_url = \"https://images.unsplash.com/photo-1472491235688-bdc81a63246e?w=400\"  # A flower\n",
    "\n",
    "print(\"üñºÔ∏è  Classifying your custom image...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    # Load and show image\n",
    "    img = load_image_from_url(custom_image_url)\n",
    "    display(img.resize((300, 300)))\n",
    "    \n",
    "    # Classify\n",
    "    results = classify_image(img)\n",
    "    \n",
    "    # Show results\n",
    "    print(\"\\nüéØ Top 5 Predictions:\")\n",
    "    print(\"-\" * 70)\n",
    "    for rank, (label, confidence) in enumerate(results, 1):\n",
    "        bar_length = int(confidence * 50)\n",
    "        bar = \"‚ñà\" * bar_length\n",
    "        print(f\"  {rank}. {label:20s} {confidence*100:5.2f}% {bar}\")\n",
    "    \n",
    "    # Highlight top prediction\n",
    "    top_label, top_confidence = results[0]\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"\\nüèÜ Best guess: {top_label} ({top_confidence*100:.2f}% confident)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    print(\"   Make sure the URL points to a valid image!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° ‡§Ö‡§≠‡•Ä ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•Å‡§Ü?\n",
    "\n",
    "1. **‡§π‡§Æ‡§®‡•á ‡§è‡§ï ‡§™‡•ç‡§∞‡•Ä-‡§ü‡•ç‡§∞‡•á‡§Ç‡§° ‡§Æ‡•â‡§°‡§≤ ‡§≤‡•ã‡§° ‡§ï‡§ø‡§Ø‡§æ** - MobileNetV2 ‡§ï‡•ã ‡§≤‡§æ‡§ñ‡•ã‡§Ç ‡§§‡§∏‡•ç‡§µ‡•Ä‡§∞‡•ã‡§Ç ‡§™‡§∞ ‡§™‡•ç‡§∞‡§∂‡§ø‡§ï‡•ç‡§∑‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§•‡§æ  \n",
    "2. **‡§π‡§Æ‡§®‡•á ‡§§‡§∏‡•ç‡§µ‡•Ä‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§™‡•ç‡§∞‡•Ä‡§™‡•ç‡§∞‡•ã‡§∏‡•á‡§∏ ‡§ï‡§ø‡§Ø‡§æ** - ‡§â‡§®‡•ç‡§π‡•á‡§Ç ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡§π‡•Ä ‡§Ü‡§ï‡§æ‡§∞ ‡§î‡§∞ ‡§´‡•â‡§∞‡•ç‡§Æ‡•á‡§ü ‡§Æ‡•á‡§Ç ‡§¨‡§¶‡§≤‡§æ  \n",
    "3. **‡§Æ‡•â‡§°‡§≤ ‡§®‡•á ‡§™‡•ç‡§∞‡•á‡§°‡§ø‡§ï‡•ç‡§∂‡§® ‡§ï‡§ø‡§Ø‡§æ** - ‡§Ø‡§π 1000 ‡§ë‡§¨‡•ç‡§ú‡•á‡§ï‡•ç‡§ü ‡§ï‡•ç‡§≤‡§æ‡§∏‡•á‡§∏ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡§Ç‡§≠‡§æ‡§µ‡§®‡§æ‡§è‡§Ç ‡§¨‡§§‡§æ‡§§‡§æ ‡§π‡•à  \n",
    "4. **‡§π‡§Æ‡§®‡•á ‡§™‡§∞‡§ø‡§£‡§æ‡§Æ‡•ã‡§Ç ‡§ï‡•ã ‡§°‡§ø‡§ï‡•ã‡§° ‡§ï‡§ø‡§Ø‡§æ** - ‡§Ö‡§Ç‡§ï‡•ã‡§Ç ‡§ï‡•ã ‡§á‡§Ç‡§∏‡§æ‡§®‡•ã‡§Ç ‡§ï‡•á ‡§™‡§¢‡§º‡§®‡•á ‡§≤‡§æ‡§Ø‡§ï ‡§≤‡•á‡§¨‡§≤ ‡§Æ‡•á‡§Ç ‡§¨‡§¶‡§≤‡§æ  \n",
    "\n",
    "### ‡§ï‡•â‡§®‡•ç‡§´‡§ø‡§°‡•á‡§Ç‡§∏ ‡§∏‡•ç‡§ï‡•ã‡§∞ ‡§ï‡•ã ‡§∏‡§Æ‡§ù‡§®‡§æ\n",
    "\n",
    "- **90-100%**: ‡§¨‡§π‡•Å‡§§ ‡§ú‡•ç‡§Ø‡§æ‡§¶‡§æ ‡§≠‡§∞‡•ã‡§∏‡•á‡§Æ‡§Ç‡§¶ (‡§≤‡§ó‡§≠‡§ó ‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§∏‡§π‡•Ä)  \n",
    "- **70-90%**: ‡§≠‡§∞‡•ã‡§∏‡•á‡§Æ‡§Ç‡§¶ (‡§∂‡§æ‡§Ø‡§¶ ‡§∏‡§π‡•Ä)  \n",
    "- **50-70%**: ‡§•‡•ã‡§°‡§º‡§æ ‡§≠‡§∞‡•ã‡§∏‡•á‡§Æ‡§Ç‡§¶ (‡§∂‡§æ‡§Ø‡§¶ ‡§∏‡§π‡•Ä ‡§π‡•ã ‡§∏‡§ï‡§§‡§æ ‡§π‡•à)  \n",
    "- **50% ‡§∏‡•á ‡§ï‡§Æ**: ‡§ú‡•ç‡§Ø‡§æ‡§¶‡§æ ‡§≠‡§∞‡•ã‡§∏‡•á‡§Æ‡§Ç‡§¶ ‡§®‡§π‡•Ä‡§Ç (‡§Ö‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§)  \n",
    "\n",
    "### ‡§™‡•ç‡§∞‡•á‡§°‡§ø‡§ï‡•ç‡§∂‡§® ‡§ó‡§≤‡§§ ‡§ï‡•ç‡§Ø‡•ã‡§Ç ‡§π‡•ã ‡§∏‡§ï‡§§‡§æ ‡§π‡•à?\n",
    "\n",
    "- **‡§Ö‡§ú‡•Ä‡§¨ ‡§ï‡•ã‡§£ ‡§Ø‡§æ ‡§∞‡•ã‡§∂‡§®‡•Ä** - ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•ã ‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§§‡§∏‡•ç‡§µ‡•Ä‡§∞‡•ã‡§Ç ‡§™‡§∞ ‡§™‡•ç‡§∞‡§∂‡§ø‡§ï‡•ç‡§∑‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§•‡§æ  \n",
    "- **‡§ï‡§à ‡§ë‡§¨‡•ç‡§ú‡•á‡§ï‡•ç‡§ü‡•ç‡§∏** - ‡§Æ‡•â‡§°‡§≤ ‡§è‡§ï ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§ë‡§¨‡•ç‡§ú‡•á‡§ï‡•ç‡§ü ‡§ï‡•Ä ‡§â‡§Æ‡•ç‡§Æ‡•Ä‡§¶ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à  \n",
    "- **‡§¶‡•Å‡§∞‡•ç‡§≤‡§≠ ‡§ë‡§¨‡•ç‡§ú‡•á‡§ï‡•ç‡§ü‡•ç‡§∏** - ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•á‡§µ‡§≤ 1000 ‡§ï‡•à‡§ü‡•á‡§ó‡§∞‡•Ä ‡§ï‡•ã ‡§ú‡§æ‡§®‡§§‡§æ ‡§π‡•à  \n",
    "- **‡§ï‡§Æ ‡§ó‡•Å‡§£‡§µ‡§§‡•ç‡§§‡§æ ‡§µ‡§æ‡§≤‡•Ä ‡§§‡§∏‡•ç‡§µ‡•Ä‡§∞** - ‡§ß‡•Å‡§Ç‡§ß‡§≤‡•Ä ‡§Ø‡§æ ‡§™‡§ø‡§ï‡•ç‡§∏‡•á‡§≤‡•á‡§ü‡•á‡§° ‡§§‡§∏‡•ç‡§µ‡•Ä‡§∞‡•á‡§Ç ‡§™‡§π‡§ö‡§æ‡§®‡§®‡§æ ‡§Æ‡•Å‡§∂‡•ç‡§ï‡§ø‡§≤ ‡§π‡•ã‡§§‡§æ ‡§π‡•à  \n",
    "\n",
    "---  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ ‡§Ö‡§ó‡§≤‡•á ‡§ï‡§¶‡§Æ\n",
    "\n",
    "1. **‡§Ö‡§≤‡§ó-‡§Ö‡§≤‡§ó ‡§§‡§∏‡•ç‡§µ‡•Ä‡§∞‡•á‡§Ç ‡§Ü‡§ú‡§º‡§Æ‡§æ‡§è‡§Ç:**\n",
    "   - [Unsplash](https://unsplash.com) ‡§™‡§∞ ‡§§‡§∏‡•ç‡§µ‡•Ä‡§∞‡•á‡§Ç ‡§ñ‡•ã‡§ú‡•á‡§Ç\n",
    "   - ‡§∞‡§æ‡§á‡§ü-‡§ï‡•ç‡§≤‡§ø‡§ï ‡§ï‡§∞‡•á‡§Ç ‚Üí \"Copy image address\" ‡§∏‡•á URL ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞‡•á‡§Ç\n",
    "\n",
    "2. **‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç:**\n",
    "   - ‡§Ö‡§Æ‡•Ç‡§∞‡•ç‡§§ ‡§ï‡§≤‡§æ ‡§ï‡•á ‡§∏‡§æ‡§• ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•ã‡§§‡§æ ‡§π‡•à?\n",
    "   - ‡§ï‡•ç‡§Ø‡§æ ‡§Ø‡§π ‡§Ö‡§≤‡§ó-‡§Ö‡§≤‡§ó ‡§ï‡•ã‡§£‡•ã‡§Ç ‡§∏‡•á ‡§µ‡§∏‡•ç‡§§‡•Å‡§ì‡§Ç ‡§ï‡•ã ‡§™‡§π‡§ö‡§æ‡§® ‡§∏‡§ï‡§§‡§æ ‡§π‡•à?\n",
    "   - ‡§Ø‡§π ‡§ï‡§à ‡§µ‡§∏‡•ç‡§§‡•Å‡§ì‡§Ç ‡§ï‡•ã ‡§ï‡•à‡§∏‡•á ‡§∏‡§Ç‡§≠‡§æ‡§≤‡§§‡§æ ‡§π‡•à?\n",
    "\n",
    "3. **‡§Ö‡§ß‡§ø‡§ï ‡§ú‡§æ‡§®‡•á‡§Ç:**\n",
    "   - [Computer Vision ‡§™‡§æ‡§†](../lessons/4-ComputerVision/README.md) ‡§ï‡§æ ‡§Ö‡§®‡•ç‡§µ‡•á‡§∑‡§£ ‡§ï‡§∞‡•á‡§Ç\n",
    "   - ‡§Ö‡§™‡§®‡§æ ‡§ñ‡•Å‡§¶ ‡§ï‡§æ ‡§á‡§Æ‡•á‡§ú ‡§ï‡•ç‡§≤‡§æ‡§∏‡§ø‡§´‡§æ‡§Ø‡§∞ ‡§ü‡•ç‡§∞‡•á‡§® ‡§ï‡§∞‡§®‡§æ ‡§∏‡•Ä‡§ñ‡•á‡§Ç\n",
    "   - ‡§∏‡§Æ‡§ù‡•á‡§Ç ‡§ï‡§ø CNNs (Convolutional Neural Networks) ‡§ï‡•à‡§∏‡•á ‡§ï‡§æ‡§Æ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ ‡§¨‡§ß‡§æ‡§à ‡§π‡•ã!\n",
    "\n",
    "‡§Ü‡§™‡§®‡•á ‡§Ö‡§≠‡•Ä-‡§Ö‡§≠‡•Ä ‡§è‡§ï ‡§Ö‡§§‡•ç‡§Ø‡§æ‡§ß‡•Å‡§®‡§ø‡§ï ‡§®‡•ç‡§Ø‡•Ç‡§∞‡§≤ ‡§®‡•á‡§ü‡§µ‡§∞‡•ç‡§ï ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§ï‡•á ‡§è‡§ï ‡§á‡§Æ‡•á‡§ú ‡§ï‡•ç‡§≤‡§æ‡§∏‡§ø‡§´‡§æ‡§Ø‡§∞ ‡§¨‡§®‡§æ‡§Ø‡§æ ‡§π‡•à!\n",
    "\n",
    "‡§Ø‡§π‡•Ä ‡§§‡§ï‡§®‡•Ä‡§ï ‡§∂‡§ï‡•ç‡§§‡§ø ‡§¶‡•á‡§§‡•Ä ‡§π‡•à:\n",
    "- Google Photos (‡§Ü‡§™‡§ï‡•Ä ‡§§‡§∏‡•ç‡§µ‡•Ä‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§ø‡§§ ‡§ï‡§∞‡§®‡§æ)\n",
    "- ‡§∏‡•á‡§≤‡•ç‡§´-‡§°‡•ç‡§∞‡§æ‡§á‡§µ‡§ø‡§Ç‡§ó ‡§ï‡§æ‡§∞‡•á‡§Ç (‡§µ‡§∏‡•ç‡§§‡•Å‡§ì‡§Ç ‡§ï‡•ã ‡§™‡§π‡§ö‡§æ‡§®‡§®‡§æ)\n",
    "- ‡§ö‡§ø‡§ï‡§ø‡§§‡•ç‡§∏‡§æ ‡§®‡§ø‡§¶‡§æ‡§® (‡§è‡§ï‡•ç‡§∏-‡§∞‡•á ‡§ï‡§æ ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§ï‡§∞‡§®‡§æ)\n",
    "- ‡§ó‡•Å‡§£‡§µ‡§§‡•ç‡§§‡§æ ‡§®‡§ø‡§Ø‡§Ç‡§§‡•ç‡§∞‡§£ (‡§§‡•ç‡§∞‡•Å‡§ü‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡§æ ‡§™‡§§‡§æ ‡§≤‡§ó‡§æ‡§®‡§æ)\n",
    "\n",
    "‡§ñ‡•ã‡§ú ‡§î‡§∞ ‡§∏‡•Ä‡§ñ‡§§‡•á ‡§∞‡§π‡•á‡§Ç! üöÄ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**‡§Ö‡§∏‡•ç‡§µ‡•Ä‡§ï‡§∞‡§£**:  \n‡§Ø‡§π ‡§¶‡§∏‡•ç‡§§‡§æ‡§µ‡•á‡§ú‡§º AI ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶ ‡§∏‡•á‡§µ‡§æ [Co-op Translator](https://github.com/Azure/co-op-translator) ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§ï‡•á ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§ ‡§ú‡§¨‡§ï‡§ø ‡§π‡§Æ ‡§∏‡§ü‡•Ä‡§ï‡§§‡§æ ‡§∏‡•Å‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§ï‡§∞‡§®‡•á ‡§ï‡§æ ‡§™‡•ç‡§∞‡§Ø‡§æ‡§∏ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç, ‡§ï‡•É‡§™‡§Ø‡§æ ‡§ß‡•ç‡§Ø‡§æ‡§® ‡§¶‡•á‡§Ç ‡§ï‡§ø ‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶ ‡§Æ‡•á‡§Ç ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø‡§Ø‡§æ‡§Ç ‡§Ø‡§æ ‡§Ö‡§∂‡•Å‡§¶‡•ç‡§ß‡§ø‡§Ø‡§æ‡§Ç ‡§π‡•ã ‡§∏‡§ï‡§§‡•Ä ‡§π‡•à‡§Ç‡•§ ‡§Æ‡•Ç‡§≤ ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•á‡§Ç ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§Æ‡•Ç‡§≤ ‡§¶‡§∏‡•ç‡§§‡§æ‡§µ‡•á‡§ú‡§º ‡§ï‡•ã ‡§™‡•ç‡§∞‡§æ‡§Æ‡§æ‡§£‡§ø‡§ï ‡§∏‡•ç‡§∞‡•ã‡§§ ‡§Æ‡§æ‡§®‡§æ ‡§ú‡§æ‡§®‡§æ ‡§ö‡§æ‡§π‡§ø‡§è‡•§ ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è, ‡§™‡•á‡§∂‡•á‡§µ‡§∞ ‡§Æ‡§æ‡§®‡§µ ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶ ‡§ï‡•Ä ‡§∏‡§ø‡§´‡§æ‡§∞‡§ø‡§∂ ‡§ï‡•Ä ‡§ú‡§æ‡§§‡•Ä ‡§π‡•à‡•§ ‡§á‡§∏ ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶ ‡§ï‡•á ‡§â‡§™‡§Ø‡•ã‡§ó ‡§∏‡•á ‡§â‡§§‡•ç‡§™‡§®‡•ç‡§® ‡§ï‡§ø‡§∏‡•Ä ‡§≠‡•Ä ‡§ó‡§≤‡§§‡§´‡§π‡§Æ‡•Ä ‡§Ø‡§æ ‡§ó‡§≤‡§§ ‡§µ‡•ç‡§Ø‡§æ‡§ñ‡•ç‡§Ø‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§π‡§Æ ‡§â‡§§‡•ç‡§§‡§∞‡§¶‡§æ‡§Ø‡•Ä ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à‡§Ç‡•§\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "coopTranslator": {
   "original_hash": "1d472141d9df46b751542b3c29f88677",
   "translation_date": "2025-10-03T11:41:52+00:00",
   "source_file": "examples/03-image-classifier.ipynb",
   "language_code": "hi"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}