<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "437c988596e751072e41a5aad3fcc5d9",
  "translation_date": "2025-08-24T09:47:10+00:00",
  "source_file": "lessons/7-Ethics/README.md",
  "language_code": "hi"
}
-->
# नैतिक और जिम्मेदार AI

आपने इस पाठ्यक्रम को लगभग पूरा कर लिया है, और मुझे उम्मीद है कि अब तक आप स्पष्ट रूप से देख सकते हैं कि AI कई औपचारिक गणितीय विधियों पर आधारित है, जो हमें डेटा में संबंध खोजने और कुछ हद तक मानव व्यवहार को दोहराने वाले मॉडल को प्रशिक्षित करने की अनुमति देती हैं। इस समय, हम AI को डेटा से पैटर्न निकालने और उन पैटर्न को नई समस्याओं को हल करने के लिए लागू करने के लिए एक बहुत ही शक्तिशाली उपकरण मानते हैं।

## [प्री-लेक्चर क्विज़](https://white-water-09ec41f0f.azurestaticapps.net/quiz/5/)

हालांकि, विज्ञान कथा में हम अक्सर ऐसी कहानियां देखते हैं जहां AI मानव जाति के लिए खतरा प्रस्तुत करता है। आमतौर पर ये कहानियां किसी प्रकार की AI विद्रोह के इर्द-गिर्द घूमती हैं, जब AI मानव के खिलाफ जाने का निर्णय लेता है। इसका मतलब है कि AI में किसी प्रकार की भावना होती है या यह अपने डेवलपर्स द्वारा अप्रत्याशित निर्णय ले सकता है।

इस पाठ्यक्रम में हमने जिस प्रकार के AI के बारे में सीखा है, वह केवल बड़े मैट्रिक्स गणित है। यह हमारी समस्याओं को हल करने में मदद करने के लिए एक बहुत ही शक्तिशाली उपकरण है, और किसी भी अन्य शक्तिशाली उपकरण की तरह - इसका उपयोग अच्छे और बुरे उद्देश्यों के लिए किया जा सकता है। महत्वपूर्ण बात यह है कि इसका *दुरुपयोग* किया जा सकता है।

## जिम्मेदार AI के सिद्धांत

AI के इस आकस्मिक या जानबूझकर दुरुपयोग से बचने के लिए, Microsoft ने [जिम्मेदार AI के सिद्धांत](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-77998-cacaste) को महत्वपूर्ण बताया है। इन सिद्धांतों के पीछे निम्नलिखित अवधारणाएं हैं:

* **निष्पक्षता** *मॉडल पूर्वाग्रहों* की महत्वपूर्ण समस्या से संबंधित है, जो प्रशिक्षण के लिए पक्षपाती डेटा का उपयोग करने के कारण हो सकता है। उदाहरण के लिए, जब हम किसी व्यक्ति के लिए सॉफ़्टवेयर डेवलपर नौकरी पाने की संभावना का अनुमान लगाने की कोशिश करते हैं, तो मॉडल पुरुषों को अधिक प्राथमिकता देने की संभावना रखता है - केवल इसलिए कि प्रशिक्षण डेटासेट संभवतः पुरुष दर्शकों की ओर पक्षपाती था। हमें प्रशिक्षण डेटा को सावधानीपूर्वक संतुलित करना और मॉडल की जांच करनी चाहिए ताकि पूर्वाग्रहों से बचा जा सके, और यह सुनिश्चित करना चाहिए कि मॉडल अधिक प्रासंगिक विशेषताओं को ध्यान में रखे।
* **विश्वसनीयता और सुरक्षा**। अपनी प्रकृति के कारण, AI मॉडल गलतियां कर सकते हैं। एक न्यूरल नेटवर्क संभावनाएं लौटाता है, और हमें निर्णय लेते समय इसे ध्यान में रखना चाहिए। हर मॉडल में कुछ सटीकता और पुनः प्राप्ति होती है, और हमें यह समझने की आवश्यकता है कि गलत सलाह से होने वाले नुकसान को कैसे रोका जाए।
* **गोपनीयता और सुरक्षा** में कुछ AI-विशिष्ट प्रभाव होते हैं। उदाहरण के लिए, जब हम किसी मॉडल को प्रशिक्षित करने के लिए कुछ डेटा का उपयोग करते हैं, तो यह डेटा किसी न किसी रूप में मॉडल में "एकीकृत" हो जाता है। एक ओर, यह सुरक्षा और गोपनीयता बढ़ाता है, दूसरी ओर - हमें यह याद रखना चाहिए कि मॉडल को किस डेटा पर प्रशिक्षित किया गया था।
* **समावेशिता** का मतलब है कि हम AI को लोगों की जगह लेने के लिए नहीं बना रहे हैं, बल्कि लोगों को बढ़ाने और हमारे काम को अधिक रचनात्मक बनाने के लिए बना रहे हैं। यह निष्पक्षता से भी संबंधित है, क्योंकि जब कम प्रतिनिधित्व वाले समुदायों से निपटते हैं, तो हम जो अधिकांश डेटासेट एकत्र करते हैं, वे संभवतः पक्षपाती होते हैं, और हमें यह सुनिश्चित करना चाहिए कि उन समुदायों को शामिल किया जाए और AI द्वारा सही तरीके से संभाला जाए।
* **पारदर्शिता**। इसमें यह सुनिश्चित करना शामिल है कि हम हमेशा स्पष्ट हैं कि AI का उपयोग किया जा रहा है। इसके अलावा, जहां भी संभव हो, हम ऐसे AI सिस्टम का उपयोग करना चाहते हैं जो *व्याख्यात्मक* हों।
* **जवाबदेही**। जब AI मॉडल कुछ निर्णय लेते हैं, तो यह हमेशा स्पष्ट नहीं होता कि उन निर्णयों के लिए कौन जिम्मेदार है। हमें यह सुनिश्चित करना चाहिए कि हम समझते हैं कि AI निर्णयों की जिम्मेदारी कहां है। अधिकांश मामलों में हम महत्वपूर्ण निर्णय लेने की प्रक्रिया में मानव को शामिल करना चाहेंगे, ताकि वास्तविक लोगों को जवाबदेह ठहराया जा सके।

## जिम्मेदार AI के लिए उपकरण

Microsoft ने [जिम्मेदार AI टूलबॉक्स](https://github.com/microsoft/responsible-ai-toolbox) विकसित किया है जिसमें उपकरणों का एक सेट शामिल है:

* व्याख्यात्मकता डैशबोर्ड (InterpretML)
* निष्पक्षता डैशबोर्ड (FairLearn)
* त्रुटि विश्लेषण डैशबोर्ड
* जिम्मेदार AI डैशबोर्ड जिसमें शामिल हैं:

   - EconML - कारण विश्लेषण के लिए उपकरण, जो "क्या होगा अगर" प्रश्नों पर केंद्रित है
   - DiCE - प्रतिवाद विश्लेषण के लिए उपकरण जो आपको यह देखने की अनुमति देता है कि मॉडल के निर्णय को प्रभावित करने के लिए किन विशेषताओं को बदलने की आवश्यकता है

AI नैतिकता के बारे में अधिक जानकारी के लिए, कृपया मशीन लर्निंग पाठ्यक्रम में [इस पाठ](https://github.com/microsoft/ML-For-Beginners/tree/main/1-Introduction/3-fairness?WT.mc_id=academic-77998-cacaste) पर जाएं जिसमें असाइनमेंट शामिल हैं।

## समीक्षा और स्व-अध्ययन

जिम्मेदार AI के बारे में अधिक जानने के लिए इस [लर्न पाथ](https://docs.microsoft.com/learn/modules/responsible-ai-principles/?WT.mc_id=academic-77998-cacaste) को लें।

## [पोस्ट-लेक्चर क्विज़](https://white-water-09ec41f0f.azurestaticapps.net/quiz/6/)

**अस्वीकरण**:  
यह दस्तावेज़ AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) का उपयोग करके अनुवादित किया गया है। जबकि हम सटीकता के लिए प्रयासरत हैं, कृपया ध्यान दें कि स्वचालित अनुवाद में त्रुटियां या अशुद्धियां हो सकती हैं। मूल भाषा में उपलब्ध मूल दस्तावेज़ को प्रामाणिक स्रोत माना जाना चाहिए। महत्वपूर्ण जानकारी के लिए, पेशेवर मानव अनुवाद की सिफारिश की जाती है। इस अनुवाद के उपयोग से उत्पन्न किसी भी गलतफहमी या गलत व्याख्या के लिए हम उत्तरदायी नहीं हैं।