<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7bd8dc72040e98e35e7225e34058cd4e",
  "translation_date": "2025-08-24T09:58:55+00:00",
  "source_file": "lessons/6-Other/22-DeepRL/lab/README.md",
  "language_code": "hi"
}
-->
## पर्यावरण

Mountain Car पर्यावरण में एक कार होती है जो एक घाटी में फंसी होती है। आपका लक्ष्य है घाटी से बाहर कूदकर झंडे तक पहुंचना। आप जो क्रियाएं कर सकते हैं, वे हैं बाईं ओर तेज़ करना, दाईं ओर तेज़ करना, या कुछ भी न करना। आप कार की स्थिति को x-अक्ष पर और उसकी गति को देख सकते हैं।

## प्रारंभिक नोटबुक

इस प्रयोगशाला को शुरू करने के लिए [MountainCar.ipynb](../../../../../../lessons/6-Other/22-DeepRL/lab/MountainCar.ipynb) खोलें।

## मुख्य सीख

इस प्रयोगशाला के दौरान आपको यह समझ में आना चाहिए कि RL एल्गोरिदम को किसी नए पर्यावरण में अपनाना अक्सर काफी सरल होता है, क्योंकि OpenAI Gym का सभी पर्यावरणों के लिए एक समान इंटरफ़ेस होता है, और एल्गोरिदम आमतौर पर पर्यावरण की प्रकृति पर अधिक निर्भर नहीं करते। आप यहां तक कि Python कोड को इस तरह से पुनर्गठित कर सकते हैं कि किसी भी पर्यावरण को RL एल्गोरिदम में एक पैरामीटर के रूप में पास किया जा सके।

**अस्वीकरण**:  
यह दस्तावेज़ AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) का उपयोग करके अनुवादित किया गया है। जबकि हम सटीकता सुनिश्चित करने का प्रयास करते हैं, कृपया ध्यान दें कि स्वचालित अनुवाद में त्रुटियां या अशुद्धियां हो सकती हैं। मूल भाषा में उपलब्ध मूल दस्तावेज़ को प्रामाणिक स्रोत माना जाना चाहिए। महत्वपूर्ण जानकारी के लिए, पेशेवर मानव अनुवाद की सिफारिश की जाती है। इस अनुवाद के उपयोग से उत्पन्न किसी भी गलतफहमी या गलत व्याख्या के लिए हम उत्तरदायी नहीं हैं।