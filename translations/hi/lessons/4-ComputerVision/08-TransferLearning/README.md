<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "717775c4050ccbffbe0c961ad8bf7bf7",
  "translation_date": "2025-08-24T09:56:09+00:00",
  "source_file": "lessons/4-ComputerVision/08-TransferLearning/README.md",
  "language_code": "hi"
}
-->
# प्री-ट्रेंड नेटवर्क्स और ट्रांसफर लर्निंग

CNNs को ट्रेन करना बहुत समय ले सकता है, और इसके लिए बहुत सारे डेटा की आवश्यकता होती है। हालांकि, अधिकांश समय नेटवर्क को उन सर्वोत्तम लो-लेवल फिल्टर्स को सीखने में लगता है, जो इमेज से पैटर्न निकालने में मदद करते हैं। एक स्वाभाविक सवाल उठता है - क्या हम एक डेटासेट पर ट्रेन किए गए न्यूरल नेटवर्क का उपयोग करके इसे अलग-अलग इमेज को वर्गीकृत करने के लिए अनुकूलित कर सकते हैं, बिना पूरे ट्रेनिंग प्रक्रिया की आवश्यकता के?

## [प्री-लेक्चर क्विज़](https://ff-quizzes.netlify.app/en/ai/quiz/15)

इस दृष्टिकोण को **ट्रांसफर लर्निंग** कहा जाता है, क्योंकि हम एक न्यूरल नेटवर्क मॉडल से दूसरे में कुछ ज्ञान ट्रांसफर करते हैं। ट्रांसफर लर्निंग में, हम आमतौर पर एक प्री-ट्रेंड मॉडल से शुरू करते हैं, जिसे किसी बड़े इमेज डेटासेट, जैसे **ImageNet**, पर ट्रेन किया गया होता है। ये मॉडल पहले से ही सामान्य इमेज से विभिन्न फीचर्स निकालने में अच्छा काम कर सकते हैं, और कई मामलों में उन निकाले गए फीचर्स के ऊपर एक क्लासिफायर बनाना अच्छे परिणाम दे सकता है।

> ✅ ट्रांसफर लर्निंग एक ऐसा शब्द है जिसे आप अन्य शैक्षणिक क्षेत्रों, जैसे शिक्षा, में भी पाते हैं। इसका मतलब है एक क्षेत्र से ज्ञान लेकर उसे दूसरे क्षेत्र में लागू करना।

## प्री-ट्रेंड मॉडल्स को फीचर एक्सट्रैक्टर्स के रूप में उपयोग करना

पिछले सेक्शन में हमने जिन कॉन्वोल्यूशनल नेटवर्क्स के बारे में बात की थी, उनमें कई लेयर्स होती हैं, जिनमें से प्रत्येक इमेज से कुछ फीचर्स निकालने के लिए होती है। ये लो-लेवल पिक्सल संयोजन (जैसे क्षैतिज/वर्टिकल लाइन या स्ट्रोक) से शुरू होकर उच्च-स्तरीय फीचर्स तक जाती हैं, जो किसी चीज़ जैसे आग की आंख का प्रतिनिधित्व करती हैं। यदि हम CNN को पर्याप्त बड़े और विविध इमेज डेटासेट पर ट्रेन करें, तो नेटवर्क को उन सामान्य फीचर्स को निकालना सीखना चाहिए।

Keras और PyTorch दोनों में कुछ सामान्य आर्किटेक्चर के लिए प्री-ट्रेंड न्यूरल नेटवर्क वेट्स को आसानी से लोड करने के लिए फंक्शन्स होती हैं, जिनमें से अधिकांश को ImageNet इमेज पर ट्रेन किया गया है। सबसे अधिक उपयोग किए जाने वाले मॉडल्स को पिछले लेसन के [CNN Architectures](../07-ConvNets/CNN_Architectures.md) पेज पर वर्णित किया गया है। विशेष रूप से, आप निम्नलिखित में से किसी एक का उपयोग करने पर विचार कर सकते हैं:

* **VGG-16/VGG-19** जो अपेक्षाकृत सरल मॉडल हैं और फिर भी अच्छी सटीकता देते हैं। अक्सर VGG का उपयोग करना एक अच्छा विकल्प होता है यह देखने के लिए कि ट्रांसफर लर्निंग कैसे काम कर रही है।
* **ResNet** माइक्रोसॉफ्ट रिसर्च द्वारा 2015 में प्रस्तावित मॉडल्स का एक परिवार है। इनमें अधिक लेयर्स होती हैं, और इसलिए अधिक संसाधनों की आवश्यकता होती है।
* **MobileNet** छोटे आकार वाले मॉडल्स का एक परिवार है, जो मोबाइल डिवाइस के लिए उपयुक्त हैं। इन्हें तब उपयोग करें जब आपके पास संसाधनों की कमी हो और आप थोड़ी सटीकता का त्याग कर सकते हों।

यहां VGG-16 नेटवर्क द्वारा एक बिल्ली की तस्वीर से निकाले गए फीचर्स का एक नमूना है:

![VGG-16 द्वारा निकाले गए फीचर्स](../../../../../lessons/4-ComputerVision/08-TransferLearning/images/features.png)

## कैट्स बनाम डॉग्स डेटासेट

इस उदाहरण में, हम [Cats and Dogs](https://www.microsoft.com/download/details.aspx?id=54765&WT.mc_id=academic-77998-cacaste) डेटासेट का उपयोग करेंगे, जो एक वास्तविक जीवन इमेज क्लासिफिकेशन परिदृश्य के बहुत करीब है।

## ✍️ अभ्यास: ट्रांसफर लर्निंग

आइए संबंधित नोटबुक्स में ट्रांसफर लर्निंग को क्रियान्वित होते हुए देखें:

* [ट्रांसफर लर्निंग - PyTorch](../../../../../lessons/4-ComputerVision/08-TransferLearning/TransferLearningPyTorch.ipynb)
* [ट्रांसफर लर्निंग - TensorFlow](../../../../../lessons/4-ComputerVision/08-TransferLearning/TransferLearningTF.ipynb)

## एडवर्सेरियल कैट को विज़ुअलाइज़ करना

प्री-ट्रेंड न्यूरल नेटवर्क के "ब्रेन" में विभिन्न पैटर्न होते हैं, जिनमें **आदर्श बिल्ली** (साथ ही आदर्श कुत्ता, आदर्श ज़ेबरा, आदि) की धारणा शामिल होती है। इसे किसी तरह **विज़ुअलाइज़ करना** दिलचस्प होगा। हालांकि, यह आसान नहीं है, क्योंकि पैटर्न पूरे नेटवर्क वेट्स में फैले हुए हैं और एक पदानुक्रमित संरचना में व्यवस्थित हैं।

एक दृष्टिकोण जो हम अपना सकते हैं वह है एक रैंडम इमेज से शुरू करना, और फिर **ग्रेडिएंट डिसेंट ऑप्टिमाइज़ेशन** तकनीक का उपयोग करके उस इमेज को इस तरह से समायोजित करना कि नेटवर्क इसे बिल्ली मानने लगे।

![इमेज ऑप्टिमाइज़ेशन लूप](../../../../../lessons/4-ComputerVision/08-TransferLearning/images/ideal-cat-loop.png)

हालांकि, यदि हम ऐसा करते हैं, तो हमें कुछ ऐसा मिलेगा जो रैंडम नॉइज़ के समान है। ऐसा इसलिए है क्योंकि *नेटवर्क को यह सोचने के लिए कई तरीके हैं कि इनपुट इमेज एक बिल्ली है*, जिनमें से कुछ दृश्य रूप से समझ में नहीं आते। जबकि उन इमेज में बिल्ली के लिए विशिष्ट कई पैटर्न होते हैं, उन्हें दृश्य रूप से विशिष्ट बनाने के लिए कुछ भी बाध्य नहीं करता।

परिणाम को बेहतर बनाने के लिए, हम लॉस फंक्शन में एक और टर्म जोड़ सकते हैं, जिसे **वेरिएशन लॉस** कहा जाता है। यह एक मीट्रिक है जो दिखाता है कि इमेज के पड़ोसी पिक्सल कितने समान हैं। वेरिएशन लॉस को कम करने से इमेज स्मूथ हो जाती है और नॉइज़ खत्म हो जाता है - जिससे अधिक दृश्य रूप से आकर्षक पैटर्न सामने आते हैं। यहां ऐसे "आदर्श" इमेज का एक उदाहरण है, जिन्हें उच्च संभावना के साथ बिल्ली और ज़ेबरा के रूप में वर्गीकृत किया गया है:

![आदर्श बिल्ली](../../../../../lessons/4-ComputerVision/08-TransferLearning/images/ideal-cat.png) | ![आदर्श ज़ेबरा](../../../../../lessons/4-ComputerVision/08-TransferLearning/images/ideal-zebra.png)
-----|-----
 *आदर्श बिल्ली* | *आदर्श ज़ेबरा*

इसी दृष्टिकोण का उपयोग तथाकथित **एडवर्सेरियल अटैक्स** करने के लिए किया जा सकता है। मान लें कि हम एक न्यूरल नेटवर्क को धोखा देना चाहते हैं और एक कुत्ते को बिल्ली की तरह दिखाना चाहते हैं। यदि हम कुत्ते की इमेज लें, जिसे नेटवर्क द्वारा कुत्ते के रूप में पहचाना जाता है, तो हम इसे थोड़ा सा समायोजित कर सकते हैं, जब तक कि नेटवर्क इसे बिल्ली के रूप में वर्गीकृत करना शुरू न कर दे:

![कुत्ते की तस्वीर](../../../../../lessons/4-ComputerVision/08-TransferLearning/images/original-dog.png) | ![कुत्ते की तस्वीर जिसे बिल्ली के रूप में वर्गीकृत किया गया](../../../../../lessons/4-ComputerVision/08-TransferLearning/images/adversarial-dog.png)
-----|-----
*कुत्ते की मूल तस्वीर* | *कुत्ते की तस्वीर जिसे बिल्ली के रूप में वर्गीकृत किया गया*

ऊपर दिए गए परिणामों को पुन: उत्पन्न करने के लिए कोड निम्नलिखित नोटबुक में देखें:

* [आदर्श और एडवर्सेरियल बिल्ली - TensorFlow](../../../../../lessons/4-ComputerVision/08-TransferLearning/AdversarialCat_TF.ipynb)

## निष्कर्ष

ट्रांसफर लर्निंग का उपयोग करके, आप कस्टम ऑब्जेक्ट क्लासिफिकेशन टास्क के लिए जल्दी से एक क्लासिफायर बना सकते हैं और उच्च सटीकता प्राप्त कर सकते हैं। आप देख सकते हैं कि अब हम जो अधिक जटिल कार्य हल कर रहे हैं, उन्हें उच्च कंप्यूटेशनल पावर की आवश्यकता होती है और उन्हें आसानी से CPU पर हल नहीं किया जा सकता। अगले यूनिट में, हम कम कंप्यूट संसाधनों का उपयोग करके उसी मॉडल को ट्रेन करने के लिए एक अधिक हल्का कार्यान्वयन उपयोग करने का प्रयास करेंगे, जिसके परिणामस्वरूप सटीकता में केवल थोड़ा सा कमी आएगी।

## 🚀 चुनौती

संबंधित नोटबुक्स में, नीचे नोट्स हैं कि ट्रांसफर ज्ञान समान ट्रेनिंग डेटा (शायद एक नए प्रकार के जानवर) के साथ सबसे अच्छा काम करता है। पूरी तरह से नए प्रकार की इमेज के साथ कुछ प्रयोग करें यह देखने के लिए कि आपके ट्रांसफर ज्ञान मॉडल कितनी अच्छी या खराब प्रदर्शन करते हैं।

## [पोस्ट-लेक्चर क्विज़](https://ff-quizzes.netlify.app/en/ai/quiz/16)

## समीक्षा और स्व-अध्ययन

[TrainingTricks.md](TrainingTricks.md) को पढ़ें ताकि आप अपने मॉडल्स को ट्रेन करने के अन्य तरीकों के बारे में अधिक जानकारी प्राप्त कर सकें।

## [असाइनमेंट](lab/README.md)

इस लैब में, हम वास्तविक जीवन [Oxford-IIIT](https://www.robots.ox.ac.uk/~vgg/data/pets/) पालतू जानवरों के डेटासेट का उपयोग करेंगे जिसमें 35 नस्लों की बिल्लियाँ और कुत्ते शामिल हैं, और हम एक ट्रांसफर लर्निंग क्लासिफायर बनाएंगे।

**अस्वीकरण**:  
यह दस्तावेज़ AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) का उपयोग करके अनुवादित किया गया है। जबकि हम सटीकता सुनिश्चित करने का प्रयास करते हैं, कृपया ध्यान दें कि स्वचालित अनुवाद में त्रुटियां या अशुद्धियां हो सकती हैं। मूल भाषा में उपलब्ध मूल दस्तावेज़ को प्रामाणिक स्रोत माना जाना चाहिए। महत्वपूर्ण जानकारी के लिए, पेशेवर मानव अनुवाद की सिफारिश की जाती है। इस अनुवाद के उपयोग से उत्पन्न किसी भी गलतफहमी या गलत व्याख्या के लिए हम उत्तरदायी नहीं हैं।