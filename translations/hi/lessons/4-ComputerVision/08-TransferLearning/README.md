<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "178c0b5ee5395733eb18aec51e71a0a9",
  "translation_date": "2025-09-23T13:28:51+00:00",
  "source_file": "lessons/4-ComputerVision/08-TransferLearning/README.md",
  "language_code": "hi"
}
-->
# प्री-ट्रेंड नेटवर्क्स और ट्रांसफर लर्निंग

CNNs को ट्रेन करने में काफी समय लग सकता है, और इसके लिए बहुत सारे डेटा की आवश्यकता होती है। हालांकि, अधिकांश समय नेटवर्क को उन सर्वोत्तम लो-लेवल फिल्टर्स को सीखने में लगता है, जो इमेज से पैटर्न निकालने में मदद करते हैं। एक स्वाभाविक सवाल उठता है - क्या हम एक डेटासेट पर ट्रेन किए गए न्यूरल नेटवर्क का उपयोग करके इसे अलग-अलग इमेज को वर्गीकृत करने के लिए अनुकूलित कर सकते हैं, बिना पूरे ट्रेनिंग प्रक्रिया की आवश्यकता के?

## [प्री-लेक्चर क्विज़](https://ff-quizzes.netlify.app/en/ai/quiz/15)

इस दृष्टिकोण को **ट्रांसफर लर्निंग** कहा जाता है, क्योंकि हम एक न्यूरल नेटवर्क मॉडल से दूसरे में कुछ ज्ञान ट्रांसफर करते हैं। ट्रांसफर लर्निंग में, हम आमतौर पर एक प्री-ट्रेंड मॉडल से शुरू करते हैं, जिसे किसी बड़े इमेज डेटासेट, जैसे **ImageNet**, पर ट्रेन किया गया होता है। ये मॉडल पहले से ही सामान्य इमेज से विभिन्न फीचर्स निकालने में अच्छा काम कर सकते हैं, और कई मामलों में उन निकाले गए फीचर्स के ऊपर एक क्लासिफायर बनाना अच्छे परिणाम दे सकता है।

> ✅ ट्रांसफर लर्निंग एक ऐसा शब्द है जिसे आप अन्य शैक्षणिक क्षेत्रों, जैसे शिक्षा, में भी पाते हैं। इसका मतलब है एक क्षेत्र से ज्ञान लेकर उसे दूसरे क्षेत्र में लागू करना।

## प्री-ट्रेंड मॉडल्स को फीचर एक्सट्रैक्टर्स के रूप में उपयोग करना

पिछले सेक्शन में हमने जिन कॉन्वोल्यूशनल नेटवर्क्स के बारे में बात की थी, उनमें कई लेयर्स होती हैं, जिनमें से प्रत्येक इमेज से कुछ फीचर्स निकालने का काम करती है। यह प्रक्रिया लो-लेवल पिक्सल संयोजनों (जैसे क्षैतिज/वर्टिकल लाइन या स्ट्रोक) से शुरू होकर उच्च-स्तरीय फीचर्स तक जाती है, जो किसी चीज़ जैसे आग की आंख से संबंधित हो सकते हैं। यदि हम CNN को पर्याप्त बड़े और विविध इमेज डेटासेट पर ट्रेन करें, तो नेटवर्क को उन सामान्य फीचर्स को निकालना सीखना चाहिए।

Keras और PyTorch दोनों में कुछ सामान्य आर्किटेक्चर के लिए प्री-ट्रेंड न्यूरल नेटवर्क वेट्स को आसानी से लोड करने के लिए फंक्शन्स उपलब्ध हैं, जिनमें से अधिकांश ImageNet इमेज पर ट्रेन किए गए हैं। सबसे अधिक उपयोग किए जाने वाले आर्किटेक्चर पिछले पाठ के [CNN Architectures](../07-ConvNets/CNN_Architectures.md) पेज पर वर्णित हैं। विशेष रूप से, आप निम्नलिखित में से किसी एक का उपयोग करने पर विचार कर सकते हैं:

* **VGG-16/VGG-19** जो अपेक्षाकृत सरल मॉडल हैं और फिर भी अच्छी सटीकता प्रदान करते हैं। अक्सर VGG का उपयोग करना एक अच्छा विकल्प होता है यह देखने के लिए कि ट्रांसफर लर्निंग कैसे काम कर रही है।
* **ResNet** माइक्रोसॉफ्ट रिसर्च द्वारा 2015 में प्रस्तावित मॉडल्स का एक परिवार है। इनमें अधिक लेयर्स होती हैं, और इसलिए अधिक संसाधनों की आवश्यकता होती है।
* **MobileNet** छोटे आकार वाले मॉडल्स का एक परिवार है, जो मोबाइल डिवाइस के लिए उपयुक्त हैं। इन्हें तब उपयोग करें जब आपके पास संसाधनों की कमी हो और आप थोड़ी सटीकता का त्याग कर सकते हों।

यहाँ VGG-16 नेटवर्क द्वारा एक बिल्ली की तस्वीर से निकाले गए फीचर्स का एक उदाहरण है:

![VGG-16 द्वारा निकाले गए फीचर्स](../../../../../translated_images/features.6291f9c7ba3a0b951af88fc9864632b9115365410765680680d30c927dd67354.hi.png)

## कैट्स बनाम डॉग्स डेटासेट

इस उदाहरण में, हम [Cats and Dogs](https://www.microsoft.com/download/details.aspx?id=54765&WT.mc_id=academic-77998-cacaste) डेटासेट का उपयोग करेंगे, जो एक वास्तविक जीवन इमेज क्लासिफिकेशन परिदृश्य के बहुत करीब है।

## ✍️ अभ्यास: ट्रांसफर लर्निंग

आइए संबंधित नोटबुक्स में ट्रांसफर लर्निंग को क्रियान्वित होते हुए देखें:

* [ट्रांसफर लर्निंग - PyTorch](TransferLearningPyTorch.ipynb)
* [ट्रांसफर लर्निंग - TensorFlow](TransferLearningTF.ipynb)

## एडवर्सेरियल कैट को विज़ुअलाइज़ करना

प्री-ट्रेंड न्यूरल नेटवर्क के "ब्रेन" में विभिन्न पैटर्न होते हैं, जिनमें **आदर्श बिल्ली** (साथ ही आदर्श कुत्ता, आदर्श ज़ेब्रा, आदि) की धारणा शामिल होती है। इसे किसी तरह **विज़ुअलाइज़ करना** दिलचस्प होगा। हालांकि, यह आसान नहीं है, क्योंकि पैटर्न पूरे नेटवर्क वेट्स में फैले हुए हैं और एक पदानुक्रमित संरचना में व्यवस्थित हैं।

एक दृष्टिकोण यह हो सकता है कि हम एक रैंडम इमेज से शुरू करें, और फिर **ग्रेडिएंट डिसेंट ऑप्टिमाइज़ेशन** तकनीक का उपयोग करके उस इमेज को इस तरह से समायोजित करें कि नेटवर्क इसे बिल्ली मानने लगे।

![इमेज ऑप्टिमाइज़ेशन लूप](../../../../../translated_images/ideal-cat-loop.999fbb8ff306e044f997032f4eef9152b453e6a990e449bbfb107de2493cc37e.hi.png)

हालांकि, यदि हम ऐसा करते हैं, तो हमें कुछ ऐसा मिलेगा जो रैंडम नॉइज़ के बहुत करीब होगा। ऐसा इसलिए है क्योंकि *नेटवर्क को यह सोचने के लिए कई तरीके हैं कि इनपुट इमेज एक बिल्ली है*, जिनमें से कुछ दृश्य रूप से समझ में नहीं आते। जबकि उन इमेज में बिल्ली के लिए विशिष्ट कई पैटर्न होते हैं, उन्हें दृश्य रूप से विशिष्ट बनाने के लिए कुछ भी बाध्य नहीं करता।

परिणाम को बेहतर बनाने के लिए, हम लॉस फंक्शन में एक और टर्म जोड़ सकते हैं, जिसे **वेरिएशन लॉस** कहा जाता है। यह एक मीट्रिक है जो दिखाता है कि इमेज के पड़ोसी पिक्सल कितने समान हैं। वेरिएशन लॉस को कम करने से इमेज स्मूथ हो जाती है और नॉइज़ हट जाता है - जिससे अधिक दृश्य रूप से आकर्षक पैटर्न सामने आते हैं। यहाँ ऐसे "आदर्श" इमेज का एक उदाहरण है, जिन्हें उच्च संभावना के साथ बिल्ली और ज़ेब्रा के रूप में वर्गीकृत किया गया है:

![आदर्श बिल्ली](../../../../../translated_images/ideal-cat.203dd4597643d6b0bd73038b87f9c0464322725e3a06ab145d25d4a861c70592.hi.png) | ![आदर्श ज़ेब्रा](../../../../../translated_images/ideal-zebra.7f70e8b54ee15a7a314000bb5df38a6cfe086ea04d60df4d3ef313d046b98a2b.hi.png)
-----|-----
 *आदर्श बिल्ली* | *आदर्श ज़ेब्रा*

इसी तरह का दृष्टिकोण तथाकथित **एडवर्सेरियल अटैक्स** करने के लिए उपयोग किया जा सकता है। मान लें कि हम एक न्यूरल नेटवर्क को धोखा देना चाहते हैं और कुत्ते को बिल्ली जैसा दिखाना चाहते हैं। यदि हम कुत्ते की इमेज लें, जिसे नेटवर्क द्वारा कुत्ते के रूप में पहचाना जाता है, तो हम इसे थोड़ा सा समायोजित कर सकते हैं, जब तक कि नेटवर्क इसे बिल्ली के रूप में वर्गीकृत करना शुरू न कर दे:

![कुत्ते की तस्वीर](../../../../../translated_images/original-dog.8f68a67d2fe0911f33041c0f7fce8aa4ea919f9d3917ec4b468298522aeb6356.hi.png) | ![कुत्ते की तस्वीर जिसे बिल्ली के रूप में वर्गीकृत किया गया](../../../../../translated_images/adversarial-dog.d9fc7773b0142b89752539bfbf884118de845b3851c5162146ea0b8809fc820f.hi.png)
-----|-----
*कुत्ते की मूल तस्वीर* | *कुत्ते की तस्वीर जिसे बिल्ली के रूप में वर्गीकृत किया गया*

ऊपर दिए गए परिणामों को पुन: उत्पन्न करने के लिए कोड निम्नलिखित नोटबुक में देखें:

* [आदर्श और एडवर्सेरियल बिल्ली - TensorFlow](AdversarialCat_TF.ipynb)

## निष्कर्ष

ट्रांसफर लर्निंग का उपयोग करके, आप कस्टम ऑब्जेक्ट क्लासिफिकेशन टास्क के लिए जल्दी से एक क्लासिफायर बना सकते हैं और उच्च सटीकता प्राप्त कर सकते हैं। आप देख सकते हैं कि अब हम जो अधिक जटिल कार्य हल कर रहे हैं, उन्हें उच्च कंप्यूटेशनल पावर की आवश्यकता है, और उन्हें आसानी से CPU पर हल नहीं किया जा सकता। अगले यूनिट में, हम कम कंप्यूट संसाधनों का उपयोग करके उसी मॉडल को ट्रेन करने के लिए एक अधिक हल्का कार्यान्वयन उपयोग करने का प्रयास करेंगे, जिसके परिणामस्वरूप सटीकता में केवल थोड़ा सा कमी आएगी।

## 🚀 चुनौती

साथ वाले नोटबुक्स में, नीचे नोट्स दिए गए हैं कि ट्रांसफर ज्ञान समान ट्रेनिंग डेटा (शायद एक नए प्रकार के जानवर) के साथ सबसे अच्छा काम करता है। पूरी तरह से नए प्रकार की इमेज के साथ कुछ प्रयोग करें यह देखने के लिए कि आपके ट्रांसफर ज्ञान मॉडल कितनी अच्छी या खराब प्रदर्शन करते हैं।

## [पोस्ट-लेक्चर क्विज़](https://ff-quizzes.netlify.app/en/ai/quiz/16)

## समीक्षा और स्व-अध्ययन

[TrainingTricks.md](TrainingTricks.md) को पढ़ें ताकि आप अपने मॉडल को ट्रेन करने के अन्य तरीकों के बारे में अधिक जानकारी प्राप्त कर सकें।

## [असाइनमेंट](lab/README.md)

इस लैब में, हम वास्तविक जीवन [Oxford-IIIT](https://www.robots.ox.ac.uk/~vgg/data/pets/) पालतू जानवरों के डेटासेट का उपयोग करेंगे जिसमें 35 नस्लों की बिल्लियाँ और कुत्ते शामिल हैं, और हम एक ट्रांसफर लर्निंग क्लासिफायर बनाएंगे।

---

