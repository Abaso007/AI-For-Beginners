<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f07c85bbf05a1f67505da98f4ecc124c",
  "translation_date": "2025-08-24T09:53:16+00:00",
  "source_file": "lessons/4-ComputerVision/10-GANs/README.md",
  "language_code": "hi"
}
-->
# जनरेटिव एडवर्सेरियल नेटवर्क्स

पिछले सेक्शन में, हमने **जनरेटिव मॉडल्स** के बारे में सीखा: ऐसे मॉडल्स जो ट्रेनिंग डेटा सेट में मौजूद इमेजेज़ के समान नई इमेजेज़ जनरेट कर सकते हैं। VAE इसका एक अच्छा उदाहरण था।

## [प्री-लेक्चर क्विज़](https://ff-quizzes.netlify.app/en/ai/quiz/19)

हालांकि, अगर हम कुछ वास्तव में अर्थपूर्ण जनरेट करने की कोशिश करें, जैसे कि एक पेंटिंग उचित रिज़ॉल्यूशन पर, तो VAE के साथ ट्रेनिंग अच्छी तरह से कन्वर्ज नहीं होती। इस उपयोग के लिए, हमें एक और आर्किटेक्चर के बारे में सीखना चाहिए जो विशेष रूप से जनरेटिव मॉडल्स के लिए डिज़ाइन किया गया है - **जनरेटिव एडवर्सेरियल नेटवर्क्स**, या GANs।

GAN का मुख्य विचार दो न्यूरल नेटवर्क्स को एक-दूसरे के खिलाफ ट्रेन करना है:

<img src="images/gan_architecture.png" width="70%"/>

> चित्र: [दिमित्री सोश्निकोव](http://soshnikov.com)

> ✅ कुछ शब्दावली:
> * **जनरेटर**: यह एक नेटवर्क है जो एक रैंडम वेक्टर लेता है और परिणामस्वरूप एक इमेज जनरेट करता है।
> * **डिस्क्रिमिनेटर**: यह एक नेटवर्क है जो एक इमेज लेता है और यह तय करता है कि वह इमेज असली है (ट्रेनिंग डेटा सेट से) या जनरेटर द्वारा बनाई गई है। यह मूल रूप से एक इमेज क्लासिफायर है।

### डिस्क्रिमिनेटर

डिस्क्रिमिनेटर की आर्किटेक्चर एक साधारण इमेज क्लासिफिकेशन नेटवर्क से अलग नहीं होती। सबसे सरल मामले में, यह एक फुली-कनेक्टेड क्लासिफायर हो सकता है, लेकिन अधिकतर यह एक [कन्वोल्यूशनल नेटवर्क](../07-ConvNets/README.md) होगा।

> ✅ एक कन्वोल्यूशनल नेटवर्क पर आधारित GAN को [DCGAN](https://arxiv.org/pdf/1511.06434.pdf) कहा जाता है।

एक CNN डिस्क्रिमिनेटर में निम्नलिखित लेयर्स होती हैं: कई कन्वोल्यूशंस+पूलिंग्स (स्पैटियल साइज को घटाते हुए) और, एक या अधिक फुली-कनेक्टेड लेयर्स जो "फीचर वेक्टर" बनाती हैं, और अंत में एक बाइनरी क्लासिफायर।

> ✅ 'पूलिंग' एक तकनीक है जो इमेज का साइज घटाती है। "पूलिंग लेयर्स डेटा के डाइमेंशन्स को घटाकर एक लेयर के न्यूरॉन क्लस्टर्स के आउटपुट को अगली लेयर के एक न्यूरॉन में जोड़ देती हैं।" - [स्रोत](https://wikipedia.org/wiki/Convolutional_neural_network#Pooling_layers)

### जनरेटर

जनरेटर थोड़ा अधिक जटिल होता है। इसे आप एक उल्टे डिस्क्रिमिनेटर के रूप में समझ सकते हैं। यह एक लेटेंट वेक्टर (फीचर वेक्टर की जगह) से शुरू होता है, जिसमें एक फुली-कनेक्टेड लेयर होती है जो इसे आवश्यक साइज/शेप में बदलती है, और उसके बाद डी-कन्वोल्यूशंस+अपस्केलिंग होती है। यह [ऑटोएन्कोडर](../09-Autoencoders/README.md) के *डिकोडर* भाग के समान है।

> ✅ क्योंकि कन्वोल्यूशन लेयर को एक लीनियर फिल्टर के रूप में इमेज पर लागू किया जाता है, डी-कन्वोल्यूशन मूल रूप से कन्वोल्यूशन के समान है और इसे समान लेयर लॉजिक का उपयोग करके लागू किया जा सकता है।

<img src="images/gan_arch_detail.png" width="70%"/>

> चित्र: [दिमित्री सोश्निकोव](http://soshnikov.com)

### GAN की ट्रेनिंग

GANs को **एडवर्सेरियल** कहा जाता है क्योंकि जनरेटर और डिस्क्रिमिनेटर के बीच लगातार प्रतिस्पर्धा होती है। इस प्रतिस्पर्धा के दौरान, दोनों जनरेटर और डिस्क्रिमिनेटर में सुधार होता है, जिससे नेटवर्क बेहतर और बेहतर इमेजेज़ बनाना सीखता है।

ट्रेनिंग दो चरणों में होती है:

* **डिस्क्रिमिनेटर की ट्रेनिंग**। यह कार्य काफी सीधा है: हम जनरेटर द्वारा बनाई गई इमेजेज़ का एक बैच जनरेट करते हैं, उन्हें 0 लेबल करते हैं (जो नकली इमेज के लिए है), और इनपुट डेटा सेट से इमेजेज़ का एक बैच लेते हैं (लेबल 1, असली इमेज के साथ)। हम कुछ *डिस्क्रिमिनेटर लॉस* प्राप्त करते हैं और बैकप्रॉप करते हैं।
* **जनरेटर की ट्रेनिंग**। यह थोड़ा अधिक जटिल है, क्योंकि हमें जनरेटर के लिए अपेक्षित आउटपुट सीधे तौर पर नहीं पता होता। हम पूरे GAN नेटवर्क को, जिसमें जनरेटर और डिस्क्रिमिनेटर शामिल हैं, रैंडम वेक्टर के साथ फीड करते हैं और उम्मीद करते हैं कि परिणाम 1 होगा (जो असली इमेज के लिए है)। फिर हम डिस्क्रिमिनेटर के पैरामीटर्स को फ्रीज़ कर देते हैं (हम इसे इस चरण में ट्रेन नहीं करना चाहते) और बैकप्रॉप करते हैं।

इस प्रक्रिया के दौरान, जनरेटर और डिस्क्रिमिनेटर दोनों के लॉस में कोई महत्वपूर्ण कमी नहीं होती। आदर्श स्थिति में, उन्हें ऑस्सिलेट करना चाहिए, जो दोनों नेटवर्क्स के प्रदर्शन में सुधार को दर्शाता है।

## ✍️ अभ्यास: GANs

* [TensorFlow/Keras में GAN नोटबुक](../../../../../lessons/4-ComputerVision/10-GANs/GANTF.ipynb)
* [PyTorch में GAN नोटबुक](../../../../../lessons/4-ComputerVision/10-GANs/GANPyTorch.ipynb)

### GAN ट्रेनिंग की समस्याएं

GANs को ट्रेन करना विशेष रूप से कठिन माना जाता है। यहां कुछ समस्याएं हैं:

* **मोड कोलैप्स**। इसका मतलब है कि जनरेटर एक सफल इमेज बनाना सीखता है जो डिस्क्रिमिनेटर को धोखा देती है, लेकिन विभिन्न प्रकार की इमेजेज़ नहीं बनाता।
* **हाइपरपैरामीटर्स के प्रति संवेदनशीलता**। अक्सर आप देख सकते हैं कि GAN बिल्कुल भी कन्वर्ज नहीं हो रहा है, और फिर अचानक लर्निंग रेट में कमी के कारण कन्वर्ज हो जाता है।
* जनरेटर और डिस्क्रिमिनेटर के बीच **संतुलन बनाए रखना**। कई मामलों में डिस्क्रिमिनेटर का लॉस जल्दी से शून्य तक गिर सकता है, जिससे जनरेटर आगे ट्रेन नहीं हो पाता। इसे दूर करने के लिए, हम जनरेटर और डिस्क्रिमिनेटर के लिए अलग-अलग लर्निंग रेट सेट कर सकते हैं, या अगर लॉस पहले से ही बहुत कम है तो डिस्क्रिमिनेटर की ट्रेनिंग को स्किप कर सकते हैं।
* **हाई रिज़ॉल्यूशन के लिए ट्रेनिंग**। यह समस्या ऑटोएन्कोडर्स के समान है, क्योंकि बहुत अधिक लेयर्स को रिकंस्ट्रक्ट करने से आर्टिफैक्ट्स उत्पन्न होते हैं। इस समस्या को आमतौर पर **प्रोग्रेसिव ग्रोइंग** के साथ हल किया जाता है, जहां पहले कुछ लेयर्स को लो-रेस इमेजेज़ पर ट्रेन किया जाता है, और फिर लेयर्स को "अनब्लॉक" या जोड़ा जाता है। एक और समाधान लेयर्स के बीच अतिरिक्त कनेक्शन्स जोड़ना और एक साथ कई रिज़ॉल्यूशंस पर ट्रेनिंग करना है - अधिक जानकारी के लिए इस [मल्टी-स्केल ग्रेडिएंट GANs पेपर](https://arxiv.org/abs/1903.06048) को देखें।

## स्टाइल ट्रांसफर

GANs कलात्मक इमेजेज़ जनरेट करने का एक शानदार तरीका है। एक और दिलचस्प तकनीक है जिसे **स्टाइल ट्रांसफर** कहा जाता है, जो एक **कंटेंट इमेज** लेता है और उसे एक अलग स्टाइल में फिर से बनाता है, **स्टाइल इमेज** से फिल्टर्स लागू करते हुए।

यह इस प्रकार काम करता है:
* हम एक रैंडम नॉइज़ इमेज (या एक कंटेंट इमेज) से शुरू करते हैं, लेकिन समझने के लिए रैंडम नॉइज़ से शुरू करना आसान है।
* हमारा लक्ष्य ऐसी इमेज बनाना होगा, जो कंटेंट इमेज और स्टाइल इमेज दोनों के करीब हो। इसे दो लॉस फंक्शन्स द्वारा निर्धारित किया जाएगा:
   - **कंटेंट लॉस**: यह वर्तमान इमेज और कंटेंट इमेज से CNN द्वारा कुछ लेयर्स पर निकाले गए फीचर्स के आधार पर गणना की जाती है।
   - **स्टाइल लॉस**: यह वर्तमान इमेज और स्टाइल इमेज के बीच एक चतुर तरीके से ग्राम मैट्रिसेस का उपयोग करके गणना की जाती है (अधिक विवरण [उदाहरण नोटबुक](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb) में)।
* इमेज को स्मूथ और नॉइज़ को हटाने के लिए, हम **वेरिएशन लॉस** भी जोड़ते हैं, जो पड़ोसी पिक्सल्स के बीच औसत दूरी की गणना करता है।
* मुख्य ऑप्टिमाइजेशन लूप वर्तमान इमेज को एडजस्ट करता है, ताकि कुल लॉस (जो सभी तीन लॉसेस का वेटेड सम है) को कम किया जा सके।

## ✍️ उदाहरण: [स्टाइल ट्रांसफर](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)

## [पोस्ट-लेक्चर क्विज़](https://ff-quizzes.netlify.app/en/ai/quiz/20)

## निष्कर्ष

इस पाठ में, आपने GANs और उन्हें ट्रेन करने के तरीके के बारे में सीखा। आपने यह भी सीखा कि इस प्रकार के न्यूरल नेटवर्क को किन विशेष चुनौतियों का सामना करना पड़ सकता है, और उनसे निपटने के लिए कुछ रणनीतियां।

## 🚀 चुनौती

[स्टाइल ट्रांसफर नोटबुक](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb) को अपनी खुद की इमेजेज़ के साथ चलाएं।

## समीक्षा और स्व-अध्ययन

GANs के बारे में अधिक पढ़ने के लिए इन संसाधनों को देखें:

* मार्को पासिनी, [10 Lessons I Learned Training GANs for one Year](https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628)
* [StyleGAN](https://en.wikipedia.org/wiki/StyleGAN), एक *डि फैक्टो* GAN आर्किटेक्चर जिसे विचार करना चाहिए।
* [Azure ML पर GANs का उपयोग करके जनरेटिव आर्ट बनाना](https://soshnikov.com/scienceart/creating-generative-art-using-gan-on-azureml/)

## असाइनमेंट

इस पाठ से संबंधित दो नोटबुक्स में से एक को फिर से देखें और GAN को अपनी खुद की इमेजेज़ पर फिर से ट्रेन करें। आप क्या बना सकते हैं?

**अस्वीकरण**:  
यह दस्तावेज़ AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) का उपयोग करके अनुवादित किया गया है। जबकि हम सटीकता के लिए प्रयासरत हैं, कृपया ध्यान दें कि स्वचालित अनुवाद में त्रुटियां या अशुद्धियां हो सकती हैं। मूल भाषा में उपलब्ध मूल दस्तावेज़ को प्रामाणिक स्रोत माना जाना चाहिए। महत्वपूर्ण जानकारी के लिए, पेशेवर मानव अनुवाद की सिफारिश की जाती है। इस अनुवाद के उपयोग से उत्पन्न किसी भी गलतफहमी या गलत व्याख्या के लिए हम उत्तरदायी नहीं हैं।