<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "088837b42b7d99198bf62db8a42411e0",
  "translation_date": "2025-08-24T09:54:34+00:00",
  "source_file": "lessons/4-ComputerVision/07-ConvNets/README.md",
  "language_code": "hi"
}
-->
# कॉन्वोल्यूशनल न्यूरल नेटवर्क्स

हमने पहले देखा है कि न्यूरल नेटवर्क्स इमेजेस के साथ काम करने में काफी अच्छे होते हैं, और यहां तक कि एक-लेयर परसेप्ट्रॉन भी MNIST डेटासेट से हस्तलिखित अंकों को पहचानने में उचित सटीकता के साथ सक्षम है। हालांकि, MNIST डेटासेट बहुत खास है, और सभी अंक इमेज के केंद्र में होते हैं, जिससे यह कार्य सरल हो जाता है।

## [प्री-लेक्चर क्विज़](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/107)

वास्तविक जीवन में, हम चाहते हैं कि हम इमेज में किसी वस्तु को उसकी सटीक स्थिति की परवाह किए बिना पहचान सकें। कंप्यूटर विज़न सामान्य वर्गीकरण से अलग है, क्योंकि जब हम इमेज में किसी विशेष वस्तु को खोजने की कोशिश कर रहे होते हैं, तो हम इमेज को स्कैन करते हैं और कुछ विशिष्ट **पैटर्न्स** और उनके संयोजनों को ढूंढते हैं। उदाहरण के लिए, जब हम बिल्ली को खोज रहे होते हैं, तो हम पहले क्षैतिज रेखाओं को देख सकते हैं, जो मूंछें बना सकती हैं, और फिर मूंछों के एक निश्चित संयोजन से हमें पता चल सकता है कि यह वास्तव में एक बिल्ली की तस्वीर है। कुछ पैटर्न्स की सापेक्ष स्थिति और उपस्थिति महत्वपूर्ण होती है, न कि उनकी इमेज में सटीक स्थिति।

पैटर्न्स को निकालने के लिए, हम **कॉन्वोल्यूशनल फिल्टर्स** की अवधारणा का उपयोग करेंगे। जैसा कि आप जानते हैं, एक इमेज को 2D-मैट्रिक्स या रंग गहराई के साथ 3D-टेंसर के रूप में दर्शाया जाता है। एक फिल्टर लागू करने का मतलब है कि हम एक अपेक्षाकृत छोटा **फिल्टर कर्नेल** मैट्रिक्स लेते हैं, और मूल इमेज में प्रत्येक पिक्सल के लिए पड़ोसी बिंदुओं के साथ भारित औसत की गणना करते हैं। इसे हम इस तरह देख सकते हैं जैसे एक छोटी खिड़की पूरी इमेज पर स्लाइड कर रही हो, और फिल्टर कर्नेल मैट्रिक्स में वज़न के अनुसार सभी पिक्सल्स का औसत निकाल रही हो।

![वर्टिकल एज फिल्टर](../../../../../lessons/4-ComputerVision/07-ConvNets/images/filter-vert.png) | ![हॉरिज़ॉन्टल एज फिल्टर](../../../../../lessons/4-ComputerVision/07-ConvNets/images/filter-horiz.png)
----|----

> छवि: दिमित्री सोश्निकोव द्वारा

उदाहरण के लिए, यदि हम MNIST अंकों पर 3x3 वर्टिकल एज और हॉरिज़ॉन्टल एज फिल्टर्स लागू करते हैं, तो हमें हाइलाइट्स (जैसे उच्च मान) मिल सकते हैं जहां हमारी मूल इमेज में वर्टिकल और हॉरिज़ॉन्टल एजेस हैं। इस प्रकार, ये दो फिल्टर्स एजेस को "खोजने" के लिए उपयोग किए जा सकते हैं। इसी तरह, हम अन्य निम्न-स्तरीय पैटर्न्स को खोजने के लिए विभिन्न फिल्टर्स डिज़ाइन कर सकते हैं:

> [Leung-Malik Filter Bank](https://www.robots.ox.ac.uk/~vgg/research/texclass/filters.html) की छवि

हालांकि, जबकि हम कुछ पैटर्न्स को निकालने के लिए फिल्टर्स को मैन्युअली डिज़ाइन कर सकते हैं, हम नेटवर्क को इस तरह से डिज़ाइन भी कर सकते हैं कि यह पैटर्न्स को स्वचालित रूप से सीख सके। यह CNN के पीछे के मुख्य विचारों में से एक है।

## CNN के पीछे मुख्य विचार

CNNs जिस तरह से काम करते हैं, वह निम्नलिखित महत्वपूर्ण विचारों पर आधारित है:

* कॉन्वोल्यूशनल फिल्टर्स पैटर्न्स को निकाल सकते हैं।
* हम नेटवर्क को इस तरह से डिज़ाइन कर सकते हैं कि फिल्टर्स स्वचालित रूप से प्रशिक्षित हो सकें।
* हम केवल मूल इमेज में ही नहीं, बल्कि उच्च-स्तरीय विशेषताओं में भी पैटर्न्स खोजने के लिए इसी दृष्टिकोण का उपयोग कर सकते हैं। इस प्रकार, CNN फीचर एक्सट्रैक्शन फीचर्स के एक पदानुक्रम पर काम करता है, जो निम्न-स्तरीय पिक्सल संयोजनों से शुरू होकर, इमेज के हिस्सों के उच्च-स्तरीय संयोजनों तक जाता है।

![पदानुक्रमिक फीचर एक्सट्रैक्शन](../../../../../lessons/4-ComputerVision/07-ConvNets/images/FeatureExtractionCNN.png)

> छवि: [Hislop-Lynch के पेपर](https://www.semanticscholar.org/paper/Computer-vision-based-pedestrian-trajectory-Hislop-Lynch/26e6f74853fc9bbb7487b06dc2cf095d36c9021d) से, उनके [शोध](https://dl.acm.org/doi/abs/10.1145/1553374.1553453) पर आधारित

## ✍️ अभ्यास: कॉन्वोल्यूशनल न्यूरल नेटवर्क्स

आइए यह समझना जारी रखें कि कॉन्वोल्यूशनल न्यूरल नेटवर्क्स कैसे काम करते हैं, और हम ट्रेन करने योग्य फिल्टर्स कैसे प्राप्त कर सकते हैं, इसके लिए निम्नलिखित नोटबुक्स पर काम करें:

* [कॉन्वोल्यूशनल न्यूरल नेटवर्क्स - PyTorch](../../../../../lessons/4-ComputerVision/07-ConvNets/ConvNetsPyTorch.ipynb)
* [कॉन्वोल्यूशनल न्यूरल नेटवर्क्स - TensorFlow](../../../../../lessons/4-ComputerVision/07-ConvNets/ConvNetsTF.ipynb)

## पिरामिड आर्किटेक्चर

अधिकांश CNNs जो इमेज प्रोसेसिंग के लिए उपयोग किए जाते हैं, तथाकथित पिरामिड आर्किटेक्चर का पालन करते हैं। मूल इमेज पर लागू पहला कॉन्वोल्यूशनल लेयर आमतौर पर अपेक्षाकृत कम संख्या में फिल्टर्स (8-16) रखता है, जो विभिन्न पिक्सल संयोजनों, जैसे क्षैतिज/वर्टिकल रेखाओं या स्ट्रोक्स से मेल खाते हैं। अगले स्तर पर, हम नेटवर्क के स्थानिक आयाम को कम करते हैं, और फिल्टर्स की संख्या बढ़ाते हैं, जो सरल विशेषताओं के अधिक संभावित संयोजनों से मेल खाती है। प्रत्येक लेयर के साथ, जैसे-जैसे हम अंतिम क्लासिफायर की ओर बढ़ते हैं, इमेज के स्थानिक आयाम घटते हैं, और फिल्टर्स की संख्या बढ़ती है।

उदाहरण के लिए, आइए VGG-16 की आर्किटेक्चर पर नज़र डालें, एक नेटवर्क जिसने 2014 में ImageNet के टॉप-5 वर्गीकरण में 92.7% सटीकता हासिल की:

![ImageNet लेयर्स](../../../../../lessons/4-ComputerVision/07-ConvNets/images/vgg-16-arch1.jpg)

![ImageNet पिरामिड](../../../../../lessons/4-ComputerVision/07-ConvNets/images/vgg-16-arch.jpg)

> छवि: [Researchgate](https://www.researchgate.net/figure/Vgg16-model-structure-To-get-the-VGG-NIN-model-we-replace-the-2-nd-4-th-6-th-7-th_fig2_335194493) से

## सबसे प्रसिद्ध CNN आर्किटेक्चर्स

[सबसे प्रसिद्ध CNN आर्किटेक्चर्स के बारे में अपनी पढ़ाई जारी रखें](CNN_Architectures.md)

**अस्वीकरण**:  
यह दस्तावेज़ AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) का उपयोग करके अनुवादित किया गया है। जबकि हम सटीकता सुनिश्चित करने का प्रयास करते हैं, कृपया ध्यान दें कि स्वचालित अनुवाद में त्रुटियां या अशुद्धियां हो सकती हैं। मूल भाषा में उपलब्ध मूल दस्तावेज़ को प्रामाणिक स्रोत माना जाना चाहिए। महत्वपूर्ण जानकारी के लिए, पेशेवर मानव अनुवाद की सिफारिश की जाती है। इस अनुवाद के उपयोग से उत्पन्न किसी भी गलतफहमी या गलत व्याख्या के लिए हम उत्तरदायी नहीं हैं।