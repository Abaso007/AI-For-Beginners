<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6522312ff835796ca34136a9462fafb2",
  "translation_date": "2025-09-23T08:25:35+00:00",
  "source_file": "lessons/5-NLP/19-NER/README.md",
  "language_code": "br"
}
-->
# Reconhecimento de Entidades Nomeadas

At√© agora, temos nos concentrado principalmente em uma tarefa de PLN - classifica√ß√£o. No entanto, existem outras tarefas de PLN que podem ser realizadas com redes neurais. Uma dessas tarefas √© o **[Reconhecimento de Entidades Nomeadas](https://wikipedia.org/wiki/Named-entity_recognition)** (NER), que trata de reconhecer entidades espec√≠ficas dentro de um texto, como lugares, nomes de pessoas, intervalos de data e hora, f√≥rmulas qu√≠micas e assim por diante.

## [Quiz pr√©-aula](https://ff-quizzes.netlify.app/en/ai/quiz/37)

## Exemplo de Uso do NER

Suponha que voc√™ queira desenvolver um chatbot de linguagem natural, semelhante ao Amazon Alexa ou Google Assistant. A forma como os chatbots inteligentes funcionam √© *entendendo* o que o usu√°rio deseja ao realizar a classifica√ß√£o de texto na frase de entrada. O resultado dessa classifica√ß√£o √© o chamado **intent**, que determina o que o chatbot deve fazer.

<img alt="Bot NER" src="images/bot-ner.png" width="50%"/>

> Imagem do autor

No entanto, o usu√°rio pode fornecer alguns par√¢metros como parte da frase. Por exemplo, ao perguntar sobre o clima, ele pode especificar um local ou uma data. Um bot deve ser capaz de entender essas entidades e preencher os par√¢metros adequadamente antes de realizar a a√ß√£o. √â exatamente aqui que o NER entra em a√ß√£o.

> ‚úÖ Outro exemplo seria [analisar artigos cient√≠ficos m√©dicos](https://soshnikov.com/science/analyzing-medical-papers-with-azure-and-text-analytics-for-health/). Um dos principais aspectos que precisamos buscar s√£o termos m√©dicos espec√≠ficos, como doen√ßas e subst√¢ncias medicinais. Enquanto um pequeno n√∫mero de doen√ßas pode ser extra√≠do usando busca por substrings, entidades mais complexas, como compostos qu√≠micos e nomes de medicamentos, exigem uma abordagem mais sofisticada.

## NER como Classifica√ß√£o de Tokens

Os modelos de NER s√£o essencialmente **modelos de classifica√ß√£o de tokens**, porque para cada um dos tokens de entrada precisamos decidir se ele pertence a uma entidade ou n√£o, e, se pertence, a qual classe de entidade.

Considere o seguinte t√≠tulo de artigo:

**Regurgita√ß√£o da v√°lvula tric√∫spide** e **carbonato de l√≠tio** **toxicidade** em um rec√©m-nascido.

As entidades aqui s√£o:

* Regurgita√ß√£o da v√°lvula tric√∫spide √© uma doen√ßa (`DIS`)
* Carbonato de l√≠tio √© uma subst√¢ncia qu√≠mica (`CHEM`)
* Toxicidade tamb√©m √© uma doen√ßa (`DIS`)

Observe que uma entidade pode abranger v√°rios tokens. E, como neste caso, precisamos distinguir entre duas entidades consecutivas. Assim, √© comum usar duas classes para cada entidade - uma especificando o primeiro token da entidade (frequentemente o prefixo `B-` √© usado, para **b**eginning/in√≠cio), e outra - a continua√ß√£o de uma entidade (`I-`, para **i**nner token/token interno). Tamb√©m usamos `O` como uma classe para representar todos os **o**utros tokens. Essa marca√ß√£o de tokens √© chamada de [marca√ß√£o BIO](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)) (ou IOB). Quando marcada, nosso t√≠tulo ficar√° assim:

Token | Tag
------|-----
Tricuspid | B-DIS
valve | I-DIS
regurgitation | I-DIS
and | O
lithium | B-CHEM
carbonate | I-CHEM
toxicity | B-DIS
in | O
a | O
newborn | O
infant | O
. | O

Como precisamos construir uma correspond√™ncia um-para-um entre tokens e classes, podemos treinar um modelo neural **muitos-para-muitos** da seguinte forma:

![Imagem mostrando padr√µes comuns de redes neurais recorrentes.](../../../../../translated_images/unreasonable-effectiveness-of-rnn.541ead816778f42dce6c42d8a56c184729aa2378d059b851be4ce12b993033df.br.jpg)

> *Imagem do [post no blog](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) de [Andrej Karpathy](http://karpathy.github.io/). Os modelos de classifica√ß√£o de tokens NER correspondem √† arquitetura de rede mais √† direita nesta imagem.*

## Treinando Modelos de NER

Como um modelo de NER √© essencialmente um modelo de classifica√ß√£o de tokens, podemos usar RNNs, com os quais j√° estamos familiarizados, para essa tarefa. Nesse caso, cada bloco da rede recorrente retornar√° o ID do token. O notebook de exemplo a seguir mostra como treinar um LSTM para classifica√ß√£o de tokens.

## ‚úçÔ∏è Notebooks de Exemplo: NER

Continue seu aprendizado no seguinte notebook:

* [NER com TensorFlow](NER-TF.ipynb)

## Conclus√£o

Um modelo de NER √© um **modelo de classifica√ß√£o de tokens**, o que significa que ele pode ser usado para realizar classifica√ß√£o de tokens. Essa √© uma tarefa muito comum em PLN, ajudando a reconhecer entidades espec√≠ficas dentro de textos, incluindo lugares, nomes, datas e mais.

## üöÄ Desafio

Complete a tarefa vinculada abaixo para treinar um modelo de reconhecimento de entidades nomeadas para termos m√©dicos e, em seguida, experimente em um conjunto de dados diferente.

## [Quiz p√≥s-aula](https://ff-quizzes.netlify.app/en/ai/quiz/38)

## Revis√£o & Autoestudo

Leia o blog [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) e siga a se√ß√£o de Leitura Adicional nesse artigo para aprofundar seu conhecimento.

## [Tarefa](lab/README.md)

Na tarefa desta li√ß√£o, voc√™ ter√° que treinar um modelo de reconhecimento de entidades m√©dicas. Voc√™ pode come√ßar treinando um modelo LSTM conforme descrito nesta li√ß√£o e, em seguida, avan√ßar para usar o modelo transformer BERT. Leia [as instru√ß√µes](lab/README.md) para obter todos os detalhes.

---

