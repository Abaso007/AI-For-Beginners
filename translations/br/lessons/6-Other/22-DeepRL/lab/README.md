<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7bd8dc72040e98e35e7225e34058cd4e",
  "translation_date": "2025-08-26T10:17:19+00:00",
  "source_file": "lessons/6-Other/22-DeepRL/lab/README.md",
  "language_code": "br"
}
-->
# Treinando o Carro da Montanha para Escapar

Tarefa do laboratório do [Currículo de IA para Iniciantes](https://github.com/microsoft/ai-for-beginners).

## Tarefa

Seu objetivo é treinar o agente de RL para controlar o [Mountain Car](https://www.gymlibrary.ml/environments/classic_control/mountain_car/) no Ambiente OpenAI.

## O Ambiente

O ambiente Mountain Car consiste em um carro preso dentro de um vale. Seu objetivo é sair do vale e alcançar a bandeira. As ações que você pode realizar são acelerar para a esquerda, para a direita ou não fazer nada. Você pode observar a posição do carro ao longo do eixo x e sua velocidade.

## Notebook Inicial

Comece o laboratório abrindo [MountainCar.ipynb](../../../../../../lessons/6-Other/22-DeepRL/lab/MountainCar.ipynb)

## Conclusão

Você deve aprender ao longo deste laboratório que adaptar algoritmos de RL para um novo ambiente é frequentemente bastante simples, porque o OpenAI Gym possui a mesma interface para todos os ambientes, e os algoritmos, como tal, não dependem muito da natureza do ambiente. Você pode até reestruturar o código Python de forma a passar qualquer ambiente para o algoritmo de RL como um parâmetro.

**Aviso Legal**:  
Este documento foi traduzido utilizando o serviço de tradução por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precisão, esteja ciente de que traduções automatizadas podem conter erros ou imprecisões. O documento original em seu idioma nativo deve ser considerado a fonte autoritativa. Para informações críticas, recomenda-se a tradução profissional realizada por humanos. Não nos responsabilizamos por quaisquer mal-entendidos ou interpretações incorretas decorrentes do uso desta tradução.