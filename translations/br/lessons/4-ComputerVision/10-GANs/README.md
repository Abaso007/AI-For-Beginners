<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f07c85bbf05a1f67505da98f4ecc124c",
  "translation_date": "2025-08-26T09:17:27+00:00",
  "source_file": "lessons/4-ComputerVision/10-GANs/README.md",
  "language_code": "br"
}
-->
# Redes Advers√°rias Generativas

Na se√ß√£o anterior, aprendemos sobre **modelos generativos**: modelos que podem gerar novas imagens semelhantes √†s do conjunto de dados de treinamento. O VAE foi um bom exemplo de modelo generativo.

## [Question√°rio pr√©-aula](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/110)

No entanto, se tentarmos gerar algo realmente significativo, como uma pintura em resolu√ß√£o razo√°vel, com o VAE, veremos que o treinamento n√£o converge bem. Para esse caso de uso, devemos aprender sobre outra arquitetura especificamente voltada para modelos generativos - as **Redes Advers√°rias Generativas**, ou GANs.

A ideia principal de uma GAN √© ter duas redes neurais que ser√£o treinadas uma contra a outra:

<img src="images/gan_architecture.png" width="70%"/>

> Imagem por [Dmitry Soshnikov](http://soshnikov.com)

> ‚úÖ Um pouco de vocabul√°rio:
> * **Gerador** √© uma rede que recebe um vetor aleat√≥rio e produz uma imagem como resultado.
> * **Discriminador** √© uma rede que recebe uma imagem e deve dizer se √© uma imagem real (do conjunto de dados de treinamento) ou se foi gerada por um gerador. Essencialmente, √© um classificador de imagens.

### Discriminador

A arquitetura do discriminador n√£o difere de uma rede de classifica√ß√£o de imagens comum. No caso mais simples, pode ser um classificador totalmente conectado, mas provavelmente ser√° uma [rede convolucional](../07-ConvNets/README.md).

> ‚úÖ Uma GAN baseada em redes convolucionais √© chamada de [DCGAN](https://arxiv.org/pdf/1511.06434.pdf)

Um discriminador CNN consiste nas seguintes camadas: v√°rias convolu√ß√µes+poolings (com tamanho espacial decrescente) e uma ou mais camadas totalmente conectadas para obter o "vetor de caracter√≠sticas", e um classificador bin√°rio final.

> ‚úÖ Um 'pooling' neste contexto √© uma t√©cnica que reduz o tamanho da imagem. "As camadas de pooling reduzem as dimens√µes dos dados combinando as sa√≠das de clusters de neur√¥nios em uma camada em um √∫nico neur√¥nio na pr√≥xima camada." - [fonte](https://wikipedia.org/wiki/Convolutional_neural_network#Pooling_layers)

### Gerador

Um Gerador √© um pouco mais complicado. Voc√™ pode consider√°-lo como um discriminador invertido. Come√ßando de um vetor latente (no lugar de um vetor de caracter√≠sticas), ele possui uma camada totalmente conectada para convert√™-lo no tamanho/forma necess√°rios, seguida por deconvolu√ß√µes+upscaling. Isso √© semelhante √† parte de *decodificador* de um [autoencoder](../09-Autoencoders/README.md).

> ‚úÖ Como a camada de convolu√ß√£o √© implementada como um filtro linear percorrendo a imagem, a deconvolu√ß√£o √© essencialmente semelhante √† convolu√ß√£o e pode ser implementada usando a mesma l√≥gica de camada.

<img src="images/gan_arch_detail.png" width="70%"/>

> Imagem por [Dmitry Soshnikov](http://soshnikov.com)

### Treinando a GAN

As GANs s√£o chamadas de **advers√°rias** porque h√° uma competi√ß√£o constante entre o gerador e o discriminador. Durante essa competi√ß√£o, tanto o gerador quanto o discriminador melhoram, fazendo com que a rede aprenda a produzir imagens cada vez melhores.

O treinamento ocorre em duas etapas:

* **Treinando o discriminador**. Essa tarefa √© bastante direta: geramos um lote de imagens com o gerador, rotulando-as como 0, o que significa imagem falsa, e pegamos um lote de imagens do conjunto de dados de entrada (com r√≥tulo 1, imagem real). Obtemos uma *perda do discriminador* e realizamos o backpropagation.
* **Treinando o gerador**. Isso √© um pouco mais complicado, porque n√£o sabemos diretamente a sa√≠da esperada para o gerador. Pegamos toda a rede GAN, composta por um gerador seguido de um discriminador, alimentamos com alguns vetores aleat√≥rios e esperamos que o resultado seja 1 (correspondente a imagens reais). Em seguida, congelamos os par√¢metros do discriminador (n√£o queremos que ele seja treinado nesta etapa) e realizamos o backpropagation.

Durante esse processo, as perdas do gerador e do discriminador n√£o diminuem significativamente. Na situa√ß√£o ideal, elas devem oscilar, correspondendo √† melhoria de ambas as redes.

## ‚úçÔ∏è Exerc√≠cios: GANs

* [Notebook GAN em TensorFlow/Keras](../../../../../lessons/4-ComputerVision/10-GANs/GANTF.ipynb)
* [Notebook GAN em PyTorch](../../../../../lessons/4-ComputerVision/10-GANs/GANPyTorch.ipynb)

### Problemas no treinamento de GANs

As GANs s√£o conhecidas por serem especialmente dif√≠ceis de treinar. Aqui est√£o alguns problemas:

* **Colapso de modo**. Esse termo significa que o gerador aprende a produzir uma √∫nica imagem bem-sucedida que engana o discriminador, em vez de uma variedade de imagens diferentes.
* **Sensibilidade a hiperpar√¢metros**. Muitas vezes, voc√™ pode ver que uma GAN n√£o converge de forma alguma e, de repente, uma redu√ß√£o na taxa de aprendizado leva √† converg√™ncia.
* Manter um **equil√≠brio** entre o gerador e o discriminador. Em muitos casos, a perda do discriminador pode cair para zero relativamente r√°pido, o que resulta no gerador sendo incapaz de continuar o treinamento. Para superar isso, podemos tentar definir taxas de aprendizado diferentes para o gerador e o discriminador ou pular o treinamento do discriminador se a perda j√° estiver muito baixa.
* Treinamento para **alta resolu√ß√£o**. Refletindo o mesmo problema dos autoencoders, esse problema √© desencadeado porque reconstruir muitas camadas de uma rede convolucional leva a artefatos. Esse problema √© geralmente resolvido com o chamado **crescimento progressivo**, onde primeiro algumas camadas s√£o treinadas em imagens de baixa resolu√ß√£o e, em seguida, as camadas s√£o "desbloqueadas" ou adicionadas. Outra solu√ß√£o seria adicionar conex√µes extras entre camadas e treinar v√°rias resolu√ß√µes ao mesmo tempo - veja este [artigo sobre Multi-Scale Gradient GANs](https://arxiv.org/abs/1903.06048) para mais detalhes.

## Transfer√™ncia de Estilo

As GANs s√£o uma √≥tima maneira de gerar imagens art√≠sticas. Outra t√©cnica interessante √© a chamada **transfer√™ncia de estilo**, que pega uma **imagem de conte√∫do** e a redesenha em um estilo diferente, aplicando filtros de uma **imagem de estilo**.

O funcionamento √© o seguinte:
* Come√ßamos com uma imagem de ru√≠do aleat√≥rio (ou com uma imagem de conte√∫do, mas para fins de entendimento √© mais f√°cil come√ßar com ru√≠do aleat√≥rio).
* Nosso objetivo ser√° criar uma imagem que seja pr√≥xima tanto da imagem de conte√∫do quanto da imagem de estilo. Isso ser√° determinado por duas fun√ß√µes de perda:
   - **Perda de conte√∫do** √© calculada com base nas caracter√≠sticas extra√≠das pela CNN em algumas camadas da imagem atual e da imagem de conte√∫do.
   - **Perda de estilo** √© calculada entre a imagem atual e a imagem de estilo de uma maneira inteligente usando matrizes de Gram (mais detalhes no [notebook de exemplo](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)).
* Para tornar a imagem mais suave e remover o ru√≠do, tamb√©m introduzimos a **Perda de varia√ß√£o**, que calcula a dist√¢ncia m√©dia entre pixels vizinhos.
* O principal loop de otimiza√ß√£o ajusta a imagem atual usando descida de gradiente (ou algum outro algoritmo de otimiza√ß√£o) para minimizar a perda total, que √© uma soma ponderada de todas as tr√™s perdas.

## ‚úçÔ∏è Exemplo: [Transfer√™ncia de Estilo](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)

## [Question√°rio p√≥s-aula](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/210)

## Conclus√£o

Nesta li√ß√£o, voc√™ aprendeu sobre GANs e como trein√°-las. Voc√™ tamb√©m aprendeu sobre os desafios especiais que esse tipo de Rede Neural pode enfrentar e algumas estrat√©gias para super√°-los.

## üöÄ Desafio

Execute o [notebook de Transfer√™ncia de Estilo](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb) usando suas pr√≥prias imagens.

## Revis√£o e Autoestudo

Para refer√™ncia, leia mais sobre GANs nestes recursos:

* Marco Pasini, [10 Li√ß√µes que Aprendi Treinando GANs por um Ano](https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628)
* [StyleGAN](https://en.wikipedia.org/wiki/StyleGAN), uma arquitetura GAN *de facto* a ser considerada.
* [Criando Arte Generativa usando GANs no Azure ML](https://soshnikov.com/scienceart/creating-generative-art-using-gan-on-azureml/)

## Tarefa

Revise um dos dois notebooks associados a esta li√ß√£o e re-treine a GAN com suas pr√≥prias imagens. O que voc√™ pode criar?

**Aviso Legal**:  
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precis√£o, esteja ciente de que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original em seu idioma nativo deve ser considerado a fonte oficial. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional feita por humanos. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes equivocadas decorrentes do uso desta tradu√ß√£o.