<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "186bf7eeab776b36f557357ea56d4751",
  "translation_date": "2025-08-26T10:26:19+00:00",
  "source_file": "lessons/3-NeuralNetworks/04-OwnFramework/README.md",
  "language_code": "mr"
}
-->
# न्यूरल नेटवर्क्सची ओळख. मल्टी-लेयर्ड परसेप्ट्रॉन

मागील विभागात, तुम्ही सर्वात सोप्या न्यूरल नेटवर्क मॉडेलबद्दल शिकलात - एक-स्तरीय परसेप्ट्रॉन, जो एक रेषीय दोन-वर्ग वर्गीकरण मॉडेल आहे.

या विभागात आपण या मॉडेलला अधिक लवचिक फ्रेमवर्कमध्ये विस्तारित करू, ज्यामुळे आपल्याला खालील गोष्टी करता येतील:

* दोन-वर्ग वर्गीकरणाशिवाय **बहु-वर्ग वर्गीकरण** करणे  
* वर्गीकरणाशिवाय **प्रत्यावर्तन समस्या** सोडवणे  
* रेषीयदृष्ट्या विभाज्य नसलेल्या वर्गांना विभक्त करणे  

आपण पायथनमध्ये आपले स्वतःचे मॉड्युलर फ्रेमवर्क देखील विकसित करू, जे आपल्याला वेगवेगळ्या न्यूरल नेटवर्क आर्किटेक्चर तयार करण्यास अनुमती देईल.

## [पूर्व-व्याख्यान प्रश्नमंजुषा](https://ff-quizzes.netlify.app/en/ai/quiz/7)

## मशीन लर्निंगचे औपचारिकरण

चला मशीन लर्निंग समस्येचे औपचारिकरण करून सुरुवात करूया. समजा आपल्याकडे **X** नावाचा प्रशिक्षण डेटासेट आहे, ज्यामध्ये **Y** लेबल्स आहेत, आणि आपल्याला *f* नावाचे मॉडेल तयार करायचे आहे, जे सर्वात अचूक अंदाज करेल. अंदाजांची गुणवत्ता **हानी फंक्शन** ℒ ने मोजली जाते. खालील हानी फंक्शन्स सामान्यतः वापरली जातात:

* प्रत्यावर्तन समस्येसाठी, जेव्हा आपल्याला एखादा आकडा भाकीत करायचा असतो, तेव्हा आपण **संपूर्ण त्रुटी** ∑<sub>i</sub>|f(x<sup>(i)</sup>)-y<sup>(i)</sup>| किंवा **वर्गीय त्रुटी** ∑<sub>i</sub>(f(x<sup>(i)</sup>)-y<sup>(i)</sup>)<sup>2</sup> वापरू शकतो.  
* वर्गीकरणासाठी, आपण **0-1 हानी** (जी मूलत: मॉडेलची **अचूकता** आहे) किंवा **लॉजिस्टिक हानी** वापरतो.  

एक-स्तरीय परसेप्ट्रॉनसाठी, फंक्शन *f* हे रेषीय फंक्शन *f(x)=wx+b* म्हणून परिभाषित केले गेले होते (इथे *w* हे वजन मॅट्रिक्स आहे, *x* हे इनपुट वैशिष्ट्यांचे वेक्टर आहे, आणि *b* हे बायस वेक्टर आहे). वेगवेगळ्या न्यूरल नेटवर्क आर्किटेक्चरमध्ये, हे फंक्शन अधिक जटिल स्वरूप घेऊ शकते.

> वर्गीकरणाच्या बाबतीत, संबंधित वर्गांचे संभाव्यते मिळवणे अनेकदा योग्य असते. नेटवर्क आउटपुट सामान्यीकृत करण्यासाठी, आपण **सॉफ्टमॅक्स** फंक्शन σ वापरतो, आणि फंक्शन *f* असे होते: *f(x)=σ(wx+b)*

वरील *f* च्या परिभाषेत, *w* आणि *b* यांना **पॅरामीटर्स** θ=⟨*w,b*⟩ म्हणतात. दिलेल्या डेटासेट ⟨**X**,**Y**⟩ वर, आपण संपूर्ण डेटासेटवरील एकूण त्रुटी पॅरामीटर्स θ च्या फंक्शन म्हणून मोजू शकतो.

> ✅ **न्यूरल नेटवर्क प्रशिक्षणाचे उद्दिष्ट म्हणजे पॅरामीटर्स θ बदलून त्रुटी कमी करणे आहे**

## ग्रेडियंट डिसेंट ऑप्टिमायझेशन

फंक्शन ऑप्टिमायझेशनसाठी एक प्रसिद्ध पद्धत म्हणजे **ग्रेडियंट डिसेंट**. यामध्ये कल्पना अशी आहे की आपण हानी फंक्शनचा पॅरामीटर्सच्या संदर्भात व्युत्पन्न (बहु-आयामी प्रकरणात **ग्रेडियंट** म्हणतात) काढू शकतो, आणि पॅरामीटर्स अशा प्रकारे बदलू शकतो की त्रुटी कमी होईल. हे पुढीलप्रमाणे औपचारिक केले जाऊ शकते:

* पॅरामीटर्स काही यादृच्छिक मूल्यांनी प्रारंभ करा w<sup>(0)</sup>, b<sup>(0)</sup>  
* खालील चरण अनेक वेळा पुन्हा करा:  
    - w<sup>(i+1)</sup> = w<sup>(i)</sup>-η∂ℒ/∂w  
    - b<sup>(i+1)</sup> = b<sup>(i)</sup>-η∂ℒ/∂b  

प्रशिक्षणादरम्यान, ऑप्टिमायझेशन चरण संपूर्ण डेटासेट विचारात घेऊन गणना केली जातात (लक्षात ठेवा की हानी सर्व प्रशिक्षण नमुन्यांमधून एकूण म्हणून मोजली जाते). तथापि, प्रत्यक्षात आपण डेटासेटचे लहान भाग घेतो, ज्यांना **मिनीबॅचेस** म्हणतात, आणि डेटा उपसंचाच्या आधारे ग्रेडियंट्सची गणना करतो. कारण प्रत्येक वेळी उपसंच यादृच्छिकपणे घेतला जातो, अशा पद्धतीला **स्टोकॅस्टिक ग्रेडियंट डिसेंट** (SGD) म्हणतात.

## मल्टी-लेयर्ड परसेप्ट्रॉन आणि बॅकप्रॉपगेशन

एक-स्तरीय नेटवर्क, जसे आपण वर पाहिले, रेषीयदृष्ट्या विभाज्य वर्गांचे वर्गीकरण करण्यास सक्षम आहे. अधिक समृद्ध मॉडेल तयार करण्यासाठी, आपण नेटवर्कच्या अनेक स्तरांचे संयोजन करू शकतो. गणितीयदृष्ट्या याचा अर्थ असा होईल की फंक्शन *f* अधिक जटिल स्वरूप घेईल, आणि ते अनेक टप्प्यांमध्ये गणना केले जाईल:
* z<sub>1</sub>=w<sub>1</sub>x+b<sub>1</sub>  
* z<sub>2</sub>=w<sub>2</sub>α(z<sub>1</sub>)+b<sub>2</sub>  
* f = σ(z<sub>2</sub>)  

इथे, α ही **गैर-रेषीय सक्रियता फंक्शन** आहे, σ ही सॉफ्टमॅक्स फंक्शन आहे, आणि पॅरामीटर्स θ=<*w<sub>1</sub>,b<sub>1</sub>,w<sub>2</sub>,b<sub>2</sub>*> आहेत.

ग्रेडियंट डिसेंट अल्गोरिदम तोच राहील, परंतु ग्रेडियंट्सची गणना करणे अधिक कठीण होईल. चेन डिफरेंशिएशन नियमाचा विचार करता, आपण व्युत्पन्ने खालीलप्रमाणे काढू शकतो:

* ∂ℒ/∂w<sub>2</sub> = (∂ℒ/∂σ)(∂σ/∂z<sub>2</sub>)(∂z<sub>2</sub>/∂w<sub>2</sub>)  
* ∂ℒ/∂w<sub>1</sub> = (∂ℒ/∂σ)(∂σ/∂z<sub>2</sub>)(∂z<sub>2</sub>/∂α)(∂α/∂z<sub>1</sub>)(∂z<sub>1</sub>/∂w<sub>1</sub>)  

> ✅ चेन डिफरेंशिएशन नियमाचा वापर हानी फंक्शनच्या पॅरामीटर्सच्या संदर्भातील व्युत्पन्ने काढण्यासाठी केला जातो.

लक्षात घ्या की या सर्व अभिव्यक्तींचा डावीकडील भाग समान आहे, आणि म्हणूनच आपण प्रभावीपणे हानी फंक्शनपासून व्युत्पन्ने "मागे" संगणकीय ग्राफद्वारे जाऊन काढू शकतो. म्हणूनच मल्टी-लेयर्ड परसेप्ट्रॉन प्रशिक्षणाची पद्धत **बॅकप्रॉपगेशन**, किंवा 'बॅकप्रॉप' म्हणून ओळखली जाते.

<img alt="compute graph" src="images/ComputeGraphGrad.png"/>

> TODO: प्रतिमेचा संदर्भ

> ✅ आपण बॅकप्रॉपचा अधिक तपशीलवार अभ्यास आपल्या नोटबुक उदाहरणात करू.  

## निष्कर्ष

या धड्यात, आपण आपले स्वतःचे न्यूरल नेटवर्क लायब्ररी तयार केले, आणि ते एका साध्या दोन-आयामी वर्गीकरण कार्यासाठी वापरले.

## 🚀 आव्हान

सोबतच्या नोटबुकमध्ये, तुम्ही मल्टी-लेयर्ड परसेप्ट्रॉन तयार करण्यासाठी आणि प्रशिक्षणासाठी स्वतःचे फ्रेमवर्क अंमलात आणाल. आधुनिक न्यूरल नेटवर्क्स कसे कार्य करतात हे तुम्हाला तपशीलवार पाहता येईल.

[OwnFramework](../../../../../lessons/3-NeuralNetworks/04-OwnFramework/OwnFramework.ipynb) नोटबुककडे जा आणि त्यावर काम करा.

## [व्याख्यानानंतरची प्रश्नमंजुषा](https://ff-quizzes.netlify.app/en/ai/quiz/8)

## पुनरावलोकन आणि स्व-अभ्यास

बॅकप्रॉपगेशन हा AI आणि ML मध्ये वापरला जाणारा एक सामान्य अल्गोरिदम आहे, जो [अधिक तपशीलवार](https://wikipedia.org/wiki/Backpropagation) अभ्यास करण्यासारखा आहे.

## [प्रकल्प](lab/README.md)

या प्रयोगशाळेत, तुम्हाला या धड्यात तयार केलेल्या फ्रेमवर्कचा वापर करून MNIST हस्तलिखित अंक वर्गीकरण समस्या सोडवायची आहे.

* [सूचना](lab/README.md)  
* [नोटबुक](../../../../../lessons/3-NeuralNetworks/04-OwnFramework/lab/MyFW_MNIST.ipynb)  

**अस्वीकरण**:  
हा दस्तऐवज AI भाषांतर सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) चा वापर करून भाषांतरित करण्यात आला आहे. आम्ही अचूकतेसाठी प्रयत्नशील असलो तरी, कृपया लक्षात घ्या की स्वयंचलित भाषांतरांमध्ये त्रुटी किंवा अचूकतेचा अभाव असू शकतो. मूळ भाषेतील मूळ दस्तऐवज हा अधिकृत स्रोत मानला जावा. महत्त्वाच्या माहितीसाठी व्यावसायिक मानवी भाषांतराची शिफारस केली जाते. या भाषांतराचा वापर केल्यामुळे उद्भवणाऱ्या कोणत्याही गैरसमज किंवा चुकीच्या अर्थासाठी आम्ही जबाबदार राहणार नाही.