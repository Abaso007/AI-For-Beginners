<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "4522e22e150be0845e03aa41209a39d5",
  "translation_date": "2025-08-26T08:25:36+00:00",
  "source_file": "lessons/5-NLP/13-TextRep/README.md",
  "language_code": "mr"
}
-->
# मजकूराचे टेन्सर्समध्ये प्रतिनिधित्व

## [पूर्व-व्याख्यान क्विझ](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/113)

## मजकूर वर्गीकरण

या विभागाच्या पहिल्या भागात, आपण **मजकूर वर्गीकरण** या कार्यावर लक्ष केंद्रित करू. आपण [AG News](https://www.kaggle.com/amananandrai/ag-news-classification-dataset) डेटासेट वापरणार आहोत, ज्यामध्ये खालीलप्रमाणे बातम्या आहेत:

* श्रेणी: विज्ञान/तंत्रज्ञान  
* शीर्षक: Ky. कंपनीला पेप्टाइड्सचा अभ्यास करण्यासाठी अनुदान मिळाले (AP)  
* मजकूर: AP - लुईव्हिल विद्यापीठातील रसायनशास्त्र संशोधकाने स्थापन केलेल्या कंपनीला विकसित करण्यासाठी अनुदान मिळाले...  

आपले उद्दिष्ट मजकूराच्या आधारे बातमीला योग्य श्रेणीत वर्गीकृत करणे असेल.

## मजकूराचे प्रतिनिधित्व

जर आपल्याला न्यूरल नेटवर्कसह नैसर्गिक भाषा प्रक्रिया (NLP) कार्ये सोडवायची असतील, तर मजकूराचे टेन्सर्समध्ये प्रतिनिधित्व करण्याचा काहीतरी मार्ग आवश्यक आहे. संगणक आधीच ASCII किंवा UTF-8 सारख्या एन्कोडिंगचा वापर करून मजकूर वर्णांना क्रमांकांमध्ये रूपांतरित करतो, जे स्क्रीनवरील फॉन्ट्सशी जुळतात.

<img alt="अक्षराला ASCII आणि बायनरी प्रतिनिधित्वाशी जुळवणारे आकृती दाखवणारी प्रतिमा" src="images/ascii-character-map.png" width="50%"/>

> [प्रतिमा स्रोत](https://www.seobility.net/en/wiki/ASCII)

आपण माणसे म्हणून, प्रत्येक अक्षर **काय दर्शवते** हे समजतो, आणि सर्व वर्ण एकत्र येऊन वाक्य तयार करतात हे देखील समजतो. परंतु, संगणकाला स्वतःहून असे समजत नाही, आणि न्यूरल नेटवर्कला प्रशिक्षणादरम्यान अर्थ शिकावा लागतो.

म्हणूनच, मजकूराचे प्रतिनिधित्व करताना आपण वेगवेगळ्या पद्धती वापरू शकतो:

* **अक्षर-स्तरीय प्रतिनिधित्व**, जिथे आपण प्रत्येक अक्षराला क्रमांक मानून मजकूराचे प्रतिनिधित्व करतो. जर आपल्या मजकूरात *C* वेगवेगळे अक्षरे असतील, तर *Hello* हा शब्द 5x*C* टेन्सरने दर्शविला जाईल. प्रत्येक अक्षराला वन-हॉट एन्कोडिंगमध्ये टेन्सरच्या एका स्तंभाशी जुळवले जाईल.  
* **शब्द-स्तरीय प्रतिनिधित्व**, जिथे आपण आपल्या मजकूरातील सर्व शब्दांचे **शब्दकोश** तयार करतो आणि नंतर शब्दांचे वन-हॉट एन्कोडिंगद्वारे प्रतिनिधित्व करतो. ही पद्धत काहीशी चांगली आहे, कारण प्रत्येक अक्षर स्वतःहून फारसा अर्थपूर्ण नसतो, आणि उच्च-स्तरीय शब्द वापरल्याने न्यूरल नेटवर्कसाठी कार्य सुलभ होते. परंतु, मोठ्या शब्दकोशाच्या आकारामुळे उच्च-आयामी विरळ टेन्सर्स हाताळावे लागतात.

कोणत्याही प्रकारच्या प्रतिनिधित्वासाठी, आपल्याला प्रथम मजकूर **टोकन्स**च्या अनुक्रमात रूपांतरित करावा लागतो, जिथे एक टोकन अक्षर, शब्द किंवा कधी कधी शब्दाचा भाग असतो. नंतर, आपण टोकनला क्रमांकात रूपांतरित करतो, सामान्यतः **शब्दकोश** वापरून, आणि हा क्रमांक वन-हॉट एन्कोडिंगद्वारे न्यूरल नेटवर्कमध्ये फीड केला जाऊ शकतो.

## एन-ग्राम्स

नैसर्गिक भाषेत, शब्दांचा अचूक अर्थ फक्त संदर्भातच ठरतो. उदाहरणार्थ, *neural network* आणि *fishing network* यांचे अर्थ पूर्णपणे वेगळे आहेत. याचा विचार करण्यासाठी, आपण शब्दांच्या जोड्यांवर आधारित मॉडेल तयार करू शकतो आणि शब्दांच्या जोड्यांना स्वतंत्र शब्दकोश टोकन्स मानू शकतो. अशा प्रकारे, *I like to go fishing* हे वाक्य खालील टोकन्सच्या अनुक्रमाने दर्शविले जाईल: *I like*, *like to*, *to go*, *go fishing*. या पद्धतीचा तोटा म्हणजे शब्दकोशाचा आकार लक्षणीय वाढतो, आणि *go fishing* आणि *go shopping* सारख्या संयोजनांना वेगवेगळ्या टोकन्सने दर्शवले जाते, जरी त्याच क्रियापदाचा वापर केला गेला असला तरी त्यांच्यात कोणताही अर्थपूर्ण साम्य नसतो.

काही प्रकरणांमध्ये, आपण तीन शब्दांच्या संयोजनांचा -- त्रि-ग्राम्स -- विचार करू शकतो. त्यामुळे ही पद्धत **एन-ग्राम्स** म्हणून ओळखली जाते. तसेच, अक्षर-स्तरीय प्रतिनिधित्वासह एन-ग्राम्स वापरणे उपयुक्त ठरू शकते, जिथे एन-ग्राम्स साधारणतः वेगवेगळ्या अक्षरसमूहांशी जुळतात.

## बॅग-ऑफ-वर्ड्स आणि TF/IDF

मजकूर वर्गीकरणासारखी कार्ये सोडवताना, आपल्याला एक निश्चित-आकाराचा वेक्टर तयार करावा लागतो, जो अंतिम घन वर्गीकरणासाठी इनपुट म्हणून वापरला जाईल. यासाठी सर्व वैयक्तिक शब्दांचे प्रतिनिधित्व एकत्र करणे, उदा. त्यांची बेरीज करणे, हा एक सोपा मार्ग आहे. जर आपण प्रत्येक शब्दाचे वन-हॉट एन्कोडिंग जोडले, तर आपल्याला वारंवारतेचा वेक्टर मिळेल, जो मजकूरात प्रत्येक शब्द किती वेळा दिसतो हे दर्शवतो. अशा प्रकारच्या मजकूराचे प्रतिनिधित्व **बॅग ऑफ वर्ड्स** (BoW) म्हणून ओळखले जाते.

<img src="images/bow.png" width="90%"/>

> लेखकाने तयार केलेली प्रतिमा

BoW मूलत: मजकूरात कोणते शब्द दिसतात आणि कोणत्या प्रमाणात हे दर्शवते, जे मजकूर कशाबद्दल आहे याचे चांगले संकेत असू शकतात. उदाहरणार्थ, राजकारणावरील बातमीमध्ये *president* आणि *country* सारखे शब्द असण्याची शक्यता असते, तर वैज्ञानिक प्रकाशनात *collider*, *discovered* असे काहीतरी असते. त्यामुळे, अनेक प्रकरणांमध्ये शब्दांची वारंवारता मजकूराच्या विषयाचे चांगले संकेतक असू शकते.

BoW चा तोटा असा आहे की काही सामान्य शब्द, जसे *and*, *is*, इत्यादी बहुतेक मजकुरांमध्ये दिसतात, आणि त्यांची वारंवारता जास्त असते, ज्यामुळे खरोखर महत्त्वाचे शब्द झाकले जातात. आपण अशा शब्दांचे महत्त्व कमी करू शकतो, जर आपण संपूर्ण दस्तऐवज संग्रहात शब्द किती वेळा दिसतो याचा विचार केला. हीच कल्पना TF/IDF पद्धतीमागे आहे, जी या धड्याशी संलग्न असलेल्या नोटबुक्समध्ये अधिक तपशीलवारपणे समजावली आहे.

तथापि, या कोणत्याही पद्धती मजकूराचा **अर्थ** पूर्णपणे समजू शकत नाहीत. हे करण्यासाठी आपल्याला अधिक शक्तिशाली न्यूरल नेटवर्क मॉडेल्सची आवश्यकता आहे, ज्याबद्दल आपण या विभागात नंतर चर्चा करू.

## ✍️ सराव: मजकूराचे प्रतिनिधित्व

खालील नोटबुक्समध्ये आपले शिक्षण सुरू ठेवा:

* [PyTorch सह मजकूराचे प्रतिनिधित्व](../../../../../lessons/5-NLP/13-TextRep/TextRepresentationPyTorch.ipynb)  
* [TensorFlow सह मजकूराचे प्रतिनिधित्व](../../../../../lessons/5-NLP/13-TextRep/TextRepresentationTF.ipynb)  

## निष्कर्ष

आत्तापर्यंत, आपण अशा तंत्रांचा अभ्यास केला आहे जे वेगवेगळ्या शब्दांना वारंवारतेचे वजन देऊ शकतात. तथापि, ते अर्थ किंवा क्रम दर्शवू शकत नाहीत. प्रसिद्ध भाषाशास्त्रज्ञ जे. आर. फर्थ यांनी 1935 मध्ये म्हटल्याप्रमाणे, "शब्दाचा पूर्ण अर्थ नेहमीच संदर्भानुसार असतो, आणि संदर्भाशिवाय अर्थाचा अभ्यास गंभीरपणे घेतला जाऊ शकत नाही." आपण या अभ्यासक्रमात पुढे मजकूरातून संदर्भात्मक माहिती कशी काढायची हे शिकू.

## 🚀 आव्हान

बॅग-ऑफ-वर्ड्स आणि वेगवेगळ्या डेटा मॉडेल्स वापरून काही इतर सराव करून पहा. तुम्हाला या [Kaggle स्पर्धेतून](https://www.kaggle.com/competitions/word2vec-nlp-tutorial/overview/part-1-for-beginners-bag-of-words) प्रेरणा मिळू शकते.

## [व्याख्यानानंतरचा क्विझ](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/213)

## पुनरावलोकन आणि स्व-अभ्यास

[Microsoft Learn](https://docs.microsoft.com/learn/modules/intro-natural-language-processing-pytorch/?WT.mc_id=academic-77998-cacaste) वर मजकूर एम्बेडिंग आणि बॅग-ऑफ-वर्ड्स तंत्रांसह आपले कौशल्य सराव करा.

## [असाइनमेंट: नोटबुक्स](assignment.md)  

**अस्वीकरण**:  
हा दस्तऐवज AI भाषांतर सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) वापरून भाषांतरित करण्यात आला आहे. आम्ही अचूकतेसाठी प्रयत्नशील असलो तरी, कृपया लक्षात घ्या की स्वयंचलित भाषांतरांमध्ये त्रुटी किंवा अचूकतेचा अभाव असू शकतो. मूळ भाषेतील मूळ दस्तऐवज हा अधिकृत स्रोत मानला जावा. महत्त्वाच्या माहितीसाठी, व्यावसायिक मानवी भाषांतराची शिफारस केली जाते. या भाषांतराचा वापर केल्यामुळे उद्भवणाऱ्या कोणत्याही गैरसमज किंवा चुकीच्या अर्थासाठी आम्ही जबाबदार राहणार नाही.