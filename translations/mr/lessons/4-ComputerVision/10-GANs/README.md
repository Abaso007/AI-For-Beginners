<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f07c85bbf05a1f67505da98f4ecc124c",
  "translation_date": "2025-08-26T09:15:23+00:00",
  "source_file": "lessons/4-ComputerVision/10-GANs/README.md",
  "language_code": "mr"
}
-->
# जनरेटिव अड्व्हर्सेरियल नेटवर्क्स

मागील विभागात आपण **जनरेटिव मॉडेल्स** म्हणजेच अशा मॉडेल्सबद्दल शिकलो जे प्रशिक्षण डेटासेटमधील प्रतिमांसारख्या नवीन प्रतिमा तयार करू शकतात. VAE हे जनरेटिव मॉडेलचे एक चांगले उदाहरण होते.

## [पूर्व-व्याख्यान क्विझ](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/110)

तथापि, जर आपण VAE वापरून उच्च रिझोल्यूशनमध्ये अर्थपूर्ण काहीतरी तयार करण्याचा प्रयत्न केला, जसे की एक पेंटिंग, तर आपल्याला दिसेल की प्रशिक्षण चांगल्या प्रकारे जुळत नाही. अशा वापरासाठी, आपल्याला जनरेटिव मॉडेल्ससाठी खास डिझाइन केलेल्या दुसऱ्या आर्किटेक्चरबद्दल शिकणे आवश्यक आहे - **जनरेटिव अड्व्हर्सेरियल नेटवर्क्स** किंवा GANs.

GAN चा मुख्य विचार म्हणजे दोन न्यूरल नेटवर्क्स तयार करणे जे एकमेकांविरुद्ध प्रशिक्षण घेतात:

<img src="images/gan_architecture.png" width="70%"/>

> प्रतिमा: [दिमित्री सॉश्निकोव्ह](http://soshnikov.com)

> ✅ थोडीशी शब्दावली:
> * **जनरेटर** हे एक नेटवर्क आहे जे काही रँडम व्हेक्टर घेते आणि त्याचा परिणाम म्हणून प्रतिमा तयार करते.
> * **डिस्क्रिमिनेटर** हे एक नेटवर्क आहे जे प्रतिमा घेते आणि ती खऱ्या डेटासेटमधून आलेली आहे की जनरेटरने तयार केलेली आहे हे ओळखते. हे मूलत: एक प्रतिमा वर्गीकरण करणारे नेटवर्क आहे.

### डिस्क्रिमिनेटर

डिस्क्रिमिनेटरचे आर्किटेक्चर सामान्य प्रतिमा वर्गीकरण नेटवर्कसारखेच असते. सर्वात सोप्या प्रकरणात, ते पूर्णपणे कनेक्टेड वर्गीकरणकर्ता असू शकते, परंतु बहुधा ते [कन्फोल्यूशनल नेटवर्क](../07-ConvNets/README.md) असेल.

> ✅ कन्फोल्यूशनल नेटवर्कवर आधारित GAN ला [DCGAN](https://arxiv.org/pdf/1511.06434.pdf) म्हणतात.

CNN डिस्क्रिमिनेटरमध्ये खालील स्तर असतात: अनेक कन्फोल्यूशन्स+पूलिंग्ज (ज्यामुळे स्पॅटियल साइज कमी होते) आणि एक किंवा अधिक पूर्णपणे कनेक्टेड स्तर जे "फीचर व्हेक्टर" तयार करतात, आणि शेवटी बायनरी वर्गीकरणकर्ता.

> ✅ 'पूलिंग' म्हणजे प्रतिमेचा आकार कमी करण्याची तंत्र. "पूलिंग स्तर डेटा परिमाण कमी करतात, एका स्तरातील न्यूरॉन क्लस्टर्सच्या आउटपुट्सना पुढील स्तरातील एका न्यूरॉनमध्ये एकत्र करून." - [स्रोत](https://wikipedia.org/wiki/Convolutional_neural_network#Pooling_layers)

### जनरेटर

जनरेटर थोडा अधिक क्लिष्ट आहे. तुम्ही याला उलट्या डिस्क्रिमिनेटरप्रमाणे समजू शकता. फीचर व्हेक्टरच्या जागी लेटंट व्हेक्टरपासून सुरुवात करून, त्यात एक पूर्णपणे कनेक्टेड स्तर असतो जो आवश्यक आकार/आकारात रूपांतरित करतो, त्यानंतर डी-कन्फोल्यूशन्स+अपस्केलिंग असते. हे [ऑटोएन्कोडर](../09-Autoencoders/README.md) च्या *डिकोडर* भागासारखे आहे.

> ✅ कारण कन्फोल्यूशन स्तर प्रतिमेवर रेषीय फिल्टर म्हणून कार्य करते, डी-कन्फोल्यूशन हे मूलत: कन्फोल्यूशनसारखेच आहे आणि त्याच स्तर लॉजिकचा वापर करून अंमलात आणले जाऊ शकते.

<img src="images/gan_arch_detail.png" width="70%"/>

> प्रतिमा: [दिमित्री सॉश्निकोव्ह](http://soshnikov.com)

### GAN चे प्रशिक्षण

GAN ला **अड्व्हर्सेरियल** असे म्हणतात कारण जनरेटर आणि डिस्क्रिमिनेटर यांच्यात सतत स्पर्धा असते. या स्पर्धेदरम्यान, जनरेटर आणि डिस्क्रिमिनेटर दोन्ही सुधारतात, ज्यामुळे नेटवर्क अधिक चांगल्या प्रतिमा तयार करायला शिकते.

प्रशिक्षण दोन टप्प्यांमध्ये होते:

* **डिस्क्रिमिनेटरचे प्रशिक्षण**. हे कार्य अगदी सोपे आहे: आम्ही जनरेटरद्वारे प्रतिमांचा एक बॅच तयार करतो, त्यांना 0 लेबल देतो (फेक प्रतिमा दर्शविण्यासाठी), आणि इनपुट डेटासेटमधून प्रतिमांचा एक बॅच घेतो (1 लेबलसह, खऱ्या प्रतिमा). आम्हाला काही *डिस्क्रिमिनेटर लॉस* मिळते आणि बॅकप्रॉप करतो.
* **जनरेटरचे प्रशिक्षण**. हे थोडे अधिक क्लिष्ट आहे, कारण आम्हाला जनरेटरसाठी अपेक्षित आउटपुट थेट माहित नाही. आम्ही जनरेटर आणि डिस्क्रिमिनेटर यांचा समावेश असलेले संपूर्ण GAN नेटवर्क घेतो, त्याला काही रँडम व्हेक्टरसह फीड करतो, आणि परिणाम 1 (खऱ्या प्रतिमांशी संबंधित) अपेक्षित करतो. त्यानंतर आम्ही डिस्क्रिमिनेटरचे पॅरामीटर्स गोठवतो (या टप्प्यावर आम्हाला ते प्रशिक्षण द्यायचे नाही) आणि बॅकप्रॉप करतो.

या प्रक्रियेदरम्यान, जनरेटर आणि डिस्क्रिमिनेटर लॉस लक्षणीयरीत्या खाली जात नाहीत. आदर्श परिस्थितीत, ते दोन्ही नेटवर्क्सच्या कामगिरीत सुधारणा दर्शविण्यासाठी ऑस्सिलेट करायला हवेत.

## ✍️ सराव: GANs

* [TensorFlow/Keras मध्ये GAN नोटबुक](../../../../../lessons/4-ComputerVision/10-GANs/GANTF.ipynb)
* [PyTorch मध्ये GAN नोटबुक](../../../../../lessons/4-ComputerVision/10-GANs/GANPyTorch.ipynb)

### GAN प्रशिक्षणातील समस्या

GAN प्रशिक्षण करणे विशेषतः कठीण असल्याचे ओळखले जाते. येथे काही समस्या आहेत:

* **मोड कोलॅप्स**. याचा अर्थ जनरेटर एक यशस्वी प्रतिमा तयार करायला शिकतो जी डिस्क्रिमिनेटरला फसवते, परंतु विविध प्रतिमा तयार करत नाही.
* **हायपरपॅरामीटर्ससाठी संवेदनशीलता**. अनेकदा असे दिसते की GAN अजिबात जुळत नाही, आणि नंतर अचानक लर्निंग रेट कमी होऊन जुळते.
* जनरेटर आणि डिस्क्रिमिनेटर यांच्यात **संतुलन राखणे**. अनेक प्रकरणांमध्ये डिस्क्रिमिनेटर लॉस तुलनेने लवकर शून्यावर पोहोचतो, ज्यामुळे जनरेटरला पुढे प्रशिक्षण देता येत नाही. यावर मात करण्यासाठी, आपण जनरेटर आणि डिस्क्रिमिनेटरसाठी भिन्न लर्निंग रेट सेट करू शकतो, किंवा लॉस आधीच खूप कमी असल्यास डिस्क्रिमिनेटर प्रशिक्षण वगळू शकतो.
* **उच्च रिझोल्यूशनसाठी प्रशिक्षण**. ऑटोएन्कोडर्ससारखीच समस्या, ही समस्या खूप जास्त कन्फोल्यूशन स्तर पुन्हा तयार केल्यामुळे आर्टिफॅक्ट्स तयार होतात. ही समस्या सामान्यतः **प्रोग्रेसिव ग्रोइंग** वापरून सोडवली जाते, जिथे सुरुवातीला काही स्तर कमी-रिझोल्यूशन प्रतिमांवर प्रशिक्षण घेतात, आणि नंतर स्तर "अनब्लॉक" किंवा जोडले जातात. आणखी एक उपाय म्हणजे स्तरांमधील अतिरिक्त कनेक्शन्स जोडणे आणि एकाच वेळी अनेक रिझोल्यूशन्सवर प्रशिक्षण देणे - यासाठी [मल्टी-स्केल ग्रेडियंट GANs पेपर](https://arxiv.org/abs/1903.06048) पहा.

## स्टाइल ट्रान्सफर

GANs हे कलात्मक प्रतिमा तयार करण्याचा एक उत्तम मार्ग आहे. आणखी एक मनोरंजक तंत्र म्हणजे **स्टाइल ट्रान्सफर**, जे एका **कंटेंट प्रतिमा** घेते आणि ती वेगळ्या शैलीत पुन्हा काढते, **स्टाइल प्रतिमा** मधील फिल्टर्स लागू करते.

हे कसे कार्य करते:
* आपण रँडम नॉईज प्रतिमेसह सुरुवात करतो (किंवा कंटेंट प्रतिमेसह, परंतु समजण्यासाठी रँडम नॉईजने सुरुवात करणे सोपे आहे)
* आपले उद्दिष्ट असे प्रतिमा तयार करणे आहे, जी कंटेंट प्रतिमा आणि स्टाइल प्रतिमेस जवळ असेल. हे दोन लॉस फंक्शन्सद्वारे ठरवले जाईल:
   - **कंटेंट लॉस** हे CNN द्वारे काही स्तरांवरून वर्तमान प्रतिमा आणि कंटेंट प्रतिमेमधून काढलेल्या वैशिष्ट्यांवर आधारित मोजले जाते.
   - **स्टाइल लॉस** हे वर्तमान प्रतिमा आणि स्टाइल प्रतिमेमधील ग्रॅम मॅट्रिसेसचा वापर करून हुशारीने मोजले जाते (अधिक तपशीलांसाठी [उदाहरण नोटबुक](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb) पहा).
* प्रतिमा गुळगुळीत करण्यासाठी आणि नॉईज काढून टाकण्यासाठी, आम्ही **व्हेरिएशन लॉस** देखील सादर करतो, जो शेजारील पिक्सेलमधील सरासरी अंतर मोजतो.
* मुख्य ऑप्टिमायझेशन लूप वर्तमान प्रतिमेला ग्रेडियंट डिसेंट (किंवा इतर काही ऑप्टिमायझेशन अल्गोरिदम) वापरून समायोजित करतो, एकूण लॉस कमी करण्यासाठी, जो सर्व तीन लॉसेसचा वेटेड सम आहे.

## ✍️ उदाहरण: [स्टाइल ट्रान्सफर](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)

## [व्याख्यानानंतरचा क्विझ](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/210)

## निष्कर्ष

या धड्यात, तुम्ही GANs आणि त्यांना कसे प्रशिक्षण द्यायचे ते शिकलात. तुम्ही या प्रकारच्या न्यूरल नेटवर्क्सना येणाऱ्या विशेष आव्हानांबद्दल आणि त्यावर मात करण्याच्या काही रणनीतींबद्दलही शिकलात.

## 🚀 आव्हान

[स्टाइल ट्रान्सफर नोटबुक](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb) चालवा आणि तुमच्या स्वतःच्या प्रतिमांचा वापर करा.

## पुनरावलोकन आणि स्व-अभ्यास

संदर्भासाठी, या स्रोतांमध्ये GANs बद्दल अधिक वाचा:

* मार्को पासिनी, [10 Lessons I Learned Training GANs for one Year](https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628)
* [स्टाइलGAN](https://en.wikipedia.org/wiki/StyleGAN), विचार करण्यासाठी एक *डिफॉल्ट* GAN आर्किटेक्चर
* [Azure ML वर GANs वापरून जनरेटिव आर्ट तयार करणे](https://soshnikov.com/scienceart/creating-generative-art-using-gan-on-azureml/)

## असाइनमेंट

या धड्याशी संबंधित दोन नोटबुक्सपैकी एक पुन्हा पहा आणि GAN ला तुमच्या स्वतःच्या प्रतिमांवर प्रशिक्षण द्या. तुम्ही काय तयार करू शकता?

**अस्वीकरण**:  
हा दस्तऐवज AI भाषांतर सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) चा वापर करून भाषांतरित करण्यात आला आहे. आम्ही अचूकतेसाठी प्रयत्नशील असलो तरी, कृपया लक्षात घ्या की स्वयंचलित भाषांतरांमध्ये त्रुटी किंवा अचूकतेचा अभाव असू शकतो. मूळ भाषेतील मूळ दस्तऐवज हा अधिकृत स्रोत मानला जावा. महत्त्वाच्या माहितीसाठी व्यावसायिक मानवी भाषांतराची शिफारस केली जाते. या भाषांतराचा वापर केल्यामुळे उद्भवणाऱ्या कोणत्याही गैरसमज किंवा चुकीच्या अर्थासाठी आम्ही जबाबदार राहणार नाही.