<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "0b306c04f5337b6e7430e5c0b16bb5c0",
  "translation_date": "2025-08-26T09:06:20+00:00",
  "source_file": "lessons/4-ComputerVision/09-Autoencoders/README.md",
  "language_code": "mr"
}
-->
# ऑटोएन्कोडर्स

जेव्हा CNNs प्रशिक्षण दिले जाते, तेव्हा एक समस्या अशी असते की आपल्याला खूप साऱ्या लेबल केलेल्या डेटाची गरज असते. प्रतिमेच्या वर्गीकरणाच्या बाबतीत, आपल्याला प्रतिमा वेगवेगळ्या वर्गांमध्ये विभागाव्या लागतात, जे एक मॅन्युअल काम आहे.

## [पूर्व-व्याख्यान क्विझ](https://ff-quizzes.netlify.app/en/ai/quiz/17)

तथापि, कधीकधी आपल्याला कच्चा (लेबल नसलेला) डेटा CNN फीचर एक्स्ट्रॅक्टर्ससाठी वापरायचा असतो, ज्याला **स्वयं-नियंत्रित शिक्षण** म्हणतात. लेबल्सच्या ऐवजी, आपण प्रशिक्षण प्रतिमा नेटवर्कच्या इनपुट आणि आउटपुट म्हणून वापरू. **ऑटोएन्कोडर** या संकल्पनेचा मुख्य उद्देश असा आहे की आपल्याकडे एक **एन्कोडर नेटवर्क** असेल, जे इनपुट प्रतिमेला काही **लॅटेंट स्पेस** मध्ये रूपांतरित करेल (सामान्यतः हा काही लहान आकाराचा वेक्टर असतो), आणि नंतर **डिकोडर नेटवर्क**, ज्याचा उद्देश मूळ प्रतिमा पुन्हा तयार करणे असेल.

> ✅ [ऑटोएन्कोडर](https://wikipedia.org/wiki/Autoencoder) म्हणजे "एक प्रकारचे कृत्रिम न्यूरल नेटवर्क जे लेबल नसलेल्या डेटाचे कार्यक्षम कोडिंग शिकण्यासाठी वापरले जाते."

ऑटोएन्कोडरला मूळ प्रतिमेतील जास्तीत जास्त माहिती अचूक पुनर्निर्मितीसाठी कॅप्चर करायची असल्याने, नेटवर्क इनपुट प्रतिमांचे सर्वोत्तम **एम्बेडिंग** शोधण्याचा प्रयत्न करते.

![ऑटोएन्कोडर आकृती](../../../../../translated_images/autoencoder_schema.5e6fc9ad98a5eb6197f3513cf3baf4dfbe1389a6ae74daebda64de9f1c99f142.mr.jpg)

> प्रतिमा [Keras ब्लॉग](https://blog.keras.io/building-autoencoders-in-keras.html) वरून

## ऑटोएन्कोडर्स वापरण्याचे प्रसंग

मूळ प्रतिमा पुन्हा तयार करणे स्वतःमध्ये फारसे उपयुक्त वाटत नसले तरी, काही प्रसंगांमध्ये ऑटोएन्कोडर्स विशेषतः उपयुक्त ठरतात:

* **प्रतिमांचे परिमाण कमी करणे** किंवा **प्रतिमा एम्बेडिंग प्रशिक्षण देणे**. सामान्यतः ऑटोएन्कोडर्स PCA पेक्षा चांगले परिणाम देतात, कारण ते प्रतिमांच्या स्थानिक स्वरूपाचा आणि श्रेणीबद्ध वैशिष्ट्यांचा विचार करतात.
* **डिनॉइजिंग**, म्हणजेच प्रतिमेतील आवाज काढून टाकणे. कारण आवाजात बऱ्याच निरुपयोगी माहितीचा समावेश असतो, ऑटोएन्कोडर त्यातील सर्व माहिती लहान लॅटेंट स्पेसमध्ये बसवू शकत नाही, त्यामुळे तो फक्त महत्त्वाचा भाग कॅप्चर करतो. डिनॉइजर्स प्रशिक्षण देताना, आपण मूळ प्रतिमांपासून सुरुवात करतो आणि कृत्रिमरित्या आवाज जोडलेल्या प्रतिमांचा ऑटोएन्कोडर इनपुट म्हणून वापर करतो.
* **सुपर-रिझोल्यूशन**, म्हणजे प्रतिमेचे रिझोल्यूशन वाढवणे. आपण उच्च-रिझोल्यूशन प्रतिमांपासून सुरुवात करतो आणि कमी रिझोल्यूशन असलेल्या प्रतिमेला ऑटोएन्कोडर इनपुट म्हणून वापरतो.
* **जनरेटिव्ह मॉडेल्स**. एकदा ऑटोएन्कोडर प्रशिक्षित झाल्यावर, डिकोडर भाग यादृच्छिक लॅटेंट वेक्टरपासून नवीन वस्तू तयार करण्यासाठी वापरला जाऊ शकतो.

## व्हेरिएशनल ऑटोएन्कोडर्स (VAE)

पारंपरिक ऑटोएन्कोडर्स इनपुट डेटाचे परिमाण कमी करतात आणि इनपुट प्रतिमांचे महत्त्वाचे वैशिष्ट्य शोधतात. तथापि, लॅटेंट वेक्टर अनेकदा अर्थपूर्ण नसतात. उदाहरणार्थ, MNIST डेटासेट घेतल्यास, वेगवेगळ्या लॅटेंट वेक्टरशी संबंधित अंक शोधणे सोपे नसते, कारण जवळचे लॅटेंट वेक्टर नेहमीच समान अंक दर्शवतील असे नाही.

दुसरीकडे, *जनरेटिव्ह* मॉडेल्स प्रशिक्षण देण्यासाठी लॅटेंट स्पेसचे काहीसे समज असणे चांगले असते. ही कल्पना आपल्याला **व्हेरिएशनल ऑटोएन्कोडर** (VAE) कडे घेऊन जाते.

VAE हा असा ऑटोएन्कोडर आहे जो लॅटेंट पॅरामीटर्सचे *सांख्यिकीय वितरण* (ज्याला **लॅटेंट वितरण** म्हणतात) अंदाज लावायला शिकतो. उदाहरणार्थ, आपल्याला लॅटेंट वेक्टर सामान्यतः z<sub>mean</sub> आणि z<sub>sigma</sub> (दोन्ही म्हणजे काही परिमाण d चे वेक्टर) सह वितरित व्हावे असे वाटू शकते. VAE मधील एन्कोडर हे पॅरामीटर्स अंदाज लावायला शिकतो, आणि नंतर डिकोडर या वितरणातून एक यादृच्छिक वेक्टर घेतो आणि वस्तू पुन्हा तयार करतो.

सारांश:

* इनपुट वेक्टरपासून, आपण `z_mean` आणि `z_log_sigma` अंदाज लावतो (थेट मानक विचलनाचा अंदाज लावण्याऐवजी, आपण त्याचा लघुगणक अंदाज लावतो)
* आपण वितरण N(z<sub>mean</sub>,exp(z<sub>log_sigma</sub>)) मधून `sample` नावाचा वेक्टर निवडतो
* डिकोडर `sample` ला इनपुट वेक्टर म्हणून वापरून मूळ प्रतिमा पुन्हा तयार करण्याचा प्रयत्न करतो

<img src="images/vae.png" width="50%">

> प्रतिमा [या ब्लॉग पोस्ट](https://ijdykeman.github.io/ml/2016/12/21/cvae.html) वरून, लेखक: इसाक डायकमन

व्हेरिएशनल ऑटोएन्कोडर्स एक जटिल लॉस फंक्शन वापरतात, ज्यामध्ये दोन भाग असतात:

* **पुनर्निर्मिती लॉस** - हे लॉस फंक्शन दर्शवते की पुन्हा तयार केलेली प्रतिमा लक्ष्याच्या किती जवळ आहे (हे Mean Squared Error किंवा MSE असू शकते). हे सामान्य ऑटोएन्कोडर्सप्रमाणेच लॉस फंक्शन आहे.
* **KL लॉस**, जे सुनिश्चित करते की लॅटेंट व्हेरिएबल वितरण सामान्य वितरणाच्या जवळ राहते. हे [कुलबॅक-लिबलर डायव्हर्जन्स](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained) या संकल्पनेवर आधारित आहे - दोन सांख्यिकीय वितरणे किती समान आहेत हे मोजण्यासाठी एक मेट्रिक.

VAE चे एक महत्त्वाचे फायदे म्हणजे ते आपल्याला नवीन प्रतिमा तुलनेने सोप्या पद्धतीने तयार करू देतात, कारण आपल्याला लॅटेंट वेक्टर कशा वितरणातून निवडायचे आहेत हे माहित असते. उदाहरणार्थ, जर आपण MNIST वर 2D लॅटेंट वेक्टरसह VAE प्रशिक्षित केले, तर आपण लॅटेंट वेक्टरच्या घटकांमध्ये बदल करून वेगवेगळे अंक मिळवू शकतो:

<img alt="vaemnist" src="images/vaemnist.png" width="50%"/>

> प्रतिमा [दिमित्री सॉश्निकोव्ह](http://soshnikov.com) यांच्याकडून

लक्षात घ्या की प्रतिमा एकमेकांमध्ये कशा मिसळतात, कारण आपण लॅटेंट पॅरामीटर स्पेसच्या वेगवेगळ्या भागांमधून लॅटेंट वेक्टर मिळवायला सुरुवात करतो. आपण या स्पेसला 2D मध्ये देखील व्हिज्युअलाइझ करू शकतो:

<img alt="vaemnist cluster" src="images/vaemnist-diag.png" width="50%"/> 

> प्रतिमा [दिमित्री सॉश्निकोव्ह](http://soshnikov.com) यांच्याकडून

## ✍️ सराव: ऑटोएन्कोडर्स

या संबंधित नोटबुक्समध्ये ऑटोएन्कोडर्सबद्दल अधिक जाणून घ्या:

* [TensorFlow मध्ये ऑटोएन्कोडर्स](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb)
* [PyTorch मध्ये ऑटोएन्कोडर्स](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoEncodersPyTorch.ipynb)

## ऑटोएन्कोडर्सची वैशिष्ट्ये

* **डेटा-विशिष्ट** - ते फक्त त्याच प्रकारच्या प्रतिमांसोबत चांगले कार्य करतात ज्यावर त्यांना प्रशिक्षण दिले गेले आहे. उदाहरणार्थ, जर आपण फुलांवर सुपर-रिझोल्यूशन नेटवर्क प्रशिक्षित केले, तर ते पोर्ट्रेट्सवर चांगले कार्य करणार नाही. कारण नेटवर्क प्रशिक्षण डेटासेटमधून शिकलेल्या वैशिष्ट्यांमधून सूक्ष्म तपशील घेऊन उच्च रिझोल्यूशन प्रतिमा तयार करू शकते.
* **लॉसी** - पुन्हा तयार केलेली प्रतिमा मूळ प्रतिमेसारखी नसते. लॉसचे स्वरूप प्रशिक्षणादरम्यान वापरलेल्या *लॉस फंक्शन* वर अवलंबून असते.
* **लेबल नसलेल्या डेटावर कार्य करते**

## [व्याख्यानानंतरचा क्विझ](https://ff-quizzes.netlify.app/en/ai/quiz/18)

## निष्कर्ष

या धड्यात, तुम्ही AI वैज्ञानिकांसाठी उपलब्ध असलेल्या विविध प्रकारच्या ऑटोएन्कोडर्सबद्दल शिकला. तुम्ही त्यांना कसे तयार करायचे आणि प्रतिमा पुन्हा तयार करण्यासाठी त्यांचा कसा वापर करायचा हे शिकला. तुम्ही VAE बद्दलही शिकला आणि नवीन प्रतिमा तयार करण्यासाठी त्याचा कसा वापर करायचा हे समजले.

## 🚀 आव्हान

या धड्यात, तुम्ही प्रतिमांसाठी ऑटोएन्कोडर्स वापरण्याबद्दल शिकला. पण ते संगीतासाठीही वापरले जाऊ शकतात! Magenta प्रकल्पाचा [MusicVAE](https://magenta.tensorflow.org/music-vae) प्रकल्प तपासा, जो संगीत पुन्हा तयार करायला शिकण्यासाठी ऑटोएन्कोडर्स वापरतो. या लायब्ररीसह काही [प्रयोग](https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/Multitrack_MusicVAE.ipynb) करा आणि तुम्ही काय तयार करू शकता ते पाहा.

## [व्याख्यानानंतरचा क्विझ](https://ff-quizzes.netlify.app/en/ai/quiz/16)

## पुनरावलोकन आणि स्व-अभ्यास

संदर्भासाठी, या स्रोतांमध्ये ऑटोएन्कोडर्सबद्दल अधिक वाचा:

* [Keras मध्ये ऑटोएन्कोडर्स तयार करणे](https://blog.keras.io/building-autoencoders-in-keras.html)
* [NeuroHive वरील ब्लॉग पोस्ट](https://neurohive.io/ru/osnovy-data-science/variacionnyj-avtojenkoder-vae/)
* [व्हेरिएशनल ऑटोएन्कोडर्स समजावून सांगितले](https://kvfrans.com/variational-autoencoders-explained/)
* [कंडिशनल व्हेरिएशनल ऑटोएन्कोडर्स](https://ijdykeman.github.io/ml/2016/12/21/cvae.html)

## असाइनमेंट

[TensorFlow वापरून या नोटबुकच्या](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb) शेवटी तुम्हाला एक 'टास्क' सापडेल - याचा तुमच्या असाइनमेंटसाठी वापर करा.

**अस्वीकरण**:  
हा दस्तऐवज AI भाषांतर सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) चा वापर करून भाषांतरित करण्यात आला आहे. आम्ही अचूकतेसाठी प्रयत्नशील असलो तरी, कृपया लक्षात घ्या की स्वयंचलित भाषांतरांमध्ये त्रुटी किंवा अचूकतेचा अभाव असू शकतो. मूळ भाषेतील दस्तऐवज हा अधिकृत स्रोत मानला जावा. महत्त्वाच्या माहितीसाठी व्यावसायिक मानवी भाषांतराची शिफारस केली जाते. या भाषांतराचा वापर केल्यामुळे उद्भवणाऱ्या कोणत्याही गैरसमज किंवा चुकीच्या अर्थासाठी आम्ही जबाबदार राहणार नाही.