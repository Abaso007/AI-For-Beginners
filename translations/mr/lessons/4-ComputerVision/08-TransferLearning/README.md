<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "717775c4050ccbffbe0c961ad8bf7bf7",
  "translation_date": "2025-08-26T09:43:41+00:00",
  "source_file": "lessons/4-ComputerVision/08-TransferLearning/README.md",
  "language_code": "mr"
}
-->
# पूर्व-प्रशिक्षित नेटवर्क्स आणि ट्रान्सफर लर्निंग

CNN प्रशिक्षणासाठी खूप वेळ लागतो आणि त्यासाठी मोठ्या प्रमाणात डेटा आवश्यक असतो. मात्र, नेटवर्कने प्रतिमांमधून नमुने काढण्यासाठी वापरले जाणारे सर्वोत्तम लो-लेव्हल फिल्टर्स शिकण्यात बराच वेळ जातो. एक नैसर्गिक प्रश्न निर्माण होतो - आपण एका डेटासेटवर प्रशिक्षित केलेल्या न्यूरल नेटवर्कचा वापर करून वेगळ्या प्रतिमा वर्गीकृत करण्यासाठी पूर्ण प्रशिक्षण प्रक्रिया न करता ते कसे अनुकूल करू शकतो?

## [पूर्व-व्याख्यान क्विझ](https://ff-quizzes.netlify.app/en/ai/quiz/15)

ही पद्धत **ट्रान्सफर लर्निंग** म्हणून ओळखली जाते, कारण आपण एका न्यूरल नेटवर्क मॉडेलमधून दुसऱ्या मॉडेलमध्ये काही ज्ञान हस्तांतरित करतो. ट्रान्सफर लर्निंगमध्ये, आपण सामान्यतः पूर्व-प्रशिक्षित मॉडेलसह सुरुवात करतो, जे मोठ्या प्रतिमा डेटासेटवर प्रशिक्षित केले गेले आहे, जसे की **ImageNet**. ही मॉडेल्स आधीच सामान्य प्रतिमांमधून विविध वैशिष्ट्ये काढण्यात चांगले काम करू शकतात, आणि अनेक प्रकरणांमध्ये, त्या काढलेल्या वैशिष्ट्यांवर आधारित वर्गीकर्ता तयार करणे चांगले परिणाम देऊ शकते.

> ✅ ट्रान्सफर लर्निंग हा शब्द इतर शैक्षणिक क्षेत्रांमध्ये देखील आढळतो, जसे की शिक्षण. याचा अर्थ एका क्षेत्रातील ज्ञान घेऊन ते दुसऱ्या क्षेत्रात लागू करणे.

## पूर्व-प्रशिक्षित मॉडेल्स फीचर एक्स्ट्रॅक्टर्स म्हणून

आम्ही मागील विभागात चर्चा केलेल्या कॉनव्होल्यूशनल नेटवर्क्समध्ये अनेक स्तर असतात, ज्यामध्ये प्रत्येक स्तर प्रतिमेतून काही वैशिष्ट्ये काढण्याचे काम करतो. हे लो-लेव्हल पिक्सेल संयोजनांपासून (जसे की आडव्या/उभ्या रेषा किंवा स्ट्रोक) सुरू होते आणि उच्च-स्तरीय वैशिष्ट्यांच्या संयोजनांपर्यंत पोहोचते, जसे की ज्वालाचा डोळा. जर आपण सामान्य आणि विविध प्रतिमांच्या मोठ्या डेटासेटवर CNN प्रशिक्षित केले, तर नेटवर्कने ती सामान्य वैशिष्ट्ये काढणे शिकले पाहिजे.

Keras आणि PyTorch मध्ये काही सामान्य आर्किटेक्चर्ससाठी पूर्व-प्रशिक्षित न्यूरल नेटवर्क वेट्स सहजपणे लोड करण्यासाठी फंक्शन्स आहेत, ज्यातील बहुतेक ImageNet प्रतिमांवर प्रशिक्षित केले गेले आहेत. सर्वात जास्त वापरले जाणारे मॉडेल्स [CNN Architectures](../07-ConvNets/CNN_Architectures.md) पृष्ठावर वर्णन केले आहेत. विशेषतः, तुम्ही खालीलपैकी एकाचा विचार करू शकता:

* **VGG-16/VGG-19** हे तुलनेने सोपे मॉडेल्स आहेत जे अजूनही चांगली अचूकता देतात. ट्रान्सफर लर्निंग कसे कार्य करते हे पाहण्यासाठी VGG वापरणे चांगला पर्याय असतो.
* **ResNet** ही मॉडेल्सची एक श्रेणी आहे जी Microsoft Research ने 2015 मध्ये प्रस्तावित केली होती. त्यामध्ये अधिक स्तर आहेत, त्यामुळे अधिक संसाधने लागतात.
* **MobileNet** ही कमी आकाराची मॉडेल्सची श्रेणी आहे, जी मोबाइल डिव्हाइससाठी योग्य आहे. जर तुमच्याकडे कमी संसाधने असतील आणि थोडी अचूकता गमावण्याची तयारी असेल तर त्यांचा वापर करा.

खाली VGG-16 नेटवर्कद्वारे एका मांजरीच्या प्रतिमेतून काढलेली वैशिष्ट्ये दिली आहेत:

![Features extracted by VGG-16](../../../../../translated_images/features.6291f9c7ba3a0b951af88fc9864632b9115365410765680680d30c927dd67354.mr.png)

## मांजरी विरुद्ध कुत्रे डेटासेट

या उदाहरणात, आपण [Cats and Dogs](https://www.microsoft.com/download/details.aspx?id=54765&WT.mc_id=academic-77998-cacaste) डेटासेट वापरणार आहोत, जे वास्तविक जीवनातील प्रतिमा वर्गीकरण परिस्थितीशी खूप जवळचे आहे.

## ✍️ व्यायाम: ट्रान्सफर लर्निंग

चला संबंधित नोटबुक्समध्ये ट्रान्सफर लर्निंग प्रत्यक्षात पाहूया:

* [Transfer Learning - PyTorch](../../../../../lessons/4-ComputerVision/08-TransferLearning/TransferLearningPyTorch.ipynb)
* [Transfer Learning - TensorFlow](../../../../../lessons/4-ComputerVision/08-TransferLearning/TransferLearningTF.ipynb)

## व्हिज्युअलायझिंग अॅडव्हर्सेरियल मांजर

पूर्व-प्रशिक्षित न्यूरल नेटवर्कमध्ये त्याच्या *मेंदूत* विविध नमुने असतात, ज्यामध्ये **आदर्श मांजर** (तसेच आदर्श कुत्रा, आदर्श झेब्रा, इ.) यांची संकल्पना असते. हे प्रतिमेचे **व्हिज्युअलायझेशन** करणे मनोरंजक ठरेल. मात्र, हे सोपे नाही, कारण नमुने नेटवर्क वेट्समध्ये विखुरलेले असतात आणि त्याचप्रमाणे ते एक श्रेणीबद्ध संरचनेत आयोजित केलेले असतात.

एक पद्धत म्हणजे आपण एका रँडम प्रतिमेसह सुरुवात करतो आणि नंतर **ग्रेडियंट डिसेंट ऑप्टिमायझेशन** तंत्र वापरून ती प्रतिमा समायोजित करण्याचा प्रयत्न करतो, ज्यामुळे नेटवर्कला वाटते की ती मांजर आहे.

![Image Optimization Loop](../../../../../translated_images/ideal-cat-loop.999fbb8ff306e044f997032f4eef9152b453e6a990e449bbfb107de2493cc37e.mr.png)

मात्र, जर आपण असे केले, तर आपल्याला काहीसे रँडम नॉईजसारखे काहीतरी मिळेल. कारण *नेटवर्कला इनपुट प्रतिमा मांजर आहे असे वाटण्यासाठी अनेक मार्ग आहेत*, ज्यामध्ये काही दृश्यदृष्ट्या अर्थपूर्ण नसलेले मार्ग देखील आहेत. जरी त्या प्रतिमांमध्ये मांजरीसाठी विशिष्ट नमुने असले तरी, त्यांना दृश्यदृष्ट्या वेगळे बनवण्यासाठी काहीही बंधन नाही.

परिणाम सुधारण्यासाठी, आपण लॉस फंक्शनमध्ये आणखी एक टर्म जोडू शकतो, ज्याला **व्हेरिएशन लॉस** म्हणतात. हे एक मेट्रिक आहे जे प्रतिमेतील शेजारील पिक्सेल किती समान आहेत हे दर्शवते. व्हेरिएशन लॉस कमी केल्याने प्रतिमा गुळगुळीत होते आणि नॉईज दूर होते - त्यामुळे अधिक दृश्यदृष्ट्या आकर्षक नमुने दिसून येतात. खाली मांजर आणि झेब्रा म्हणून वर्गीकृत केलेल्या "आदर्श" प्रतिमांचे उदाहरण दिले आहे:

![Ideal Cat](../../../../../translated_images/ideal-cat.203dd4597643d6b0bd73038b87f9c0464322725e3a06ab145d25d4a861c70592.mr.png) | ![Ideal Zebra](../../../../../translated_images/ideal-zebra.7f70e8b54ee15a7a314000bb5df38a6cfe086ea04d60df4d3ef313d046b98a2b.mr.png)
-----|-----
 *आदर्श मांजर* | *आदर्श झेब्रा*

अशाच प्रकारे **अॅडव्हर्सेरियल अटॅक्स** देखील न्यूरल नेटवर्कवर करता येतात. समजा, आपण न्यूरल नेटवर्कला मूर्ख बनवायचे आहे आणि कुत्र्याला मांजरासारखे बनवायचे आहे. जर आपण कुत्र्याची प्रतिमा घेतली, जी नेटवर्कद्वारे कुत्रा म्हणून ओळखली जाते, तर आपण ती थोडीशी समायोजित करू शकतो, जोपर्यंत नेटवर्क ती मांजर म्हणून वर्गीकृत करत नाही:

![Picture of a Dog](../../../../../translated_images/original-dog.8f68a67d2fe0911f33041c0f7fce8aa4ea919f9d3917ec4b468298522aeb6356.mr.png) | ![Picture of a dog classified as a cat](../../../../../translated_images/adversarial-dog.d9fc7773b0142b89752539bfbf884118de845b3851c5162146ea0b8809fc820f.mr.png)
-----|-----
*कुत्र्याची मूळ प्रतिमा* | *कुत्र्याची प्रतिमा जी मांजर म्हणून वर्गीकृत केली जाते*

वरील परिणाम पुनरुत्पादित करण्यासाठी कोड खालील नोटबुकमध्ये पहा:

* [Ideal and Adversarial Cat - TensorFlow](../../../../../lessons/4-ComputerVision/08-TransferLearning/AdversarialCat_TF.ipynb)

## निष्कर्ष

ट्रान्सफर लर्निंग वापरून, तुम्ही कस्टम ऑब्जेक्ट वर्गीकरण कार्यासाठी जलदपणे वर्गीकर्ता तयार करू शकता आणि उच्च अचूकता प्राप्त करू शकता. तुम्ही पाहू शकता की आपण आता सोडवत असलेल्या अधिक जटिल कार्यांसाठी उच्च संगणकीय शक्ती आवश्यक आहे आणि CPU वर सहजपणे सोडवता येत नाही. पुढील युनिटमध्ये, आपण कमी संगणकीय संसाधने वापरून समान मॉडेल प्रशिक्षणासाठी अधिक हलकी अंमलबजावणी वापरण्याचा प्रयत्न करू, ज्यामुळे अचूकतेत थोडीशी घट होते.

## 🚀 आव्हान

सहायक नोटबुक्समध्ये, प्रशिक्षण डेटा थोडासा समान असताना ट्रान्सफर ज्ञान कसे चांगले कार्य करते याबद्दल तळाशी काही टिपा आहेत (कदाचित प्राण्याचा नवीन प्रकार). पूर्णपणे नवीन प्रकारच्या प्रतिमांसह काही प्रयोग करा आणि तुमचे ट्रान्सफर ज्ञान मॉडेल्स किती चांगले किंवा वाईट कार्य करतात ते पाहा.

## [व्याख्यानानंतरचा क्विझ](https://ff-quizzes.netlify.app/en/ai/quiz/16)

## पुनरावलोकन आणि स्व-अभ्यास

[TrainingTricks.md](TrainingTricks.md) वाचा आणि तुमच्या मॉडेल्स प्रशिक्षणाच्या इतर पद्धतींबद्दल अधिक सखोल ज्ञान मिळवा.

## [असाइनमेंट](lab/README.md)

या प्रयोगशाळेत, आपण वास्तविक जीवनातील [Oxford-IIIT](https://www.robots.ox.ac.uk/~vgg/data/pets/) पाळीव प्राणी डेटासेट वापरणार आहोत ज्यामध्ये मांजरी आणि कुत्र्यांच्या 35 जाती आहेत, आणि आपण ट्रान्सफर लर्निंग वर्गीकर्ता तयार करू.

**अस्वीकरण**:  
हा दस्तऐवज AI भाषांतर सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) चा वापर करून भाषांतरित करण्यात आला आहे. आम्ही अचूकतेसाठी प्रयत्नशील असलो तरी, कृपया लक्षात घ्या की स्वयंचलित भाषांतरांमध्ये त्रुटी किंवा अचूकतेचा अभाव असू शकतो. मूळ भाषेतील मूळ दस्तऐवज हा अधिकृत स्रोत मानला जावा. महत्त्वाच्या माहितीसाठी व्यावसायिक मानवी भाषांतराची शिफारस केली जाते. या भाषांतराचा वापर केल्यामुळे उद्भवलेल्या कोणत्याही गैरसमज किंवा चुकीच्या अर्थासाठी आम्ही जबाबदार राहणार नाही.