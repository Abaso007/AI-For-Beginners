<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ae074cd940fc2f4dc24fc07b66ccbd99",
  "translation_date": "2025-08-26T09:48:39+00:00",
  "source_file": "lessons/4-ComputerVision/08-TransferLearning/TrainingTricks.md",
  "language_code": "mr"
}
-->
# डीप लर्निंग प्रशिक्षण तंत्र

जसे न्यूरल नेटवर्क्स अधिक खोलवर जातात, त्यांचे प्रशिक्षण अधिक आव्हानात्मक बनते. एक मोठी समस्या म्हणजे [vanishing gradients](https://en.wikipedia.org/wiki/Vanishing_gradient_problem) किंवा [exploding gradients](https://deepai.org/machine-learning-glossary-and-terms/exploding-gradient-problem#:~:text=Exploding%20gradients%20are%20a%20problem,updates%20are%20small%20and%20controlled.). [हा लेख](https://towardsdatascience.com/the-vanishing-exploding-gradient-problem-in-deep-neural-networks-191358470c11) या समस्यांवर चांगले स्पष्टीकरण देतो.

डीप नेटवर्क्सचे प्रशिक्षण अधिक कार्यक्षम बनवण्यासाठी काही तंत्र वापरता येतात.

## मूल्ये योग्य श्रेणीत ठेवणे

सांख्यिकीय गणना अधिक स्थिर बनवण्यासाठी, आपल्याला हे सुनिश्चित करायचे आहे की आपल्या न्यूरल नेटवर्कमधील सर्व मूल्ये योग्य श्रेणीत असावीत, सामान्यतः [-1..1] किंवा [0..1]. ही फार कठोर अट नाही, परंतु फ्लोटिंग पॉइंट गणनांची प्रकृती अशी आहे की वेगवेगळ्या परिमाणांच्या मूल्यांना एकत्रितपणे अचूकपणे हाताळता येत नाही. उदाहरणार्थ, जर आपण 10<sup>-10</sup> आणि 10<sup>10</sup> जोडले, तर आपल्याला 10<sup>10</sup> मिळण्याची शक्यता आहे, कारण लहान मूल्य मोठ्या मूल्याच्या समान क्रमात "रूपांतरित" होईल आणि त्यामुळे मँटिसा गमावली जाईल.

बहुतेक अॅक्टिवेशन फंक्शन्समध्ये [-1..1] च्या आसपास नॉन-लिनिअरिटी असते, त्यामुळे सर्व इनपुट डेटा [-1..1] किंवा [0..1] श्रेणीत स्केल करणे योग्य ठरते.

## प्रारंभिक वजन प्रारंभिककरण

आदर्शतः, नेटवर्क लेयर्समधून जाण्यानंतर मूल्ये समान श्रेणीत असावीत. त्यामुळे वजन अशा प्रकारे प्रारंभिक करणे महत्त्वाचे आहे की मूल्यांचे वितरण टिकून राहील.

सामान्य वितरण **N(0,1)** चांगली कल्पना नाही, कारण जर आपल्याकडे *n* इनपुट्स असतील, तर आउटपुटचा मानक विचलन *n* असेल, आणि मूल्ये [0..1] श्रेणीतून बाहेर जाण्याची शक्यता असेल.

खालील प्रारंभिककरणे सामान्यतः वापरली जातात:

 * युनिफॉर्म वितरण -- `uniform`
 * **N(0,1/n)** -- `gaussian`
 * **N(0,1/√n_in)** हे सुनिश्चित करते की शून्य सरासरी आणि मानक विचलन 1 असलेल्या इनपुट्ससाठी समान सरासरी/मानक विचलन टिकून राहील
 * **N(0,√2/(n_in+n_out))** -- ज्याला **Xavier initialization** (`glorot`) म्हणतात, हे फॉरवर्ड आणि बॅकवर्ड प्रोपोगेशन दरम्यान सिग्नल्स श्रेणीत ठेवण्यास मदत करते

## बॅच नॉर्मलायझेशन

योग्य वजन प्रारंभिकरण असूनही, प्रशिक्षणादरम्यान वजन खूप मोठे किंवा लहान होऊ शकते, आणि ते सिग्नल्स योग्य श्रेणीतून बाहेर नेतील. सिग्नल्स परत आणण्यासाठी आपण **नॉर्मलायझेशन** तंत्र वापरू शकतो. जरी त्यापैकी अनेक असले (वेट नॉर्मलायझेशन, लेयर नॉर्मलायझेशन), तरी सर्वात जास्त वापरले जाणारे तंत्र म्हणजे बॅच नॉर्मलायझेशन.

**बॅच नॉर्मलायझेशन** ची कल्पना म्हणजे मिनिबॅचमधील सर्व मूल्यांचा विचार करणे आणि त्या मूल्यांवर आधारित नॉर्मलायझेशन करणे (उदा. सरासरी वजा करणे आणि मानक विचलनाने भाग करणे). हे नेटवर्क लेयर म्हणून अंमलात आणले जाते जे वजन लागू केल्यानंतर, परंतु अॅक्टिवेशन फंक्शनच्या आधी हे नॉर्मलायझेशन करते. परिणामी, अंतिम अचूकता जास्त आणि प्रशिक्षण जलद होण्याची शक्यता असते.

येथे बॅच नॉर्मलायझेशनवरील [मूळ पेपर](https://arxiv.org/pdf/1502.03167.pdf), [विकिपीडियावर स्पष्टीकरण](https://en.wikipedia.org/wiki/Batch_normalization), आणि [एक चांगला परिचयात्मक ब्लॉग पोस्ट](https://towardsdatascience.com/batch-normalization-in-3-levels-of-understanding-14c2da90a338) (आणि [रशियन भाषेत](https://habrahabr.ru/post/309302/)) दिला आहे.

## ड्रॉपआउट

**ड्रॉपआउट** हे एक मनोरंजक तंत्र आहे जे प्रशिक्षणादरम्यान काही प्रमाणात रँडम न्यूरॉन्स काढून टाकते. हे एक लेयर म्हणून अंमलात आणले जाते ज्यामध्ये एक पॅरामीटर असतो (काढून टाकायच्या न्यूरॉन्सचा टक्केवारी, सामान्यतः 10%-50%), आणि प्रशिक्षणादरम्यान हे इनपुट व्हेक्टरचे रँडम घटक शून्य करते, त्यानंतर पुढील लेयरकडे पाठवते.

जरी हे विचित्र कल्पना वाटत असले तरी, आपण [`Dropout.ipynb`](../../../../../lessons/4-ComputerVision/08-TransferLearning/Dropout.ipynb) नोटबुकमध्ये MNIST अंक वर्गीकरणकर्ता प्रशिक्षणावर ड्रॉपआउटचा परिणाम पाहू शकता. हे प्रशिक्षण जलद करते आणि कमी प्रशिक्षण epochs मध्ये उच्च अचूकता मिळवण्यास मदत करते.

या प्रभावाचे स्पष्टीकरण काही प्रकारे दिले जाऊ शकते:

 * हे मॉडेलसाठी एक रँडम धक्का मानले जाऊ शकते, जे स्थानिक किमानतेच्या बाहेर ऑप्टिमायझेशन घेते
 * हे *अप्रत्यक्ष मॉडेल सरासरीकरण* मानले जाऊ शकते, कारण आपण म्हणू शकतो की ड्रॉपआउट दरम्यान आपण किंचित वेगळ्या मॉडेलचे प्रशिक्षण घेत आहोत

> *काही लोक म्हणतात की जेव्हा एखादी मद्यधुंद व्यक्ती काहीतरी शिकण्याचा प्रयत्न करते, तेव्हा ती गोष्ट दुसऱ्या दिवशी चांगल्या प्रकारे लक्षात ठेवते, तुलनेत एका तंदुरुस्त व्यक्तीपेक्षा, कारण काही न्यूरॉन्स नीट कार्य करत नसलेल्या मेंदूने अर्थ समजून घेण्यासाठी चांगले जुळवून घेतले. आम्ही स्वतः हे खरे आहे की नाही हे कधीच तपासले नाही.*

## ओव्हरफिटिंग टाळणे

डीप लर्निंगमधील एक महत्त्वाचा पैलू म्हणजे [ओव्हरफिटिंग](../../3-NeuralNetworks/05-Frameworks/Overfitting.md) टाळण्याची क्षमता. जरी अत्यंत शक्तिशाली न्यूरल नेटवर्क मॉडेल वापरण्याचा मोह होऊ शकतो, तरी आपल्याला नेहमी मॉडेल पॅरामीटर्सची संख्या प्रशिक्षण नमुन्यांच्या संख्येसोबत संतुलित ठेवावी लागते.

> आपण यापूर्वी सादर केलेल्या [ओव्हरफिटिंग](../../3-NeuralNetworks/05-Frameworks/Overfitting.md) संकल्पनेची खात्री करून घ्या!

ओव्हरफिटिंग टाळण्यासाठी काही मार्ग आहेत:

 * अर्ली स्टॉपिंग -- सतत व्हॅलिडेशन सेटवरील त्रुटीचे निरीक्षण करणे आणि व्हॅलिडेशन त्रुटी वाढू लागल्यावर प्रशिक्षण थांबवणे.
 * स्पष्ट वेट डिके / रेग्युलरायझेशन -- हाय अॅबसोल्यूट वेट्ससाठी लॉस फंक्शनमध्ये अतिरिक्त दंड जोडणे, ज्यामुळे मॉडेलला अत्यंत अस्थिर परिणाम मिळण्यापासून रोखले जाते
 * मॉडेल सरासरीकरण -- अनेक मॉडेल्सचे प्रशिक्षण घेणे आणि नंतर परिणाम सरासरी करणे. यामुळे व्हेरियन्स कमी होतो.
 * ड्रॉपआउट (अप्रत्यक्ष मॉडेल सरासरीकरण)

## ऑप्टिमायझर्स / प्रशिक्षण अल्गोरिदम

प्रशिक्षणाचा आणखी एक महत्त्वाचा पैलू म्हणजे चांगला प्रशिक्षण अल्गोरिदम निवडणे. जरी पारंपरिक **gradient descent** एक योग्य पर्याय आहे, तरी कधीकधी ते खूप धीमे असू शकते किंवा इतर समस्यांना कारणीभूत ठरू शकते.

डीप लर्निंगमध्ये, आपण **Stochastic Gradient Descent** (SGD) वापरतो, जो प्रशिक्षण सेटमधून रँडमपणे निवडलेल्या मिनिबॅचेसवर लागू केलेला gradient descent आहे. वेट्स खालील सूत्राने समायोजित केले जातात:

w<sup>t+1</sup> = w<sup>t</sup> - η∇ℒ

### मोमेंटम

**मोमेंटम SGD** मध्ये, आपण मागील चरणांमधील ग्रेडियंटचा काही भाग ठेवतो. हे असेच आहे जसे आपण जडत्वाने कुठेतरी जात आहोत, आणि आपल्याला वेगळ्या दिशेने धक्का मिळतो, आपला मार्ग त्वरित बदलत नाही, परंतु मूळ हालचालीचा काही भाग ठेवतो. येथे आपण *गती* दर्शवण्यासाठी आणखी एक व्हेक्टर v सादर करतो:

* v<sup>t+1</sup> = γ v<sup>t</sup> - η∇ℒ
* w<sup>t+1</sup> = w<sup>t</sup>+v<sup>t+1</sup>

येथे γ पॅरामीटर दर्शवतो की आपण जडत्वाचा किती विचार करतो: γ=0 पारंपरिक SGD ला अनुरूप आहे; γ=1 हे शुद्ध हालचालीचे समीकरण आहे.

### Adam, Adagrad, इत्यादी

प्रत्येक लेयरमध्ये आपण काही मॅट्रिक्स W<sub>i</sub> ने सिग्नल्स गुणाकार करतो, ||W<sub>i</sub>|| वर अवलंबून, ग्रेडियंट कमी होऊ शकतो आणि 0 च्या जवळ असतो किंवा अनिश्चितपणे वाढतो. ही Exploding/Vanishing Gradients समस्येची मुळ आहे.

या समस्येचे एक उपाय म्हणजे समीकरणात ग्रेडियंटचा फक्त दिशा वापरणे आणि अॅबसोल्यूट मूल्य दुर्लक्षित करणे, उदा.

w<sup>t+1</sup> = w<sup>t</sup> - η(∇ℒ/||∇ℒ||), जिथे ||∇ℒ|| = √∑(∇ℒ)<sup>2</sup>

हा अल्गोरिदम **Adagrad** म्हणून ओळखला जातो. याच कल्पनेचा वापर करणारे इतर अल्गोरिदम: **RMSProp**, **Adam**

> **Adam** अनेक अनुप्रयोगांसाठी एक अत्यंत कार्यक्षम अल्गोरिदम मानला जातो, त्यामुळे जर तुम्हाला कोणता वापरायचा आहे याची खात्री नसेल - Adam वापरा.

### ग्रेडियंट क्लिपिंग

ग्रेडियंट क्लिपिंग ही वरील कल्पनेची विस्तारित आवृत्ती आहे. जेव्हा ||∇ℒ|| ≤ θ असते, तेव्हा आपण वेट ऑप्टिमायझेशनमध्ये मूळ ग्रेडियंट विचारात घेतो, आणि जेव्हा ||∇ℒ|| > θ असते - तेव्हा आपण ग्रेडियंट त्याच्या नॉर्मने भागतो. येथे θ हा पॅरामीटर आहे, बहुतेक प्रकरणांमध्ये आपण θ=1 किंवा θ=10 घेऊ शकतो.

### लर्निंग रेट डिके

प्रशिक्षणाचा यशस्वी परिणाम लर्निंग रेट पॅरामीटर η वर अवलंबून असतो. हे गृहीत धरणे तार्किक आहे की η चे मोठे मूल्य जलद प्रशिक्षण देते, जे आपण सामान्यतः प्रशिक्षणाच्या सुरुवातीला इच्छित असतो, आणि नंतर η चे छोटे मूल्य नेटवर्कला सूक्ष्म-ट्यून करण्यास परवानगी देते. त्यामुळे, बहुतेक प्रकरणांमध्ये आपण प्रशिक्षणाच्या प्रक्रियेत η कमी करू इच्छितो.

हे प्रत्येक प्रशिक्षण epoch नंतर η ला काही संख्येने (उदा. 0.98) गुणाकार करून किंवा अधिक जटिल **लर्निंग रेट शेड्यूल** वापरून केले जाऊ शकते.

## वेगवेगळ्या नेटवर्क आर्किटेक्चर्स

तुमच्या समस्येसाठी योग्य नेटवर्क आर्किटेक्चर निवडणे कठीण असू शकते. सामान्यतः, आपण अशा आर्किटेक्चर निवडतो जे आपल्या विशिष्ट कार्यासाठी (किंवा तत्सम कार्यासाठी) कार्य करण्यासाठी सिद्ध झाले आहे. येथे संगणकीय दृष्टिकोनासाठी न्यूरल नेटवर्क आर्किटेक्चर्सचा [चांगला आढावा](https://www.topbots.com/a-brief-history-of-neural-network-architectures/) दिला आहे.

> आपल्याकडे असलेल्या प्रशिक्षण नमुन्यांच्या संख्येसाठी पुरेसे शक्तिशाली असे आर्किटेक्चर निवडणे महत्त्वाचे आहे. खूप शक्तिशाली मॉडेल निवडल्याने [ओव्हरफिटिंग](../../3-NeuralNetworks/05-Frameworks/Overfitting.md) होऊ शकते.

आवश्यक जटिलतेनुसार आपोआप समायोजित होणारे आर्किटेक्चर वापरणे हा आणखी एक चांगला मार्ग आहे. काही प्रमाणात, **ResNet** आर्किटेक्चर आणि **Inception** हे स्वतः समायोजित करणारे आहेत. [संगणकीय दृष्टिकोन आर्किटेक्चर्सवर अधिक माहिती](../07-ConvNets/CNN_Architectures.md).

**अस्वीकरण**:  
हा दस्तऐवज AI भाषांतर सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) चा वापर करून भाषांतरित करण्यात आला आहे. आम्ही अचूकतेसाठी प्रयत्नशील असलो तरी, कृपया लक्षात घ्या की स्वयंचलित भाषांतरांमध्ये त्रुटी किंवा अचूकतेचा अभाव असू शकतो. मूळ भाषेतील मूळ दस्तऐवज हा अधिकृत स्रोत मानला जावा. महत्त्वाच्या माहितीसाठी व्यावसायिक मानवी भाषांतराची शिफारस केली जाते. या भाषांतराचा वापर केल्यामुळे उद्भवलेल्या कोणत्याही गैरसमज किंवा चुकीच्या अर्थासाठी आम्ही जबाबदार राहणार नाही.