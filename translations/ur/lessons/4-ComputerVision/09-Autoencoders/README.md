<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "0b306c04f5337b6e7430e5c0b16bb5c0",
  "translation_date": "2025-08-26T09:03:54+00:00",
  "source_file": "lessons/4-ComputerVision/09-Autoencoders/README.md",
  "language_code": "ur"
}
-->
# آٹو اینکوڈرز

جب سی این اینز کو تربیت دی جاتی ہے، تو ایک مسئلہ یہ ہوتا ہے کہ ہمیں بہت زیادہ لیبل شدہ ڈیٹا کی ضرورت ہوتی ہے۔ مثال کے طور پر، امیج کلاسیفیکیشن کے معاملے میں، ہمیں تصاویر کو مختلف کلاسز میں تقسیم کرنا پڑتا ہے، جو ایک دستی کام ہے۔

## [پری لیکچر کوئز](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/109)

تاہم، ہم سی این این فیچر ایکسٹریکٹرز کو تربیت دینے کے لیے خام (غیر لیبل شدہ) ڈیٹا استعمال کرنا چاہتے ہیں، جسے **سیلف سپروائزڈ لرننگ** کہا جاتا ہے۔ لیبلز کے بجائے، ہم تربیتی تصاویر کو نیٹ ورک ان پٹ اور آؤٹ پٹ دونوں کے طور پر استعمال کریں گے۔ **آٹو اینکوڈر** کا بنیادی خیال یہ ہے کہ ہمارے پاس ایک **اینکوڈر نیٹ ورک** ہوگا جو ان پٹ تصویر کو کسی **لیٹنٹ اسپیس** میں تبدیل کرے گا (عام طور پر یہ کچھ چھوٹے سائز کا ویکٹر ہوتا ہے)، پھر **ڈیکوڈر نیٹ ورک**، جس کا مقصد اصل تصویر کو دوبارہ بنانا ہوگا۔

> ✅ ایک [آٹو اینکوڈر](https://wikipedia.org/wiki/Autoencoder) "مصنوعی نیورل نیٹ ورک کی ایک قسم ہے جو غیر لیبل شدہ ڈیٹا کے مؤثر کوڈنگز سیکھنے کے لیے استعمال ہوتی ہے۔"

چونکہ ہم آٹو اینکوڈر کو تربیت دے رہے ہیں تاکہ اصل تصویر سے زیادہ سے زیادہ معلومات حاصل کی جا سکیں تاکہ درست تعمیر نو ہو، نیٹ ورک ان پٹ تصاویر کے بہترین **ایمبیڈنگ** تلاش کرنے کی کوشش کرتا ہے تاکہ معنی کو پکڑا جا سکے۔

![آٹو اینکوڈر ڈایاگرام](../../../../../translated_images/autoencoder_schema.5e6fc9ad98a5eb6197f3513cf3baf4dfbe1389a6ae74daebda64de9f1c99f142.ur.jpg)

> تصویر [Keras بلاگ](https://blog.keras.io/building-autoencoders-in-keras.html) سے لی گئی ہے

## آٹو اینکوڈرز کے استعمال کے منظرنامے

اگرچہ اصل تصاویر کو دوبارہ بنانا بذات خود مفید نہیں لگتا، لیکن کچھ منظرنامے ایسے ہیں جہاں آٹو اینکوڈرز خاص طور پر کارآمد ہوتے ہیں:

* **تصاویر کے طول و عرض کو کم کرنا** یا **امیج ایمبیڈنگز کی تربیت**۔ عام طور پر آٹو اینکوڈرز پی سی اے سے بہتر نتائج دیتے ہیں، کیونکہ یہ تصاویر کی مکانی نوعیت اور درجہ بندی کی خصوصیات کو مدنظر رکھتے ہیں۔
* **شور کو ختم کرنا**، یعنی تصویر سے شور کو ہٹانا۔ چونکہ شور بہت زیادہ غیر ضروری معلومات لے کر آتا ہے، آٹو اینکوڈر اسے نسبتاً چھوٹے لیٹنٹ اسپیس میں فٹ نہیں کر سکتا، اور اس طرح یہ تصویر کے صرف اہم حصے کو پکڑتا ہے۔ جب ڈینائزرز کو تربیت دی جاتی ہے، تو ہم اصل تصاویر سے شروع کرتے ہیں، اور آٹو اینکوڈر کے ان پٹ کے طور پر مصنوعی طور پر شامل کردہ شور کے ساتھ تصاویر استعمال کرتے ہیں۔
* **سپر ریزولوشن**، تصویر کی ریزولوشن بڑھانا۔ ہم ہائی ریزولوشن تصاویر سے شروع کرتے ہیں، اور آٹو اینکوڈر ان پٹ کے طور پر کم ریزولوشن والی تصویر استعمال کرتے ہیں۔
* **جنریٹو ماڈلز**۔ ایک بار جب ہم آٹو اینکوڈر کو تربیت دے لیتے ہیں، تو ڈیکوڈر حصہ نئے اشیاء بنانے کے لیے استعمال کیا جا سکتا ہے، جو کہ رینڈم لیٹنٹ ویکٹرز سے شروع ہوتا ہے۔

## ویرییشنل آٹو اینکوڈرز (VAE)

روایتی آٹو اینکوڈرز کسی طرح ان پٹ ڈیٹا کے طول و عرض کو کم کرتے ہیں، ان پٹ تصاویر کی اہم خصوصیات کو سمجھتے ہیں۔ تاہم، لیٹنٹ ویکٹرز اکثر زیادہ معنی خیز نہیں ہوتے۔ دوسرے الفاظ میں، MNIST ڈیٹاسیٹ کو مثال کے طور پر لیتے ہوئے، یہ سمجھنا کہ مختلف لیٹنٹ ویکٹرز کے ساتھ کون سے ہندسے مطابقت رکھتے ہیں، آسان کام نہیں ہے، کیونکہ قریبی لیٹنٹ ویکٹرز ضروری نہیں کہ ایک ہی ہندسے سے مطابقت رکھتے ہوں۔

دوسری طرف، *جنریٹو* ماڈلز کو تربیت دینے کے لیے لیٹنٹ اسپیس کی کچھ سمجھ ہونا بہتر ہے۔ یہ خیال ہمیں **ویرییشنل آٹو اینکوڈر** (VAE) کی طرف لے جاتا ہے۔

VAE وہ آٹو اینکوڈر ہے جو لیٹنٹ پیرامیٹرز کی *شماریاتی تقسیم* کی پیش گوئی کرنا سیکھتا ہے، جسے **لیٹنٹ ڈسٹریبیوشن** کہا جاتا ہے۔ مثال کے طور پر، ہم چاہتے ہیں کہ لیٹنٹ ویکٹرز کو کچھ اوسط z<sub>mean</sub> اور معیاری انحراف z<sub>sigma</sub> کے ساتھ معمول کے مطابق تقسیم کیا جائے (اوسط اور معیاری انحراف دونوں کچھ طول و عرض d کے ویکٹر ہیں)۔ VAE میں اینکوڈر ان پیرامیٹرز کی پیش گوئی کرنا سیکھتا ہے، اور پھر ڈیکوڈر اس تقسیم سے ایک رینڈم ویکٹر لیتا ہے تاکہ اشیاء کو دوبارہ بنایا جا سکے۔

خلاصہ:

 * ان پٹ ویکٹر سے، ہم `z_mean` اور `z_log_sigma` کی پیش گوئی کرتے ہیں (معیاری انحراف کی بجائے، ہم اس کا لوگارتھم پیش گوئی کرتے ہیں)
 * ہم تقسیم N(z<sub>mean</sub>,exp(z<sub>log\_sigma</sub>)) سے ایک ویکٹر `sample` لیتے ہیں
 * ڈیکوڈر `sample` کو ان پٹ ویکٹر کے طور پر استعمال کرتے ہوئے اصل تصویر کو ڈی کوڈ کرنے کی کوشش کرتا ہے

 <img src="images/vae.png" width="50%">

> تصویر [اس بلاگ پوسٹ](https://ijdykeman.github.io/ml/2016/12/21/cvae.html) سے لی گئی ہے، جو Isaak Dykeman نے لکھی ہے

ویرییشنل آٹو اینکوڈرز ایک پیچیدہ نقصان کے فنکشن کا استعمال کرتے ہیں جو دو حصوں پر مشتمل ہوتا ہے:

* **ریکنسٹرکشن نقصان** وہ نقصان کا فنکشن ہے جو ظاہر کرتا ہے کہ دوبارہ بنائی گئی تصویر ہدف کے کتنی قریب ہے (یہ Mean Squared Error، یا MSE ہو سکتا ہے)۔ یہ وہی نقصان کا فنکشن ہے جو عام آٹو اینکوڈرز میں استعمال ہوتا ہے۔
* **KL نقصان**، جو یقینی بناتا ہے کہ لیٹنٹ ویرئیبل ڈسٹریبیوشن نارمل ڈسٹریبیوشن کے قریب رہتا ہے۔ یہ [Kullback-Leibler divergence](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained) کے تصور پر مبنی ہے - دو شماریاتی تقسیموں کی مماثلت کا اندازہ لگانے کے لیے ایک میٹرک۔

VAEs کا ایک اہم فائدہ یہ ہے کہ وہ ہمیں نسبتاً آسانی سے نئی تصاویر بنانے کی اجازت دیتے ہیں، کیونکہ ہمیں معلوم ہوتا ہے کہ لیٹنٹ ویکٹرز کو کس تقسیم سے نمونہ لینا ہے۔ مثال کے طور پر، اگر ہم MNIST پر 2D لیٹنٹ ویکٹر کے ساتھ VAE کو تربیت دیتے ہیں، تو ہم لیٹنٹ ویکٹر کے اجزاء کو مختلف کر کے مختلف ہندسے حاصل کر سکتے ہیں:

<img alt="vaemnist" src="images/vaemnist.png" width="50%"/>

> تصویر [Dmitry Soshnikov](http://soshnikov.com) کی ہے

مشاہدہ کریں کہ تصاویر ایک دوسرے میں کیسے ضم ہو رہی ہیں، جیسے ہی ہم لیٹنٹ پیرامیٹر اسپیس کے مختلف حصوں سے لیٹنٹ ویکٹرز حاصل کرتے ہیں۔ ہم اس اسپیس کو 2D میں بھی دیکھ سکتے ہیں:

<img alt="vaemnist cluster" src="images/vaemnist-diag.png" width="50%"/> 

> تصویر [Dmitry Soshnikov](http://soshnikov.com) کی ہے

## ✍️ مشقیں: آٹو اینکوڈرز

آٹو اینکوڈرز کے بارے میں مزید جانیں ان متعلقہ نوٹ بکس میں:

* [TensorFlow میں آٹو اینکوڈرز](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb)
* [PyTorch میں آٹو اینکوڈرز](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoEncodersPyTorch.ipynb)

## آٹو اینکوڈرز کی خصوصیات

* **ڈیٹا مخصوص** - یہ صرف ان قسم کی تصاویر کے ساتھ اچھا کام کرتے ہیں جن پر انہیں تربیت دی گئی ہو۔ مثال کے طور پر، اگر ہم پھولوں پر سپر ریزولوشن نیٹ ورک کو تربیت دیں، تو یہ پورٹریٹس پر اچھا کام نہیں کرے گا۔ اس کی وجہ یہ ہے کہ نیٹ ورک تربیتی ڈیٹاسیٹ سے سیکھے گئے فیچرز سے باریک تفصیلات لے کر ہائی ریزولوشن تصویر بنا سکتا ہے۔
* **لوسی** - دوبارہ بنائی گئی تصویر اصل تصویر جیسی نہیں ہوتی۔ نقصان کی نوعیت تربیت کے دوران استعمال کیے گئے *نقصان کے فنکشن* سے متعین ہوتی ہے۔
* **غیر لیبل شدہ ڈیٹا** پر کام کرتا ہے

## [پوسٹ لیکچر کوئز](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/209)

## نتیجہ

اس سبق میں، آپ نے آٹو اینکوڈرز کی مختلف اقسام کے بارے میں سیکھا جو AI سائنسدان کے لیے دستیاب ہیں۔ آپ نے انہیں بنانے اور تصاویر کو دوبارہ بنانے کے لیے استعمال کرنے کا طریقہ سیکھا۔ آپ نے VAE کے بارے میں بھی سیکھا اور اسے نئی تصاویر بنانے کے لیے استعمال کرنے کا طریقہ سمجھا۔

## 🚀 چیلنج

اس سبق میں، آپ نے تصاویر کے لیے آٹو اینکوڈرز کے استعمال کے بارے میں سیکھا۔ لیکن انہیں موسیقی کے لیے بھی استعمال کیا جا سکتا ہے! Magenta پروجیکٹ کے [MusicVAE](https://magenta.tensorflow.org/music-vae) پروجیکٹ کو دیکھیں، جو آٹو اینکوڈرز کو موسیقی کو دوبارہ بنانے کے لیے سیکھنے کے لیے استعمال کرتا ہے۔ اس لائبریری کے ساتھ کچھ [تجربات](https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/Multitrack_MusicVAE.ipynb) کریں تاکہ دیکھیں آپ کیا بنا سکتے ہیں۔

## [پوسٹ لیکچر کوئز](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/208)

## جائزہ اور خود مطالعہ

حوالہ کے لیے، آٹو اینکوڈرز کے بارے میں مزید پڑھیں ان وسائل میں:

* [Keras میں آٹو اینکوڈرز بنانا](https://blog.keras.io/building-autoencoders-in-keras.html)
* [NeuroHive پر بلاگ پوسٹ](https://neurohive.io/ru/osnovy-data-science/variacionnyj-avtojenkoder-vae/)
* [ویرییشنل آٹو اینکوڈرز کی وضاحت](https://kvfrans.com/variational-autoencoders-explained/)
* [کنڈیشنل ویرییشنل آٹو اینکوڈرز](https://ijdykeman.github.io/ml/2016/12/21/cvae.html)

## اسائنمنٹ

[TensorFlow کا استعمال کرتے ہوئے اس نوٹ بک](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb) کے آخر میں آپ کو ایک 'ٹاسک' ملے گا - اسے اپنی اسائنمنٹ کے طور پر استعمال کریں۔

**ڈسکلیمر**:  
یہ دستاویز AI ترجمہ سروس [Co-op Translator](https://github.com/Azure/co-op-translator) کا استعمال کرتے ہوئے ترجمہ کی گئی ہے۔ ہم درستگی کے لیے کوشش کرتے ہیں، لیکن براہ کرم آگاہ رہیں کہ خودکار ترجمے میں غلطیاں یا غیر درستیاں ہو سکتی ہیں۔ اصل دستاویز کو اس کی اصل زبان میں مستند ذریعہ سمجھا جانا چاہیے۔ اہم معلومات کے لیے، پیشہ ور انسانی ترجمہ کی سفارش کی جاتی ہے۔ ہم اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کے ذمہ دار نہیں ہیں۔