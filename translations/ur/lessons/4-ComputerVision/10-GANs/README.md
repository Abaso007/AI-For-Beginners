<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f07c85bbf05a1f67505da98f4ecc124c",
  "translation_date": "2025-08-26T09:13:40+00:00",
  "source_file": "lessons/4-ComputerVision/10-GANs/README.md",
  "language_code": "ur"
}
-->
# جنریٹو ایڈورسریل نیٹ ورکس

پچھلے حصے میں، ہم نے **جنریٹو ماڈلز** کے بارے میں سیکھا: ایسے ماڈلز جو تربیتی ڈیٹا سیٹ میں موجود تصاویر جیسی نئی تصاویر بنا سکتے ہیں۔ VAE جنریٹو ماڈل کی ایک اچھی مثال تھی۔

## [پری لیکچر کوئز](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/110)

تاہم، اگر ہم کچھ واقعی معنی خیز بنانا چاہیں، جیسے مناسب ریزولوشن پر ایک پینٹنگ، VAE کے ساتھ، تو ہمیں نظر آئے گا کہ تربیت اچھی طرح سے نہیں ہوتی۔ اس استعمال کے لیے، ہمیں ایک اور آرکیٹیکچر کے بارے میں سیکھنا چاہیے جو خاص طور پر جنریٹو ماڈلز کے لیے بنایا گیا ہے - **جنریٹو ایڈورسریل نیٹ ورکس**، یا GANs۔

GAN کا بنیادی خیال یہ ہے کہ دو نیورل نیٹ ورکس ہوں جو ایک دوسرے کے خلاف تربیت دیے جائیں:

<img src="images/gan_architecture.png" width="70%"/>

> تصویر: [Dmitry Soshnikov](http://soshnikov.com)

> ✅ تھوڑی سی وضاحت:
> * **جنریٹر** ایک نیٹ ورک ہے جو کچھ بے ترتیب ویکٹر لیتا ہے اور نتیجے میں تصویر بناتا ہے۔
> * **ڈسکرمنیٹر** ایک نیٹ ورک ہے جو تصویر لیتا ہے اور یہ بتانا چاہیے کہ آیا یہ حقیقی تصویر ہے (تربیتی ڈیٹا سیٹ سے)، یا یہ جنریٹر نے بنائی ہے۔ یہ بنیادی طور پر ایک تصویر کی درجہ بندی کرنے والا ہے۔

### ڈسکرمنیٹر

ڈسکرمنیٹر کی آرکیٹیکچر عام تصویر کی درجہ بندی کرنے والے نیٹ ورک سے مختلف نہیں ہے۔ سب سے آسان صورت میں یہ مکمل طور پر جڑا ہوا درجہ بندی کرنے والا ہو سکتا ہے، لیکن زیادہ تر امکان ہے کہ یہ ایک [کنوولوشنل نیٹ ورک](../07-ConvNets/README.md) ہوگا۔

> ✅ کنوولوشنل نیٹ ورکس پر مبنی GAN کو [DCGAN](https://arxiv.org/pdf/1511.06434.pdf) کہا جاتا ہے۔

ایک CNN ڈسکرمنیٹر درج ذیل تہوں پر مشتمل ہوتا ہے: کئی کنوولوشنز+پولنگز (کم ہوتی ہوئی اسپیشل سائز کے ساتھ) اور ایک یا زیادہ مکمل طور پر جڑی ہوئی تہیں تاکہ "فیچر ویکٹر" حاصل ہو، اور آخر میں بائنری درجہ بندی کرنے والا۔

> ✅ 'پولنگ' اس سیاق و سباق میں ایک تکنیک ہے جو تصویر کے سائز کو کم کرتی ہے۔ "پولنگ تہیں ڈیٹا کے ابعاد کو کم کرتی ہیں، ایک تہہ میں نیورون کلسٹرز کے آؤٹ پٹ کو اگلی تہہ میں ایک نیورون میں یکجا کر کے۔" - [ماخذ](https://wikipedia.org/wiki/Convolutional_neural_network#Pooling_layers)

### جنریٹر

جنریٹر تھوڑا زیادہ پیچیدہ ہے۔ آپ اسے ایک الٹا ڈسکرمنیٹر سمجھ سکتے ہیں۔ ایک لیٹنٹ ویکٹر سے شروع کرتے ہوئے (فیچر ویکٹر کی جگہ)، اس میں ایک مکمل طور پر جڑی ہوئی تہہ ہوتی ہے جو اسے مطلوبہ سائز/شکل میں تبدیل کرتی ہے، اس کے بعد ڈی کنوولوشنز+اپسکیلنگ۔ یہ [آٹو انکوڈر](../09-Autoencoders/README.md) کے *ڈیکوڈر* حصے سے ملتا جلتا ہے۔

> ✅ چونکہ کنوولوشن تہہ تصویر کے ذریعے ایک لکیری فلٹر کے طور پر نافذ کی جاتی ہے، ڈی کنوولوشن بنیادی طور پر کنوولوشن جیسی ہوتی ہے، اور اسے اسی تہہ منطق کا استعمال کرتے ہوئے نافذ کیا جا سکتا ہے۔

<img src="images/gan_arch_detail.png" width="70%"/>

> تصویر: [Dmitry Soshnikov](http://soshnikov.com)

### GAN کی تربیت

GANs کو **ایڈورسریل** کہا جاتا ہے کیونکہ جنریٹر اور ڈسکرمنیٹر کے درمیان مسلسل مقابلہ ہوتا ہے۔ اس مقابلے کے دوران، جنریٹر اور ڈسکرمنیٹر دونوں بہتر ہوتے ہیں، اس طرح نیٹ ورک بہتر اور بہتر تصاویر بنانا سیکھتا ہے۔

تربیت دو مراحل میں ہوتی ہے:

* **ڈسکرمنیٹر کی تربیت**۔ یہ کام کافی سیدھا ہے: ہم جنریٹر کے ذریعے تصاویر کا ایک بیچ بناتے ہیں، انہیں 0 کے لیبل کے ساتھ نشان زد کرتے ہیں، جو جعلی تصویر کے لیے ہے، اور ان پٹ ڈیٹا سیٹ سے تصاویر کا ایک بیچ لیتے ہیں (لیبل 1، حقیقی تصویر کے ساتھ)۔ ہم کچھ *ڈسکرمنیٹر نقصان* حاصل کرتے ہیں، اور بیک پروپ کرتے ہیں۔
* **جنریٹر کی تربیت**۔ یہ تھوڑا زیادہ پیچیدہ ہے، کیونکہ ہم جنریٹر کے لیے براہ راست متوقع آؤٹ پٹ نہیں جانتے۔ ہم پورے GAN نیٹ ورک کو جنریٹر کے ساتھ ڈسکرمنیٹر کے بعد لیتے ہیں، اسے کچھ بے ترتیب ویکٹرز کے ساتھ فیڈ کرتے ہیں، اور توقع کرتے ہیں کہ نتیجہ 1 ہوگا (حقیقی تصاویر کے مطابق)۔ پھر ہم ڈسکرمنیٹر کے پیرامیٹرز کو منجمد کرتے ہیں (ہم نہیں چاہتے کہ یہ اس مرحلے پر تربیت دی جائے)، اور بیک پروپ کرتے ہیں۔

اس عمل کے دوران، جنریٹر اور ڈسکرمنیٹر دونوں کے نقصانات نمایاں طور پر کم نہیں ہو رہے ہوتے۔ مثالی صورتحال میں، انہیں جھولنا چاہیے، جو دونوں نیٹ ورکس کی کارکردگی کو بہتر بنانے کے مطابق ہو۔

## ✍️ مشقیں: GANs

* [GAN نوٹ بک TensorFlow/Keras میں](../../../../../lessons/4-ComputerVision/10-GANs/GANTF.ipynb)
* [GAN نوٹ بک PyTorch میں](../../../../../lessons/4-ComputerVision/10-GANs/GANPyTorch.ipynb)

### GAN کی تربیت کے مسائل

GANs کو تربیت دینا خاص طور پر مشکل سمجھا جاتا ہے۔ یہاں چند مسائل ہیں:

* **موڈ کولپس**۔ اس اصطلاح سے مراد ہے کہ جنریٹر ایک کامیاب تصویر بنانا سیکھتا ہے جو جنریٹر کو دھوکہ دیتی ہے، اور مختلف تصاویر کی قسم نہیں بناتا۔
* **ہائپر پیرامیٹرز کے لیے حساسیت**۔ اکثر آپ دیکھ سکتے ہیں کہ GAN بالکل بھی کنورج نہیں کرتا، اور پھر اچانک سیکھنے کی شرح میں کمی کنورجنس کی طرف لے جاتی ہے۔
* جنریٹر اور ڈسکرمنیٹر کے درمیان **توازن** برقرار رکھنا۔ بہت سے معاملات میں ڈسکرمنیٹر نقصان نسبتاً جلدی صفر تک گر سکتا ہے، جس کے نتیجے میں جنریٹر مزید تربیت حاصل کرنے کے قابل نہیں ہوتا۔ اس پر قابو پانے کے لیے، ہم جنریٹر اور ڈسکرمنیٹر کے لیے مختلف سیکھنے کی شرح مقرر کرنے کی کوشش کر سکتے ہیں، یا اگر نقصان پہلے ہی بہت کم ہو تو ڈسکرمنیٹر کی تربیت کو چھوڑ سکتے ہیں۔
* **اعلی ریزولوشن** کے لیے تربیت۔ آٹو انکوڈرز کے ساتھ اسی مسئلے کی عکاسی کرتے ہوئے، یہ مسئلہ اس وقت پیدا ہوتا ہے جب کنوولوشنل نیٹ ورک کی بہت سی تہوں کو دوبارہ تعمیر کرنے سے آرٹیفیکٹس پیدا ہوتے ہیں۔ اس مسئلے کو عام طور پر **پروگریسو گروئنگ** کے ساتھ حل کیا جاتا ہے، جب پہلے چند تہوں کو کم ریزولوشن تصاویر پر تربیت دی جاتی ہے، اور پھر تہوں کو "ان بلاک" یا شامل کیا جاتا ہے۔ ایک اور حل تہوں کے درمیان اضافی کنکشن شامل کرنا اور ایک ساتھ کئی ریزولوشنز کی تربیت دینا ہوگا - مزید تفصیلات کے لیے اس [ملٹی اسکیل گریڈینٹ GANs پیپر](https://arxiv.org/abs/1903.06048) کو دیکھیں۔

## اسٹائل ٹرانسفر

GANs آرٹسٹک تصاویر بنانے کا ایک بہترین طریقہ ہیں۔ ایک اور دلچسپ تکنیک **اسٹائل ٹرانسفر** کہلاتی ہے، جو ایک **مواد کی تصویر** لیتی ہے، اور اسے مختلف انداز میں دوبارہ بناتی ہے، **اسٹائل تصویر** سے فلٹرز لگاتے ہوئے۔

یہ طریقہ کار اس طرح کام کرتا ہے:
* ہم ایک بے ترتیب شور تصویر سے شروع کرتے ہیں (یا مواد کی تصویر سے، لیکن سمجھنے کے لیے بے ترتیب شور سے شروع کرنا آسان ہے)
* ہمارا مقصد ایسی تصویر بنانا ہوگا، جو مواد کی تصویر اور اسٹائل تصویر دونوں کے قریب ہو۔ یہ دو نقصان کے فنکشنز کے ذریعے طے کیا جائے گا:
   - **مواد نقصان** موجودہ تصویر اور مواد کی تصویر سے CNN کے ذریعے کچھ تہوں پر نکالی گئی خصوصیات کی بنیاد پر حساب کیا جاتا ہے۔
   - **اسٹائل نقصان** موجودہ تصویر اور اسٹائل تصویر کے درمیان ایک ہوشیار طریقے سے گرام میٹرکس کا استعمال کرتے ہوئے حساب کیا جاتا ہے (مزید تفصیلات [مثال نوٹ بک](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb) میں)
* تصویر کو ہموار بنانے اور شور کو دور کرنے کے لیے، ہم **ویریئشن نقصان** بھی متعارف کراتے ہیں، جو پڑوسی پکسلز کے درمیان اوسط فاصلہ حساب کرتا ہے۔
* بنیادی اصلاحی لوپ موجودہ تصویر کو ایڈجسٹ کرتا ہے، کل نقصان کو کم کرنے کے لیے، جو تمام تین نقصانات کا وزنی مجموعہ ہے، گریڈینٹ ڈیسنٹ (یا کچھ اور اصلاحی الگورتھم) کا استعمال کرتے ہوئے۔

## ✍️ مثال: [اسٹائل ٹرانسفر](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)

## [پوسٹ لیکچر کوئز](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/210)

## نتیجہ

اس سبق میں، آپ نے GANs اور انہیں تربیت دینے کے طریقے کے بارے میں سیکھا۔ آپ نے اس قسم کے نیورل نیٹ ورک کو درپیش خاص چیلنجز اور ان سے آگے بڑھنے کے لیے کچھ حکمت عملیوں کے بارے میں بھی سیکھا۔

## 🚀 چیلنج

اپنی تصاویر استعمال کرتے ہوئے [اسٹائل ٹرانسفر نوٹ بک](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb) کو چلائیں۔

## جائزہ اور خود مطالعہ

حوالے کے لیے، ان وسائل میں GANs کے بارے میں مزید پڑھیں:

* مارکو پاسینی، [10 سبق جو میں نے GANs کی تربیت کرتے ہوئے ایک سال میں سیکھے](https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628)
* [StyleGAN](https://en.wikipedia.org/wiki/StyleGAN)، ایک *ڈی فیکٹو* GAN آرکیٹیکچر پر غور کریں
* [Azure ML پر GANs کا استعمال کرتے ہوئے جنریٹو آرٹ بنانا](https://soshnikov.com/scienceart/creating-generative-art-using-gan-on-azureml/)

## اسائنمنٹ

اس سبق سے وابستہ دو نوٹ بکس میں سے کسی ایک کو دوبارہ دیکھیں اور GAN کو اپنی تصاویر پر دوبارہ تربیت دیں۔ آپ کیا بنا سکتے ہیں؟

**ڈس کلیمر**:  
یہ دستاویز AI ترجمہ سروس [Co-op Translator](https://github.com/Azure/co-op-translator) کا استعمال کرتے ہوئے ترجمہ کی گئی ہے۔ ہم درستگی کے لیے کوشش کرتے ہیں، لیکن براہ کرم آگاہ رہیں کہ خودکار ترجمے میں غلطیاں یا عدم درستگی ہو سکتی ہیں۔ اصل دستاویز کو اس کی اصل زبان میں مستند ذریعہ سمجھا جانا چاہیے۔ اہم معلومات کے لیے، پیشہ ور انسانی ترجمہ کی سفارش کی جاتی ہے۔ اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کے لیے ہم ذمہ دار نہیں ہیں۔