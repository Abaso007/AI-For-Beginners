<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ae074cd940fc2f4dc24fc07b66ccbd99",
  "translation_date": "2025-08-26T09:46:44+00:00",
  "source_file": "lessons/4-ComputerVision/08-TransferLearning/TrainingTricks.md",
  "language_code": "ur"
}
-->
# ڈیپ لرننگ ٹریننگ کے طریقے

جب نیورل نیٹ ورکس زیادہ گہرے ہو جاتے ہیں، تو ان کی تربیت کا عمل زیادہ مشکل ہو جاتا ہے۔ ایک بڑا مسئلہ [vanishing gradients](https://en.wikipedia.org/wiki/Vanishing_gradient_problem) یا [exploding gradients](https://deepai.org/machine-learning-glossary-and-terms/exploding-gradient-problem#:~:text=Exploding%20gradients%20are%20a%20problem,updates%20are%20small%20and%20controlled.) ہے۔ [یہ پوسٹ](https://towardsdatascience.com/the-vanishing-exploding-gradient-problem-in-deep-neural-networks-191358470c11) ان مسائل کا اچھا تعارف فراہم کرتی ہے۔

گہرے نیٹ ورکس کی تربیت کو زیادہ مؤثر بنانے کے لیے، کچھ تکنیکیں استعمال کی جا سکتی ہیں۔

## ویلیوز کو مناسب حد میں رکھنا

عدداتی حسابات کو زیادہ مستحکم بنانے کے لیے، ہمیں یہ یقینی بنانا ہوگا کہ ہمارے نیورل نیٹ ورک کے اندر تمام ویلیوز مناسب پیمانے پر ہوں، عام طور پر [-1..1] یا [0..1]۔ یہ کوئی سخت شرط نہیں ہے، لیکن فلوٹنگ پوائنٹ حسابات کی نوعیت ایسی ہے کہ مختلف شدت کی ویلیوز کو ایک ساتھ درست طریقے سے جوڑا نہیں جا سکتا۔ مثال کے طور پر، اگر ہم 10<sup>-10</sup> اور 10<sup>10</sup> کو جمع کریں، تو ہمیں ممکنہ طور پر 10<sup>10</sup> ملے گا، کیونکہ چھوٹی ویلیو بڑی ویلیو کے برابر "تبدیل" ہو جائے گی، اور اس طرح mantissa ضائع ہو جائے گی۔

زیادہ تر ایکٹیویشن فنکشنز [-1..1] کے ارد گرد غیر خطی ہوتے ہیں، اور اس لیے یہ سمجھ میں آتا ہے کہ تمام ان پٹ ڈیٹا کو [-1..1] یا [0..1] کے وقفے میں اسکیل کیا جائے۔

## ابتدائی وزن کی ترتیب

مثالی طور پر، ہم چاہتے ہیں کہ نیٹ ورک لیئرز سے گزرنے کے بعد ویلیوز ایک ہی حد میں رہیں۔ اس لیے یہ ضروری ہے کہ وزن کو اس طرح ترتیب دیا جائے کہ ویلیوز کی تقسیم برقرار رہے۔

عام تقسیم **N(0,1)** ایک اچھا خیال نہیں ہے، کیونکہ اگر ہمارے پاس *n* ان پٹس ہوں، تو آؤٹ پٹ کا معیاری انحراف *n* ہوگا، اور ویلیوز ممکنہ طور پر [0..1] کے وقفے سے باہر نکل جائیں گی۔

مندرجہ ذیل ترتیبیں اکثر استعمال کی جاتی ہیں:

- یونیفارم تقسیم -- `uniform`
- **N(0,1/n)** -- `gaussian`
- **N(0,1/√n_in)** اس بات کی ضمانت دیتا ہے کہ صفر اوسط اور معیاری انحراف 1 والے ان پٹس کے لیے وہی اوسط/معیاری انحراف برقرار رہے گا
- **N(0,√2/(n_in+n_out))** -- جسے **Xavier initialization** (`glorot`) کہا جاتا ہے، یہ سگنلز کو فارورڈ اور بیکورڈ پروپیگیشن کے دوران حد میں رکھنے میں مدد کرتا ہے

## بیچ نارملائزیشن

صحیح وزن کی ترتیب کے باوجود، تربیت کے دوران وزن بہت بڑے یا چھوٹے ہو سکتے ہیں، اور وہ سگنلز کو مناسب حد سے باہر لے جائیں گے۔ ہم سگنلز کو واپس لانے کے لیے **نارملائزیشن** تکنیکوں میں سے ایک استعمال کر سکتے ہیں۔ حالانکہ ان میں سے کئی ہیں (وزن نارملائزیشن، لیئر نارملائزیشن)، سب سے زیادہ استعمال ہونے والی بیچ نارملائزیشن ہے۔

**بیچ نارملائزیشن** کا خیال یہ ہے کہ منی بیچ کے تمام ویلیوز کو مدنظر رکھا جائے، اور ان ویلیوز کی بنیاد پر نارملائزیشن (یعنی اوسط کو گھٹانا اور معیاری انحراف سے تقسیم کرنا) انجام دیا جائے۔ یہ ایک نیٹ ورک لیئر کے طور پر نافذ کیا جاتا ہے جو وزن لگانے کے بعد، لیکن ایکٹیویشن فنکشن سے پہلے یہ نارملائزیشن کرتا ہے۔ نتیجے کے طور پر، ہم ممکنہ طور پر زیادہ حتمی درستگی اور تیز تربیت دیکھتے ہیں۔

یہاں بیچ نارملائزیشن پر [اصل مقالہ](https://arxiv.org/pdf/1502.03167.pdf)، [ویکیپیڈیا پر وضاحت](https://en.wikipedia.org/wiki/Batch_normalization)، اور [ایک اچھا تعارفی بلاگ پوسٹ](https://towardsdatascience.com/batch-normalization-in-3-levels-of-understanding-14c2da90a338) (اور ایک [روسی زبان میں](https://habrahabr.ru/post/309302/))۔

## ڈراپ آؤٹ

**ڈراپ آؤٹ** ایک دلچسپ تکنیک ہے جو تربیت کے دوران کچھ فیصد بے ترتیب نیورونز کو ہٹا دیتی ہے۔ یہ ایک لیئر کے طور پر نافذ کیا جاتا ہے جس میں ایک پیرامیٹر ہوتا ہے (ہٹانے کے لیے نیورونز کا فیصد، عام طور پر 10%-50%)، اور تربیت کے دوران یہ ان پٹ ویکٹر کے بے ترتیب عناصر کو صفر کر دیتا ہے، اس سے پہلے کہ وہ اگلی لیئر کو منتقل ہوں۔

حالانکہ یہ ایک عجیب خیال لگ سکتا ہے، آپ MNIST ڈیجٹ کلاسیفائر کی تربیت پر ڈراپ آؤٹ کے اثرات [`Dropout.ipynb`](../../../../../lessons/4-ComputerVision/08-TransferLearning/Dropout.ipynb) نوٹ بک میں دیکھ سکتے ہیں۔ یہ تربیت کو تیز کرتا ہے اور ہمیں کم تربیتی ایپوکز میں زیادہ درستگی حاصل کرنے کی اجازت دیتا ہے۔

اس اثر کو کئی طریقوں سے بیان کیا جا سکتا ہے:

- اسے ماڈل کے لیے ایک بے ترتیب جھٹکے کے عنصر کے طور پر سمجھا جا سکتا ہے، جو آپٹیمائزیشن کو مقامی کم سے باہر لے جاتا ہے
- اسے *ماڈل اوسط کاری* کے طور پر سمجھا جا سکتا ہے، کیونکہ ہم کہہ سکتے ہیں کہ ڈراپ آؤٹ کے دوران ہم تھوڑا مختلف ماڈل کی تربیت کر رہے ہیں

> *کچھ لوگ کہتے ہیں کہ جب کوئی نشے میں شخص کچھ سیکھنے کی کوشش کرتا ہے، تو وہ اگلی صبح اسے بہتر یاد رکھتا ہے، ایک ہوش مند شخص کے مقابلے میں، کیونکہ کچھ خراب نیورونز کے ساتھ دماغ بہتر طور پر مطلب کو سمجھنے کے لیے ڈھالنے کی کوشش کرتا ہے۔ ہم نے کبھی خود یہ نہیں آزمایا کہ یہ سچ ہے یا نہیں*

## اوورفٹنگ کو روکنا

ڈیپ لرننگ کا ایک بہت اہم پہلو یہ ہے کہ [اوورفٹنگ](../../3-NeuralNetworks/05-Frameworks/Overfitting.md) کو روکنے کے قابل ہو۔ حالانکہ یہ بہت طاقتور نیورل نیٹ ورک ماڈل استعمال کرنے کا لالچ دے سکتا ہے، ہمیں ہمیشہ ماڈل پیرامیٹرز کی تعداد کو تربیتی نمونوں کی تعداد کے ساتھ متوازن رکھنا چاہیے۔

> اس بات کو یقینی بنائیں کہ آپ [اوورفٹنگ](../../3-NeuralNetworks/05-Frameworks/Overfitting.md) کے تصور کو سمجھتے ہیں جو ہم نے پہلے متعارف کرایا ہے!

اوورفٹنگ کو روکنے کے کئی طریقے ہیں:

- ابتدائی روک تھام -- ویلیڈیشن سیٹ پر غلطی کو مسلسل مانیٹر کریں اور تربیت کو روکیں جب ویلیڈیشن کی غلطی بڑھنا شروع ہو جائے۔
- واضح وزن کی کمی / ریگولرائزیشن -- نقصان کے فنکشن میں وزن کی زیادہ مطلق ویلیوز کے لیے اضافی جرمانہ شامل کرنا، جو ماڈل کو بہت غیر مستحکم نتائج حاصل کرنے سے روکتا ہے
- ماڈل اوسط کاری -- کئی ماڈلز کی تربیت اور پھر نتیجہ کو اوسط کرنا۔ یہ تغیر کو کم کرنے میں مدد کرتا ہے۔
- ڈراپ آؤٹ (ماڈل اوسط کاری)

## آپٹیمائزرز / تربیتی الگورتھمز

تربیت کا ایک اور اہم پہلو اچھا تربیتی الگورتھم منتخب کرنا ہے۔ حالانکہ کلاسیکل **gradient descent** ایک معقول انتخاب ہے، یہ کبھی کبھی بہت سست ہو سکتا ہے، یا دیگر مسائل پیدا کر سکتا ہے۔

ڈیپ لرننگ میں، ہم **Stochastic Gradient Descent** (SGD) استعمال کرتے ہیں، جو تربیتی سیٹ سے بے ترتیب طور پر منتخب کردہ منی بیچز پر لاگو ہوتا ہے۔ وزن کو اس فارمولے کے ذریعے ایڈجسٹ کیا جاتا ہے:

w<sup>t+1</sup> = w<sup>t</sup> - η∇ℒ

### مومینٹم

**مومینٹم SGD** میں، ہم پچھلے مراحل سے گریڈینٹ کا ایک حصہ رکھتے ہیں۔ یہ اس طرح ہے جیسے ہم کہیں جڑت کے ساتھ حرکت کر رہے ہوں، اور ہمیں کسی مختلف سمت میں دھکا ملے، ہماری رفتار فوراً نہیں بدلتی، بلکہ اصل حرکت کا کچھ حصہ برقرار رکھتی ہے۔ یہاں ہم ایک اور ویکٹر v متعارف کراتے ہیں جو *رفتار* کی نمائندگی کرتا ہے:

- v<sup>t+1</sup> = γ v<sup>t</sup> - η∇ℒ
- w<sup>t+1</sup> = w<sup>t</sup>+v<sup>t+1</sup>

یہاں پیرامیٹر γ اس حد کو ظاہر کرتا ہے جس میں ہم جڑت کو مدنظر رکھتے ہیں: γ=0 کلاسیکل SGD کے مطابق ہے؛ γ=1 ایک خالص حرکت مساوات ہے۔

### آدم، اڈاگراد، وغیرہ

چونکہ ہر لیئر میں ہم سگنلز کو کسی میٹرکس W<sub>i</sub> سے ضرب دیتے ہیں، ||W<sub>i</sub>|| پر منحصر ہے، گریڈینٹ یا تو کم ہو سکتا ہے اور 0 کے قریب ہو سکتا ہے، یا غیر معینہ طور پر بڑھ سکتا ہے۔ یہ Exploding/Vanishing Gradients مسئلے کی اصل ہے۔

اس مسئلے کا ایک حل یہ ہے کہ وزن کی اصلاح کے فارمولے میں گریڈینٹ کی سمت کو استعمال کیا جائے، اور مطلق ویلیو کو نظر انداز کیا جائے، یعنی:

w<sup>t+1</sup> = w<sup>t</sup> - η(∇ℒ/||∇ℒ||), جہاں ||∇ℒ|| = √∑(∇ℒ)<sup>2</sup>

اس الگورتھم کو **Adagrad** کہا جاتا ہے۔ دیگر الگورتھمز جو اسی خیال کو استعمال کرتے ہیں: **RMSProp**, **Adam**

> **Adam** کو بہت سی ایپلیکیشنز کے لیے ایک بہت مؤثر الگورتھم سمجھا جاتا ہے، لہذا اگر آپ کو یقین نہ ہو کہ کون سا استعمال کرنا ہے - Adam استعمال کریں۔

### گریڈینٹ کلپنگ

گریڈینٹ کلپنگ اوپر دیے گئے خیال کی توسیع ہے۔ جب ||∇ℒ|| ≤ θ ہو، تو ہم وزن کی اصلاح میں اصل گریڈینٹ کو مدنظر رکھتے ہیں، اور جب ||∇ℒ|| > θ ہو - ہم گریڈینٹ کو اس کے نارم سے تقسیم کرتے ہیں۔ یہاں θ ایک پیرامیٹر ہے، زیادہ تر معاملات میں ہم θ=1 یا θ=10 لے سکتے ہیں۔

### لرننگ ریٹ ڈیکے

تربیت کی کامیابی اکثر لرننگ ریٹ پیرامیٹر η پر منحصر ہوتی ہے۔ یہ منطقی ہے کہ η کی بڑی ویلیوز تیز تربیت کا نتیجہ دیتی ہیں، جو ہم عام طور پر تربیت کے آغاز میں چاہتے ہیں، اور پھر η کی چھوٹی ویلیوز ہمیں نیٹ ورک کو بہتر بنانے کی اجازت دیتی ہیں۔ اس طرح، زیادہ تر معاملات میں ہم تربیت کے عمل میں η کو کم کرنا چاہتے ہیں۔

یہ تربیت کے ہر ایپوک کے بعد η کو کسی نمبر (مثلاً 0.98) سے ضرب دے کر کیا جا سکتا ہے، یا زیادہ پیچیدہ **لرننگ ریٹ شیڈول** استعمال کر کے۔

## مختلف نیٹ ورک آرکیٹیکچرز

اپنے مسئلے کے لیے صحیح نیٹ ورک آرکیٹیکچر کا انتخاب کرنا مشکل ہو سکتا ہے۔ عام طور پر، ہم وہ آرکیٹیکچر لیں گے جو ہمارے مخصوص کام (یا اسی طرح کے) کے لیے کام کرنے کے لیے ثابت ہو چکا ہو۔ یہاں کمپیوٹر وژن کے لیے نیورل نیٹ ورک آرکیٹیکچرز کا [اچھا جائزہ](https://www.topbots.com/a-brief-history-of-neural-network-architectures/) ہے۔

> یہ ضروری ہے کہ ایسا آرکیٹیکچرز منتخب کریں جو ہمارے پاس موجود تربیتی نمونوں کی تعداد کے لیے کافی طاقتور ہو۔ بہت طاقتور ماڈل کا انتخاب [اوورفٹنگ](../../3-NeuralNetworks/05-Frameworks/Overfitting.md) کا نتیجہ دے سکتا ہے۔

ایک اور اچھا طریقہ یہ ہوگا کہ ایسا آرکیٹیکچر استعمال کریں جو مطلوبہ پیچیدگی کے مطابق خود بخود ایڈجسٹ ہو۔ کسی حد تک، **ResNet** آرکیٹیکچر اور **Inception** خود کو ایڈجسٹ کرنے والے ہیں۔ [کمپیوٹر وژن آرکیٹیکچرز پر مزید](../07-ConvNets/CNN_Architectures.md)

**ڈس کلیمر**:  
یہ دستاویز AI ترجمہ سروس [Co-op Translator](https://github.com/Azure/co-op-translator) کا استعمال کرتے ہوئے ترجمہ کی گئی ہے۔ ہم درستگی کے لیے کوشش کرتے ہیں، لیکن براہ کرم آگاہ رہیں کہ خودکار ترجمے میں غلطیاں یا عدم درستگی ہو سکتی ہیں۔ اصل دستاویز کو اس کی اصل زبان میں مستند ذریعہ سمجھا جانا چاہیے۔ اہم معلومات کے لیے، پیشہ ور انسانی ترجمہ کی سفارش کی جاتی ہے۔ اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کے لیے ہم ذمہ دار نہیں ہیں۔