<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "4522e22e150be0845e03aa41209a39d5",
  "translation_date": "2025-08-26T08:24:06+00:00",
  "source_file": "lessons/5-NLP/13-TextRep/README.md",
  "language_code": "ur"
}
-->
# ٹیکسٹ کو ٹینسرز کے طور پر پیش کرنا

## [لیکچر سے پہلے کا کوئز](https://ff-quizzes.netlify.app/en/ai/quiz/25)

## ٹیکسٹ کی درجہ بندی

اس سیکشن کے پہلے حصے میں، ہم **ٹیکسٹ کی درجہ بندی** کے کام پر توجہ مرکوز کریں گے۔ ہم [AG News](https://www.kaggle.com/amananandrai/ag-news-classification-dataset) ڈیٹاسیٹ استعمال کریں گے، جس میں خبروں کے مضامین درج ذیل کی طرح شامل ہیں:

* زمرہ: سائنس/ٹیکنالوجی  
* عنوان: Ky. کمپنی کو پیپٹائڈز کے مطالعے کے لیے گرانٹ ملی (AP)  
* متن: AP - لوئس ول یونیورسٹی کے ایک کیمسٹری محقق کی قائم کردہ کمپنی کو ترقی کے لیے گرانٹ ملی...  

ہمارا مقصد یہ ہوگا کہ متن کی بنیاد پر خبر کو ایک زمرے میں درجہ بند کریں۔

## ٹیکسٹ کی نمائندگی

اگر ہم نیورل نیٹ ورکس کے ساتھ نیچرل لینگویج پروسیسنگ (NLP) کے کام حل کرنا چاہتے ہیں، تو ہمیں ٹیکسٹ کو ٹینسرز کے طور پر پیش کرنے کا کوئی طریقہ درکار ہوگا۔ کمپیوٹر پہلے ہی ٹیکسٹ کے حروف کو نمبروں کے طور پر پیش کرتے ہیں، جو آپ کی اسکرین پر فونٹس کے ساتھ میپ کیے جاتے ہیں، جیسے ASCII یا UTF-8 انکوڈنگز کے ذریعے۔

<img alt="تصویر جو ایک حرف کو ASCII اور بائنری نمائندگی کے ساتھ میپ کرنے کا خاکہ دکھا رہی ہے" src="images/ascii-character-map.png" width="50%"/>

> [تصویر کا ماخذ](https://www.seobility.net/en/wiki/ASCII)

انسانوں کے طور پر، ہم سمجھتے ہیں کہ ہر حرف **کیا ظاہر کرتا ہے**، اور تمام حروف مل کر جملے کے الفاظ کیسے بناتے ہیں۔ تاہم، کمپیوٹرز خود سے ایسی سمجھ نہیں رکھتے، اور نیورل نیٹ ورک کو تربیت کے دوران اس معنی کو سیکھنا پڑتا ہے۔

لہٰذا، ہم ٹیکسٹ کی نمائندگی کے لیے مختلف طریقے استعمال کر سکتے ہیں:

* **کریکٹر لیول کی نمائندگی**، جس میں ہم ٹیکسٹ کو اس طرح پیش کرتے ہیں کہ ہر حرف کو ایک نمبر کے طور پر لیا جاتا ہے۔ اگر ہمارے ٹیکسٹ کارپس میں *C* مختلف حروف ہوں، تو لفظ *Hello* کو 5x*C* ٹینسر کے طور پر پیش کیا جائے گا۔ ہر حرف ون-ہاٹ انکوڈنگ میں ایک ٹینسر کالم کے مطابق ہوگا۔  
* **ورڈ لیول کی نمائندگی**، جس میں ہم اپنے ٹیکسٹ کے تمام الفاظ کا ایک **لغت** بناتے ہیں، اور پھر الفاظ کو ون-ہاٹ انکوڈنگ کے ذریعے پیش کرتے ہیں۔ یہ طریقہ کسی حد تک بہتر ہے، کیونکہ ہر حرف بذات خود زیادہ معنی نہیں رکھتا، اور اس طرح اعلیٰ سطحی معنوی تصورات - الفاظ - کا استعمال کرکے ہم نیورل نیٹ ورک کے لیے کام کو آسان بناتے ہیں۔ تاہم، بڑے لغت کے سائز کی وجہ سے، ہمیں ہائی ڈائمینشنل اسپارس ٹینسرز سے نمٹنا پڑتا ہے۔

چاہے کوئی بھی نمائندگی ہو، ہمیں پہلے ٹیکسٹ کو **ٹوکینز** کی ترتیب میں تبدیل کرنا ہوگا، جہاں ایک ٹوکین ایک حرف، ایک لفظ، یا کبھی کبھی ایک لفظ کا حصہ بھی ہو سکتا ہے۔ پھر، ہم ٹوکین کو ایک نمبر میں تبدیل کرتے ہیں، عام طور پر **لغت** کا استعمال کرتے ہوئے، اور یہ نمبر ون-ہاٹ انکوڈنگ کے ذریعے نیورل نیٹ ورک میں فیڈ کیا جا سکتا ہے۔

## این-گرامز

قدرتی زبان میں، الفاظ کے درست معنی صرف سیاق و سباق میں ہی طے کیے جا سکتے ہیں۔ مثال کے طور پر، *neural network* اور *fishing network* کے معنی مکمل طور پر مختلف ہیں۔ اس بات کو مدنظر رکھنے کے لیے ایک طریقہ یہ ہے کہ ہم اپنے ماڈل کو الفاظ کے جوڑوں پر بنائیں، اور لفظی جوڑوں کو الگ لغتی ٹوکینز کے طور پر سمجھیں۔ اس طرح، جملہ *I like to go fishing* درج ذیل ٹوکینز کی ترتیب میں پیش کیا جائے گا: *I like*, *like to*, *to go*, *go fishing*۔ اس طریقے کا مسئلہ یہ ہے کہ لغت کا سائز نمایاں طور پر بڑھ جاتا ہے، اور *go fishing* اور *go shopping* جیسی ترکیبیں مختلف ٹوکینز کے ذریعے پیش کی جاتی ہیں، جو کسی بھی معنوی مشابہت کو شیئر نہیں کرتیں، حالانکہ فعل ایک جیسا ہے۔

کچھ صورتوں میں، ہم تین الفاظ کے جوڑ -- یعنی ٹرائی-گرامز -- کا استعمال بھی کر سکتے ہیں۔ اس لیے اس طریقے کو عام طور پر **این-گرامز** کہا جاتا ہے۔ یہ بھی سمجھ میں آتا ہے کہ این-گرامز کو کریکٹر لیول کی نمائندگی کے ساتھ استعمال کیا جائے، جس صورت میں این-گرامز مختلف سلیبلز کے تقریباً مساوی ہوں گے۔

## بیگ آف ورڈز اور TF/IDF

جب ہم ٹیکسٹ کی درجہ بندی جیسے کام حل کرتے ہیں، تو ہمیں ٹیکسٹ کو ایک مقررہ سائز کے ویکٹر کے ذریعے پیش کرنے کے قابل ہونا چاہیے، جسے ہم حتمی ڈینس کلاسیفائر کے ان پٹ کے طور پر استعمال کریں گے۔ اس کا ایک آسان طریقہ یہ ہے کہ تمام انفرادی لفظی نمائندگیوں کو یکجا کریں، مثلاً انہیں جمع کرکے۔ اگر ہم ہر لفظ کی ون-ہاٹ انکوڈنگز کو جمع کریں، تو ہمیں فریکوئنسیز کا ایک ویکٹر ملے گا، جو یہ ظاہر کرے گا کہ ہر لفظ متن میں کتنی بار ظاہر ہوتا ہے۔ ٹیکسٹ کی اس قسم کی نمائندگی کو **بیگ آف ورڈز** (BoW) کہا جاتا ہے۔

<img src="images/bow.png" width="90%"/>

> تصویر مصنف کی جانب سے

BoW بنیادی طور پر یہ ظاہر کرتا ہے کہ کون سے الفاظ متن میں ظاہر ہوتے ہیں اور کس مقدار میں، جو واقعی یہ ظاہر کرنے کے لیے ایک اچھا اشارہ ہو سکتا ہے کہ متن کس بارے میں ہے۔ مثال کے طور پر، سیاست پر مبنی خبر کے مضمون میں ممکنہ طور پر *president* اور *country* جیسے الفاظ شامل ہوں گے، جبکہ سائنسی اشاعت میں *collider*، *discovered* وغیرہ جیسے الفاظ ہوں گے۔ اس طرح، لفظی فریکوئنسیز کئی صورتوں میں متن کے مواد کا ایک اچھا اشارہ ہو سکتی ہیں۔

BoW کا مسئلہ یہ ہے کہ کچھ عام الفاظ، جیسے *and*، *is* وغیرہ، زیادہ تر متون میں ظاہر ہوتے ہیں، اور ان کی فریکوئنسی سب سے زیادہ ہوتی ہے، جو واقعی اہم الفاظ کو چھپا دیتی ہے۔ ہم ان الفاظ کی اہمیت کو کم کر سکتے ہیں، اس بات کو مدنظر رکھتے ہوئے کہ الفاظ پوری دستاویز کے مجموعے میں کتنی بار ظاہر ہوتے ہیں۔ یہ TF/IDF طریقے کے پیچھے بنیادی خیال ہے، جسے اس سبق سے منسلک نوٹ بکس میں مزید تفصیل سے کور کیا گیا ہے۔

تاہم، ان میں سے کوئی بھی طریقہ ٹیکسٹ کے **معنی** کو مکمل طور پر مدنظر نہیں رکھ سکتا۔ ہمیں اس کے لیے مزید طاقتور نیورل نیٹ ورک ماڈلز کی ضرورت ہے، جن پر ہم اس سیکشن میں بعد میں بات کریں گے۔

## ✍️ مشقیں: ٹیکسٹ کی نمائندگی

اپنی تعلیم کو درج ذیل نوٹ بکس میں جاری رکھیں:

* [PyTorch کے ساتھ ٹیکسٹ کی نمائندگی](../../../../../lessons/5-NLP/13-TextRep/TextRepresentationPyTorch.ipynb)  
* [TensorFlow کے ساتھ ٹیکسٹ کی نمائندگی](../../../../../lessons/5-NLP/13-TextRep/TextRepresentationTF.ipynb)  

## نتیجہ

اب تک، ہم نے وہ تکنیکیں سیکھیں جو مختلف الفاظ کو فریکوئنسی وزن دے سکتی ہیں۔ تاہم، یہ معنی یا ترتیب کو پیش کرنے سے قاصر ہیں۔ جیسا کہ مشہور لسانیات دان جے آر فرث نے 1935 میں کہا تھا، "کسی لفظ کا مکمل مطلب ہمیشہ سیاق و سباق میں ہوتا ہے، اور سیاق و سباق کے بغیر معنی کا کوئی مطالعہ سنجیدگی سے نہیں لیا جا سکتا۔" ہم اس کورس میں بعد میں سیکھیں گے کہ زبان کی ماڈلنگ کا استعمال کرتے ہوئے متن سے سیاق و سباق کی معلومات کو کیسے حاصل کیا جائے۔

## 🚀 چیلنج

بیگ آف ورڈز اور مختلف ڈیٹا ماڈلز کا استعمال کرتے ہوئے کچھ دیگر مشقیں آزمائیں۔ آپ اس [کگل مقابلے](https://www.kaggle.com/competitions/word2vec-nlp-tutorial/overview/part-1-for-beginners-bag-of-words) سے متاثر ہو سکتے ہیں۔

## [لیکچر کے بعد کا کوئز](https://ff-quizzes.netlify.app/en/ai/quiz/26)

## جائزہ اور خود مطالعہ

[Microsoft Learn](https://docs.microsoft.com/learn/modules/intro-natural-language-processing-pytorch/?WT.mc_id=academic-77998-cacaste) پر ٹیکسٹ ایمبیڈنگز اور بیگ آف ورڈز تکنیکوں کے ساتھ اپنی مہارتوں کو مشق کریں۔

## [اسائنمنٹ: نوٹ بکس](assignment.md)  

**ڈسکلیمر**:  
یہ دستاویز AI ترجمہ سروس [Co-op Translator](https://github.com/Azure/co-op-translator) کا استعمال کرتے ہوئے ترجمہ کی گئی ہے۔ ہم درستگی کے لیے پوری کوشش کرتے ہیں، لیکن براہ کرم آگاہ رہیں کہ خودکار ترجمے میں غلطیاں یا خامیاں ہو سکتی ہیں۔ اصل دستاویز کو اس کی اصل زبان میں مستند ذریعہ سمجھا جانا چاہیے۔ اہم معلومات کے لیے، پیشہ ور انسانی ترجمہ کی سفارش کی جاتی ہے۔ اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کے لیے ہم ذمہ دار نہیں ہیں۔