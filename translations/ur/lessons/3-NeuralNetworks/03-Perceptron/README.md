<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "0c37770bba4fff3c71dc00eb261ee61b",
  "translation_date": "2025-08-26T10:36:18+00:00",
  "source_file": "lessons/3-NeuralNetworks/03-Perceptron/README.md",
  "language_code": "ur"
}
-->
# نیورل نیٹ ورکس کا تعارف: پرسیپٹرون

## [لیکچر سے پہلے کا کوئز](https://ff-quizzes.netlify.app/en/ai/quiz/5)

جدید نیورل نیٹ ورک جیسی کسی چیز کو نافذ کرنے کی پہلی کوششوں میں سے ایک 1957 میں کارنیل ایئروناٹیکل لیبارٹری کے فرینک روزن بلیٹ نے کی تھی۔ یہ ایک ہارڈویئر نفاذ تھا جسے "مارک-1" کہا جاتا تھا، جو بنیادی جیومیٹرک اشکال جیسے مثلث، مربع اور دائرے کو پہچاننے کے لیے ڈیزائن کیا گیا تھا۔

|      |      |
|--------------|-----------|
|<img src='images/Rosenblatt-wikipedia.jpg' alt='فرینک روزن بلیٹ'/> | <img src='images/Mark_I_perceptron_wikipedia.jpg' alt='مارک 1 پرسیپٹرون' />|

> تصاویر [ویکیپیڈیا سے](https://en.wikipedia.org/wiki/Perceptron)

ایک ان پٹ تصویر کو 20x20 فوٹو سیل کے ایک صف کے ذریعے ظاہر کیا گیا تھا، لہذا نیورل نیٹ ورک کے 400 ان پٹس اور ایک بائنری آؤٹ پٹ تھا۔ ایک سادہ نیٹ ورک میں ایک نیورون ہوتا تھا، جسے **تھریش ہولڈ لاجک یونٹ** بھی کہا جاتا ہے۔ نیورل نیٹ ورک کے ویٹس پوٹینشیومیٹرز کی طرح کام کرتے تھے جنہیں تربیت کے مرحلے کے دوران دستی طور پر ایڈجسٹ کرنے کی ضرورت ہوتی تھی۔

> ✅ پوٹینشیومیٹر ایک ایسا آلہ ہے جو صارف کو سرکٹ کی مزاحمت کو ایڈجسٹ کرنے کی اجازت دیتا ہے۔

> نیویارک ٹائمز نے اس وقت پرسیپٹرون کے بارے میں لکھا: *ایک الیکٹرانک کمپیوٹر کا جنین جس کے بارے میں [نیوی] کو توقع ہے کہ وہ چل سکے گا، بات کر سکے گا، دیکھ سکے گا، لکھ سکے گا، خود کو دوبارہ پیدا کر سکے گا اور اپنی موجودگی سے آگاہ ہو سکے گا۔*

## پرسیپٹرون ماڈل

فرض کریں کہ ہمارے ماڈل میں N فیچرز ہیں، اس صورت میں ان پٹ ویکٹر N سائز کا ایک ویکٹر ہوگا۔ پرسیپٹرون ایک **بائنری کلاسیفکیشن** ماڈل ہے، یعنی یہ ان پٹ ڈیٹا کی دو کلاسز کے درمیان فرق کر سکتا ہے۔ ہم فرض کریں گے کہ ہر ان پٹ ویکٹر x کے لیے ہمارے پرسیپٹرون کا آؤٹ پٹ +1 یا -1 ہوگا، جو کلاس پر منحصر ہے۔ آؤٹ پٹ درج ذیل فارمولے کا استعمال کرتے ہوئے حساب کیا جائے گا:

y(x) = f(w<sup>T</sup>x)

جہاں f ایک اسٹیپ ایکٹیویشن فنکشن ہے۔

<!-- img src="http://www.sciweavers.org/tex2img.php?eq=f%28x%29%20%3D%20%5Cbegin%7Bcases%7D%0A%20%20%20%20%20%20%20%20%20%2B1%20%26%20x%20%5Cgeq%200%20%5C%5C%0A%20%20%20%20%20%20%20%20%20-1%20%26%20x%20%3C%200%0A%20%20%20%20%20%20%20%5Cend%7Bcases%7D%20%5C%5C%0A&bc=White&fc=Black&im=jpg&fs=12&ff=arev&edit=0" align="center" border="0" alt="f(x) = \begin{cases} +1 & x \geq 0 \\ -1 & x < 0 \end{cases} \\" width="154" height="50" / -->
<img src="images/activation-func.png"/>

## پرسیپٹرون کی تربیت

پرسیپٹرون کو تربیت دینے کے لیے ہمیں ایک ویٹس ویکٹر w تلاش کرنے کی ضرورت ہے جو زیادہ تر ویلیوز کو درست طریقے سے کلاسیفائی کرے، یعنی سب سے کم **غلطی** دے۔ یہ غلطی E درج ذیل طریقے سے **پرسیپٹرون معیار** کے ذریعے بیان کی گئی ہے:

E(w) = -∑w<sup>T</sup>x<sub>i</sub>t<sub>i</sub>

جہاں:

* مجموعہ ان تربیتی ڈیٹا پوائنٹس i پر لیا جاتا ہے جو غلط کلاسیفکیشن کا نتیجہ دیتے ہیں۔
* x<sub>i</sub> ان پٹ ڈیٹا ہے، اور t<sub>i</sub> منفی اور مثبت مثالوں کے لیے بالترتیب -1 یا +1 ہے۔

یہ معیار ویٹس w کے ایک فنکشن کے طور پر سمجھا جاتا ہے، اور ہمیں اسے کم سے کم کرنا ہوتا ہے۔ اکثر، ایک طریقہ جسے **گریڈینٹ ڈیسنٹ** کہا جاتا ہے استعمال کیا جاتا ہے، جس میں ہم کچھ ابتدائی ویٹس w<sup>(0)</sup> سے شروع کرتے ہیں، اور پھر ہر قدم پر ویٹس کو درج ذیل فارمولے کے مطابق اپ ڈیٹ کرتے ہیں:

w<sup>(t+1)</sup> = w<sup>(t)</sup> - η∇E(w)

یہاں η کو **لرننگ ریٹ** کہا جاتا ہے، اور ∇E(w) E کا **گریڈینٹ** ظاہر کرتا ہے۔ جب ہم گریڈینٹ کا حساب لگاتے ہیں، تو ہمیں یہ ملتا ہے:

w<sup>(t+1)</sup> = w<sup>(t)</sup> + ∑ηx<sub>i</sub>t<sub>i</sub>

Python میں اس کا الگورتھم کچھ یوں دکھائی دیتا ہے:

```python
def train(positive_examples, negative_examples, num_iterations = 100, eta = 1):

    weights = [0,0,0] # Initialize weights (almost randomly :)
        
    for i in range(num_iterations):
        pos = random.choice(positive_examples)
        neg = random.choice(negative_examples)

        z = np.dot(pos, weights) # compute perceptron output
        if z < 0: # positive example classified as negative
            weights = weights + eta*weights.shape

        z  = np.dot(neg, weights)
        if z >= 0: # negative example classified as positive
            weights = weights - eta*weights.shape

    return weights
```

## نتیجہ

اس سبق میں، آپ نے پرسیپٹرون کے بارے میں سیکھا، جو ایک بائنری کلاسیفکیشن ماڈل ہے، اور اسے ویٹس ویکٹر کا استعمال کرتے ہوئے کیسے تربیت دی جاتی ہے۔

## 🚀 چیلنج

اگر آپ اپنا پرسیپٹرون بنانا چاہتے ہیں، تو [Microsoft Learn پر یہ لیب](https://docs.microsoft.com/en-us/azure/machine-learning/component-reference/two-class-averaged-perceptron?WT.mc_id=academic-77998-cacaste) آزمائیں، جو [Azure ML ڈیزائنر](https://docs.microsoft.com/en-us/azure/machine-learning/concept-designer?WT.mc_id=academic-77998-cacaste) کا استعمال کرتی ہے۔

## [لیکچر کے بعد کا کوئز](https://ff-quizzes.netlify.app/en/ai/quiz/6)

## جائزہ اور خود مطالعہ

یہ دیکھنے کے لیے کہ ہم پرسیپٹرون کو کھلونا مسئلہ اور حقیقی زندگی کے مسائل حل کرنے کے لیے کیسے استعمال کر سکتے ہیں، اور سیکھنا جاری رکھنے کے لیے - [پرسیپٹرون](../../../../../lessons/3-NeuralNetworks/03-Perceptron/Perceptron.ipynb) نوٹ بک پر جائیں۔

یہاں پرسیپٹرون کے بارے میں ایک دلچسپ [مضمون](https://towardsdatascience.com/what-is-a-perceptron-basics-of-neural-networks-c4cfea20c590) بھی موجود ہے۔

## [اسائنمنٹ](lab/README.md)

اس سبق میں، ہم نے بائنری کلاسیفکیشن کے کام کے لیے ایک پرسیپٹرون نافذ کیا، اور اسے دو ہاتھ سے لکھے ہوئے ہندسوں کے درمیان کلاسیفائی کرنے کے لیے استعمال کیا۔ اس لیب میں، آپ سے کہا گیا ہے کہ ہندسوں کی مکمل کلاسیفکیشن کا مسئلہ حل کریں، یعنی یہ تعین کریں کہ دی گئی تصویر کے لیے کون سا ہندسہ سب سے زیادہ ممکنہ طور پر مطابقت رکھتا ہے۔

* [ہدایات](lab/README.md)  
* [نوٹ بک](../../../../../lessons/3-NeuralNetworks/03-Perceptron/lab/PerceptronMultiClass.ipynb)  

**ڈسکلیمر**:  
یہ دستاویز AI ترجمہ سروس [Co-op Translator](https://github.com/Azure/co-op-translator) کا استعمال کرتے ہوئے ترجمہ کی گئی ہے۔ ہم درستگی کے لیے کوشش کرتے ہیں، لیکن براہ کرم آگاہ رہیں کہ خودکار ترجمے میں غلطیاں یا غیر درستیاں ہو سکتی ہیں۔ اصل دستاویز کو اس کی اصل زبان میں مستند ذریعہ سمجھا جانا چاہیے۔ اہم معلومات کے لیے، پیشہ ور انسانی ترجمہ کی سفارش کی جاتی ہے۔ ہم اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کے ذمہ دار نہیں ہیں۔