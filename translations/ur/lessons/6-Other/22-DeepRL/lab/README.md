<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7bd8dc72040e98e35e7225e34058cd4e",
  "translation_date": "2025-08-26T10:16:32+00:00",
  "source_file": "lessons/6-Other/22-DeepRL/lab/README.md",
  "language_code": "ur"
}
-->
## ماحول

ماؤنٹین کار کا ماحول ایک گاڑی پر مشتمل ہے جو ایک وادی میں پھنس گئی ہے۔ آپ کا مقصد وادی سے باہر چھلانگ لگا کر جھنڈے تک پہنچنا ہے۔ آپ جو اقدامات کر سکتے ہیں وہ ہیں: بائیں طرف تیز کرنا، دائیں طرف تیز کرنا، یا کچھ نہ کرنا۔ آپ گاڑی کی پوزیشن کو x-axis پر اور رفتار کو دیکھ سکتے ہیں۔

## نوٹ بک شروع کرنا

لیب کو شروع کرنے کے لیے [MountainCar.ipynb](../../../../../../lessons/6-Other/22-DeepRL/lab/MountainCar.ipynb) کھولیں۔

## نتیجہ

آپ کو اس لیب کے دوران یہ سیکھنا چاہیے کہ RL الگورتھم کو کسی نئے ماحول میں اپنانا اکثر کافی آسان ہوتا ہے، کیونکہ OpenAI Gym تمام ماحول کے لیے ایک جیسا انٹرفیس فراہم کرتا ہے، اور الگورتھم عام طور پر ماحول کی نوعیت پر زیادہ انحصار نہیں کرتے۔ آپ Python کوڈ کو اس طرح سے دوبارہ ترتیب دے سکتے ہیں کہ RL الگورتھم کو کسی بھی ماحول کو پیرامیٹر کے طور پر پاس کیا جا سکے۔

**ڈسکلیمر**:  
یہ دستاویز AI ترجمہ سروس [Co-op Translator](https://github.com/Azure/co-op-translator) کا استعمال کرتے ہوئے ترجمہ کی گئی ہے۔ ہم درستگی کے لیے پوری کوشش کرتے ہیں، لیکن براہ کرم آگاہ رہیں کہ خودکار ترجمے میں غلطیاں یا خامیاں ہو سکتی ہیں۔ اصل دستاویز کو اس کی اصل زبان میں مستند ذریعہ سمجھا جانا چاہیے۔ اہم معلومات کے لیے، پیشہ ور انسانی ترجمہ کی سفارش کی جاتی ہے۔ اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کے لیے ہم ذمہ دار نہیں ہیں۔