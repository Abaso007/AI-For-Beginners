<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "437c988596e751072e41a5aad3fcc5d9",
  "translation_date": "2025-08-26T07:58:12+00:00",
  "source_file": "lessons/7-Ethics/README.md",
  "language_code": "ur"
}
-->
# اخلاقی اور ذمہ دار AI

آپ اس کورس کو تقریباً مکمل کر چکے ہیں، اور مجھے امید ہے کہ اب تک آپ واضح طور پر دیکھ سکتے ہیں کہ AI کئی رسمی ریاضیاتی طریقوں پر مبنی ہے جو ہمیں ڈیٹا میں تعلقات تلاش کرنے اور ماڈلز کو انسانی رویے کے کچھ پہلوؤں کی نقل کرنے کے لیے تربیت دینے کی اجازت دیتے ہیں۔ اس وقت کی تاریخ میں، ہم AI کو ایک بہت طاقتور ٹول سمجھتے ہیں جو ڈیٹا سے پیٹرنز نکالنے اور ان پیٹرنز کو نئے مسائل حل کرنے کے لیے استعمال کرنے میں مدد دیتا ہے۔

## [لیکچر سے پہلے کا کوئز](https://white-water-09ec41f0f.azurestaticapps.net/quiz/5/)

تاہم، سائنس فکشن میں ہم اکثر ایسی کہانیاں دیکھتے ہیں جہاں AI انسانیت کے لیے خطرہ پیش کرتا ہے۔ عام طور پر یہ کہانیاں کسی قسم کی AI بغاوت کے گرد گھومتی ہیں، جب AI انسانوں کا سامنا کرنے کا فیصلہ کرتا ہے۔ اس کا مطلب یہ ہے کہ AI کے پاس کسی قسم کا جذبہ یا اپنے ڈویلپرز کی توقعات سے ہٹ کر فیصلے کرنے کی صلاحیت ہے۔

اس کورس میں جس قسم کے AI کے بارے میں ہم نے سیکھا ہے وہ صرف بڑی میٹرکس ریاضی ہے۔ یہ ہمارے مسائل حل کرنے میں مدد دینے کے لیے ایک بہت طاقتور ٹول ہے، اور کسی بھی دوسرے طاقتور ٹول کی طرح - اسے اچھے اور برے مقاصد کے لیے استعمال کیا جا سکتا ہے۔ اہم بات یہ ہے کہ اسے *غلط استعمال* کیا جا سکتا ہے۔

## ذمہ دار AI کے اصول

AI کے حادثاتی یا جان بوجھ کر غلط استعمال سے بچنے کے لیے، Microsoft نے [ذمہ دار AI کے اصول](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-77998-cacaste) بیان کیے ہیں۔ درج ذیل تصورات ان اصولوں کی بنیاد ہیں:

* **منصفانہ ہونا** ماڈل کے تعصبات کے اہم مسئلے سے متعلق ہے، جو تربیت کے لیے متعصب ڈیٹا استعمال کرنے کی وجہ سے ہو سکتے ہیں۔ مثال کے طور پر، جب ہم کسی شخص کے لیے سافٹ ویئر ڈویلپر کی نوکری حاصل کرنے کے امکان کی پیش گوئی کرنے کی کوشش کرتے ہیں، تو ماڈل ممکنہ طور پر مردوں کو زیادہ ترجیح دے گا - صرف اس لیے کہ تربیتی ڈیٹا سیٹ ممکنہ طور پر مرد سامعین کی طرف متعصب تھا۔ ہمیں تربیتی ڈیٹا کو احتیاط سے متوازن کرنا ہوگا اور ماڈل کی جانچ کرنی ہوگی تاکہ تعصبات سے بچا جا سکے، اور یہ یقینی بنانا ہوگا کہ ماڈل زیادہ متعلقہ خصوصیات کو مدنظر رکھے۔
* **قابل اعتماد اور محفوظ ہونا**۔ اپنی نوعیت کے لحاظ سے، AI ماڈلز غلطیاں کر سکتے ہیں۔ ایک نیورل نیٹ ورک امکانات واپس کرتا ہے، اور ہمیں فیصلے کرتے وقت اسے مدنظر رکھنا ہوگا۔ ہر ماڈل کی کچھ درستگی اور یادداشت ہوتی ہے، اور ہمیں یہ سمجھنا ہوگا تاکہ غلط مشورے سے ہونے والے نقصان کو روکا جا سکے۔
* **پرائیویسی اور سیکیورٹی** کے کچھ AI سے متعلق مضمرات ہیں۔ مثال کے طور پر، جب ہم کسی ماڈل کو تربیت دینے کے لیے کچھ ڈیٹا استعمال کرتے ہیں، تو یہ ڈیٹا کسی حد تک ماڈل میں "ضم" ہو جاتا ہے۔ ایک طرف، یہ سیکیورٹی اور پرائیویسی کو بڑھاتا ہے، دوسری طرف - ہمیں یاد رکھنا ہوگا کہ ماڈل کس ڈیٹا پر تربیت یافتہ تھا۔
* **شمولیت** کا مطلب یہ ہے کہ ہم AI لوگوں کی جگہ لینے کے لیے نہیں بلکہ لوگوں کو بڑھانے اور ہمارے کام کو زیادہ تخلیقی بنانے کے لیے بنا رہے ہیں۔ یہ منصفانہ ہونے سے بھی متعلق ہے، کیونکہ جب کم نمائندگی والے کمیونٹیز کے ساتھ معاملہ کرتے ہیں، تو زیادہ تر ڈیٹا سیٹس جو ہم جمع کرتے ہیں ممکنہ طور پر متعصب ہوتے ہیں، اور ہمیں یہ یقینی بنانا ہوگا کہ ان کمیونٹیز کو شامل کیا جائے اور AI کے ذریعے صحیح طریقے سے ہینڈل کیا جائے۔
* **شفافیت**۔ اس میں یہ یقینی بنانا شامل ہے کہ ہم ہمیشہ واضح کریں کہ AI استعمال ہو رہا ہے۔ نیز، جہاں ممکن ہو، ہم ایسے AI سسٹمز استعمال کرنا چاہتے ہیں جو *قابل وضاحت* ہوں۔
* **جوابدہی**۔ جب AI ماڈلز کچھ فیصلے کرتے ہیں، تو یہ ہمیشہ واضح نہیں ہوتا کہ ان فیصلوں کی ذمہ داری کس پر ہے۔ ہمیں یہ یقینی بنانا ہوگا کہ ہم سمجھتے ہیں کہ AI کے فیصلوں کی ذمہ داری کہاں ہے۔ زیادہ تر معاملات میں ہم اہم فیصلے کرنے کے عمل میں انسانوں کو شامل کرنا چاہیں گے، تاکہ اصل لوگوں کو جوابدہ بنایا جا سکے۔

## ذمہ دار AI کے لیے ٹولز

Microsoft نے [ذمہ دار AI ٹول باکس](https://github.com/microsoft/responsible-ai-toolbox) تیار کیا ہے جس میں کئی ٹولز شامل ہیں:

* Interpretability Dashboard (InterpretML)
* Fairness Dashboard (FairLearn)
* Error Analysis Dashboard
* Responsible AI Dashboard جس میں شامل ہیں:

   - EconML - Causal Analysis کے لیے ٹول، جو "کیا ہو اگر" سوالات پر توجہ دیتا ہے
   - DiCE - Counterfactual Analysis کے لیے ٹول جو آپ کو دکھاتا ہے کہ ماڈل کے فیصلے کو متاثر کرنے کے لیے کون سی خصوصیات کو تبدیل کرنے کی ضرورت ہے

AI Ethics کے بارے میں مزید معلومات کے لیے، براہ کرم [یہ سبق](https://github.com/microsoft/ML-For-Beginners/tree/main/1-Introduction/3-fairness?WT.mc_id=academic-77998-cacaste) دیکھیں جو مشین لرننگ نصاب میں اسائنمنٹس شامل کرتا ہے۔

## جائزہ اور خود مطالعہ

ذمہ دار AI کے بارے میں مزید جاننے کے لیے یہ [Learn Path](https://docs.microsoft.com/learn/modules/responsible-ai-principles/?WT.mc_id=academic-77998-cacaste) لیں۔

## [لیکچر کے بعد کا کوئز](https://white-water-09ec41f0f.azurestaticapps.net/quiz/6/)

**ڈسکلیمر**:  
یہ دستاویز AI ترجمہ سروس [Co-op Translator](https://github.com/Azure/co-op-translator) کا استعمال کرتے ہوئے ترجمہ کی گئی ہے۔ ہم درستگی کے لیے کوشش کرتے ہیں، لیکن براہ کرم آگاہ رہیں کہ خودکار ترجمے میں غلطیاں یا غیر درستیاں ہو سکتی ہیں۔ اصل دستاویز کو اس کی اصل زبان میں مستند ذریعہ سمجھا جانا چاہیے۔ اہم معلومات کے لیے، پیشہ ور انسانی ترجمہ کی سفارش کی جاتی ہے۔ ہم اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کے ذمہ دار نہیں ہیں۔