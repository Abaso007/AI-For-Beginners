<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f07c85bbf05a1f67505da98f4ecc124c",
  "translation_date": "2025-08-24T09:16:30+00:00",
  "source_file": "lessons/4-ComputerVision/10-GANs/README.md",
  "language_code": "es"
}
-->
# Redes Generativas Antag√≥nicas

En la secci√≥n anterior, aprendimos sobre los **modelos generativos**: modelos que pueden generar nuevas im√°genes similares a las del conjunto de datos de entrenamiento. VAE fue un buen ejemplo de un modelo generativo.

## [Cuestionario previo a la clase](https://ff-quizzes.netlify.app/en/ai/quiz/19)

Sin embargo, si intentamos generar algo realmente significativo, como una pintura con una resoluci√≥n razonable, usando VAE, veremos que el entrenamiento no converge bien. Para este caso de uso, debemos aprender sobre otra arquitectura espec√≠ficamente orientada a modelos generativos: las **Redes Generativas Antag√≥nicas**, o GANs.

La idea principal de una GAN es tener dos redes neuronales que se entrenan una contra la otra:

<img src="images/gan_architecture.png" width="70%"/>

> Imagen por [Dmitry Soshnikov](http://soshnikov.com)

> ‚úÖ Un poco de vocabulario:
> * **Generador** es una red que toma un vector aleatorio y produce una imagen como resultado.
> * **Discriminador** es una red que toma una imagen y debe determinar si es una imagen real (del conjunto de datos de entrenamiento) o si fue generada por un generador. Es esencialmente un clasificador de im√°genes.

### Discriminador

La arquitectura del discriminador no difiere de una red de clasificaci√≥n de im√°genes ordinaria. En el caso m√°s simple, puede ser un clasificador completamente conectado, pero lo m√°s probable es que sea una [red convolucional](../07-ConvNets/README.md).

> ‚úÖ Una GAN basada en redes convolucionales se llama [DCGAN](https://arxiv.org/pdf/1511.06434.pdf)

Un discriminador CNN consta de las siguientes capas: varias convoluciones+poolings (con tama√±o espacial decreciente) y una o m√°s capas completamente conectadas para obtener un "vector de caracter√≠sticas", clasificador binario final.

> ‚úÖ Un 'pooling' en este contexto es una t√©cnica que reduce el tama√±o de la imagen. "Las capas de pooling reducen las dimensiones de los datos combinando las salidas de los grupos de neuronas en una capa en una sola neurona en la siguiente capa." - [fuente](https://wikipedia.org/wiki/Convolutional_neural_network#Pooling_layers)

### Generador

Un generador es un poco m√°s complicado. Puedes considerarlo como un discriminador invertido. Comenzando desde un vector latente (en lugar de un vector de caracter√≠sticas), tiene una capa completamente conectada para convertirlo en el tama√±o/forma requerida, seguida de deconvoluciones+escalado. Esto es similar a la parte de *decodificador* de un [autoencoder](../09-Autoencoders/README.md).

> ‚úÖ Debido a que la capa de convoluci√≥n se implementa como un filtro lineal que recorre la imagen, la deconvoluci√≥n es esencialmente similar a la convoluci√≥n y puede implementarse utilizando la misma l√≥gica de capa.

<img src="images/gan_arch_detail.png" width="70%"/>

> Imagen por [Dmitry Soshnikov](http://soshnikov.com)

### Entrenamiento de la GAN

Las GANs se llaman **antag√≥nicas** porque hay una competencia constante entre el generador y el discriminador. Durante esta competencia, tanto el generador como el discriminador mejoran, y la red aprende a producir im√°genes cada vez mejores.

El entrenamiento ocurre en dos etapas:

* **Entrenamiento del discriminador**. Esta tarea es bastante sencilla: generamos un lote de im√°genes con el generador, etiquet√°ndolas como 0, lo que significa imagen falsa, y tomamos un lote de im√°genes del conjunto de datos de entrada (con etiqueta 1, imagen real). Obtenemos una *p√©rdida del discriminador* y realizamos retropropagaci√≥n.
* **Entrenamiento del generador**. Esto es un poco m√°s complicado porque no conocemos directamente la salida esperada para el generador. Tomamos toda la red GAN que consiste en un generador seguido por un discriminador, la alimentamos con algunos vectores aleatorios y esperamos que el resultado sea 1 (correspondiente a im√°genes reales). Luego congelamos los par√°metros del discriminador (no queremos que se entrene en este paso) y realizamos la retropropagaci√≥n.

Durante este proceso, las p√©rdidas tanto del generador como del discriminador no disminuyen significativamente. En la situaci√≥n ideal, deber√≠an oscilar, lo que corresponde a que ambas redes mejoran su rendimiento.

## ‚úçÔ∏è Ejercicios: GANs

* [Notebook de GAN en TensorFlow/Keras](../../../../../lessons/4-ComputerVision/10-GANs/GANTF.ipynb)
* [Notebook de GAN en PyTorch](../../../../../lessons/4-ComputerVision/10-GANs/GANPyTorch.ipynb)

### Problemas con el entrenamiento de GANs

Las GANs son conocidas por ser especialmente dif√≠ciles de entrenar. Aqu√≠ hay algunos problemas:

* **Colapso de modo**. Este t√©rmino se refiere a que el generador aprende a producir una imagen exitosa que enga√±a al discriminador, pero no una variedad de im√°genes diferentes.
* **Sensibilidad a los hiperpar√°metros**. A menudo puedes ver que una GAN no converge en absoluto, y luego, de repente, una disminuci√≥n en la tasa de aprendizaje lleva a la convergencia.
* Mantener un **equilibrio** entre el generador y el discriminador. En muchos casos, la p√©rdida del discriminador puede caer a cero relativamente r√°pido, lo que resulta en que el generador no pueda entrenarse m√°s. Para superar esto, podemos intentar establecer diferentes tasas de aprendizaje para el generador y el discriminador, o saltar el entrenamiento del discriminador si la p√©rdida ya es demasiado baja.
* Entrenamiento para **alta resoluci√≥n**. Reflejando el mismo problema que con los autoencoders, este problema se desencadena porque reconstruir demasiadas capas de una red convolucional lleva a artefactos. Este problema se resuelve t√≠picamente con el llamado **crecimiento progresivo**, donde primero se entrenan algunas capas con im√°genes de baja resoluci√≥n y luego se "desbloquean" o se agregan capas. Otra soluci√≥n ser√≠a agregar conexiones adicionales entre capas y entrenar varias resoluciones a la vez; consulta este art√≠culo [Multi-Scale Gradient GANs](https://arxiv.org/abs/1903.06048) para m√°s detalles.

## Transferencia de estilo

Las GANs son una excelente manera de generar im√°genes art√≠sticas. Otra t√©cnica interesante es la llamada **transferencia de estilo**, que toma una **imagen de contenido** y la redibuja en un estilo diferente, aplicando filtros de una **imagen de estilo**.

El funcionamiento es el siguiente:
* Comenzamos con una imagen de ruido aleatorio (o con una imagen de contenido, pero para entenderlo es m√°s f√°cil comenzar con ruido aleatorio).
* Nuestro objetivo ser√≠a crear una imagen que est√© cerca tanto de la imagen de contenido como de la imagen de estilo. Esto se determinar√° mediante dos funciones de p√©rdida:
   - **P√©rdida de contenido** se calcula en funci√≥n de las caracter√≠sticas extra√≠das por la CNN en algunas capas de la imagen actual y la imagen de contenido.
   - **P√©rdida de estilo** se calcula entre la imagen actual y la imagen de estilo de una manera ingeniosa utilizando matrices de Gram (m√°s detalles en el [notebook de ejemplo](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)).
* Para hacer la imagen m√°s suave y eliminar el ruido, tambi√©n introducimos **p√©rdida de variaci√≥n**, que calcula la distancia promedio entre p√≠xeles vecinos.
* El bucle principal de optimizaci√≥n ajusta la imagen actual utilizando descenso de gradiente (u otro algoritmo de optimizaci√≥n) para minimizar la p√©rdida total, que es una suma ponderada de todas las p√©rdidas.

## ‚úçÔ∏è Ejemplo: [Transferencia de estilo](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)

## [Cuestionario posterior a la clase](https://ff-quizzes.netlify.app/en/ai/quiz/20)

## Conclusi√≥n

En esta lecci√≥n, aprendiste sobre las GANs y c√≥mo entrenarlas. Tambi√©n aprendiste sobre los desaf√≠os especiales que este tipo de red neuronal puede enfrentar y algunas estrategias para superarlos.

## üöÄ Desaf√≠o

Ejecuta el [notebook de transferencia de estilo](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb) usando tus propias im√°genes.

## Revisi√≥n y autoestudio

Para referencia, lee m√°s sobre GANs en estos recursos:

* Marco Pasini, [10 Lecciones que aprend√≠ entrenando GANs durante un a√±o](https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628)
* [StyleGAN](https://en.wikipedia.org/wiki/StyleGAN), una arquitectura GAN *de facto* a considerar.
* [Creando arte generativo usando GANs en Azure ML](https://soshnikov.com/scienceart/creating-generative-art-using-gan-on-azureml/)

## Tarea

Revisita uno de los dos notebooks asociados a esta lecci√≥n y vuelve a entrenar la GAN con tus propias im√°genes. ¬øQu√© puedes crear?

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Si bien nos esforzamos por lograr precisi√≥n, tenga en cuenta que las traducciones autom√°ticas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse como la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas que puedan surgir del uso de esta traducci√≥n.