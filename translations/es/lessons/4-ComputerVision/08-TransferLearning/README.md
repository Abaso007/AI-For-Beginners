<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "717775c4050ccbffbe0c961ad8bf7bf7",
  "translation_date": "2025-08-24T09:19:02+00:00",
  "source_file": "lessons/4-ComputerVision/08-TransferLearning/README.md",
  "language_code": "es"
}
-->
# Redes Pre-entrenadas y Aprendizaje por Transferencia

Entrenar redes neuronales convolucionales (CNN) puede llevar mucho tiempo y requiere una gran cantidad de datos. Sin embargo, gran parte del tiempo se invierte en aprender los mejores filtros de bajo nivel que una red puede usar para extraer patrones de las im√°genes. Surge una pregunta natural: ¬øpodemos usar una red neuronal entrenada en un conjunto de datos y adaptarla para clasificar im√°genes diferentes sin necesidad de un proceso de entrenamiento completo?

## [Cuestionario previo a la lecci√≥n](https://ff-quizzes.netlify.app/en/ai/quiz/15)

Este enfoque se llama **aprendizaje por transferencia**, porque transferimos conocimiento de un modelo de red neuronal a otro. En el aprendizaje por transferencia, normalmente comenzamos con un modelo pre-entrenado, que ha sido entrenado en un gran conjunto de datos de im√°genes, como **ImageNet**. Estos modelos ya son buenos extrayendo diferentes caracter√≠sticas de im√°genes gen√©ricas, y en muchos casos, simplemente construir un clasificador sobre esas caracter√≠sticas extra√≠das puede dar buenos resultados.

> ‚úÖ El Aprendizaje por Transferencia es un t√©rmino que tambi√©n se encuentra en otros campos acad√©micos, como la Educaci√≥n. Se refiere al proceso de tomar conocimiento de un dominio y aplicarlo en otro.

## Modelos Pre-entrenados como Extractores de Caracter√≠sticas

Las redes convolucionales de las que hablamos en la secci√≥n anterior contienen varias capas, cada una de las cuales est√° dise√±ada para extraer caracter√≠sticas de la imagen, comenzando con combinaciones de p√≠xeles de bajo nivel (como l√≠neas horizontales/verticales o trazos), hasta combinaciones de caracter√≠sticas de nivel superior, como un ojo o una llama. Si entrenamos una CNN en un conjunto de datos suficientemente grande y diverso, la red deber√≠a aprender a extraer esas caracter√≠sticas comunes.

Tanto Keras como PyTorch contienen funciones para cargar f√°cilmente pesos de redes neuronales pre-entrenadas para algunas arquitecturas comunes, la mayor√≠a de las cuales fueron entrenadas en im√°genes de ImageNet. Las m√°s utilizadas se describen en la p√°gina [Arquitecturas de CNN](../07-ConvNets/CNN_Architectures.md) de la lecci√≥n anterior. En particular, podr√≠as considerar usar una de las siguientes:

* **VGG-16/VGG-19**, que son modelos relativamente simples pero con buena precisi√≥n. Usar VGG como primer intento es una buena opci√≥n para ver c√≥mo funciona el aprendizaje por transferencia.
* **ResNet**, una familia de modelos propuesta por Microsoft Research en 2015. Tienen m√°s capas y, por lo tanto, requieren m√°s recursos.
* **MobileNet**, una familia de modelos de tama√±o reducido, adecuados para dispositivos m√≥viles. √ösalos si tienes recursos limitados y puedes sacrificar un poco de precisi√≥n.

Aqu√≠ hay caracter√≠sticas de ejemplo extra√≠das de una imagen de un gato por la red VGG-16:

![Caracter√≠sticas extra√≠das por VGG-16](../../../../../lessons/4-ComputerVision/08-TransferLearning/images/features.png)

## Conjunto de Datos de Gatos vs. Perros

En este ejemplo, utilizaremos un conjunto de datos de [Gatos y Perros](https://www.microsoft.com/download/details.aspx?id=54765&WT.mc_id=academic-77998-cacaste), que se asemeja mucho a un escenario real de clasificaci√≥n de im√°genes.

## ‚úçÔ∏è Ejercicio: Aprendizaje por Transferencia

Veamos el aprendizaje por transferencia en acci√≥n en los notebooks correspondientes:

* [Aprendizaje por Transferencia - PyTorch](../../../../../lessons/4-ComputerVision/08-TransferLearning/TransferLearningPyTorch.ipynb)
* [Aprendizaje por Transferencia - TensorFlow](../../../../../lessons/4-ComputerVision/08-TransferLearning/TransferLearningTF.ipynb)

## Visualizando un Gato Adversarial

Una red neuronal pre-entrenada contiene diferentes patrones en su *cerebro*, incluyendo nociones de un **gato ideal** (as√≠ como un perro ideal, una cebra ideal, etc.). Ser√≠a interesante de alguna manera **visualizar esta imagen**. Sin embargo, no es sencillo, porque los patrones est√°n distribuidos por todos los pesos de la red y organizados en una estructura jer√°rquica.

Un enfoque que podemos tomar es comenzar con una imagen aleatoria y luego usar la t√©cnica de **optimizaci√≥n por descenso de gradiente** para ajustar esa imagen de tal manera que la red comience a pensar que es un gato.

![Bucle de Optimizaci√≥n de Imagen](../../../../../lessons/4-ComputerVision/08-TransferLearning/images/ideal-cat-loop.png)

Sin embargo, si hacemos esto, obtendremos algo muy similar a un ruido aleatorio. Esto se debe a que *hay muchas formas de hacer que la red piense que la imagen de entrada es un gato*, incluidas algunas que no tienen sentido visualmente. Aunque esas im√°genes contienen muchos patrones t√≠picos de un gato, no hay nada que las obligue a ser visualmente distintivas.

Para mejorar el resultado, podemos agregar otro t√©rmino a la funci√≥n de p√©rdida, llamado **p√©rdida de variaci√≥n**. Es una m√©trica que muestra cu√°n similares son los p√≠xeles vecinos de la imagen. Minimizar la p√©rdida de variaci√≥n hace que la imagen sea m√°s suave y elimina el ruido, revelando as√≠ patrones m√°s atractivos visualmente. Aqu√≠ hay un ejemplo de tales im√°genes "ideales", clasificadas como gato y como cebra con alta probabilidad:

![Gato Ideal](../../../../../lessons/4-ComputerVision/08-TransferLearning/images/ideal-cat.png) | ![Cebra Ideal](../../../../../lessons/4-ComputerVision/08-TransferLearning/images/ideal-zebra.png)
-----|-----
*Gato Ideal* | *Cebra Ideal*

Un enfoque similar puede usarse para realizar los llamados **ataques adversariales** en una red neuronal. Supongamos que queremos enga√±ar a una red neuronal y hacer que un perro parezca un gato. Si tomamos la imagen de un perro, que la red reconoce como un perro, podemos modificarla un poco usando optimizaci√≥n por descenso de gradiente, hasta que la red comience a clasificarla como un gato:

![Imagen de un Perro](../../../../../lessons/4-ComputerVision/08-TransferLearning/images/original-dog.png) | ![Imagen de un perro clasificado como un gato](../../../../../lessons/4-ComputerVision/08-TransferLearning/images/adversarial-dog.png)
-----|-----
*Imagen original de un perro* | *Imagen de un perro clasificado como un gato*

Consulta el c√≥digo para reproducir los resultados anteriores en el siguiente notebook:

* [Gato Ideal y Adversarial - TensorFlow](../../../../../lessons/4-ComputerVision/08-TransferLearning/AdversarialCat_TF.ipynb)

## Conclusi√≥n

Usando el aprendizaje por transferencia, puedes armar r√°pidamente un clasificador para una tarea de clasificaci√≥n de objetos personalizada y lograr alta precisi√≥n. Puedes ver que las tareas m√°s complejas que estamos resolviendo ahora requieren mayor potencia computacional y no pueden resolverse f√°cilmente en la CPU. En la pr√≥xima unidad, intentaremos usar una implementaci√≥n m√°s ligera para entrenar el mismo modelo utilizando menos recursos computacionales, lo que resulta en una precisi√≥n ligeramente menor.

## üöÄ Desaf√≠o

En los notebooks adjuntos, hay notas al final sobre c√≥mo el conocimiento transferido funciona mejor con datos de entrenamiento algo similares (quiz√°s un nuevo tipo de animal). Realiza experimentos con tipos completamente nuevos de im√°genes para ver qu√© tan bien o mal funcionan tus modelos de conocimiento transferido.

## [Cuestionario posterior a la lecci√≥n](https://ff-quizzes.netlify.app/en/ai/quiz/16)

## Revisi√≥n y Autoestudio

Lee [TrainingTricks.md](TrainingTricks.md) para profundizar tu conocimiento sobre otras formas de entrenar tus modelos.

## [Asignaci√≥n](lab/README.md)

En este laboratorio, utilizaremos el conjunto de datos real [Oxford-IIIT](https://www.robots.ox.ac.uk/~vgg/data/pets/) de mascotas con 35 razas de gatos y perros, y construiremos un clasificador de aprendizaje por transferencia.

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Aunque nos esforzamos por garantizar la precisi√≥n, tenga en cuenta que las traducciones automatizadas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse como la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas que puedan surgir del uso de esta traducci√≥n.