<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "bd10f434e444bce61b7f97eeb1ff6a55",
  "translation_date": "2025-08-24T09:14:01+00:00",
  "source_file": "lessons/5-NLP/19-NER/README.md",
  "language_code": "es"
}
-->
# Reconocimiento de Entidades Nombradas

Hasta ahora, nos hemos concentrado principalmente en una tarea de PLN: la clasificaci√≥n. Sin embargo, existen otras tareas de PLN que se pueden realizar con redes neuronales. Una de esas tareas es **[Reconocimiento de Entidades Nombradas](https://wikipedia.org/wiki/Named-entity_recognition)** (NER, por sus siglas en ingl√©s), que se ocupa de reconocer entidades espec√≠ficas dentro de un texto, como lugares, nombres de personas, intervalos de fechas y horas, f√≥rmulas qu√≠micas, entre otros.

## [Cuestionario previo a la lecci√≥n](https://ff-quizzes.netlify.app/en/ai/quiz/37)

## Ejemplo de Uso de NER

Supongamos que deseas desarrollar un chatbot de lenguaje natural, similar a Amazon Alexa o Google Assistant. La forma en que funcionan los chatbots inteligentes es *entendiendo* lo que el usuario quiere mediante la clasificaci√≥n de texto en la frase de entrada. El resultado de esta clasificaci√≥n es el llamado **intento**, que determina lo que el chatbot debe hacer.

<img alt="Bot NER" src="images/bot-ner.png" width="50%"/>

> Imagen del autor

Sin embargo, un usuario puede proporcionar algunos par√°metros como parte de la frase. Por ejemplo, al preguntar por el clima, puede especificar una ubicaci√≥n o una fecha. Un bot debe ser capaz de entender esas entidades y completar los espacios de los par√°metros en consecuencia antes de realizar la acci√≥n. Aqu√≠ es exactamente donde entra en juego NER.

> ‚úÖ Otro ejemplo ser√≠a [analizar art√≠culos cient√≠ficos m√©dicos](https://soshnikov.com/science/analyzing-medical-papers-with-azure-and-text-analytics-for-health/). Una de las principales cosas que necesitamos buscar son t√©rminos m√©dicos espec√≠ficos, como enfermedades y sustancias m√©dicas. Mientras que un peque√±o n√∫mero de enfermedades probablemente se pueda extraer mediante b√∫squeda de subcadenas, entidades m√°s complejas, como compuestos qu√≠micos y nombres de medicamentos, requieren un enfoque m√°s sofisticado.

## NER como Clasificaci√≥n de Tokens

Los modelos de NER son esencialmente **modelos de clasificaci√≥n de tokens**, porque para cada uno de los tokens de entrada necesitamos decidir si pertenece a una entidad o no, y si lo hace, a qu√© clase de entidad pertenece.

Consideremos el siguiente t√≠tulo de un art√≠culo:

**Regurgitaci√≥n de la v√°lvula tric√∫spide** y **carbonato de litio** **toxicidad** en un reci√©n nacido.

Las entidades aqu√≠ son:

* Regurgitaci√≥n de la v√°lvula tric√∫spide es una enfermedad (`DIS`)
* Carbonato de litio es una sustancia qu√≠mica (`CHEM`)
* Toxicidad tambi√©n es una enfermedad (`DIS`)

Observa que una entidad puede abarcar varios tokens. Y, como en este caso, necesitamos distinguir entre dos entidades consecutivas. Por lo tanto, es com√∫n usar dos clases para cada entidad: una que especifica el primer token de la entidad (a menudo se usa el prefijo `B-`, para **b**eginning o inicio), y otra para la continuaci√≥n de una entidad (`I-`, para **i**nner token o token interno). Tambi√©n usamos `O` como clase para representar todos los **o**tros tokens. Este etiquetado de tokens se llama [etiquetado BIO](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)) (o IOB). Cuando se etiqueta, nuestro t√≠tulo se ver√° as√≠:

Token | Etiqueta
------|---------
Tricuspid | B-DIS
valve | I-DIS
regurgitation | I-DIS
and | O
lithium | B-CHEM
carbonate | I-CHEM
toxicity | B-DIS
in | O
a | O
newborn | O
infant | O
. | O

Dado que necesitamos construir una correspondencia uno a uno entre tokens y clases, podemos entrenar un modelo neuronal **muchos a muchos** como el que se muestra en esta imagen:

![Imagen que muestra patrones comunes de redes neuronales recurrentes.](../../../../../lessons/5-NLP/17-GenerativeNetworks/images/unreasonable-effectiveness-of-rnn.jpg)

> *Imagen de [este art√≠culo](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) de [Andrej Karpathy](http://karpathy.github.io/). Los modelos de clasificaci√≥n de tokens NER corresponden a la arquitectura de red m√°s a la derecha en esta imagen.*

## Entrenamiento de Modelos NER

Dado que un modelo NER es esencialmente un modelo de clasificaci√≥n de tokens, podemos usar RNNs, con las que ya estamos familiarizados, para esta tarea. En este caso, cada bloque de la red recurrente devolver√° el ID del token. El siguiente cuaderno de ejemplo muestra c√≥mo entrenar un LSTM para la clasificaci√≥n de tokens.

## ‚úçÔ∏è Cuadernos de Ejemplo: NER

Contin√∫a tu aprendizaje en el siguiente cuaderno:

* [NER con TensorFlow](../../../../../lessons/5-NLP/19-NER/NER-TF.ipynb)

## Conclusi√≥n

Un modelo NER es un **modelo de clasificaci√≥n de tokens**, lo que significa que se puede usar para realizar clasificaci√≥n de tokens. Esta es una tarea muy com√∫n en PLN, que ayuda a reconocer entidades espec√≠ficas dentro de un texto, incluyendo lugares, nombres, fechas y m√°s.

## üöÄ Desaf√≠o

Completa la tarea vinculada a continuaci√≥n para entrenar un modelo de reconocimiento de entidades nombradas para t√©rminos m√©dicos, y luego pru√©balo en un conjunto de datos diferente.

## [Cuestionario posterior a la lecci√≥n](https://ff-quizzes.netlify.app/en/ai/quiz/38)

## Revisi√≥n y Autoestudio

Lee el art√≠culo [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) y sigue la secci√≥n de Lecturas Adicionales en ese art√≠culo para profundizar tu conocimiento.

## [Tarea](lab/README.md)

En la tarea de esta lecci√≥n, tendr√°s que entrenar un modelo de reconocimiento de entidades m√©dicas. Puedes comenzar entrenando un modelo LSTM como se describe en esta lecci√≥n, y luego avanzar al uso del modelo transformador BERT. Lee [las instrucciones](lab/README.md) para obtener todos los detalles.

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Si bien nos esforzamos por lograr precisi√≥n, tenga en cuenta que las traducciones autom√°ticas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse como la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas que puedan surgir del uso de esta traducci√≥n.