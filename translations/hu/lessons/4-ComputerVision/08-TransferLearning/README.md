<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "717775c4050ccbffbe0c961ad8bf7bf7",
  "translation_date": "2025-08-25T23:06:25+00:00",
  "source_file": "lessons/4-ComputerVision/08-TransferLearning/README.md",
  "language_code": "hu"
}
-->
# El≈ëre betan√≠tott h√°l√≥zatok √©s transzfer tanul√°s

A CNN-ek tan√≠t√°sa sok id≈ët vehet ig√©nybe, √©s ehhez nagy mennyis√©g≈± adat sz√ºks√©ges. Az id≈ë nagy r√©sz√©t azonban azzal t√∂ltj√ºk, hogy megtanuljuk azokat az alacsony szint≈± sz≈±r≈ëket, amelyeket a h√°l√≥zat haszn√°lhat a mint√°k kinyer√©s√©re a k√©pekb≈ël. Felmer√ºl egy term√©szetes k√©rd√©s: haszn√°lhatunk-e egy m√°sik adathalmazon betan√≠tott neur√°lis h√°l√≥zatot, √©s adapt√°lhatjuk-e azt k√ºl√∂nb√∂z≈ë k√©pek oszt√°lyoz√°s√°ra an√©lk√ºl, hogy teljes tan√≠t√°si folyamatra lenne sz√ºks√©g?

## [El≈ëad√°s el≈ëtti kv√≠z](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/108)

Ezt a megk√∂zel√≠t√©st **transzfer tanul√°snak** nevezz√ºk, mivel egy neur√°lis h√°l√≥zati modellb≈ël √°tvissz√ºk a tud√°st egy m√°sikba. A transzfer tanul√°s sor√°n √°ltal√°ban egy el≈ëre betan√≠tott modellel kezd√ºnk, amelyet egy nagy k√©padathalmazon, p√©ld√°ul az **ImageNet**-en tan√≠tottak. Ezek a modellek m√°r j√≥ eredm√©nyeket √©rhetnek el k√ºl√∂nb√∂z≈ë jellemz≈ëk kinyer√©s√©ben √°ltal√°nos k√©pekb≈ël, √©s sok esetben elegend≈ë egy oszt√°lyoz√≥t √©p√≠teni ezekre a kinyert jellemz≈ëkre, hogy j√≥ eredm√©nyt √©rj√ºnk el.

> ‚úÖ A transzfer tanul√°s kifejez√©s m√°s tudom√°nyter√ºleteken is el≈ëfordul, p√©ld√°ul az oktat√°sban. Arra utal, hogy egy ter√ºleten szerzett tud√°st egy m√°sik ter√ºleten alkalmazunk.

## El≈ëre betan√≠tott modellek mint jellemz≈ëk kinyer≈ëi

Az el≈ëz≈ë szakaszban t√°rgyalt konvol√∫ci√≥s h√°l√≥zatok t√∂bb r√©tegb≈ël √°llnak, amelyek mindegyike bizonyos jellemz≈ëket nyer ki a k√©pb≈ël, kezdve az alacsony szint≈± pixelkombin√°ci√≥kt√≥l (p√©ld√°ul v√≠zszintes/f√ºgg≈ëleges vonal vagy stroke), eg√©szen a magasabb szint≈± jellemz≈ëkombin√°ci√≥kig, amelyek p√©ld√°ul egy l√°ng szem√©nek felelnek meg. Ha egy CNN-t el√©g nagy, √°ltal√°nos √©s v√°ltozatos k√©padathalmazon tan√≠tunk, a h√°l√≥zatnak meg kell tanulnia ezeket a k√∂z√∂s jellemz≈ëket kinyerni.

Mind a Keras, mind a PyTorch tartalmaz funkci√≥kat, amelyekkel k√∂nnyen bet√∂lthet≈ëk el≈ëre betan√≠tott neur√°lis h√°l√≥zati s√∫lyok n√©h√°ny gyakori architekt√∫r√°hoz, amelyek t√∂bbs√©g√©t ImageNet k√©peken tan√≠tott√°k. A leggyakrabban haszn√°ltakat az el≈ëz≈ë leck√©ben tal√°lhat√≥ [CNN Architekt√∫r√°k](../07-ConvNets/CNN_Architectures.md) oldalon ismertett√ºk. K√ºl√∂n√∂sen √©rdemes megfontolni az al√°bbiakat:

* **VGG-16/VGG-19**, amelyek viszonylag egyszer≈± modellek, de m√©gis j√≥ pontoss√°got adnak. Gyakran j√≥ v√°laszt√°s a VGG haszn√°lata els≈ë pr√≥b√°lkoz√°sk√©nt, hogy l√°ssuk, hogyan m≈±k√∂dik a transzfer tanul√°s.
* **ResNet**, amelyet a Microsoft Research javasolt 2015-ben. Ezeknek t√∂bb r√©teg√ºk van, √≠gy t√∂bb er≈ëforr√°st ig√©nyelnek.
* **MobileNet**, amely cs√∂kkentett m√©ret≈± modellek csal√°dja, mobil eszk√∂z√∂kre alkalmas. Haszn√°lja ≈ëket, ha kev√©s er≈ëforr√°ssal rendelkezik, √©s hajland√≥ egy kis pontoss√°got fel√°ldozni.

√çme n√©h√°ny jellemz≈ë, amelyet egy macska k√©p√©b≈ël nyert ki a VGG-16 h√°l√≥zat:

![Jellemz≈ëk, amelyeket a VGG-16 nyert ki](../../../../../translated_images/features.6291f9c7ba3a0b951af88fc9864632b9115365410765680680d30c927dd67354.hu.png)

## Macsk√°k √©s kuty√°k adathalmaz

Ebben a p√©ld√°ban a [Macsk√°k √©s Kuty√°k](https://www.microsoft.com/download/details.aspx?id=54765&WT.mc_id=academic-77998-cacaste) adathalmazt fogjuk haszn√°lni, amely nagyon k√∂zel √°ll egy val√≥s √©letbeli k√©poszt√°lyoz√°si feladathoz.

## ‚úçÔ∏è Gyakorlat: Transzfer tanul√°s

N√©zz√ºk meg a transzfer tanul√°st m≈±k√∂d√©s k√∂zben a megfelel≈ë notebookokban:

* [Transzfer tanul√°s - PyTorch](../../../../../lessons/4-ComputerVision/08-TransferLearning/TransferLearningPyTorch.ipynb)
* [Transzfer tanul√°s - TensorFlow](../../../../../lessons/4-ComputerVision/08-TransferLearning/TransferLearningTF.ipynb)

## Az ellens√©ges macska vizualiz√°l√°sa

Az el≈ëre betan√≠tott neur√°lis h√°l√≥zat k√ºl√∂nb√∂z≈ë mint√°kat tartalmaz az *agy√°ban*, bele√©rtve az **ide√°lis macska** fogalm√°t (valamint ide√°lis kutya, ide√°lis zebra stb.). √ârdekes lenne valahogy **vizualiz√°lni ezt a k√©pet**. Ez azonban nem egyszer≈±, mert a mint√°k sz√©tsz√≥r√≥dnak a h√°l√≥zat s√∫lyai k√∂z√∂tt, √©s hierarchikus strukt√∫r√°ban vannak szervezve.

Egy megk√∂zel√≠t√©s, amit alkalmazhatunk, az, hogy egy v√©letlenszer≈± k√©ppel kezd√ºnk, majd megpr√≥b√°ljuk **gradiens cs√∂kken√©s optimaliz√°ci√≥s** technik√°val √∫gy m√≥dos√≠tani azt a k√©pet, hogy a h√°l√≥zat elkezdje azt macsk√°nak gondolni.

![K√©p optimaliz√°ci√≥s ciklus](../../../../../translated_images/ideal-cat-loop.999fbb8ff306e044f997032f4eef9152b453e6a990e449bbfb107de2493cc37e.hu.png)

Ha ezt tessz√ºk, akkor valami nagyon hasonl√≥t kapunk, mint egy v√©letlenszer≈± zaj. Ennek az az oka, hogy *sokf√©lek√©ppen lehet a h√°l√≥zatot r√°venni arra, hogy a bemeneti k√©pet macsk√°nak gondolja*, bele√©rtve olyanokat is, amelyek vizu√°lisan nem √©rtelmezhet≈ëk. B√°r ezek a k√©pek sok olyan mint√°t tartalmaznak, amelyek tipikusak egy macsk√°ra, semmi sem k√©nyszer√≠ti ≈ëket arra, hogy vizu√°lisan megk√ºl√∂nb√∂ztethet≈ëk legyenek.

Az eredm√©ny jav√≠t√°sa √©rdek√©ben hozz√°adhatunk egy m√°sik tagot a vesztes√©gf√ºggv√©nyhez, amelyet **vari√°ci√≥s vesztes√©gnek** nevez√ºnk. Ez egy metrika, amely megmutatja, mennyire hasonl√≥ak a k√©p szomsz√©dos pixelei. A vari√°ci√≥s vesztes√©g minimaliz√°l√°sa sim√°bb√° teszi a k√©pet, √©s megszabadul a zajt√≥l - √≠gy vizu√°lisan vonz√≥bb mint√°kat t√°r fel. √çme egy p√©lda az ilyen "ide√°lis" k√©pekre, amelyeket nagy val√≥sz√≠n≈±s√©ggel macsk√°nak √©s zebr√°nak oszt√°lyoznak:

![Ide√°lis macska](../../../../../translated_images/ideal-cat.203dd4597643d6b0bd73038b87f9c0464322725e3a06ab145d25d4a861c70592.hu.png) | ![Ide√°lis zebra](../../../../../translated_images/ideal-zebra.7f70e8b54ee15a7a314000bb5df38a6cfe086ea04d60df4d3ef313d046b98a2b.hu.png)
-----|-----
 *Ide√°lis macska* | *Ide√°lis zebra*

Hasonl√≥ megk√∂zel√≠t√©st alkalmazhatunk √∫gynevezett **ellens√©ges t√°mad√°sok** v√©grehajt√°s√°ra egy neur√°lis h√°l√≥zaton. Tegy√ºk fel, hogy meg akarjuk t√©veszteni a neur√°lis h√°l√≥zatot, √©s egy kuty√°t macsk√°nak akarunk l√°ttatni. Ha vesz√ºnk egy kutya k√©p√©t, amelyet a h√°l√≥zat kutyak√©nt ismer fel, akkor azt egy kicsit m√≥dos√≠thatjuk gradiens cs√∂kken√©s optimaliz√°ci√≥val, am√≠g a h√°l√≥zat macskak√©nt nem kezdi oszt√°lyozni:

![K√©p egy kuty√°r√≥l](../../../../../translated_images/original-dog.8f68a67d2fe0911f33041c0f7fce8aa4ea919f9d3917ec4b468298522aeb6356.hu.png) | ![K√©p egy kuty√°r√≥l, amelyet macsk√°nak oszt√°lyoznak](../../../../../translated_images/adversarial-dog.d9fc7773b0142b89752539bfbf884118de845b3851c5162146ea0b8809fc820f.hu.png)
-----|-----
*Eredeti k√©p egy kuty√°r√≥l* | *K√©p egy kuty√°r√≥l, amelyet macsk√°nak oszt√°lyoznak*

N√©zze meg a fenti eredm√©nyek reproduk√°l√°s√°hoz sz√ºks√©ges k√≥dot az al√°bbi notebookban:

* [Ide√°lis √©s ellens√©ges macska - TensorFlow](../../../../../lessons/4-ComputerVision/08-TransferLearning/AdversarialCat_TF.ipynb)

## K√∂vetkeztet√©s

A transzfer tanul√°s seg√≠ts√©g√©vel gyorsan √∂ssze√°ll√≠that egy oszt√°lyoz√≥t egy egyedi objektum oszt√°lyoz√°si feladathoz, √©s magas pontoss√°got √©rhet el. L√°that√≥, hogy az √∂sszetettebb feladatok, amelyeket most megoldunk, nagyobb sz√°m√≠t√°si teljes√≠tm√©nyt ig√©nyelnek, √©s nem oldhat√≥k meg k√∂nnyen CPU-n. A k√∂vetkez≈ë egys√©gben megpr√≥b√°lunk egy k√∂nnyebb implement√°ci√≥t haszn√°lni ugyanazon modell tan√≠t√°s√°ra alacsonyabb sz√°m√≠t√°si er≈ëforr√°sokkal, ami csak kiss√© alacsonyabb pontoss√°got eredm√©nyez.

## üöÄ Kih√≠v√°s

A k√≠s√©r≈ë notebookokban vannak megjegyz√©sek az alj√°n arr√≥l, hogy a transzfer tud√°s legjobban hasonl√≥ tan√≠t√°si adatokkal m≈±k√∂dik (p√©ld√°ul egy √∫j √°llatfajta). K√≠s√©rletezzen teljesen √∫j t√≠pus√∫ k√©pekkel, hogy l√°ssa, mennyire j√≥l vagy rosszul teljes√≠tenek a transzfer tud√°s modellek.

## [El≈ëad√°s ut√°ni kv√≠z](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/208)

## √Åttekint√©s √©s √∂n√°ll√≥ tanul√°s

Olvassa el a [TrainingTricks.md](TrainingTricks.md) f√°jlt, hogy elm√©ly√≠tse tud√°s√°t a modellek tan√≠t√°s√°nak egy√©b m√≥djair√≥l.

## [Feladat](lab/README.md)

Ebben a laborban a val√≥s √©letb≈ël vett [Oxford-IIIT](https://www.robots.ox.ac.uk/~vgg/data/pets/) h√°zi√°llatok adathalmazt fogjuk haszn√°lni, amely 35 macska- √©s kutyafajt√°t tartalmaz, √©s egy transzfer tanul√°si oszt√°lyoz√≥t fogunk √©p√≠teni.

**Felel≈ëss√©g kiz√°r√°sa**:  
Ez a dokumentum az AI ford√≠t√°si szolg√°ltat√°s [Co-op Translator](https://github.com/Azure/co-op-translator) seg√≠ts√©g√©vel lett leford√≠tva. B√°r t√∂reksz√ºnk a pontoss√°gra, k√©rj√ºk, vegye figyelembe, hogy az automatikus ford√≠t√°sok hib√°kat vagy pontatlans√°gokat tartalmazhatnak. Az eredeti dokumentum az eredeti nyelv√©n tekintend≈ë hiteles forr√°snak. Kritikus inform√°ci√≥k eset√©n javasolt professzion√°lis emberi ford√≠t√°st ig√©nybe venni. Nem v√°llalunk felel≈ëss√©get semmilyen f√©lre√©rt√©s√©rt vagy t√©ves √©rtelmez√©s√©rt, amely a ford√≠t√°s haszn√°lat√°b√≥l eredhet.