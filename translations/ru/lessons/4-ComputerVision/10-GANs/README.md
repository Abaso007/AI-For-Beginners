<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f07c85bbf05a1f67505da98f4ecc124c",
  "translation_date": "2025-08-26T06:40:17+00:00",
  "source_file": "lessons/4-ComputerVision/10-GANs/README.md",
  "language_code": "ru"
}
-->
# Генеративно-состязательные сети

В предыдущем разделе мы узнали о **генеративных моделях**: моделях, которые могут создавать новые изображения, похожие на те, что находятся в обучающем наборе данных. Примером такой модели является VAE.

## [Тест перед лекцией](https://ff-quizzes.netlify.app/en/ai/quiz/19)

Однако, если мы попытаемся создать что-то действительно значимое, например, картину с разумным разрешением, используя VAE, мы заметим, что обучение не сходится должным образом. Для таких случаев стоит изучить другую архитектуру, специально предназначенную для генеративных моделей, — **Генеративно-состязательные сети** (Generative Adversarial Networks, GANs).

Основная идея GAN заключается в использовании двух нейронных сетей, которые обучаются друг против друга:

<img src="images/gan_architecture.png" width="70%"/>

> Изображение предоставлено [Дмитрием Сошниковым](http://soshnikov.com)

> ✅ Немного терминологии:
> * **Генератор** — это сеть, которая принимает случайный вектор и создает изображение в качестве результата.
> * **Дискриминатор** — это сеть, которая принимает изображение и должна определить, является ли оно реальным (из обучающего набора данных) или сгенерированным генератором. По сути, это классификатор изображений.

### Дискриминатор

Архитектура дискриминатора не отличается от обычной сети для классификации изображений. В простейшем случае это может быть полностью связанный классификатор, но чаще всего это будет [сверточная сеть](../07-ConvNets/README.md).

> ✅ GAN, основанный на сверточных сетях, называется [DCGAN](https://arxiv.org/pdf/1511.06434.pdf)

Сверточный дискриминатор состоит из следующих слоев: нескольких сверточных слоев с понижением пространственного размера (с использованием пулинга) и одного или нескольких полностью связанных слоев для получения "векторных признаков", а затем финального бинарного классификатора.

> ✅ "Пулинг" в данном контексте — это метод уменьшения размера изображения. "Слои пулинга уменьшают размер данных, объединяя выходы кластеров нейронов на одном слое в один нейрон на следующем слое." - [источник](https://wikipedia.org/wiki/Convolutional_neural_network#Pooling_layers)

### Генератор

Генератор устроен немного сложнее. Его можно рассматривать как обратный дискриминатор. Начиная с латентного вектора (вместо вектора признаков), он использует полностью связанный слой для преобразования вектора в требуемый размер/форму, а затем применяет деконволюции и масштабирование. Это похоже на *декодер* в [автоэнкодере](../09-Autoencoders/README.md).

> ✅ Поскольку сверточный слой реализуется как линейный фильтр, проходящий по изображению, деконволюция по сути аналогична свертке и может быть реализована с использованием той же логики слоя.

<img src="images/gan_arch_detail.png" width="70%"/>

> Изображение предоставлено [Дмитрием Сошниковым](http://soshnikov.com)

### Обучение GAN

GAN называются **состязательными**, потому что между генератором и дискриминатором идет постоянное соревнование. В ходе этого соревнования обе сети улучшаются, и сеть учится создавать все более качественные изображения.

Обучение происходит в два этапа:

* **Обучение дискриминатора**. Эта задача довольно проста: мы генерируем партию изображений с помощью генератора, помечая их как 0 (фейковые изображения), и берем партию изображений из входного набора данных (с меткой 1, реальные изображения). Затем вычисляем *функцию потерь дискриминатора* и выполняем обратное распространение ошибки.
* **Обучение генератора**. Этот этап сложнее, так как мы не знаем ожидаемый результат для генератора напрямую. Мы берем всю сеть GAN, состоящую из генератора и дискриминатора, подаем на вход случайные векторы и ожидаем, что результат будет 1 (соответствует реальным изображениям). Затем мы "замораживаем" параметры дискриминатора (чтобы он не обучался на этом этапе) и выполняем обратное распространение ошибки.

В процессе обучения функции потерь генератора и дискриминатора обычно не уменьшаются значительно. В идеале они должны колебаться, что соответствует улучшению обеих сетей.

## ✍️ Упражнения: GAN

* [Блокнот GAN на TensorFlow/Keras](../../../../../lessons/4-ComputerVision/10-GANs/GANTF.ipynb)
* [Блокнот GAN на PyTorch](../../../../../lessons/4-ComputerVision/10-GANs/GANPyTorch.ipynb)

### Проблемы при обучении GAN

GAN известны своей сложностью в обучении. Вот несколько распространенных проблем:

* **Коллапс моды**. Это означает, что генератор учится создавать одно успешное изображение, которое обманывает дискриминатор, вместо того чтобы генерировать разнообразные изображения.
* **Чувствительность к гиперпараметрам**. Часто можно заметить, что GAN не сходится вообще, а затем внезапное уменьшение скорости обучения приводит к сходимости.
* Поддержание **баланса** между генератором и дискриминатором. Во многих случаях функция потерь дискриминатора может быстро упасть до нуля, что делает невозможным дальнейшее обучение генератора. Чтобы этого избежать, можно попробовать установить разные скорости обучения для генератора и дискриминатора или пропускать обучение дискриминатора, если его функция потерь уже слишком мала.
* Обучение для **высокого разрешения**. Эта проблема аналогична проблеме с автоэнкодерами: восстановление слишком большого количества слоев сверточной сети приводит к артефактам. Обычно это решается с помощью так называемого **прогрессивного роста**, когда сначала обучаются несколько слоев на изображениях низкого разрешения, а затем слои "разблокируются" или добавляются. Другим решением может быть добавление дополнительных связей между слоями и обучение нескольких разрешений одновременно — подробнее об этом можно узнать в статье [Multi-Scale Gradient GANs](https://arxiv.org/abs/1903.06048).

## Перенос стиля

GAN — отличный инструмент для создания художественных изображений. Еще одна интересная техника — это так называемый **перенос стиля**, который берет одно **изображение-контент** и перерисовывает его в другом стиле, используя фильтры из **изображения-стиля**.

Как это работает:
* Мы начинаем с изображения, заполненного случайным шумом (или с изображения-контента, но для понимания проще начать с шума).
* Наша цель — создать такое изображение, которое будет близко как к изображению-контенту, так и к изображению-стилю. Это определяется двумя функциями потерь:
   - **Потеря контента** вычисляется на основе признаков, извлеченных CNN на некоторых слоях из текущего изображения и изображения-контента.
   - **Потеря стиля** вычисляется между текущим изображением и изображением-стилем с использованием матриц Грама (подробнее в [примере блокнота](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)).
* Чтобы сделать изображение более гладким и убрать шум, мы также вводим **потерю вариации**, которая вычисляет среднее расстояние между соседними пикселями.
* Основной цикл оптимизации корректирует текущее изображение с использованием градиентного спуска (или другого алгоритма оптимизации) для минимизации общей функции потерь, которая является взвешенной суммой всех трех потерь.

## ✍️ Пример: [Перенос стиля](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)

## [Тест после лекции](https://ff-quizzes.netlify.app/en/ai/quiz/20)

## Заключение

В этом уроке вы узнали о GAN и о том, как их обучать. Вы также узнали о специфических проблемах, с которыми может столкнуться этот тип нейронных сетей, и о стратегиях их преодоления.

## 🚀 Задание

Пройдите через [блокнот по переносу стиля](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb), используя свои собственные изображения.

## Обзор и самостоятельное изучение

Для справки, прочитайте больше о GAN в следующих ресурсах:

* Марко Пазини, [10 уроков, которые я усвоил, обучая GAN в течение года](https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628)
* [StyleGAN](https://en.wikipedia.org/wiki/StyleGAN) — архитектура GAN, ставшая *де-факто* стандартом
* [Создание генеративного искусства с использованием GAN на Azure ML](https://soshnikov.com/scienceart/creating-generative-art-using-gan-on-azureml/)

## Задание

Перейдите к одному из двух блокнотов, связанных с этим уроком, и переобучите GAN на своих собственных изображениях. Что вы сможете создать?

**Отказ от ответственности**:  
Этот документ был переведен с использованием сервиса автоматического перевода [Co-op Translator](https://github.com/Azure/co-op-translator). Хотя мы стремимся к точности, пожалуйста, учитывайте, что автоматические переводы могут содержать ошибки или неточности. Оригинальный документ на его родном языке следует считать авторитетным источником. Для получения критически важной информации рекомендуется профессиональный перевод человеком. Мы не несем ответственности за любые недоразумения или неправильные интерпретации, возникающие в результате использования данного перевода.