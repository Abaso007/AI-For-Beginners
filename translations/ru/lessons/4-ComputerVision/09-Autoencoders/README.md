<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "0b306c04f5337b6e7430e5c0b16bb5c0",
  "translation_date": "2025-08-26T06:39:24+00:00",
  "source_file": "lessons/4-ComputerVision/09-Autoencoders/README.md",
  "language_code": "ru"
}
-->
# Автоэнкодеры

При обучении сверточных нейронных сетей (CNN) одной из проблем является необходимость большого количества размеченных данных. Например, для классификации изображений нужно вручную разделить изображения на разные классы.

## [Тест перед лекцией](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/109)

Однако можно использовать необработанные (неразмеченные) данные для обучения CNN в качестве извлекателей признаков, что называется **самостоятельным обучением** (self-supervised learning). Вместо меток мы будем использовать обучающие изображения как входные данные и как выходные. Основная идея **автоэнкодера** заключается в том, что у нас будет **сеть-энкодер**, которая преобразует входное изображение в некоторое **скрытое пространство** (обычно это вектор меньшего размера), а затем **сеть-декодер**, задача которой — восстановить исходное изображение.

> ✅ [Автоэнкодер](https://wikipedia.org/wiki/Autoencoder) — это "тип искусственной нейронной сети, используемой для изучения эффективного кодирования неразмеченных данных."

Поскольку мы обучаем автоэнкодер захватывать как можно больше информации из исходного изображения для его точного восстановления, сеть пытается найти наилучшее **встраивание** (embedding) входных изображений, чтобы уловить их смысл.

![Схема автоэнкодера](../../../../../translated_images/autoencoder_schema.5e6fc9ad98a5eb6197f3513cf3baf4dfbe1389a6ae74daebda64de9f1c99f142.ru.jpg)

> Изображение из [блога Keras](https://blog.keras.io/building-autoencoders-in-keras.html)

## Сценарии использования автоэнкодеров

Хотя восстановление исходных изображений само по себе может показаться не очень полезным, есть несколько сценариев, где автоэнкодеры особенно эффективны:

* **Снижение размерности изображений для визуализации** или **обучение встраиваний изображений**. Обычно автоэнкодеры дают лучшие результаты, чем PCA, так как учитывают пространственную природу изображений и иерархические признаки.
* **Удаление шума** (denoising), то есть удаление шума с изображения. Поскольку шум содержит много бесполезной информации, автоэнкодер не может вместить его в относительно небольшое скрытое пространство и захватывает только важные части изображения. При обучении денойзеров мы начинаем с исходных изображений и используем изображения с искусственно добавленным шумом в качестве входных данных для автоэнкодера.
* **Повышение разрешения** (super-resolution), увеличение разрешения изображения. Мы начинаем с изображений высокого разрешения и используем изображения с более низким разрешением в качестве входных данных для автоэнкодера.
* **Генеративные модели**. После обучения автоэнкодера часть декодера можно использовать для создания новых объектов, начиная с случайных скрытых векторов.

## Вариационные автоэнкодеры (VAE)

Традиционные автоэнкодеры каким-то образом уменьшают размерность входных данных, выделяя важные признаки входных изображений. Однако скрытые векторы часто не имеют очевидного смысла. Например, если взять набор данных MNIST, определить, какие цифры соответствуют различным скрытым векторам, не так просто, так как близкие скрытые векторы не обязательно будут соответствовать одинаковым цифрам.

С другой стороны, для обучения *генеративных* моделей лучше иметь некоторое понимание скрытого пространства. Эта идея приводит нас к **вариационным автоэнкодерам** (VAE).

VAE — это автоэнкодер, который обучается предсказывать *статистическое распределение* скрытых параметров, так называемое **скрытое распределение**. Например, мы можем захотеть, чтобы скрытые векторы имели нормальное распределение с некоторым средним z<sub>mean</sub> и стандартным отклонением z<sub>sigma</sub> (оба параметра — это векторы некоторой размерности d). Энкодер в VAE обучается предсказывать эти параметры, а декодер берет случайный вектор из этого распределения для восстановления объекта.

Подытожим:

 * Из входного вектора мы предсказываем `z_mean` и `z_log_sigma` (вместо стандартного отклонения предсказывается его логарифм)
 * Мы выбираем случайный вектор `sample` из распределения N(z<sub>mean</sub>,exp(z<sub>log\_sigma</sub>))
 * Декодер пытается восстановить исходное изображение, используя `sample` как входной вектор

 <img src="images/vae.png" width="50%">

> Изображение из [этого блога](https://ijdykeman.github.io/ml/2016/12/21/cvae.html) Исаака Дайкмана

Вариационные автоэнкодеры используют сложную функцию потерь, состоящую из двух частей:

* **Потери восстановления** (Reconstruction loss) — функция потерь, показывающая, насколько восстановленное изображение близко к целевому (например, среднеквадратичная ошибка, MSE). Это та же функция потерь, что и в обычных автоэнкодерах.
* **KL-потери**, которые обеспечивают, чтобы распределение скрытых переменных оставалось близким к нормальному распределению. Это основано на понятии [дивергенции Кульбака-Лейблера](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained) — метрике для оценки сходства двух статистических распределений.

Одним из важных преимуществ VAE является то, что они позволяют относительно легко генерировать новые изображения, так как мы знаем, из какого распределения брать скрытые векторы. Например, если мы обучим VAE с 2D скрытым вектором на MNIST, мы сможем варьировать компоненты скрытого вектора, чтобы получить разные цифры:

<img alt="vaemnist" src="images/vaemnist.png" width="50%"/>

> Изображение от [Дмитрия Сошникова](http://soshnikov.com)

Обратите внимание, как изображения плавно переходят друг в друга, когда мы начинаем брать скрытые векторы из разных частей пространства скрытых параметров. Мы также можем визуализировать это пространство в 2D:

<img alt="vaemnist cluster" src="images/vaemnist-diag.png" width="50%"/> 

> Изображение от [Дмитрия Сошникова](http://soshnikov.com)

## ✍️ Упражнения: Автоэнкодеры

Узнайте больше об автоэнкодерах в следующих ноутбуках:

* [Автоэнкодеры в TensorFlow](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb)
* [Автоэнкодеры в PyTorch](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoEncodersPyTorch.ipynb)

## Свойства автоэнкодеров

* **Специфичность данных** — они хорошо работают только с тем типом изображений, на которых были обучены. Например, если обучить сеть повышения разрешения на цветах, она плохо справится с портретами. Это связано с тем, что сеть создает изображение более высокого разрешения, используя мелкие детали, извлеченные из обучающего набора данных.
* **Потеря информации** — восстановленное изображение не идентично исходному. Характер потерь определяется *функцией потерь*, используемой при обучении.
* Работают с **неразмеченными данными**

## [Тест после лекции](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/209)

## Заключение

В этом уроке вы узнали о различных типах автоэнкодеров, доступных для исследователя ИИ. Вы научились их строить и использовать для восстановления изображений. Вы также узнали о VAE и о том, как использовать их для генерации новых изображений.

## 🚀 Задание

В этом уроке вы узнали об использовании автоэнкодеров для изображений. Но их можно использовать и для музыки! Ознакомьтесь с проектом [MusicVAE](https://magenta.tensorflow.org/music-vae) от Magenta, который использует автоэнкодеры для обучения восстановления музыки. Проведите [эксперименты](https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/Multitrack_MusicVAE.ipynb) с этой библиотекой, чтобы увидеть, что вы можете создать.

## [Тест после лекции](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/208)

## Обзор и самостоятельное изучение

Для справки прочитайте больше об автоэнкодерах в следующих ресурсах:

* [Создание автоэнкодеров в Keras](https://blog.keras.io/building-autoencoders-in-keras.html)
* [Статья на NeuroHive](https://neurohive.io/ru/osnovy-data-science/variacionnyj-avtojenkoder-vae/)
* [Объяснение вариационных автоэнкодеров](https://kvfrans.com/variational-autoencoders-explained/)
* [Условные вариационные автоэнкодеры](https://ijdykeman.github.io/ml/2016/12/21/cvae.html)

## Задание

В конце [этого ноутбука на TensorFlow](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb) вы найдете задание — используйте его в качестве домашней работы.

**Отказ от ответственности**:  
Этот документ был переведен с использованием сервиса автоматического перевода [Co-op Translator](https://github.com/Azure/co-op-translator). Хотя мы стремимся к точности, пожалуйста, учитывайте, что автоматические переводы могут содержать ошибки или неточности. Оригинальный документ на его родном языке следует считать авторитетным источником. Для получения критически важной информации рекомендуется профессиональный перевод человеком. Мы не несем ответственности за любые недоразумения или неправильные интерпретации, возникающие в результате использования данного перевода.