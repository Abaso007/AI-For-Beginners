<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "0b306c04f5337b6e7430e5c0b16bb5c0",
  "translation_date": "2025-08-28T19:33:56+00:00",
  "source_file": "lessons/4-ComputerVision/09-Autoencoders/README.md",
  "language_code": "fi"
}
-->
# Autokooderit

Kun koulutamme CNN-verkkoja, yksi ongelmista on, ett√§ tarvitsemme paljon merkitty√§ dataa. Kuvien luokittelussa t√§m√§ tarkoittaa, ett√§ kuvat on jaoteltava eri luokkiin, mik√§ vaatii manuaalista ty√∂t√§.

## [Ennakkokysely](https://ff-quizzes.netlify.app/en/ai/quiz/17)

Toisaalta voimme haluta k√§ytt√§√§ raakadataa (ilman merkint√∂j√§) CNN-ominaisuuksien oppimiseen, mit√§ kutsutaan **itseohjautuvaksi oppimiseksi**. Merkittyjen tietojen sijaan k√§yt√§mme harjoituskuvia sek√§ verkon sy√∂tteen√§ ett√§ tulosteena. **Autokooderin** p√§√§idea on, ett√§ meill√§ on **enkooderiverkko**, joka muuntaa sy√∂tekuvan johonkin **latenttitilaan** (yleens√§ pienemm√§n kokoiseen vektoriin), ja **dekooderiverkko**, jonka teht√§v√§n√§ on rekonstruoida alkuper√§inen kuva.

> ‚úÖ [Autokooderi](https://wikipedia.org/wiki/Autoencoder) on "keinotekoisen neuroverkon tyyppi, jota k√§ytet√§√§n oppimaan tehokkaita koodauksia merkitsem√§tt√∂m√§st√§ datasta."

Koska koulutamme autokooderia tallentamaan mahdollisimman paljon alkuper√§isen kuvan tietoa tarkkaa rekonstruointia varten, verkko pyrkii l√∂yt√§m√§√§n parhaan **upotuksen** sy√∂tekuville niiden merkityksen tallentamiseksi.

![Autokooderin kaavio](../../../../../translated_images/autoencoder_schema.5e6fc9ad98a5eb6197f3513cf3baf4dfbe1389a6ae74daebda64de9f1c99f142.fi.jpg)

> Kuva [Keras-blogista](https://blog.keras.io/building-autoencoders-in-keras.html)

## Autokooderien k√§ytt√∂skenaariot

Vaikka alkuper√§isten kuvien rekonstruointi ei itsess√§√§n vaikuta kovin hy√∂dylliselt√§, on olemassa muutamia skenaarioita, joissa autokooderit ovat erityisen hy√∂dyllisi√§:

* **Kuvien ulottuvuuden pienent√§minen visualisointia varten** tai **kuva-upotusten oppiminen**. Yleens√§ autokooderit antavat parempia tuloksia kuin PCA, koska ne ottavat huomioon kuvien spatiaalisen luonteen ja hierarkkiset piirteet.
* **Kohinanpoisto**, eli kohinan poistaminen kuvasta. Koska kohina sis√§lt√§√§ paljon tarpeetonta tietoa, autokooderi ei pysty tallentamaan kaikkea suhteellisen pieneen latenttitilaan, ja n√§in se tallentaa vain kuvan t√§rke√§t osat. Kohinanpoistajien koulutuksessa aloitamme alkuper√§isist√§ kuvista ja k√§yt√§mme kuvia, joihin on lis√§tty keinotekoista kohinaa, autokooderin sy√∂tteen√§.
* **Superresoluutio**, eli kuvan resoluution parantaminen. Aloitamme korkearesoluutioisista kuvista ja k√§yt√§mme matalamman resoluution kuvaa autokooderin sy√∂tteen√§.
* **Generatiiviset mallit**. Kun autokooderi on koulutettu, dekooderiosaa voidaan k√§ytt√§√§ uusien objektien luomiseen satunnaisista latenttivektoreista.

## Variatiiviset autokooderit (VAE)

Perinteiset autokooderit pienent√§v√§t sy√∂tteen ulottuvuutta jollain tavalla ja tunnistavat sy√∂tekuvien t√§rke√§t piirteet. Latenttivektorit eiv√§t kuitenkaan usein ole kovin merkityksellisi√§. Esimerkiksi MNIST-datasetin tapauksessa ei ole helppoa selvitt√§√§, mitk√§ numerot vastaavat eri latenttivektoreita, koska l√§heiset latenttivektorit eiv√§t v√§ltt√§m√§tt√§ vastaa samoja numeroita.

Generatiivisten mallien kouluttamisessa on kuitenkin hy√∂dyllist√§ ymm√§rt√§√§ latenttitilaa. T√§m√§ ajatus johtaa meid√§t **variatiiviseen autokooderiin** (VAE).

VAE on autokooderi, joka oppii ennustamaan latenttiparametrien *tilastollisen jakauman*, niin sanotun **latenttijakauman**. Esimerkiksi voimme haluta, ett√§ latenttivektorit jakautuvat normaalisti keskiarvolla z<sub>mean</sub> ja keskihajonnalla z<sub>sigma</sub> (sek√§ keskiarvo ett√§ keskihajonta ovat jonkin ulottuvuuden d vektoreita). VAE:n enkooderi oppii ennustamaan n√§m√§ parametrit, ja dekooderi k√§ytt√§√§ satunnaista vektoria t√§st√§ jakaumasta rekonstruoidakseen objektin.

Yhteenveto:

* Sy√∂tevektorista ennustamme `z_mean` ja `z_log_sigma` (keskihajonnan sijaan ennustamme sen logaritmin)
* Otamme vektorin `sample` jakaumasta N(z<sub>mean</sub>,exp(z<sub>log_sigma</sub>))
* Dekooderi yritt√§√§ dekoodata alkuper√§isen kuvan k√§ytt√§en `sample`-vektoria sy√∂tteen√§

<img src="images/vae.png" width="50%">

> Kuva [t√§st√§ blogikirjoituksesta](https://ijdykeman.github.io/ml/2016/12/21/cvae.html) kirjoittanut Isaak Dykeman

Variatiiviset autokooderit k√§ytt√§v√§t monimutkaista h√§vi√∂funktiota, joka koostuu kahdesta osasta:

* **Rekonstruktioh√§vi√∂** on h√§vi√∂funktio, joka osoittaa, kuinka l√§hell√§ rekonstruoitu kuva on kohdetta (esimerkiksi keskineli√∂virhe, MSE). Se on sama h√§vi√∂funktio kuin tavallisissa autokoodereissa.
* **KL-h√§vi√∂**, joka varmistaa, ett√§ latenttimuuttujien jakaumat pysyv√§t l√§hell√§ normaalia jakaumaa. Se perustuu [Kullback-Leiblerin divergenssiin](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained) - metriikkaan, jolla arvioidaan kahden tilastollisen jakauman samankaltaisuutta.

Yksi VAE:n t√§rkeist√§ eduista on, ett√§ niiden avulla voimme luoda uusia kuvia suhteellisen helposti, koska tied√§mme, mist√§ jakaumasta voimme ottaa n√§ytteit√§ latenttivektoreille. Esimerkiksi, jos koulutamme VAE:n 2D-latenttivektorilla MNIST-datasetilla, voimme muuttaa latenttivektorin komponentteja saadaksemme erilaisia numeroita:

<img alt="vaemnist" src="images/vaemnist.png" width="50%"/>

> Kuva [Dmitry Soshnikovilta](http://soshnikov.com)

Huomaa, kuinka kuvat sulautuvat toisiinsa, kun alamme ottaa latenttivektoreita eri osista latenttiparametritilaa. Voimme my√∂s visualisoida t√§m√§n tilan 2D-muodossa:

<img alt="vaemnist cluster" src="images/vaemnist-diag.png" width="50%"/> 

> Kuva [Dmitry Soshnikovilta](http://soshnikov.com)

## ‚úçÔ∏è Harjoitukset: Autokooderit

Opi lis√§√§ autokoodereista n√§iss√§ vastaavissa muistikirjoissa:

* [Autokooderit TensorFlow'ssa](AutoencodersTF.ipynb)
* [Autokooderit PyTorchissa](AutoEncodersPyTorch.ipynb)

## Autokooderien ominaisuudet

* **Dataan sidottu** - ne toimivat hyvin vain sellaisten kuvien kanssa, joilla ne on koulutettu. Esimerkiksi, jos koulutamme superresoluutioverkon kukilla, se ei toimi hyvin muotokuvilla. T√§m√§ johtuu siit√§, ett√§ verkko voi tuottaa korkeamman resoluution kuvan ottamalla yksityiskohtia koulutusdatan oppimista piirteist√§.
* **H√§vi√∂llinen** - rekonstruoitu kuva ei ole sama kuin alkuper√§inen kuva. H√§vi√∂n luonne m√§√§r√§ytyy koulutuksessa k√§ytetyn *h√§vi√∂funktion* mukaan.
* Toimii **merkitsem√§tt√∂m√§ll√§ datalla**

## [J√§lkikysely](https://ff-quizzes.netlify.app/en/ai/quiz/18)

## Yhteenveto

T√§ss√§ oppitunnissa opit erilaisista autokooderityypeist√§, joita teko√§lytutkija voi k√§ytt√§√§. Opit, kuinka niit√§ rakennetaan ja kuinka niit√§ k√§ytet√§√§n kuvien rekonstruointiin. Opit my√∂s VAE:sta ja sen k√§yt√∂st√§ uusien kuvien luomiseen.

## üöÄ Haaste

T√§ss√§ oppitunnissa opit k√§ytt√§m√§√§n autokoodereita kuvien kanssa. Mutta niit√§ voidaan k√§ytt√§√§ my√∂s musiikkiin! Tutustu Magenta-projektin [MusicVAE](https://magenta.tensorflow.org/music-vae) -projektiin, joka k√§ytt√§√§ autokoodereita musiikin rekonstruinnin oppimiseen. Tee [kokeiluja](https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/Multitrack_MusicVAE.ipynb) t√§m√§n kirjaston kanssa n√§hd√§ksesi, mit√§ voit luoda.

## [J√§lkikysely](https://ff-quizzes.netlify.app/en/ai/quiz/16)

## Kertaus ja itseopiskelu

Lis√§tietoja autokoodereista l√∂yd√§t n√§ist√§ resursseista:

* [Autokooderien rakentaminen Kerasilla](https://blog.keras.io/building-autoencoders-in-keras.html)
* [Blogikirjoitus NeuroHivessa](https://neurohive.io/ru/osnovy-data-science/variacionnyj-avtojenkoder-vae/)
* [Variatiiviset autokooderit selitettyn√§](https://kvfrans.com/variational-autoencoders-explained/)
* [Ehdolliset variatiiviset autokooderit](https://ijdykeman.github.io/ml/2016/12/21/cvae.html)

## Teht√§v√§

[TensorFlow-muistikirjan](AutoencodersTF.ipynb) lopussa on 'teht√§v√§' - k√§yt√§ sit√§ teht√§v√§n√§si.

---

**Vastuuvapauslauseke**:  
T√§m√§ asiakirja on k√§√§nnetty k√§ytt√§m√§ll√§ teko√§lypohjaista k√§√§nn√∂spalvelua [Co-op Translator](https://github.com/Azure/co-op-translator). Vaikka pyrimme tarkkuuteen, huomioithan, ett√§ automaattiset k√§√§nn√∂kset voivat sis√§lt√§√§ virheit√§ tai ep√§tarkkuuksia. Alkuper√§inen asiakirja sen alkuper√§isell√§ kielell√§ tulisi pit√§√§ ensisijaisena l√§hteen√§. Kriittisen tiedon osalta suositellaan ammattimaista ihmisk√§√§nn√∂st√§. Emme ole vastuussa v√§√§rink√§sityksist√§ tai virhetulkinnoista, jotka johtuvat t√§m√§n k√§√§nn√∂ksen k√§yt√∂st√§.