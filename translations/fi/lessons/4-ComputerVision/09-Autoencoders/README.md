<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1b8d9e1b3a6f1daa864b1ff3dfc3076d",
  "translation_date": "2025-09-23T09:58:20+00:00",
  "source_file": "lessons/4-ComputerVision/09-Autoencoders/README.md",
  "language_code": "fi"
}
-->
# Autokooderit

Kun koulutetaan CNN-verkkoja, yksi ongelmista on, ett√§ tarvitsemme paljon merkitty√§ dataa. Kuvien luokittelussa meid√§n t√§ytyy jakaa kuvat eri luokkiin, mik√§ vaatii manuaalista ty√∂t√§.

## [Ennakkokysely](https://ff-quizzes.netlify.app/en/ai/quiz/17)

Voimme kuitenkin haluta k√§ytt√§√§ raakadataa (merkitsem√§t√∂nt√§) CNN-ominaisuuksien oppimiseen, mik√§ tunnetaan nimell√§ **itseohjautuva oppiminen**. Sen sijaan, ett√§ k√§ytt√§isimme luokkia, k√§yt√§mme koulutuskuvia sek√§ verkon sy√∂tteen√§ ett√§ ulostulona. **Autokooderin** p√§√§idea on, ett√§ meill√§ on **kooderiverkko**, joka muuntaa sy√∂tekuvan johonkin **latenttitilaan** (yleens√§ pienemm√§n kokoiseen vektoriin), ja sitten **dekooderiverkko**, jonka teht√§v√§n√§ on rekonstruoida alkuper√§inen kuva.

> ‚úÖ [Autokooderi](https://wikipedia.org/wiki/Autoencoder) on "er√§√§nlainen teko√§lyverkko, jota k√§ytet√§√§n oppimaan tehokkaita koodauksia merkitsem√§tt√∂m√§st√§ datasta."

Koska koulutamme autokooderia tallentamaan mahdollisimman paljon alkuper√§isen kuvan informaatiota tarkkaa rekonstruointia varten, verkko pyrkii l√∂yt√§m√§√§n parhaan **upotuksen** sy√∂tekuville merkityksen tallentamiseksi.

![Autokooderin kaavio](../../../../../translated_images/autoencoder_schema.5e6fc9ad98a5eb6197f3513cf3baf4dfbe1389a6ae74daebda64de9f1c99f142.fi.jpg)

> Kuva [Keras-blogista](https://blog.keras.io/building-autoencoders-in-keras.html)

## Autokooderien k√§ytt√∂skenaariot

Vaikka alkuper√§isten kuvien rekonstruointi ei itsess√§√§n vaikuta hy√∂dylliselt√§, on olemassa muutamia skenaarioita, joissa autokooderit ovat erityisen hy√∂dyllisi√§:

* **Kuvien dimensioiden pienent√§minen visualisointia varten** tai **kuva-upotusten kouluttaminen**. Yleens√§ autokooderit antavat parempia tuloksia kuin PCA, koska ne ottavat huomioon kuvien spatiaalisen luonteen ja hierarkkiset ominaisuudet.
* **Kohinan poisto**, eli kohinan poistaminen kuvasta. Koska kohina sis√§lt√§√§ paljon turhaa informaatiota, autokooderi ei pysty tallentamaan kaikkea suhteellisen pieneen latenttitilaan, ja n√§in se tallentaa vain kuvan t√§rke√§t osat. Kohinanpoistajaa koulutettaessa k√§yt√§mme alkuper√§isi√§ kuvia ja sy√∂t√§mme autokooderille kuvia, joihin on lis√§tty keinotekoisesti kohinaa.
* **Superresoluutio**, eli kuvan resoluution parantaminen. Aloitamme korkearesoluutioisilla kuvilla ja k√§yt√§mme matalamman resoluution kuvaa autokooderin sy√∂tteen√§.
* **Generatiiviset mallit**. Kun autokooderi on koulutettu, dekooderiosaa voidaan k√§ytt√§√§ uusien objektien luomiseen satunnaisista latenttivektoreista.

## Variatiiviset autokooderit (VAE)

Perinteiset autokooderit pienent√§v√§t sy√∂tteen datan dimensioita jollain tavalla, tunnistaen sy√∂tekuvien t√§rke√§t ominaisuudet. Latenttivektorit eiv√§t kuitenkaan usein ole kovin merkityksellisi√§. Esimerkiksi MNIST-datasetin tapauksessa ei ole helppoa selvitt√§√§, mitk√§ numerot vastaavat eri latenttivektoreita, koska l√§hekk√§iset latenttivektorit eiv√§t v√§ltt√§m√§tt√§ vastaa samoja numeroita.

Generatiivisten mallien kouluttamisessa on kuitenkin hy√∂dyllist√§ ymm√§rt√§√§ latenttitilaa. T√§m√§ idea johtaa meid√§t **variatiiviseen autokooderiin** (VAE).

VAE on autokooderi, joka oppii ennustamaan latenttiparametrien *tilastollisen jakauman*, niin kutsutun **latenttijakauman**. Esimerkiksi voimme haluta, ett√§ latenttivektorit jakautuvat normaalisti jonkin keskiarvon z<sub>mean</sub> ja keskihajonnan z<sub>sigma</sub> mukaan (sek√§ keskiarvo ett√§ keskihajonta ovat vektoreita, joiden dimensio on d). VAE:n kooderi oppii ennustamaan n√§m√§ parametrit, ja dekooderi ottaa satunnaisen vektorin t√§st√§ jakaumasta rekonstruoidakseen objektin.

Yhteenveto:

 * Sy√∂tevektorista ennustamme `z_mean` ja `z_log_sigma` (sen sijaan, ett√§ ennustaisimme keskihajonnan suoraan, ennustamme sen logaritmin)
 * Otamme n√§ytteen `sample` jakaumasta N(z<sub>mean</sub>,exp(z<sub>log\_sigma</sub>))
 * Dekooderi yritt√§√§ dekoodata alkuper√§isen kuvan k√§ytt√§en `sample`-vektoria sy√∂tteen√§

 <img src="images/vae.png" width="50%">

> Kuva [t√§st√§ blogikirjoituksesta](https://ijdykeman.github.io/ml/2016/12/21/cvae.html) kirjoittanut Isaak Dykeman

Variatiiviset autokooderit k√§ytt√§v√§t monimutkaista h√§vi√∂funktiota, joka koostuu kahdesta osasta:

* **Rekonstruktiotappio** on h√§vi√∂funktio, joka osoittaa, kuinka l√§hell√§ rekonstruoitu kuva on kohdetta (se voi olla esimerkiksi Mean Squared Error eli MSE). Se on sama h√§vi√∂funktio kuin tavallisissa autokoodereissa.
* **KL-tappio**, joka varmistaa, ett√§ latenttimuuttujien jakauma pysyy l√§hell√§ normaalia jakaumaa. Se perustuu [Kullback-Leiblerin divergenssiin](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained) - metriikkaan, joka arvioi, kuinka samanlaisia kaksi tilastollista jakaumaa ovat.

Yksi t√§rke√§ etu VAE:ssa on, ett√§ niiden avulla voidaan luoda uusia kuvia suhteellisen helposti, koska tied√§mme, mist√§ jakaumasta voimme ottaa n√§ytteit√§ latenttivektoreille. Esimerkiksi, jos koulutamme VAE:n 2D-latenttivektorilla MNIST-datasetilla, voimme sitten muuttaa latenttivektorin komponentteja saadaksemme eri numeroita:

<img alt="vaemnist" src="images/vaemnist.png" width="50%"/>

> Kuva [Dmitry Soshnikovilta](http://soshnikov.com)

Huomaa, kuinka kuvat sulautuvat toisiinsa, kun alamme saada latenttivektoreita eri osista latenttiparametritilaa. Voimme my√∂s visualisoida t√§m√§n tilan 2D-muodossa:

<img alt="vaemnist cluster" src="images/vaemnist-diag.png" width="50%"/> 

> Kuva [Dmitry Soshnikovilta](http://soshnikov.com)

## ‚úçÔ∏è Harjoitukset: Autokooderit

Tutustu autokoodereihin n√§iss√§ vastaavissa muistikirjoissa:

* [Autokooderit TensorFlow:ssa](AutoencodersTF.ipynb)
* [Autokooderit PyTorch:ssa](AutoEncodersPyTorch.ipynb)

## Autokooderien ominaisuudet

* **Dataan sidottu** - ne toimivat hyvin vain sen tyyppisten kuvien kanssa, joilla ne on koulutettu. Esimerkiksi, jos koulutamme superresoluutiomallin kukilla, se ei toimi hyvin muotokuvilla. T√§m√§ johtuu siit√§, ett√§ verkko voi tuottaa korkearesoluutioisen kuvan ottamalla hienoja yksityiskohtia ominaisuuksista, jotka on opittu koulutusdatasta.
* **H√§vi√∂llinen** - rekonstruoitu kuva ei ole sama kuin alkuper√§inen kuva. H√§vi√∂n luonne m√§√§ritell√§√§n koulutuksessa k√§ytetyn *h√§vi√∂funktion* mukaan.
* Toimii **merkitsem√§tt√∂m√§ll√§ datalla**

## [J√§lkikysely](https://ff-quizzes.netlify.app/en/ai/quiz/18)

## Yhteenveto

T√§ss√§ oppitunnissa opit erilaisista autokooderityypeist√§, joita teko√§lytutkija voi k√§ytt√§√§. Opit, kuinka niit√§ rakennetaan ja kuinka niit√§ k√§ytet√§√§n kuvien rekonstruointiin. Opit my√∂s VAE:sta ja sen k√§yt√∂st√§ uusien kuvien luomiseen.

## üöÄ Haaste

T√§ss√§ oppitunnissa opit k√§ytt√§m√§√§n autokoodereita kuvien kanssa. Mutta niit√§ voidaan k√§ytt√§√§ my√∂s musiikin kanssa! Tutustu Magenta-projektin [MusicVAE](https://magenta.tensorflow.org/music-vae) -projektiin, joka k√§ytt√§√§ autokoodereita musiikin rekonstruointiin. Tee joitakin [kokeiluja](https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/Multitrack_MusicVAE.ipynb) t√§m√§n kirjaston kanssa ja katso, mit√§ voit luoda.

## [J√§lkikysely](https://ff-quizzes.netlify.app/en/ai/quiz/16)

## Kertaus ja itseopiskelu

Lis√§tietoja autokoodereista l√∂yd√§t n√§ist√§ l√§hteist√§:

* [Autokooderien rakentaminen Kerasilla](https://blog.keras.io/building-autoencoders-in-keras.html)
* [Blogikirjoitus NeuroHivessa](https://neurohive.io/ru/osnovy-data-science/variacionnyj-avtojenkoder-vae/)
* [Variatiiviset autokooderit selitettyn√§](https://kvfrans.com/variational-autoencoders-explained/)
* [Ehdolliset variatiiviset autokooderit](https://ijdykeman.github.io/ml/2016/12/21/cvae.html)

## Teht√§v√§

[TensorFlow-muistikirjan](AutoencodersTF.ipynb) lopussa l√∂yd√§t "teht√§v√§n" - k√§yt√§ t√§t√§ teht√§v√§n√§si.

---

