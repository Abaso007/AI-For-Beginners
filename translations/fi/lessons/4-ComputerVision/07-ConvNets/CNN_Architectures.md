<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "53faab85adfcebd8c10bcd71dc2fa557",
  "translation_date": "2025-09-23T09:56:27+00:00",
  "source_file": "lessons/4-ComputerVision/07-ConvNets/CNN_Architectures.md",
  "language_code": "fi"
}
-->
# Tunnetut CNN-arkkitehtuurit

### VGG-16

VGG-16 on verkko, joka saavutti 92,7 % tarkkuuden ImageNetin top-5-luokittelussa vuonna 2014. Sen kerrosrakenne on seuraava:

![ImageNet Layers](../../../../../translated_images/vgg-16-arch1.d901a5583b3a51baeaab3e768567d921e5d54befa46e1e642616c5458c934028.fi.jpg)

Kuten n√§et, VGG noudattaa perinteist√§ pyramidirakennetta, joka koostuu konvoluutio- ja pooling-kerrosten sarjasta.

![ImageNet Pyramid](../../../../../translated_images/vgg-16-arch.64ff2137f50dd49fdaa786e3f3a975b3f22615efd13efb19c5d22f12e01451a1.fi.jpg)

> Kuva [Researchgate](https://www.researchgate.net/figure/Vgg16-model-structure-To-get-the-VGG-NIN-model-we-replace-the-2-nd-4-th-6-th-7-th_fig2_335194493) -sivustolta

### ResNet

ResNet on Microsoft Researchin vuonna 2015 ehdottama malliperhe. ResNetin p√§√§idea on k√§ytt√§√§ **residuaalilohkoja**:

<img src="images/resnet-block.png" width="300"/>

> Kuva [t√§st√§ artikkelista](https://arxiv.org/pdf/1512.03385.pdf)

Identiteettisiirron k√§ytt√∂ mahdollistaa sen, ett√§ kerros ennustaa **erotuksen** edellisen kerroksen tuloksen ja residuaalilohkon ulostulon v√§lill√§ - t√§st√§ nimi *residuaali*. N√§m√§ lohkot ovat paljon helpompia kouluttaa, ja niiden avulla voidaan rakentaa verkkoja, joissa on satoja t√§llaisia lohkoja (yleisimm√§t variantit ovat ResNet-52, ResNet-101 ja ResNet-152).

Voit my√∂s ajatella t√§t√§ verkkoa kykenev√§ksi mukauttamaan monimutkaisuutensa datan mukaan. Aluksi, kun verkkoa aletaan kouluttaa, painojen arvot ovat pieni√§, ja suurin osa signaalista kulkee identiteettisiirron kautta. Koulutuksen edetess√§ ja painojen kasvaessa verkon parametrien merkitys kasvaa, ja verkko mukautuu tarjoamaan tarvittavan ilmaisukyvyn koulutuskuvien oikeaan luokitteluun.

### Google Inception

Google Inception -arkkitehtuuri vie t√§m√§n idean askeleen pidemm√§lle ja rakentaa jokaisen verkon kerroksen useiden eri polkujen yhdistelm√§n√§:

<img src="images/inception.png" width="400"/>

> Kuva [Researchgate](https://www.researchgate.net/figure/Inception-module-with-dimension-reductions-left-and-schema-for-Inception-ResNet-v1_fig2_355547454) -sivustolta

T√§ss√§ on t√§rke√§√§ korostaa 1x1-konvoluutioiden roolia, sill√§ aluksi ne eiv√§t tunnu j√§rkevilt√§. Miksi tarvitsisimme 1x1-suodattimen kuvan l√§pik√§ymiseen? On kuitenkin muistettava, ett√§ konvoluutiosuodattimet toimivat my√∂s useiden syvyyskanavien kanssa (alun perin - RGB-v√§rit, my√∂hemmiss√§ kerroksissa - eri suodattimien kanavat), ja 1x1-konvoluutioita k√§ytet√§√§n n√§iden sy√∂tt√∂kanavien yhdist√§miseen eri koulutettavilla painoilla. Sit√§ voidaan my√∂s pit√§√§ kanavadimension alin√§ytteistyksen√§ (pooling).

T√§ss√§ on [hyv√§ blogikirjoitus](https://medium.com/analytics-vidhya/talented-mr-1x1-comprehensive-look-at-1x1-convolution-in-deep-learning-f6b355825578) aiheesta ja [alkuper√§inen artikkeli](https://arxiv.org/pdf/1312.4400.pdf).

### MobileNet

MobileNet on malliperhe, jonka koko on pienennetty, ja se sopii mobiililaitteille. K√§yt√§ niit√§, jos resurssit ovat rajalliset ja voit tinki√§ hieman tarkkuudesta. Niiden p√§√§idea on niin sanottu **syvyyssuuntaan erottuva konvoluutio**, joka mahdollistaa konvoluutiosuodattimien esitt√§misen tilakonvoluutioiden ja syvyyskanavien 1x1-konvoluution yhdistelm√§n√§. T√§m√§ v√§hent√§√§ merkitt√§v√§sti parametrien m√§√§r√§√§, mik√§ tekee verkosta pienemm√§n ja helpomman kouluttaa v√§hemm√§ll√§ datalla.

T√§ss√§ on [hyv√§ blogikirjoitus MobileNetist√§](https://medium.com/analytics-vidhya/image-classification-with-mobilenet-cc6fbb2cd470).

## Yhteenveto

T√§ss√§ osiossa olet oppinut tietokonen√§k√∂√∂n liittyvien neuroverkkojen p√§√§konseptin - konvoluutioverkot. Todelliset arkkitehtuurit, jotka mahdollistavat kuvien luokittelun, objektien tunnistamisen ja jopa kuvien generoinnin, perustuvat kaikki CNN:iin, mutta niiss√§ on enemm√§n kerroksia ja joitakin lis√§koulutustekniikoita.

## üöÄ Haaste

Liitetyiss√§ muistikirjoissa on alareunassa muistiinpanoja siit√§, miten saavuttaa parempi tarkkuus. Tee kokeita n√§hd√§ksesi, voitko saavuttaa korkeampaa tarkkuutta.

## [Luennon j√§lkeinen kysely](https://ff-quizzes.netlify.app/en/ai/quiz/14)

## Kertaus ja itseopiskelu

Vaikka CNN:it√§ k√§ytet√§√§n useimmiten tietokonen√§k√∂teht√§viss√§, ne soveltuvat yleisesti kiinte√§n kokoisten kuvioiden tunnistamiseen. Esimerkiksi, jos k√§sittelemme √§√§ni√§, voimme my√∂s k√§ytt√§√§ CNN:it√§ etsim√§√§n tiettyj√§ kuvioita √§√§nisignaalista - t√§ss√§ tapauksessa suodattimet olisivat 1-ulotteisia (ja t√§t√§ CNN:√§√§ kutsuttaisiin 1D-CNN:ksi). Lis√§ksi joskus k√§ytet√§√§n 3D-CNN:√§√§ piirteiden tunnistamiseen moniulotteisessa tilassa, kuten tiettyjen tapahtumien havaitsemiseen videolla - CNN voi tunnistaa tiettyj√§ kuvioita piirteiden muutoksessa ajan kuluessa. Tee kertaus ja itseopiskelu muista teht√§vist√§, joita CNN:ill√§ voidaan tehd√§.

## [Teht√§v√§](lab/README.md)

T√§ss√§ laboratoriossa teht√§v√§n√§si on luokitella eri kissan- ja koirarotuja. N√§m√§ kuvat ovat monimutkaisempia kuin MNIST-datasetti, niiden dimensio on suurempi, ja luokkia on yli 10.

---

