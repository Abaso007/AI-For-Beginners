<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6522312ff835796ca34136a9462fafb2",
  "translation_date": "2025-09-23T10:04:10+00:00",
  "source_file": "lessons/5-NLP/19-NER/README.md",
  "language_code": "fi"
}
-->
# Nimien tunnistus (Named Entity Recognition)

T√§h√§n menness√§ olemme keskittyneet p√§√§asiassa yhteen NLP-teht√§v√§√§n - luokitteluun. On kuitenkin olemassa my√∂s muita NLP-teht√§vi√§, joita voidaan toteuttaa neuroverkoilla. Yksi n√§ist√§ teht√§vist√§ on **[nimien tunnistus](https://wikipedia.org/wiki/Named-entity_recognition)** (NER), joka keskittyy tunnistamaan tekstist√§ tiettyj√§ entiteettej√§, kuten paikkoja, henkil√∂n nimi√§, p√§iv√§m√§√§r√§- ja aikav√§lej√§, kemiallisia kaavoja ja niin edelleen.

## [Ennakkokysely](https://ff-quizzes.netlify.app/en/ai/quiz/37)

## Esimerkki NER:n k√§yt√∂st√§

Oletetaan, ett√§ haluat kehitt√§√§ luonnollisen kielen chatbotin, joka on samanlainen kuin Amazon Alexa tai Google Assistant. √Ñlykk√§√§t chatbotit toimivat *ymm√§rt√§m√§ll√§* k√§ytt√§j√§n tarpeet tekem√§ll√§ tekstiluokittelua sy√∂tteen√§ annettuun lauseeseen. T√§m√§n luokittelun tuloksena saadaan niin sanottu **intentio**, joka m√§√§ritt√§√§, mit√§ chatbotin tulisi tehd√§.

<img alt="Bot NER" src="images/bot-ner.png" width="50%"/>

> Kuva: kirjoittaja

K√§ytt√§j√§ voi kuitenkin antaa joitakin parametreja osana lausetta. Esimerkiksi s√§√§t√§ kysyess√§√§n h√§n voi m√§√§ritt√§√§ sijainnin tai ajankohdan. Botin tulisi pysty√§ ymm√§rt√§m√§√§n n√§m√§ entiteetit ja t√§ytt√§m√§√§n parametripaikat vastaavasti ennen toiminnan suorittamista. Juuri t√§ss√§ NER astuu kuvaan.

> ‚úÖ Toinen esimerkki voisi olla [tieteellisten l√§√§ketieteellisten artikkeleiden analysointi](https://soshnikov.com/science/analyzing-medical-papers-with-azure-and-text-analytics-for-health/). Yksi t√§rkeimmist√§ asioista, joita meid√§n t√§ytyy etsi√§, ovat tietyt l√§√§ketieteelliset termit, kuten sairaudet ja l√§√§keaineet. Vaikka pieni m√§√§r√§ sairauksia voidaan todenn√§k√∂isesti tunnistaa merkkijonohakua k√§ytt√§m√§ll√§, monimutkaisemmat entiteetit, kuten kemialliset yhdisteet ja l√§√§kkeiden nimet, vaativat monimutkaisempaa l√§hestymistapaa.

## NER token-luokitteluna

NER-mallit ovat pohjimmiltaan **token-luokittelumalleja**, koska jokaiselle sy√∂tteen tokenille meid√§n t√§ytyy p√§√§tt√§√§, kuuluuko se johonkin entiteettiin vai ei, ja jos kuuluu - mihin entiteettiluokkaan.

Tarkastellaan seuraavaa artikkelin otsikkoa:

**Kolmiliuskaisen l√§p√§n vuoto** ja **litiumkarbonaatin** **toksisuus** vastasyntyneell√§ lapsella.

Entiteetit t√§ss√§ ovat:

* Kolmiliuskaisen l√§p√§n vuoto on sairaus (`DIS`)
* Litiumkarbonaatti on kemiallinen aine (`CHEM`)
* Toksisuus on my√∂s sairaus (`DIS`)

Huomaa, ett√§ yksi entiteetti voi ulottua usean tokenin yli. Ja kuten t√§ss√§ tapauksessa, meid√§n t√§ytyy erottaa toisistaan kaksi per√§kk√§ist√§ entiteetti√§. Siksi on yleist√§ k√§ytt√§√§ kahta luokkaa kullekin entiteetille - yksi m√§√§ritt√§√§ entiteetin ensimm√§isen tokenin (usein k√§ytet√§√§n etuliitett√§ `B-`, joka tarkoittaa **b**eginning eli alkua), ja toinen entiteetin jatkumon (`I-`, joka tarkoittaa **i**nner eli sis√§ist√§ tokenia). K√§yt√§mme my√∂s `O`-luokkaa edustamaan kaikkia **m**uita tokeneita. T√§llainen tokenien tagitus tunnetaan nimell√§ [BIO-tagitus](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)) (tai IOB). Kun otsikko on tagitettu, se n√§ytt√§√§ t√§lt√§:

Token | Tag
------|-----
Kolmiliuskaisen | B-DIS
l√§p√§n | I-DIS
vuoto | I-DIS
ja | O
litium | B-CHEM
karbonaatti | I-CHEM
toksisuus | B-DIS
vastasyntyneell√§ | O
lapsella | O
. | O

Koska meid√§n t√§ytyy rakentaa yksi-yhteen vastaavuus tokenien ja luokkien v√§lill√§, voimme kouluttaa oikeanpuoleisen **moni-moniin** neuroverkkopohjaisen mallin t√§st√§ kuvasta:

![Kuva, joka esitt√§√§ yleisi√§ toistuvien neuroverkkojen rakenteita.](../../../../../translated_images/unreasonable-effectiveness-of-rnn.541ead816778f42dce6c42d8a56c184729aa2378d059b851be4ce12b993033df.fi.jpg)

> *Kuva [t√§st√§ blogikirjoituksesta](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) kirjoittajalta [Andrej Karpathy](http://karpathy.github.io/). NER token-luokittelumallit vastaavat oikeanpuoleista verkkoarkkitehtuuria t√§ss√§ kuvassa.*

## NER-mallien kouluttaminen

Koska NER-malli on pohjimmiltaan token-luokittelumalli, voimme k√§ytt√§√§ RNN:it√§, joihin olemme jo tutustuneet, t√§m√§n teht√§v√§n suorittamiseen. T√§ss√§ tapauksessa jokainen toistuvan verkon lohko palauttaa tokenin ID:n. Seuraava esimerkkivihko n√§ytt√§√§, kuinka LSTM voidaan kouluttaa token-luokitteluun.

## ‚úçÔ∏è Esimerkkivihkot: NER

Jatka oppimista seuraavassa vihkossa:

* [NER TensorFlow'lla](NER-TF.ipynb)

## Yhteenveto

NER-malli on **token-luokittelumalli**, mik√§ tarkoittaa, ett√§ sit√§ voidaan k√§ytt√§√§ token-luokittelun suorittamiseen. T√§m√§ on eritt√§in yleinen teht√§v√§ NLP:ss√§, ja se auttaa tunnistamaan tekstist√§ tiettyj√§ entiteettej√§, kuten paikkoja, nimi√§, p√§iv√§m√§√§ri√§ ja paljon muuta.

## üöÄ Haaste

Suorita alla linkitetty teht√§v√§, jossa koulutat nimien tunnistusmallin l√§√§ketieteellisi√§ termej√§ varten, ja kokeile sit√§ sitten eri datasetill√§.

## [J√§lkikysely](https://ff-quizzes.netlify.app/en/ai/quiz/38)

## Kertaus ja itseopiskelu

Lue blogikirjoitus [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) ja tutustu artikkelin lis√§lukemisosioon syvent√§√§ksesi tiet√§myst√§si.

## [Teht√§v√§](lab/README.md)

T√§m√§n oppitunnin teht√§v√§ss√§ sinun tulee kouluttaa l√§√§ketieteellisten entiteettien tunnistusmalli. Voit aloittaa LSTM-mallin kouluttamisella, kuten t√§ss√§ oppitunnissa on kuvattu, ja jatkaa BERT-transformerimallin k√§ytt√§miseen. Lue [ohjeet](lab/README.md) saadaksesi kaikki yksityiskohdat.

---

