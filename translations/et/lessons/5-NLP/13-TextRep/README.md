<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "dbd3f73e4139f030ecb2e20387d70fee",
  "translation_date": "2025-10-11T11:41:12+00:00",
  "source_file": "lessons/5-NLP/13-TextRep/README.md",
  "language_code": "et"
}
-->
# Teksti esindamine tensoritena

## [Eelloengu viktoriin](https://ff-quizzes.netlify.app/en/ai/quiz/25)

## Tekstiklassifikatsioon

Selle osa esimeses pooles keskendume **tekstiklassifikatsiooni** √ºlesandele. Kasutame [AG News](https://www.kaggle.com/amananandrai/ag-news-classification-dataset) andmestikku, mis sisaldab uudisartikleid, n√§iteks j√§rgmisi:

* Kategooria: Teadus/Tehnoloogia
* Pealkiri: Ky. ettev√µte v√µidab granti peptiidide uurimiseks (AP)
* Sisu: AP - Keemiauuringutega tegeleva Louisville'i √ºlikooli teadlase asutatud ettev√µte v√µitis granti, et arendada...

Meie eesm√§rk on klassifitseerida uudisartikkel √ºheks kategooriaks, tuginedes tekstile.

## Teksti esindamine

Kui tahame lahendada loomuliku keele t√∂√∂tlemise (NLP) √ºlesandeid n√§rviv√µrkudega, peame leidma viisi, kuidas teksti tensoritena esitada. Arvutid esindavad tekstim√§rke juba numbritena, mis kaardistuvad ekraanil olevate fontidega, kasutades kodeeringuid nagu ASCII v√µi UTF-8.

<img alt="Pilt, mis n√§itab skeemi, kuidas m√§rk kaardistub ASCII ja binaarse esitusena" src="../../../../../translated_images/ascii-character-map.18ed6aa7f3b0a7ffeb29db95be05a245b6a20712bb2c3a9963c1ec7e9df70358.et.png" width="50%"/>

> [Pildi allikas](https://www.seobility.net/en/wiki/ASCII)

Inimestena m√µistame, mida iga t√§ht **esindab**, ja kuidas k√µik m√§rgid kokku moodustavad lause s√µnad. Kuid arvutid ise sellist arusaama ei oma, ning n√§rviv√µrk peab t√§henduse √µppima treeningu k√§igus.

Seet√µttu saame teksti esindamisel kasutada erinevaid l√§henemisviise:

* **Tasemel esindamine**, kus k√§sitleme iga m√§rki numbrina. Kui meil on *C* erinevat m√§rki tekstikorpuses, siis s√µna *Hello* esitatakse 5x*C* tensorina. Iga t√§ht vastab √ºhe-kuuma kodeeringus tensoriveerule.
* **S√µnatasemel esindamine**, kus loome tekstis k√µigi s√µnade **s√µnavara** ja esindame s√µnu √ºhe-kuuma kodeeringuga. See l√§henemine on m√µnev√µrra parem, sest iga t√§ht iseenesest ei oma suurt t√§hendust, ja kasutades k√µrgema taseme semantilisi m√µisteid - s√µnu - lihtsustame √ºlesannet n√§rviv√µrgule. Kuid suure s√µnastiku suuruse t√µttu peame tegelema k√µrgedimensiooniliste h√µredate tensoritega.

S√µltumata esitusviisist peame esmalt teisendama teksti **tokenite** jadaks, kus √ºks token on kas m√§rk, s√µna v√µi m√µnikord isegi osa s√µnast. Seej√§rel teisendame tokeni numbriks, kasutades tavaliselt **s√µnavara**, ja see number saab √ºhe-kuuma kodeeringu kaudu n√§rviv√µrku sisendiks.

## N-grammid

Loomulikus keeles saab s√µnade t√§pset t√§hendust m√§√§rata ainult kontekstis. N√§iteks on *n√§rviv√µrk* ja *kalav√µrk* t√§hendused t√§iesti erinevad. √úks viis seda arvesse v√µtta on luua mudel s√µnapaaride p√µhjal ja k√§sitleda s√µnapaare eraldi s√µnavara tokenitena. Sel viisil esitatakse lause *Mulle meeldib kalal k√§ia* j√§rgmiste tokenite jadana: *Mulle meeldib*, *meeldib k√§ia*, *k√§ia kalal*. Selle l√§henemise probleem on, et s√µnastiku suurus kasvab m√§rkimisv√§√§rselt, ja kombinatsioonid nagu *k√§ia kalal* ja *k√§ia poes* esitatakse erinevate tokenitena, mis ei jaga semantilist sarnasust vaatamata sama verbi kasutamisele.

M√µnel juhul v√µime kaaluda ka tri-grammide - kolme s√µna kombinatsioonide - kasutamist. Seet√µttu nimetatakse seda l√§henemist sageli **n-grammideks**. Samuti on m√µistlik kasutada n-gramme m√§rgitasemel esindamisel, kus n-grammid vastavad ligikaudu erinevatele silpidele.

## S√µnakott ja TF/IDF

Tekstiklassifikatsiooni √ºlesannete lahendamisel peame suutma esitada teksti √ºhe fikseeritud suurusega vektorina, mida kasutame l√µpliku tiheda klassifikaatori sisendina. √úks lihtsamaid viise seda teha on kombineerida k√µik √ºksikud s√µnaesitused, n√§iteks neid liites. Kui liidame iga s√µna √ºhe-kuuma kodeeringud, saame sagedusvektori, mis n√§itab, mitu korda iga s√µna tekstis esineb. Sellist teksti esitust nimetatakse **s√µnakotiks** (BoW).

<img src="../../../../../translated_images/bow.3811869cff59368d951c7a765ed20ebeaf7d10680eb602ea7c5312fb22f7b7ad.et.png" width="90%"/>

> Pilt autori poolt

S√µnakott esindab sisuliselt, millised s√µnad tekstis esinevad ja millistes kogustes, mis v√µib t√µepoolest olla hea n√§itaja, millest tekst r√§√§gib. N√§iteks poliitiliste uudiste artikkel sisaldab t√µen√§oliselt s√µnu nagu *president* ja *riik*, samas kui teaduslikus publikatsioonis leidub midagi sellist nagu *kollider*, *avastatud* jne. Seega v√µivad s√µnade sagedused paljudel juhtudel olla hea n√§itaja teksti sisust.

S√µnakoti probleem on aga see, et teatud tavalised s√µnad, nagu *ja*, *on* jne, esinevad enamikus tekstides ja neil on k√µrgeimad sagedused, varjutades s√µnu, mis on t√µeliselt olulised. Nende s√µnade t√§htsust saame v√§hendada, v√µttes arvesse s√µnade esinemissagedust kogu dokumendikogus. See on TF/IDF l√§henemise peamine idee, mida k√§sitletakse selle √µppetunni juurde kuuluvates m√§rkmikes √ºksikasjalikumalt.

Kuid √ºkski neist l√§henemistest ei suuda t√§ielikult arvesse v√µtta teksti **semantikat**. Selleks vajame v√µimsamaid n√§rviv√µrgu mudeleid, mida k√§sitleme hiljem selles osas.

## ‚úçÔ∏è Harjutused: Teksti esitus

J√§tka √µppimist j√§rgmistes m√§rkmikes:

* [Teksti esitus PyTorchiga](TextRepresentationPyTorch.ipynb)
* [Teksti esitus TensorFlowga](TextRepresentationTF.ipynb)

## Kokkuv√µte

Siiani oleme uurinud tehnikaid, mis lisavad s√µnadele sageduskaalu. Need ei suuda siiski esitada t√§hendust ega j√§rjekorda. Nagu kuulus lingvist J. R. Firth √ºtles 1935. aastal: "S√µna t√§ielik t√§hendus on alati kontekstuaalne, ja √ºkski t√§henduse uurimine v√§ljaspool konteksti ei ole t√µsiseltv√µetav." √ïpime hiljem kursusel, kuidas tekstist kontekstuaalset teavet p√º√ºda, kasutades keelemudeleid.

## üöÄ V√§ljakutse

Proovi m√µnda muud harjutust, kasutades s√µnakotti ja erinevaid andmemudeleid. Inspiratsiooni v√µid saada sellest [Kaggle'i v√µistlusest](https://www.kaggle.com/competitions/word2vec-nlp-tutorial/overview/part-1-for-beginners-bag-of-words).

## [J√§relloengu viktoriin](https://ff-quizzes.netlify.app/en/ai/quiz/26)

## √úlevaade ja iseseisev √µppimine

Harjuta oma oskusi tekstiesituste ja s√µnakoti tehnikatega [Microsoft Learnis](https://docs.microsoft.com/learn/modules/intro-natural-language-processing-pytorch/?WT.mc_id=academic-77998-cacaste).

## [√úlesanne: M√§rkmikud](assignment.md)

---

**Lahti√ºtlus**:  
See dokument on t√µlgitud, kasutades AI t√µlketeenust [Co-op Translator](https://github.com/Azure/co-op-translator). Kuigi p√º√ºame tagada t√§psust, palun arvestage, et automaatsed t√µlked v√µivad sisaldada vigu v√µi ebat√§psusi. Algne dokument selle algkeeles tuleks lugeda autoriteetseks allikaks. Olulise teabe puhul on soovitatav kasutada professionaalset inimt√µlget. Me ei vastuta selle t√µlke kasutamisest tulenevate arusaamatuste v√µi valede t√µlgenduste eest.