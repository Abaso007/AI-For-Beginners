<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "d76a7eda28de5210c8b1ba50a6216c69",
  "translation_date": "2025-10-11T11:23:28+00:00",
  "source_file": "lessons/4-ComputerVision/11-ObjectDetection/README.md",
  "language_code": "et"
}
-->
# Objektide tuvastamine

Pildiklassifikatsiooni mudelid, millega oleme seni tegelenud, v√µtsid pildi ja andsid kategoorilise tulemuse, n√§iteks klassi 'number' MNIST-probleemis. Kuid paljudel juhtudel ei taha me lihtsalt teada, et pilt kujutab objekte ‚Äì me tahame m√§√§rata nende t√§pse asukoha. Just seda eesm√§rki t√§idab **objektide tuvastamine**.

## [Eelloengu viktoriin](https://ff-quizzes.netlify.app/en/ai/quiz/21)

![Objektide tuvastamine](../../../../../translated_images/Screen_Shot_2016-11-17_at_11.14.54_AM.b4bb3769353287be1b905373ed9c858102c054b16e4595c76ec3f7bba0feb549.et.png)

> Pilt [YOLO v2 veebilehelt](https://pjreddie.com/darknet/yolov2/)

## Naivne l√§henemine objektide tuvastamisele

Oletame, et tahame leida kassi pildilt. V√§ga naiivne l√§henemine objektide tuvastamisele oleks j√§rgmine:

1. Jagame pildi mitmeks v√§iksemaks osaks.
2. K√§ivitame pildiklassifikatsiooni igal osal.
3. Need osad, mis annavad piisavalt k√µrge aktiveerimise, v√µib pidada objektiks, mida otsime.

![Naivne objektide tuvastamine](../../../../../translated_images/naive-detection.e7f1ba220ccd08c68a2ea8e06a7ed75c3fcc738c2372f9e00b7f4299a8659c01.et.png)

> *Pilt [harjutuste m√§rkmikust](ObjectDetection-TF.ipynb)*

Kuid see l√§henemine pole ideaalne, kuna see v√µimaldab algoritmil m√§√§rata objekti piiritleva kasti asukohta v√§ga ebat√§pselt. T√§psema asukoha m√§√§ramiseks peame kasutama mingisugust **regressiooni**, et ennustada piiritlevate kastide koordinaate ‚Äì ja selleks on vaja spetsiifilisi andmekogumeid.

## Regressioon objektide tuvastamiseks

[See blogipostitus](https://towardsdatascience.com/object-detection-with-neural-networks-a4e2c46b4491) pakub suurep√§rast sissejuhatust kujundite tuvastamisse.

## Andmekogumid objektide tuvastamiseks

Selle √ºlesande jaoks v√µite kohata j√§rgmisi andmekogumeid:

* [PASCAL VOC](http://host.robots.ox.ac.uk/pascal/VOC/) ‚Äì 20 klassi
* [COCO](http://cocodataset.org/#home) ‚Äì Tavalised objektid kontekstis. 80 klassi, piiritlevad kastid ja segmentatsioonimaskid

![COCO](../../../../../translated_images/coco-examples.71bc60380fa6cceb7caad48bd09e35b6028caabd363aa04fee89c414e0870e86.et.jpg)

## Objektide tuvastamise m√µ√µdikud

### √úhisosa ja √ºhenduse suhe (Intersection over Union)

Kui pildiklassifikatsiooni puhul on lihtne m√µ√µta, kui h√§sti algoritm t√∂√∂tab, siis objektide tuvastamise puhul peame m√µ√µtma nii klassi √µigsust kui ka tuvastatud piiritleva kasti asukoha t√§psust. Viimase jaoks kasutame nn **√ºhisosa ja √ºhenduse suhet** (IoU), mis m√µ√µdab, kui h√§sti kaks kasti (v√µi kaks suvalist ala) kattuvad.

![IoU](../../../../../translated_images/iou_equation.9a4751d40fff4e119ecd0a7bcca4e71ab1dc83e0d4f2a0d66ff0859736f593cf.et.png)

> *Joonis 2 [sellest suurep√§rasest blogipostitusest IoU kohta](https://pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/)*

Idee on lihtne ‚Äì jagame kahe kujundi √ºhisosa pindala nende √ºhenduse pindalaga. Kahe identse ala puhul oleks IoU v√§√§rtus 1, samas kui t√§iesti eraldatud alade puhul oleks see 0. Muudel juhtudel varieerub see 0 ja 1 vahel. Tavaliselt arvestame ainult neid piiritlevaid kaste, mille IoU √ºletab teatud v√§√§rtuse.

### Keskmine t√§psus (Average Precision)

Oletame, et tahame m√µ√µta, kui h√§sti tuvastatakse teatud klassi objekte $C$. Selleks kasutame **keskmise t√§psuse** m√µ√µdikut, mis arvutatakse j√§rgmiselt:

1. V√µtame t√§psuse ja tagasikutsumise k√µvera, mis n√§itab t√§psust s√µltuvalt tuvastamise l√§ve v√§√§rtusest (vahemikus 0 kuni 1).
2. S√µltuvalt l√§vest tuvastatakse pildil rohkem v√µi v√§hem objekte ning t√§psuse ja tagasikutsumise v√§√§rtused muutuvad.
3. K√µver n√§eb v√§lja selline:

<img src="https://github.com/shwars/NeuroWorkshop/raw/master/images/ObjDetectionPrecisionRecall.png"/>

> *Pilt [NeuroWorkshopist](http://github.com/shwars/NeuroWorkshop)*

Keskmine t√§psus klassi $C$ jaoks on selle k√µvera alune pindala. T√§psemalt jagatakse tagasikutsumise telg tavaliselt 10 osaks ja t√§psus keskmistatakse k√µigi nende punktide √ºle:

$$
AP = {1\over11}\sum_{i=0}^{10}\mbox{Precision}(\mbox{Recall}={i\over10})
$$

### AP ja IoU

Arvestame ainult neid tuvastusi, mille IoU √ºletab teatud v√§√§rtuse. N√§iteks PASCAL VOC andmekogumis eeldatakse tavaliselt $\mbox{IoU Threshold} = 0.5$, samas kui COCO-s m√µ√µdetakse AP-d erinevate $\mbox{IoU Threshold}$ v√§√§rtuste jaoks.

<img src="https://github.com/shwars/NeuroWorkshop/raw/master/images/ObjDetectionPrecisionRecallIoU.png"/>

> *Pilt [NeuroWorkshopist](http://github.com/shwars/NeuroWorkshop)*

### Keskmine keskmine t√§psus ‚Äì mAP

Peamine objektide tuvastamise m√µ√µdik on **keskmine keskmine t√§psus** ehk **mAP**. See on keskmise t√§psuse v√§√§rtus, keskmistatud k√µigi objektiklasside ja m√µnikord ka $\mbox{IoU Threshold}$ √ºle. T√§psemalt on mAP arvutamise protsess kirjeldatud
[selles blogipostituses](https://medium.com/@timothycarlen/understanding-the-map-evaluation-metric-for-object-detection-a07fe6962cf3) ja [siin koos koodin√§idetega](https://gist.github.com/tarlen5/008809c3decf19313de216b9208f3734).

## Erinevad objektide tuvastamise l√§henemised

Objektide tuvastamise algoritme on kahte laia klassi:

* **Piirkonna ettepanekuv√µrgud** (R-CNN, Fast R-CNN, Faster R-CNN). Peamine idee on genereerida **huvipiirkonnad** (ROI) ja k√§ivitada nende √ºle CNN, otsides maksimaalset aktiveerimist. See on natuke sarnane naiivse l√§henemisega, v√§lja arvatud see, et ROIsid genereeritakse nutikamalt. √úks peamisi puudusi sellistel meetoditel on see, et need on aeglased, kuna vajame CNN klassifikaatori mitut l√§bimist pildi √ºle.
* **√úhe l√§bimise** (YOLO, SSD, RetinaNet) meetodid. Nendes arhitektuurides kujundatakse v√µrk nii, et see ennustaks nii klasse kui ka ROIsid √ºhe l√§bimisega.

### R-CNN: Piirkonna p√µhine CNN

[R-CNN](http://islab.ulsan.ac.kr/files/announcement/513/rcnn_pami.pdf) kasutab [Selective Search](http://www.huppelen.nl/publications/selectiveSearchDraft.pdf), et genereerida ROI piirkondade hierarhiline struktuur, mis seej√§rel l√§bib CNN-i funktsioonide ekstraktorid ja SVM-klassi m√§√§rajad, et m√§√§rata objekti klass, ning lineaarse regressiooni, et m√§√§rata *piiritleva kasti* koordinaadid. [Ametlik artikkel](https://arxiv.org/pdf/1506.01497v1.pdf)

![RCNN](../../../../../translated_images/rcnn1.cae407020dfb1d1fb572656e44f75cd6c512cc220591c116c506652c10e47f26.et.png)

> *Pilt van de Sande et al. ICCV‚Äô11*

![RCNN-1](../../../../../translated_images/rcnn2.2d9530bb83516484ec65b250c22dbf37d3d23244f32864ebcb91d98fe7c3112c.et.png)

> *Pildid [sellest blogist](https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e)*

### F-RCNN ‚Äì Kiire R-CNN

See l√§henemine on sarnane R-CNN-iga, kuid piirkonnad m√§√§ratakse p√§rast konvolutsioonikihtide rakendamist.

![FRCNN](../../../../../translated_images/f-rcnn.3cda6d9bb41888754037d2d9763e2298a96de5d9bc2a21db3147357aa5da9b1a.et.png)

> Pilt [ametlikust artiklist](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf), [arXiv](https://arxiv.org/pdf/1504.08083.pdf), 2015

### Kiirem R-CNN

Selle l√§henemise peamine idee on kasutada n√§rviv√µrku ROIside ennustamiseks ‚Äì nn *piirkonna ettepanekuv√µrk*. [Artikkel](https://arxiv.org/pdf/1506.01497.pdf), 2016

![FasterRCNN](../../../../../translated_images/faster-rcnn.8d46c099b87ef30ab2ea26dbc4bdd85b974a57ba8eb526f65dc4cd0a4711de30.et.png)

> Pilt [ametlikust artiklist](https://arxiv.org/pdf/1506.01497.pdf)

### R-FCN: Piirkonna p√µhine t√§ielikult konvolutsiooniline v√µrk

See algoritm on isegi kiirem kui Faster R-CNN. Peamine idee on j√§rgmine:

1. Ekstraheerime funktsioonid ResNet-101 abil.
2. Funktsioone t√∂√∂deldakse **positsioonitundliku skoorikaardiga**. Iga objekt klassist $C$ jagatakse $k\times k$ piirkondadeks ja treenime ennustama objektide osi.
3. Iga osa $k\times k$ piirkondadest h√§√§letavad k√µik v√µrgud objektiklasside eest ja maksimaalse h√§√§lega objektiklass valitakse.

![r-fcn pilt](../../../../../translated_images/r-fcn.13eb88158b99a3da50fa2787a6be5cb310d47f0e9655cc93a1090dc7aab338d1.et.png)

> Pilt [ametlikust artiklist](https://arxiv.org/abs/1605.06409)

### YOLO ‚Äì You Only Look Once

YOLO on reaalajas √ºhe l√§bimise algoritm. Peamine idee on j√§rgmine:

 * Pilt jagatakse $S\times S$ piirkondadeks.
 * Iga piirkonna jaoks ennustab **CNN** $n$ v√µimalikku objekti, *piiritleva kasti* koordinaate ja *usaldusv√§√§rsust*=*t√µen√§osust* * IoU.

 ![YOLO](../../../../../translated_images/yolo.a2648ec82ee8bb4ea27537677adb482fd4b733ca1705c561b6a24a85102dced5.et.png)

> Pilt [ametlikust artiklist](https://arxiv.org/abs/1506.02640)

### Muud algoritmid

* RetinaNet: [ametlik artikkel](https://arxiv.org/abs/1708.02002)
   - [PyTorchi implementatsioon Torchvisionis](https://pytorch.org/vision/stable/_modules/torchvision/models/detection/retinanet.html)
   - [Kerase implementatsioon](https://github.com/fizyr/keras-retinanet)
   - [Objektide tuvastamine RetinaNetiga](https://keras.io/examples/vision/retinanet/) Kerase n√§idetes
* SSD (Single Shot Detector): [ametlik artikkel](https://arxiv.org/abs/1512.02325)

## ‚úçÔ∏è Harjutused: Objektide tuvastamine

J√§tkake √µppimist j√§rgmises m√§rkmikus:

[ObjectDetection.ipynb](ObjectDetection.ipynb)

## Kokkuv√µte

Selles tunnis tegite kiir√ºlevaate erinevatest viisidest, kuidas objektide tuvastamist saab teostada!

## üöÄ V√§ljakutse

Lugege l√§bi need artiklid ja m√§rkmikud YOLO kohta ning proovige neid ise:

* [Hea blogipostitus](https://www.analyticsvidhya.com/blog/2018/12/practical-guide-object-detection-yolo-framewor-python/) YOLO kirjeldamiseks
 * [Ametlik veebileht](https://pjreddie.com/darknet/yolo/)
 * Yolo: [Kerase implementatsioon](https://github.com/experiencor/keras-yolo2), [samm-sammult m√§rkmik](https://github.com/experiencor/basic-yolo-keras/blob/master/Yolo%20Step-by-Step.ipynb)
 * Yolo v2: [Kerase implementatsioon](https://github.com/experiencor/keras-yolo2), [samm-sammult m√§rkmik](https://github.com/experiencor/keras-yolo2/blob/master/Yolo%20Step-by-Step.ipynb)

## [J√§relloengu viktoriin](https://ff-quizzes.netlify.app/en/ai/quiz/22)

## √úlevaade ja iseseisev √µppimine

* [Objektide tuvastamine](https://tjmachinelearning.com/lectures/1718/obj/) autor Nikhil Sardana
* [Hea v√µrdlus objektide tuvastamise algoritmide kohta](https://lilianweng.github.io/lil-log/2018/12/27/object-detection-part-4.html)
* [√úlevaade s√ºva√µppe algoritmidest objektide tuvastamiseks](https://medium.com/comet-app/review-of-deep-learning-algorithms-for-object-detection-c1f3d437b852)
* [Samm-sammuline sissejuhatus p√µhilistesse objektide tuvastamise algoritmidesse](https://www.analyticsvidhya.com/blog/2018/10/a-step-by-step-introduction-to-the-basic-object-detection-algorithms-part-1/)
* [Kiirema R-CNN-i implementatsioon Pythonis objektide tuvastamiseks](https://www.analyticsvidhya.com/blog/2018/11/implementation-faster-r-cnn-python-object-detection/)

## [√úlesanne: Objektide tuvastamine](lab/README.md)

---

**Lahti√ºtlus**:  
See dokument on t√µlgitud, kasutades AI t√µlketeenust [Co-op Translator](https://github.com/Azure/co-op-translator). Kuigi p√º√ºame tagada t√§psust, palun arvestage, et automaatsed t√µlked v√µivad sisaldada vigu v√µi ebat√§psusi. Algne dokument selle algses keeles tuleks lugeda autoriteetseks allikaks. Olulise teabe puhul on soovitatav kasutada professionaalset inimt√µlget. Me ei vastuta selle t√µlke kasutamisest tulenevate arusaamatuste v√µi valesti t√µlgenduste eest.