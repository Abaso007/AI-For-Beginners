<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "186bf7eeab776b36f557357ea56d4751",
  "translation_date": "2025-08-24T20:55:35+00:00",
  "source_file": "lessons/3-NeuralNetworks/04-OwnFramework/README.md",
  "language_code": "fr"
}
-->
# Introduction aux r√©seaux neuronaux. Perceptron multicouche

Dans la section pr√©c√©dente, vous avez d√©couvert le mod√®le de r√©seau neuronal le plus simple : le perceptron √† une couche, un mod√®le de classification lin√©aire √† deux classes.

Dans cette section, nous allons √©tendre ce mod√®le √† un cadre plus flexible, nous permettant de :

* effectuer une **classification multi-classes** en plus de la classification √† deux classes
* r√©soudre des **probl√®mes de r√©gression** en plus de la classification
* s√©parer des classes qui ne sont pas lin√©airement s√©parables

Nous d√©velopperons √©galement notre propre cadre modulaire en Python, qui nous permettra de construire diff√©rentes architectures de r√©seaux neuronaux.

## [Quiz avant le cours](https://ff-quizzes.netlify.app/en/ai/quiz/7)

## Formalisation de l'apprentissage automatique

Commen√ßons par formaliser le probl√®me de l'apprentissage automatique. Supposons que nous disposons d'un ensemble de donn√©es d'entra√Ænement **X** avec des √©tiquettes **Y**, et que nous devons construire un mod√®le *f* qui fera des pr√©dictions les plus pr√©cises possibles. La qualit√© des pr√©dictions est mesur√©e par une **fonction de perte** ‚Ñí. Les fonctions de perte suivantes sont souvent utilis√©es :

* Pour un probl√®me de r√©gression, lorsque nous devons pr√©dire un nombre, nous pouvons utiliser **l'erreur absolue** ‚àë<sub>i</sub>|f(x<sup>(i)</sup>)-y<sup>(i)</sup>|, ou **l'erreur quadratique** ‚àë<sub>i</sub>(f(x<sup>(i)</sup>)-y<sup>(i)</sup>)<sup>2</sup>
* Pour la classification, nous utilisons la **perte 0-1** (qui est essentiellement la m√™me chose que **l'exactitude** du mod√®le), ou la **perte logistique**.

Pour un perceptron √† une couche, la fonction *f* √©tait d√©finie comme une fonction lin√©aire *f(x)=wx+b* (ici *w* est la matrice de poids, *x* est le vecteur des caract√©ristiques d'entr√©e, et *b* est le vecteur de biais). Pour diff√©rentes architectures de r√©seaux neuronaux, cette fonction peut prendre une forme plus complexe.

> Dans le cas de la classification, il est souvent souhaitable d'obtenir des probabilit√©s des classes correspondantes en sortie du r√©seau. Pour convertir des nombres arbitraires en probabilit√©s (par exemple, pour normaliser la sortie), nous utilisons souvent la fonction **softmax** œÉ, et la fonction *f* devient *f(x)=œÉ(wx+b)*.

Dans la d√©finition de *f* ci-dessus, *w* et *b* sont appel√©s **param√®tres** Œ∏=‚ü®*w,b*‚ü©. √âtant donn√© l'ensemble de donn√©es ‚ü®**X**,**Y**‚ü©, nous pouvons calculer une erreur globale sur l'ensemble des donn√©es en fonction des param√®tres Œ∏.

> ‚úÖ **L'objectif de l'entra√Ænement d'un r√©seau neuronal est de minimiser l'erreur en faisant varier les param√®tres Œ∏**

## Optimisation par descente de gradient

Il existe une m√©thode bien connue d'optimisation de fonction appel√©e **descente de gradient**. L'id√©e est que nous pouvons calculer une d√©riv√©e (dans le cas multidimensionnel appel√©e **gradient**) de la fonction de perte par rapport aux param√®tres, et faire varier les param√®tres de mani√®re √† r√©duire l'erreur. Cela peut √™tre formalis√© comme suit :

* Initialiser les param√®tres avec des valeurs al√©atoires w<sup>(0)</sup>, b<sup>(0)</sup>
* R√©p√©ter l'√©tape suivante plusieurs fois :
    - w<sup>(i+1)</sup> = w<sup>(i)</sup>-Œ∑‚àÇ‚Ñí/‚àÇw
    - b<sup>(i+1)</sup> = b<sup>(i)</sup>-Œ∑‚àÇ‚Ñí/‚àÇb

Pendant l'entra√Ænement, les √©tapes d'optimisation sont cens√©es √™tre calcul√©es en tenant compte de l'ensemble des donn√©es (rappelez-vous que la perte est calcul√©e comme une somme sur tous les √©chantillons d'entra√Ænement). Cependant, dans la pratique, nous prenons de petites portions de l'ensemble de donn√©es appel√©es **minibatches**, et calculons les gradients sur un sous-ensemble de donn√©es. Comme le sous-ensemble est choisi al√©atoirement √† chaque fois, cette m√©thode est appel√©e **descente de gradient stochastique** (SGD).

## Perceptrons multicouches et r√©tropropagation

Un r√©seau √† une couche, comme nous l'avons vu ci-dessus, est capable de classer des classes lin√©airement s√©parables. Pour construire un mod√®le plus riche, nous pouvons combiner plusieurs couches du r√©seau. Math√©matiquement, cela signifie que la fonction *f* aurait une forme plus complexe et serait calcul√©e en plusieurs √©tapes :
* z<sub>1</sub>=w<sub>1</sub>x+b<sub>1</sub>
* z<sub>2</sub>=w<sub>2</sub>Œ±(z<sub>1</sub>)+b<sub>2</sub>
* f = œÉ(z<sub>2</sub>)

Ici, Œ± est une **fonction d'activation non lin√©aire**, œÉ est une fonction softmax, et les param√®tres Œ∏=<*w<sub>1</sub>,b<sub>1</sub>,w<sub>2</sub>,b<sub>2</sub>*>.

L'algorithme de descente de gradient resterait le m√™me, mais il serait plus difficile de calculer les gradients. En utilisant la r√®gle de diff√©renciation en cha√Æne, nous pouvons calculer les d√©riv√©es comme suit :

* ‚àÇ‚Ñí/‚àÇw<sub>2</sub> = (‚àÇ‚Ñí/‚àÇœÉ)(‚àÇœÉ/‚àÇz<sub>2</sub>)(‚àÇz<sub>2</sub>/‚àÇw<sub>2</sub>)
* ‚àÇ‚Ñí/‚àÇw<sub>1</sub> = (‚àÇ‚Ñí/‚àÇœÉ)(‚àÇœÉ/‚àÇz<sub>2</sub>)(‚àÇz<sub>2</sub>/‚àÇŒ±)(‚àÇŒ±/‚àÇz<sub>1</sub>)(‚àÇz<sub>1</sub>/‚àÇw<sub>1</sub>)

> ‚úÖ La r√®gle de diff√©renciation en cha√Æne est utilis√©e pour calculer les d√©riv√©es de la fonction de perte par rapport aux param√®tres.

Notez que la partie la plus √† gauche de toutes ces expressions est la m√™me, et nous pouvons donc calculer efficacement les d√©riv√©es en commen√ßant par la fonction de perte et en remontant "en arri√®re" √† travers le graphe computationnel. Ainsi, la m√©thode d'entra√Ænement d'un perceptron multicouche est appel√©e **r√©tropropagation**, ou 'backprop'.

<img alt="compute graph" src="images/ComputeGraphGrad.png"/>

> TODO : citation de l'image

> ‚úÖ Nous couvrirons la r√©tropropagation en beaucoup plus de d√©tails dans notre exemple de notebook.  

## Conclusion

Dans cette le√ßon, nous avons construit notre propre biblioth√®que de r√©seaux neuronaux, et nous l'avons utilis√©e pour une t√¢che de classification simple en deux dimensions.

## üöÄ D√©fi

Dans le notebook associ√©, vous allez impl√©menter votre propre cadre pour construire et entra√Æner des perceptrons multicouches. Vous pourrez voir en d√©tail comment fonctionnent les r√©seaux neuronaux modernes.

Passez au notebook [OwnFramework](../../../../../lessons/3-NeuralNetworks/04-OwnFramework/OwnFramework.ipynb) et travaillez dessus.

## [Quiz apr√®s le cours](https://ff-quizzes.netlify.app/en/ai/quiz/8)

## R√©vision et auto-apprentissage

La r√©tropropagation est un algorithme courant utilis√© en IA et en apprentissage automatique, qui m√©rite d'√™tre √©tudi√© [plus en d√©tail](https://wikipedia.org/wiki/Backpropagation).

## [Devoir](lab/README.md)

Dans ce laboratoire, vous √™tes invit√© √† utiliser le cadre que vous avez construit dans cette le√ßon pour r√©soudre la classification des chiffres manuscrits MNIST.

* [Instructions](lab/README.md)
* [Notebook](../../../../../lessons/3-NeuralNetworks/04-OwnFramework/lab/MyFW_MNIST.ipynb)

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, il est recommand√© de recourir √† une traduction humaine professionnelle. Nous d√©clinons toute responsabilit√© en cas de malentendus ou d'interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.