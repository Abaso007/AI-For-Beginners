<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1b8d9e1b3a6f1daa864b1ff3dfc3076d",
  "translation_date": "2025-09-23T11:57:45+00:00",
  "source_file": "lessons/4-ComputerVision/09-Autoencoders/README.md",
  "language_code": "fr"
}
-->
# Autoencodeurs

Lors de l'entra√Ænement des CNN, l'un des probl√®mes est que nous avons besoin de beaucoup de donn√©es annot√©es. Dans le cas de la classification d'images, il faut s√©parer les images en diff√©rentes classes, ce qui demande un effort manuel.

## [Quiz avant le cours](https://ff-quizzes.netlify.app/en/ai/quiz/17)

Cependant, nous pourrions vouloir utiliser des donn√©es brutes (non annot√©es) pour entra√Æner des extracteurs de caract√©ristiques CNN, ce que l'on appelle **l'apprentissage auto-supervis√©**. Au lieu d'utiliser des √©tiquettes, nous utilisons les images d'entra√Ænement comme √† la fois entr√©e et sortie du r√©seau. L'id√©e principale de l'**autoencodeur** est d'avoir un **r√©seau encodeur** qui convertit l'image d'entr√©e en un certain **espace latent** (g√©n√©ralement un vecteur de taille r√©duite), puis un **r√©seau d√©codeur**, dont l'objectif est de reconstruire l'image originale.

> ‚úÖ Un [autoencodeur](https://wikipedia.org/wiki/Autoencoder) est "un type de r√©seau de neurones artificiels utilis√© pour apprendre des codages efficaces de donn√©es non annot√©es."

√âtant donn√© que nous entra√Ænons un autoencodeur pour capturer autant d'informations que possible de l'image originale afin de la reconstruire avec pr√©cision, le r√©seau cherche √† trouver la meilleure **repr√©sentation** des images d'entr√©e pour en saisir le sens.

![Diagramme Autoencodeur](../../../../../translated_images/autoencoder_schema.5e6fc9ad98a5eb6197f3513cf3baf4dfbe1389a6ae74daebda64de9f1c99f142.fr.jpg)

> Image tir√©e du [blog Keras](https://blog.keras.io/building-autoencoders-in-keras.html)

## Sc√©narios d'utilisation des autoencodeurs

Bien que la reconstruction des images originales ne semble pas utile en soi, il existe plusieurs sc√©narios o√π les autoencodeurs sont particuli√®rement utiles :

* **R√©duction de la dimension des images pour la visualisation** ou **entra√Ænement des repr√©sentations d'images**. Les autoencodeurs donnent g√©n√©ralement de meilleurs r√©sultats que la PCA, car ils tiennent compte de la nature spatiale des images et des caract√©ristiques hi√©rarchiques.
* **D√©noiser**, c'est-√†-dire supprimer le bruit d'une image. √âtant donn√© que le bruit contient beaucoup d'informations inutiles, l'autoencodeur ne peut pas tout int√©grer dans un espace latent relativement petit, et capture donc uniquement les parties importantes de l'image. Lors de l'entra√Ænement des d√©bruiteurs, on commence par des images originales et on utilise des images avec du bruit ajout√© artificiellement comme entr√©e pour l'autoencodeur.
* **Super-r√©solution**, augmentation de la r√©solution des images. On commence avec des images haute r√©solution et on utilise l'image de r√©solution inf√©rieure comme entr√©e de l'autoencodeur.
* **Mod√®les g√©n√©ratifs**. Une fois l'autoencodeur entra√Æn√©, la partie d√©codeur peut √™tre utilis√©e pour cr√©er de nouveaux objets √† partir de vecteurs latents al√©atoires.

## Autoencodeurs Variationnels (VAE)

Les autoencodeurs traditionnels r√©duisent la dimension des donn√©es d'entr√©e en identifiant les caract√©ristiques importantes des images d'entr√©e. Cependant, les vecteurs latents n'ont souvent pas beaucoup de sens. En d'autres termes, si l'on prend l'exemple du dataset MNIST, il n'est pas facile de d√©terminer quels chiffres correspondent √† diff√©rents vecteurs latents, car des vecteurs latents proches ne correspondent pas n√©cessairement aux m√™mes chiffres.

En revanche, pour entra√Æner des mod√®les *g√©n√©ratifs*, il est pr√©f√©rable de comprendre l'espace latent. Cette id√©e nous m√®ne aux **autoencodeurs variationnels** (VAE).

Un VAE est un autoencodeur qui apprend √† pr√©dire une *distribution statistique* des param√®tres latents, appel√©e **distribution latente**. Par exemple, nous pouvons vouloir que les vecteurs latents soient distribu√©s normalement avec une moyenne z<sub>mean</sub> et un √©cart-type z<sub>sigma</sub> (la moyenne et l'√©cart-type sont tous deux des vecteurs de dimensionnalit√© d). L'encodeur dans le VAE apprend √† pr√©dire ces param√®tres, puis le d√©codeur prend un vecteur al√©atoire de cette distribution pour reconstruire l'objet.

En r√©sum√© :

 * √Ä partir du vecteur d'entr√©e, nous pr√©disons `z_mean` et `z_log_sigma` (au lieu de pr√©dire directement l'√©cart-type, nous pr√©disons son logarithme)
 * Nous √©chantillonnons un vecteur `sample` √† partir de la distribution N(z<sub>mean</sub>,exp(z<sub>log\_sigma</sub>))
 * Le d√©codeur essaie de d√©coder l'image originale en utilisant `sample` comme vecteur d'entr√©e

 <img src="images/vae.png" width="50%">

> Image tir√©e de [cet article de blog](https://ijdykeman.github.io/ml/2016/12/21/cvae.html) par Isaak Dykeman

Les autoencodeurs variationnels utilisent une fonction de perte complexe compos√©e de deux parties :

* **Perte de reconstruction**, une fonction de perte qui mesure √† quel point l'image reconstruite est proche de la cible (elle peut √™tre l'erreur quadratique moyenne, ou MSE). C'est la m√™me fonction de perte que dans les autoencodeurs classiques.
* **Perte KL**, qui garantit que les distributions des variables latentes restent proches d'une distribution normale. Elle est bas√©e sur la notion de [divergence de Kullback-Leibler](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained) - une m√©trique pour estimer la similarit√© entre deux distributions statistiques.

Un avantage important des VAE est qu'ils permettent de g√©n√©rer de nouvelles images relativement facilement, car nous savons de quelle distribution √©chantillonner les vecteurs latents. Par exemple, si nous entra√Ænons un VAE avec un vecteur latent 2D sur MNIST, nous pouvons ensuite varier les composantes du vecteur latent pour obtenir diff√©rents chiffres :

<img alt="vaemnist" src="images/vaemnist.png" width="50%"/>

> Image par [Dmitry Soshnikov](http://soshnikov.com)

Observez comment les images se fondent les unes dans les autres, √† mesure que nous obtenons des vecteurs latents provenant de diff√©rentes parties de l'espace des param√®tres latents. Nous pouvons √©galement visualiser cet espace en 2D :

<img alt="vaemnist cluster" src="images/vaemnist-diag.png" width="50%"/> 

> Image par [Dmitry Soshnikov](http://soshnikov.com)

## ‚úçÔ∏è Exercices : Autoencodeurs

Apprenez-en davantage sur les autoencodeurs dans ces notebooks correspondants :

* [Autoencodeurs avec TensorFlow](AutoencodersTF.ipynb)
* [Autoencodeurs avec PyTorch](AutoEncodersPyTorch.ipynb)

## Propri√©t√©s des autoencodeurs

* **Sp√©cifiques aux donn√©es** - ils fonctionnent bien uniquement avec le type d'images sur lequel ils ont √©t√© entra√Æn√©s. Par exemple, si nous entra√Ænons un r√©seau de super-r√©solution sur des fleurs, il ne fonctionnera pas bien sur des portraits. Cela s'explique par le fait que le r√©seau peut produire une image de r√©solution sup√©rieure en utilisant des d√©tails fins issus des caract√©ristiques apprises √† partir du dataset d'entra√Ænement.
* **Avec perte** - l'image reconstruite n'est pas identique √† l'image originale. La nature de la perte est d√©finie par la *fonction de perte* utilis√©e lors de l'entra√Ænement.
* Fonctionne sur des donn√©es **non annot√©es**

## [Quiz apr√®s le cours](https://ff-quizzes.netlify.app/en/ai/quiz/18)

## Conclusion

Dans cette le√ßon, vous avez appris les diff√©rents types d'autoencodeurs disponibles pour le scientifique en IA. Vous avez appris √† les construire et √† les utiliser pour reconstruire des images. Vous avez √©galement d√©couvert le VAE et comment l'utiliser pour g√©n√©rer de nouvelles images.

## üöÄ D√©fi

Dans cette le√ßon, vous avez appris √† utiliser les autoencodeurs pour les images. Mais ils peuvent √©galement √™tre utilis√©s pour la musique ! D√©couvrez le projet [MusicVAE](https://magenta.tensorflow.org/music-vae) du projet Magenta, qui utilise des autoencodeurs pour apprendre √† reconstruire de la musique. Faites quelques [exp√©riences](https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/Multitrack_MusicVAE.ipynb) avec cette biblioth√®que pour voir ce que vous pouvez cr√©er.

## [Quiz apr√®s le cours](https://ff-quizzes.netlify.app/en/ai/quiz/16)

## R√©vision & Auto-apprentissage

Pour r√©f√©rence, lisez-en davantage sur les autoencodeurs dans ces ressources :

* [Construire des autoencodeurs avec Keras](https://blog.keras.io/building-autoencoders-in-keras.html)
* [Article de blog sur NeuroHive](https://neurohive.io/ru/osnovy-data-science/variacionnyj-avtojenkoder-vae/)
* [Explication des autoencodeurs variationnels](https://kvfrans.com/variational-autoencoders-explained/)
* [Autoencodeurs variationnels conditionnels](https://ijdykeman.github.io/ml/2016/12/21/cvae.html)

## Devoir

√Ä la fin de [ce notebook avec TensorFlow](AutoencodersTF.ipynb), vous trouverez une "t√¢che" - utilisez-la comme votre devoir.

---

