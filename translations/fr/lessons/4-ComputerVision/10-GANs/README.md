<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f07c85bbf05a1f67505da98f4ecc124c",
  "translation_date": "2025-08-24T20:50:21+00:00",
  "source_file": "lessons/4-ComputerVision/10-GANs/README.md",
  "language_code": "fr"
}
-->
# R√©seaux Adversaires G√©n√©ratifs

Dans la section pr√©c√©dente, nous avons appris sur les **mod√®les g√©n√©ratifs** : des mod√®les capables de g√©n√©rer de nouvelles images similaires √† celles du jeu de donn√©es d'entra√Ænement. Le VAE √©tait un bon exemple de mod√®le g√©n√©ratif.

## [Quiz avant le cours](https://ff-quizzes.netlify.app/en/ai/quiz/19)

Cependant, si nous essayons de g√©n√©rer quelque chose de vraiment significatif, comme une peinture avec une r√©solution raisonnable, avec un VAE, nous constaterons que l'entra√Ænement ne converge pas bien. Pour ce cas d'utilisation, nous devrions nous int√©resser √† une autre architecture sp√©cifiquement con√ßue pour les mod√®les g√©n√©ratifs - les **R√©seaux Adversaires G√©n√©ratifs**, ou GANs.

L'id√©e principale d'un GAN est d'avoir deux r√©seaux neuronaux qui seront entra√Æn√©s l'un contre l'autre :

<img src="images/gan_architecture.png" width="70%"/>

> Image par [Dmitry Soshnikov](http://soshnikov.com)

> ‚úÖ Un peu de vocabulaire :
> * **G√©n√©rateur** : un r√©seau qui prend un vecteur al√©atoire et produit une image en r√©sultat.
> * **Discriminateur** : un r√©seau qui prend une image et doit d√©terminer si elle est une image r√©elle (provenant du jeu de donn√©es d'entra√Ænement) ou si elle a √©t√© g√©n√©r√©e par un g√©n√©rateur. C'est essentiellement un classificateur d'images.

### Discriminateur

L'architecture du discriminateur ne diff√®re pas d'un r√©seau de classification d'images ordinaire. Dans le cas le plus simple, il peut s'agir d'un classificateur enti√®rement connect√©, mais il sera tr√®s probablement un [r√©seau convolutionnel](../07-ConvNets/README.md).

> ‚úÖ Un GAN bas√© sur des r√©seaux convolutionnels est appel√© un [DCGAN](https://arxiv.org/pdf/1511.06434.pdf)

Un discriminateur CNN se compose des couches suivantes : plusieurs convolutions+poolings (avec une taille spatiale d√©croissante) et une ou plusieurs couches enti√®rement connect√©es pour obtenir un "vecteur de caract√©ristiques", suivi d'un classificateur binaire final.

> ‚úÖ Un 'pooling' dans ce contexte est une technique qui r√©duit la taille de l'image. "Les couches de pooling r√©duisent les dimensions des donn√©es en combinant les sorties de clusters de neurones √† une couche en un seul neurone dans la couche suivante." - [source](https://wikipedia.org/wiki/Convolutional_neural_network#Pooling_layers)

### G√©n√©rateur

Un g√©n√©rateur est l√©g√®rement plus complexe. Vous pouvez le consid√©rer comme un discriminateur invers√©. En partant d'un vecteur latent (√† la place d'un vecteur de caract√©ristiques), il poss√®de une couche enti√®rement connect√©e pour le convertir √† la taille/forme requise, suivie de d√©convolutions+agrandissements. Cela ressemble √† la partie *d√©codage* d'un [autoencodeur](../09-Autoencoders/README.md).

> ‚úÖ √âtant donn√© que la couche de convolution est impl√©ment√©e comme un filtre lin√©aire parcourant l'image, la d√©convolution est essentiellement similaire √† la convolution et peut √™tre mise en ≈ìuvre en utilisant la m√™me logique de couche.

<img src="images/gan_arch_detail.png" width="70%"/>

> Image par [Dmitry Soshnikov](http://soshnikov.com)

### Entra√Ænement du GAN

Les GANs sont appel√©s **adversaires** parce qu'il y a une comp√©tition constante entre le g√©n√©rateur et le discriminateur. Pendant cette comp√©tition, le g√©n√©rateur et le discriminateur s'am√©liorent, ce qui permet au r√©seau d'apprendre √† produire des images de plus en plus r√©alistes.

L'entra√Ænement se d√©roule en deux √©tapes :

* **Entra√Ænement du discriminateur**. Cette t√¢che est assez simple : nous g√©n√©rons un lot d'images avec le g√©n√©rateur, en les √©tiquetant 0, ce qui signifie image fausse, et nous prenons un lot d'images du jeu de donn√©es d'entr√©e (avec l'√©tiquette 1, image r√©elle). Nous obtenons une *perte du discriminateur* et effectuons une r√©tropropagation.
* **Entra√Ænement du g√©n√©rateur**. Cela est l√©g√®rement plus complexe, car nous ne connaissons pas directement la sortie attendue pour le g√©n√©rateur. Nous prenons tout le r√©seau GAN compos√© d'un g√©n√©rateur suivi d'un discriminateur, le nourrissons avec des vecteurs al√©atoires et attendons que le r√©sultat soit 1 (correspondant √† des images r√©elles). Nous gelons ensuite les param√®tres du discriminateur (nous ne voulons pas qu'il soit entra√Æn√© √† cette √©tape) et effectuons la r√©tropropagation.

Pendant ce processus, les pertes du g√©n√©rateur et du discriminateur ne diminuent pas significativement. Dans une situation id√©ale, elles devraient osciller, correspondant √† l'am√©lioration des performances des deux r√©seaux.

## ‚úçÔ∏è Exercices : GANs

* [Notebook GAN avec TensorFlow/Keras](../../../../../lessons/4-ComputerVision/10-GANs/GANTF.ipynb)
* [Notebook GAN avec PyTorch](../../../../../lessons/4-ComputerVision/10-GANs/GANPyTorch.ipynb)

### Probl√®mes li√©s √† l'entra√Ænement des GANs

Les GANs sont connus pour √™tre particuli√®rement difficiles √† entra√Æner. Voici quelques probl√®mes :

* **Effondrement de mode**. Ce terme signifie que le g√©n√©rateur apprend √† produire une seule image r√©ussie qui trompe le discriminateur, et non une vari√©t√© d'images diff√©rentes.
* **Sensibilit√© aux hyperparam√®tres**. Il arrive souvent qu'un GAN ne converge pas du tout, puis qu'une diminution soudaine du taux d'apprentissage entra√Æne une convergence.
* Maintenir un **√©quilibre** entre le g√©n√©rateur et le discriminateur. Dans de nombreux cas, la perte du discriminateur peut chuter √† z√©ro relativement rapidement, ce qui emp√™che le g√©n√©rateur de continuer √† s'entra√Æner. Pour surmonter cela, nous pouvons essayer de d√©finir des taux d'apprentissage diff√©rents pour le g√©n√©rateur et le discriminateur, ou de sauter l'entra√Ænement du discriminateur si la perte est d√©j√† trop faible.
* Entra√Ænement pour une **haute r√©solution**. Refl√©tant le m√™me probl√®me que les autoencodeurs, ce probl√®me est d√©clench√© parce que reconstruire trop de couches d'un r√©seau convolutionnel entra√Æne des artefacts. Ce probl√®me est g√©n√©ralement r√©solu par ce qu'on appelle la **croissance progressive**, o√π les premi√®res couches sont entra√Æn√©es sur des images basse r√©solution, puis des couches sont "d√©bloqu√©es" ou ajout√©es. Une autre solution consiste √† ajouter des connexions suppl√©mentaires entre les couches et √† entra√Æner plusieurs r√©solutions √† la fois - voir cet article [Multi-Scale Gradient GANs](https://arxiv.org/abs/1903.06048) pour plus de d√©tails.

## Transfert de style

Les GANs sont un excellent moyen de g√©n√©rer des images artistiques. Une autre technique int√©ressante est le **transfert de style**, qui prend une **image de contenu** et la redessine dans un style diff√©rent, en appliquant des filtres √† partir d'une **image de style**.

Voici comment cela fonctionne :
* Nous commen√ßons avec une image de bruit al√©atoire (ou avec une image de contenu, mais pour mieux comprendre, il est plus simple de commencer avec du bruit al√©atoire).
* Notre objectif est de cr√©er une image qui soit proche √† la fois de l'image de contenu et de l'image de style. Cela sera d√©termin√© par deux fonctions de perte :
   - **Perte de contenu** : calcul√©e √† partir des caract√©ristiques extraites par le CNN √† certains niveaux de l'image actuelle et de l'image de contenu.
   - **Perte de style** : calcul√©e entre l'image actuelle et l'image de style d'une mani√®re astucieuse en utilisant des matrices de Gram (plus de d√©tails dans le [notebook d'exemple](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)).
* Pour rendre l'image plus lisse et √©liminer le bruit, nous introduisons √©galement une **perte de variation**, qui calcule la distance moyenne entre les pixels voisins.
* La boucle principale d'optimisation ajuste l'image actuelle en utilisant la descente de gradient (ou un autre algorithme d'optimisation) pour minimiser la perte totale, qui est une somme pond√©r√©e de toutes les pertes.

## ‚úçÔ∏è Exemple : [Transfert de style](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)

## [Quiz apr√®s le cours](https://ff-quizzes.netlify.app/en/ai/quiz/20)

## Conclusion

Dans cette le√ßon, vous avez appris sur les GANs et comment les entra√Æner. Vous avez √©galement d√©couvert les d√©fis sp√©cifiques auxquels ce type de r√©seau neuronal peut √™tre confront√©, ainsi que des strat√©gies pour les surmonter.

## üöÄ D√©fi

Parcourez le [notebook de transfert de style](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb) en utilisant vos propres images.

## R√©vision et √©tude personnelle

Pour r√©f√©rence, lisez davantage sur les GANs dans ces ressources :

* Marco Pasini, [10 Le√ßons que j'ai apprises en entra√Ænant des GANs pendant un an](https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628)
* [StyleGAN](https://en.wikipedia.org/wiki/StyleGAN), une architecture GAN *de facto* √† consid√©rer
* [Cr√©er de l'art g√©n√©ratif avec des GANs sur Azure ML](https://soshnikov.com/scienceart/creating-generative-art-using-gan-on-azureml/)

## Devoir

Revisitez l'un des deux notebooks associ√©s √† cette le√ßon et r√©entra√Ænez le GAN avec vos propres images. Que pouvez-vous cr√©er ?

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, il est recommand√© de recourir √† une traduction humaine professionnelle. Nous d√©clinons toute responsabilit√© en cas de malentendus ou d'interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.