<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7bd8dc72040e98e35e7225e34058cd4e",
  "translation_date": "2025-08-24T20:54:55+00:00",
  "source_file": "lessons/6-Other/22-DeepRL/lab/README.md",
  "language_code": "fr"
}
-->
## L'Environnement

L'environnement Mountain Car consiste en une voiture piégée dans une vallée. Votre objectif est de sortir de la vallée et d'atteindre le drapeau. Les actions que vous pouvez effectuer sont : accélérer vers la gauche, accélérer vers la droite, ou ne rien faire. Vous pouvez observer la position de la voiture sur l'axe x, ainsi que sa vitesse.

## Cahier de Départ

Commencez le laboratoire en ouvrant [MountainCar.ipynb](../../../../../../lessons/6-Other/22-DeepRL/lab/MountainCar.ipynb)

## Ce qu'il faut Retenir

Vous devriez apprendre au cours de ce laboratoire qu'adapter des algorithmes de RL à un nouvel environnement est souvent assez simple, car OpenAI Gym propose la même interface pour tous les environnements, et les algorithmes ne dépendent pas fortement de la nature de l'environnement. Vous pouvez même restructurer le code Python de manière à passer n'importe quel environnement à l'algorithme de RL en tant que paramètre.

**Avertissement** :  
Ce document a été traduit à l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatisées peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit être considéré comme la source faisant autorité. Pour des informations critiques, il est recommandé de recourir à une traduction professionnelle réalisée par un humain. Nous déclinons toute responsabilité en cas de malentendus ou d'interprétations erronées résultant de l'utilisation de cette traduction.