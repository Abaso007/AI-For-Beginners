{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Класифікація цифр MNIST за допомогою нашого фреймворку\n",
    "\n",
    "Лабораторне завдання з [Курсу \"Штучний інтелект для початківців\"](https://github.com/microsoft/ai-for-beginners).\n",
    "\n",
    "### Зчитування набору даних\n",
    "\n",
    "Цей код завантажує набір даних із репозиторію в інтернеті. Ви також можете вручну скопіювати набір даних із каталогу `/data` репозиторію AI Curriculum.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  9.9M  100  9.9M    0     0   9.9M      0  0:00:01 --:--:--  0:00:01 15.8M\n"
     ]
    }
   ],
   "source": [
    "!rm *.pkl\n",
    "!wget https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/data/mnist.pkl.gz\n",
    "!gzip -d mnist.pkl.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('mnist.pkl','rb') as f:\n",
    "    MNIST = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = MNIST['Train']['Labels']\n",
    "data = MNIST['Train']['Features']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте подивимось, яка форма даних у нас є:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Розподіл даних\n",
    "\n",
    "Ми будемо використовувати Scikit Learn для розподілу даних між навчальним і тестовим наборами даних:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 33600, test samples: 8400\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(data,labels,test_size=0.2)\n",
    "\n",
    "print(f\"Train samples: {len(features_train)}, test samples: {len(features_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Інструкції\n",
    "\n",
    "1. Візьміть код фреймворку з уроку та вставте його в цей ноутбук або (ще краще) в окремий модуль Python.\n",
    "1. Визначте та навчіть одношаровий перцептрон, спостерігаючи за точністю навчання та валідації під час тренування.\n",
    "1. Спробуйте зрозуміти, чи відбулося перенавчання, і налаштуйте параметри шару для покращення точності.\n",
    "1. Повторіть попередні кроки для двошарових і трьошарових перцептронів. Спробуйте експериментувати з різними функціями активації між шарами.\n",
    "1. Спробуйте відповісти на наступні запитання:\n",
    "    - Чи впливає функція активації між шарами на продуктивність мережі?\n",
    "    - Чи потрібна нам двошарова або трьошарова мережа для цього завдання?\n",
    "    - Чи виникли у вас проблеми під час навчання мережі? Особливо коли кількість шарів збільшувалася.\n",
    "    - Як поводяться ваги мережі під час навчання? Ви можете побудувати графік максимального абсолютного значення вагів залежно від епохи, щоб зрозуміти взаємозв’язок.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Відмова від відповідальності**:  \nЦей документ був перекладений за допомогою сервісу автоматичного перекладу [Co-op Translator](https://github.com/Azure/co-op-translator). Хоча ми прагнемо до точності, будь ласка, майте на увазі, що автоматичні переклади можуть містити помилки або неточності. Оригінальний документ на його рідній мові слід вважати авторитетним джерелом. Для критичної інформації рекомендується професійний людський переклад. Ми не несемо відповідальності за будь-які непорозуміння або неправильні тлумачення, що виникають внаслідок використання цього перекладу.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "86193a1ab0ba47eac1c69c1756090baa3b420b3eea7d4aafab8b85f8b312f0c5"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "coopTranslator": {
   "original_hash": "6fa055f484eb5d6bdf41166a356d3abf",
   "translation_date": "2025-08-30T09:48:17+00:00",
   "source_file": "lessons/3-NeuralNetworks/04-OwnFramework/lab/MyFW_MNIST.ipynb",
   "language_code": "uk"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}