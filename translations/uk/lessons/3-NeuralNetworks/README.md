<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1c6b8c7c1778a35fc1139b7f2aecb7b3",
  "translation_date": "2025-08-25T23:43:43+00:00",
  "source_file": "lessons/3-NeuralNetworks/README.md",
  "language_code": "uk"
}
-->
# Вступ до нейронних мереж

![Резюме змісту "Вступ до нейронних мереж" у вигляді малюнка](../../../../translated_images/ai-neuralnetworks.1c687ae40bc86e834f497844866a26d3e0886650a67a4bbe29442e2f157d3b18.uk.png)

Як ми обговорювали у вступі, одним із способів досягнення інтелекту є навчання **комп'ютерної моделі** або **штучного мозку**. З середини 20-го століття дослідники пробували різні математичні моделі, і лише в останні роки цей напрямок став надзвичайно успішним. Такі математичні моделі мозку називаються **нейронними мережами**.

> Іноді нейронні мережі називають *штучними нейронними мережами* (Artificial Neural Networks, ANNs), щоб підкреслити, що йдеться про моделі, а не про реальні мережі нейронів.

## Машинне навчання

Нейронні мережі є частиною більшої дисципліни, яка називається **машинним навчанням**, метою якої є використання даних для навчання комп'ютерних моделей, здатних вирішувати задачі. Машинне навчання становить значну частину штучного інтелекту, однак у цьому курсі ми не розглядаємо класичне машинне навчання.

> Відвідайте наш окремий курс **[Машинне навчання для початківців](http://github.com/microsoft/ml-for-beginners)**, щоб дізнатися більше про класичне машинне навчання.

У машинному навчанні ми припускаємо, що маємо певний набір даних прикладів **X** і відповідні вихідні значення **Y**. Приклади часто є N-вимірними векторами, які складаються з **характеристик**, а вихідні значення називаються **мітками**.

Ми розглянемо дві найпоширеніші задачі машинного навчання:

* **Класифікація**, де потрібно класифікувати вхідний об'єкт у дві або більше категорії.
* **Регресія**, де потрібно передбачити числове значення для кожного з вхідних зразків.

> При представленні входів і виходів у вигляді тензорів, вхідний набір даних є матрицею розміру M×N, де M — кількість зразків, а N — кількість характеристик. Вихідні мітки **Y** — це вектор розміру M.

У цьому курсі ми зосередимося лише на моделях нейронних мереж.

## Модель нейрона

З біології ми знаємо, що наш мозок складається з нейронних клітин, кожна з яких має кілька "входів" (аксони) і один вихід (дендрит). Аксони і дендрити можуть проводити електричні сигнали, а зв’язки між аксонами і дендритами можуть мати різний ступінь провідності (який контролюється нейромедіаторами).

![Модель нейрона](../../../../translated_images/synapse-wikipedia.ed20a9e4726ea1c6a3ce8fec51c0b9bec6181946dca0fe4e829bc12fa3bacf01.uk.jpg) | ![Модель нейрона](../../../../translated_images/artneuron.1a5daa88d20ebe6f5824ddb89fba0bdaaf49f67e8230c1afbec42909df1fc17e.uk.png)
----|----
Реальний нейрон *([Зображення](https://en.wikipedia.org/wiki/Synapse#/media/File:SynapseSchematic_lines.svg) з Wikipedia)* | Штучний нейрон *(Зображення автора)*

Таким чином, найпростіша математична модель нейрона містить кілька входів X<sub>1</sub>, ..., X<sub>N</sub> і один вихід Y, а також набір ваг W<sub>1</sub>, ..., W<sub>N</sub>. Вихід обчислюється як:

<img src="images/netout.png" alt="Y = f\left(\sum_{i=1}^N X_iW_i\right)" width="131" height="53" align="center"/>

де f — це деяка нелінійна **функція активації**.

> Ранні моделі нейрона були описані в класичній статті [A logical calculus of the ideas immanent in nervous activity](https://www.cs.cmu.edu/~./epxing/Class/10715/reading/McCulloch.and.Pitts.pdf) Воррена МакКалока і Волтера Піттса у 1943 році. Дональд Хебб у своїй книзі "[The Organization of Behavior: A Neuropsychological Theory](https://books.google.com/books?id=VNetYrB8EBoC)" запропонував спосіб навчання таких мереж.

## У цьому розділі

У цьому розділі ми дізнаємося про:
* [Перцептрон](03-Perceptron/README.md), одну з найперших моделей нейронних мереж для класифікації на дві категорії
* [Багатошарові мережі](04-OwnFramework/README.md) з відповідним ноутбуком [як створити власний фреймворк](../../../../lessons/3-NeuralNetworks/04-OwnFramework/OwnFramework.ipynb)
* [Фреймворки нейронних мереж](05-Frameworks/README.md), з такими ноутбуками: [PyTorch](../../../../lessons/3-NeuralNetworks/05-Frameworks/IntroPyTorch.ipynb) і [Keras/Tensorflow](../../../../lessons/3-NeuralNetworks/05-Frameworks/IntroKerasTF.ipynb)
* [Перенавчання](../../../../lessons/3-NeuralNetworks/05-Frameworks)

**Відмова від відповідальності**:  
Цей документ було перекладено за допомогою сервісу автоматичного перекладу [Co-op Translator](https://github.com/Azure/co-op-translator). Хоча ми прагнемо до точності, будь ласка, майте на увазі, що автоматичні переклади можуть містити помилки або неточності. Оригінальний документ мовою оригіналу слід вважати авторитетним джерелом. Для критично важливої інформації рекомендується професійний людський переклад. Ми не несемо відповідальності за будь-які непорозуміння або неправильне тлумачення, що виникли внаслідок використання цього перекладу.