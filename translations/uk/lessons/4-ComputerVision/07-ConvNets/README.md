<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a560d5b845962cf33dc102266e409568",
  "translation_date": "2025-09-23T15:28:51+00:00",
  "source_file": "lessons/4-ComputerVision/07-ConvNets/README.md",
  "language_code": "uk"
}
-->
# Конволюційні нейронні мережі

Ми вже бачили, що нейронні мережі досить добре працюють із зображеннями, і навіть одношаровий перцептрон здатний розпізнавати рукописні цифри з набору даних MNIST з прийнятною точністю. Однак набір даних MNIST є дуже специфічним, і всі цифри в ньому центровані всередині зображення, що спрощує задачу.

## [Тест перед лекцією](https://ff-quizzes.netlify.app/en/ai/quiz/13)

У реальному житті ми хочемо мати можливість розпізнавати об'єкти на зображенні незалежно від їх точного розташування. Комп'ютерний зір відрізняється від загальної класифікації, тому що, коли ми намагаємося знайти певний об'єкт на зображенні, ми скануємо його, шукаючи специфічні **шаблони** та їх комбінації. Наприклад, шукаючи кота, ми спочатку можемо шукати горизонтальні лінії, які можуть утворювати вуса, а потім певна комбінація вусів може підказати нам, що це дійсно зображення кота. Важливими є відносне розташування та наявність певних шаблонів, а не їх точне положення на зображенні.

Для вилучення шаблонів ми будемо використовувати поняття **конволюційних фільтрів**. Як вам відомо, зображення представляється у вигляді 2D-матриці або 3D-тензора з глибиною кольору. Застосування фільтра означає, що ми беремо відносно невелику матрицю **ядра фільтра**, і для кожного пікселя в оригінальному зображенні обчислюємо зважене середнє з сусідніми точками. Це можна уявити як невелике вікно, яке ковзає по всьому зображенню, усереднюючи всі пікселі відповідно до ваг у матриці ядра фільтра.

![Фільтр вертикальних країв](../../../../../translated_images/filter-vert.b7148390ca0bc356ddc7e55555d2481819c1e86ddde9dce4db5e71a69d6f887f.uk.png) | ![Фільтр горизонтальних країв](../../../../../translated_images/filter-horiz.59b80ed4feb946efbe201a7fe3ca95abb3364e266e6fd90820cb893b4d3a6dda.uk.png)
----|----

> Зображення Дмитра Сошникова

Наприклад, якщо ми застосуємо 3x3 фільтри вертикальних і горизонтальних країв до цифр MNIST, ми можемо отримати виділення (наприклад, високі значення) там, де є вертикальні та горизонтальні краї в нашому оригінальному зображенні. Таким чином, ці два фільтри можуть бути використані для "пошуку" країв. Аналогічно, ми можемо створювати різні фільтри для пошуку інших низькорівневих шаблонів:

<img src="images/lmfilters.jpg" width="500" align="center"/>

> Зображення [банку фільтрів Leung-Malik](https://www.robots.ox.ac.uk/~vgg/research/texclass/filters.html)

Однак, хоча ми можемо вручну створювати фільтри для вилучення певних шаблонів, ми також можемо спроєктувати мережу таким чином, щоб вона автоматично навчалася шаблонам. Це одна з основних ідей CNN.

## Основні ідеї CNN

Робота CNN базується на таких важливих ідеях:

* Конволюційні фільтри можуть вилучати шаблони
* Ми можемо спроєктувати мережу таким чином, щоб фільтри навчалися автоматично
* Ми можемо використовувати той самий підхід для пошуку шаблонів у високорівневих ознаках, а не лише в оригінальному зображенні. Таким чином, вилучення ознак у CNN працює на ієрархії ознак, починаючи з низькорівневих комбінацій пікселів і до високорівневих комбінацій частин зображення.

![Ієрархічне вилучення ознак](../../../../../translated_images/FeatureExtractionCNN.d9b456cbdae7cb643fde3032b81b2940e3cf8be842e29afac3f482725ba7f95c.uk.png)

> Зображення з [статті Hislop-Lynch](https://www.semanticscholar.org/paper/Computer-vision-based-pedestrian-trajectory-Hislop-Lynch/26e6f74853fc9bbb7487b06dc2cf095d36c9021d), засноване на [їхньому дослідженні](https://dl.acm.org/doi/abs/10.1145/1553374.1553453)

## ✍️ Вправи: Конволюційні нейронні мережі

Продовжимо досліджувати, як працюють конволюційні нейронні мережі, і як ми можемо досягти навчання фільтрів, працюючи з відповідними ноутбуками:

* [Конволюційні нейронні мережі - PyTorch](ConvNetsPyTorch.ipynb)
* [Конволюційні нейронні мережі - TensorFlow](ConvNetsTF.ipynb)

## Пірамідальна архітектура

Більшість CNN, які використовуються для обробки зображень, слідують так званій пірамідальній архітектурі. Перший конволюційний шар, застосований до оригінальних зображень, зазвичай має відносно невелику кількість фільтрів (8-16), які відповідають різним комбінаціям пікселів, таким як горизонтальні/вертикальні лінії або штрихи. На наступному рівні ми зменшуємо просторовий розмір мережі та збільшуємо кількість фільтрів, що відповідає більшій кількості можливих комбінацій простих ознак. З кожним шаром, наближаючись до фінального класифікатора, просторові розміри зображення зменшуються, а кількість фільтрів зростає.

Наприклад, давайте розглянемо архітектуру VGG-16, мережі, яка досягла 92.7% точності в топ-5 класифікації ImageNet у 2014 році:

![Шари ImageNet](../../../../../translated_images/vgg-16-arch1.d901a5583b3a51baeaab3e768567d921e5d54befa46e1e642616c5458c934028.uk.jpg)

![Піраміда ImageNet](../../../../../translated_images/vgg-16-arch.64ff2137f50dd49fdaa786e3f3a975b3f22615efd13efb19c5d22f12e01451a1.uk.jpg)

> Зображення з [Researchgate](https://www.researchgate.net/figure/Vgg16-model-structure-To-get-the-VGG-NIN-model-we-replace-the-2-nd-4-th-6-th-7-th_fig2_335194493)

## Найвідоміші архітектури CNN

[Продовжуйте вивчення найвідоміших архітектур CNN](CNN_Architectures.md)

---

