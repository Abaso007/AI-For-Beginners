<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ae074cd940fc2f4dc24fc07b66ccbd99",
  "translation_date": "2025-08-25T23:15:13+00:00",
  "source_file": "lessons/4-ComputerVision/08-TransferLearning/TrainingTricks.md",
  "language_code": "uk"
}
-->
# Трюки для тренування глибокого навчання

Коли нейронні мережі стають глибшими, процес їхнього тренування стає дедалі складнішим. Однією з основних проблем є так звані [зникаючі градієнти](https://en.wikipedia.org/wiki/Vanishing_gradient_problem) або [вибухаючі градієнти](https://deepai.org/machine-learning-glossary-and-terms/exploding-gradient-problem#:~:text=Exploding%20gradients%20are%20a%20problem,updates%20are%20small%20and%20controlled.). [Ця стаття](https://towardsdatascience.com/the-vanishing-exploding-gradient-problem-in-deep-neural-networks-191358470c11) дає гарне введення в ці проблеми.

Щоб зробити тренування глибоких мереж більш ефективним, можна використовувати кілька технік.

## Збереження значень у розумному інтервалі

Для забезпечення стабільності чисельних обчислень важливо, щоб усі значення в нейронній мережі знаходилися в розумному масштабі, зазвичай [-1..1] або [0..1]. Це не дуже сувора вимога, але природа обчислень з плаваючою точкою така, що значення різних порядків величини не можуть бути точно оброблені разом. Наприклад, якщо ми додаємо 10<sup>-10</sup> і 10<sup>10</sup>, то, ймовірно, отримаємо 10<sup>10</sup>, оскільки менше значення буде "перетворене" до того ж порядку, що й більше, і мантиса буде втрачена.

Більшість функцій активації мають нелінійності в межах [-1..1], тому має сенс масштабувати всі вхідні дані до інтервалу [-1..1] або [0..1].

## Ініціалізація початкових ваг

Ідеально, щоб значення залишалися в тому ж діапазоні після проходження через шари мережі. Тому важливо ініціалізувати ваги таким чином, щоб зберегти розподіл значень.

Нормальний розподіл **N(0,1)** не є гарною ідеєю, оскільки якщо у нас є *n* входів, стандартне відхилення виходу буде *n*, і значення, ймовірно, вийдуть за межі інтервалу [0..1].

Часто використовуються такі ініціалізації:

- Рівномірний розподіл — `uniform`
- **N(0,1/n)** — `gaussian`
- **N(0,1/√n_in)** гарантує, що для входів із середнім значенням 0 і стандартним відхиленням 1 залишаться ті ж середнє значення і стандартне відхилення
- **N(0,√2/(n_in+n_out))** — так звана **ініціалізація Ксав'єра** (`glorot`), яка допомагає зберігати сигнали в діапазоні як під час прямого, так і зворотного поширення

## Нормалізація батчів

Навіть при правильній ініціалізації ваги можуть стати надто великими або малими під час тренування, що виведе сигнали за межі правильного діапазону. Ми можемо повернути сигнали назад, використовуючи одну з технік **нормалізації**. Хоча існує кілька таких технік (нормалізація ваг, нормалізація шарів), найчастіше використовується нормалізація батчів.

Ідея **нормалізації батчів** полягає в тому, щоб враховувати всі значення в межах мінібатчу і виконувати нормалізацію (тобто віднімати середнє значення і ділити на стандартне відхилення) на основі цих значень. Це реалізується як шар мережі, який виконує нормалізацію після застосування ваг, але перед функцією активації. У результаті ми, ймовірно, побачимо вищу кінцеву точність і швидше тренування.

Ось [оригінальна стаття](https://arxiv.org/pdf/1502.03167.pdf) про нормалізацію батчів, [пояснення у Вікіпедії](https://en.wikipedia.org/wiki/Batch_normalization) і [гарний вступний блог](https://towardsdatascience.com/batch-normalization-in-3-levels-of-understanding-14c2da90a338) (а також [стаття російською](https://habrahabr.ru/post/309302/)).

## Dropout

**Dropout** — це цікава техніка, яка видаляє певний відсоток випадкових нейронів під час тренування. Вона також реалізується як шар із одним параметром (відсоток нейронів для видалення, зазвичай 10%-50%), і під час тренування вона обнуляє випадкові елементи вхідного вектора перед передачею його до наступного шару.

Хоча це може здатися дивною ідеєю, ви можете побачити ефект dropout на тренуванні класифікатора цифр MNIST у ноутбуці [`Dropout.ipynb`](../../../../../lessons/4-ComputerVision/08-TransferLearning/Dropout.ipynb). Це прискорює тренування і дозволяє досягти вищої точності за меншу кількість епох.

Цей ефект можна пояснити кількома способами:

- Це можна вважати випадковим шоковим фактором для моделі, який виводить оптимізацію з локального мінімуму
- Це можна вважати *неявним усередненням моделі*, оскільки під час dropout ми тренуємо трохи іншу модель

> *Дехто каже, що коли п'яна людина намагається щось вивчити, вона запам'ятає це краще наступного ранку порівняно з тверезою людиною, оскільки мозок із деякими нефункціонуючими нейронами намагається краще адаптуватися, щоб зрозуміти сенс. Ми ніколи не перевіряли, чи це правда.*

## Запобігання перенавчанню

Одним із дуже важливих аспектів глибокого навчання є здатність запобігати [перенавчанню](../../3-NeuralNetworks/05-Frameworks/Overfitting.md). Хоча може бути спокусливо використовувати дуже потужну модель нейронної мережі, ми завжди повинні балансувати кількість параметрів моделі з кількістю навчальних зразків.

> Переконайтеся, що ви розумієте концепцію [перенавчання](../../3-NeuralNetworks/05-Frameworks/Overfitting.md), яку ми раніше пояснювали!

Існує кілька способів запобігти перенавчанню:

- Раннє зупинення — постійний моніторинг помилки на валідаційному наборі і зупинка тренування, коли помилка валідації починає зростати.
- Явний розпад ваг / регуляризація — додавання додаткового штрафу до функції втрат за високі абсолютні значення ваг, що запобігає отриманню дуже нестабільних результатів.
- Усереднення моделі — тренування кількох моделей і потім усереднення результату. Це допомагає мінімізувати варіацію.
- Dropout (неявне усереднення моделі)

## Оптимізатори / алгоритми тренування

Ще одним важливим аспектом тренування є вибір гарного алгоритму тренування. Хоча класичний **градієнтний спуск** є розумним вибором, він іноді може бути надто повільним або призводити до інших проблем.

У глибокому навчанні ми використовуємо **стохастичний градієнтний спуск** (SGD), який є градієнтним спуском, застосованим до мінібатчів, випадково вибраних із навчального набору. Ваги коригуються за цією формулою:

w<sup>t+1</sup> = w<sup>t</sup> - η∇ℒ

### Momentum

У **momentum SGD** ми зберігаємо частину градієнта з попередніх кроків. Це схоже на те, коли ми рухаємося з інерцією, і отримуємо поштовх у іншому напрямку — наша траєкторія не змінюється миттєво, а зберігає частину початкового руху. Тут ми вводимо ще один вектор v для представлення *швидкості*:

- v<sup>t+1</sup> = γ v<sup>t</sup> - η∇ℒ
- w<sup>t+1</sup> = w<sup>t</sup>+v<sup>t+1</sup>

Тут параметр γ вказує, наскільки ми враховуємо інерцію: γ=0 відповідає класичному SGD; γ=1 — це чисте рівняння руху.

### Adam, Adagrad тощо

Оскільки в кожному шарі ми множимо сигнали на деяку матрицю W<sub>i</sub>, залежно від ||W<sub>i</sub>|| градієнт може або зменшуватися і бути близьким до 0, або зростати безмежно. Це і є суть проблеми вибухаючих/зникаючих градієнтів.

Одним із рішень цієї проблеми є використання лише напрямку градієнта в рівнянні, ігноруючи абсолютне значення, тобто:

w<sup>t+1</sup> = w<sup>t</sup> - η(∇ℒ/||∇ℒ||), де ||∇ℒ|| = √∑(∇ℒ)<sup>2</sup>

Цей алгоритм називається **Adagrad**. Інші алгоритми, які використовують ту ж ідею: **RMSProp**, **Adam**

> **Adam** вважається дуже ефективним алгоритмом для багатьох застосувань, тому якщо ви не впевнені, який вибрати — використовуйте Adam.

### Gradient clipping

Gradient clipping — це розширення ідеї вище. Коли ||∇ℒ|| ≤ θ, ми враховуємо оригінальний градієнт у оптимізації ваг, а коли ||∇ℒ|| > θ — ми ділимо градієнт на його норму. Тут θ — це параметр, у більшості випадків можна взяти θ=1 або θ=10.

### Зменшення швидкості навчання

Успіх тренування часто залежить від параметра швидкості навчання η. Логічно припустити, що більші значення η призводять до швидшого тренування, що зазвичай бажано на початку тренування, а менші значення η дозволяють тонко налаштувати мережу. Тому в більшості випадків ми хочемо зменшувати η у процесі тренування.

Це можна зробити шляхом множення η на деяке число (наприклад, 0.98) після кожної епохи тренування або використовуючи більш складний **графік швидкості навчання**.

## Різні архітектури мереж

Вибір правильної архітектури мережі для вашої задачі може бути складним. Зазвичай ми беремо архітектуру, яка довела свою ефективність для нашої конкретної задачі (або схожої). Ось [гарний огляд](https://www.topbots.com/a-brief-history-of-neural-network-architectures/) архітектур нейронних мереж для комп'ютерного зору.

> Важливо вибрати архітектуру, яка буде достатньо потужною для кількості навчальних зразків, які ми маємо. Вибір надто потужної моделі може призвести до [перенавчання](../../3-NeuralNetworks/05-Frameworks/Overfitting.md).

Ще одним гарним варіантом буде використання архітектури, яка автоматично адаптується до необхідної складності. До певної міри архітектури **ResNet** і **Inception** є самоналаштовуваними. [Детальніше про архітектури для комп'ютерного зору](../07-ConvNets/CNN_Architectures.md).

**Відмова від відповідальності**:  
Цей документ було перекладено за допомогою сервісу автоматичного перекладу [Co-op Translator](https://github.com/Azure/co-op-translator). Хоча ми прагнемо до точності, звертаємо вашу увагу, що автоматичні переклади можуть містити помилки або неточності. Оригінальний документ на його рідній мові слід вважати авторитетним джерелом. Для критично важливої інформації рекомендується професійний людський переклад. Ми не несемо відповідальності за будь-які непорозуміння або неправильні тлумачення, що виникли внаслідок використання цього перекладу.