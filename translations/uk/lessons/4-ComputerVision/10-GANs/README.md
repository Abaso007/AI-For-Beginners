<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f07c85bbf05a1f67505da98f4ecc124c",
  "translation_date": "2025-08-25T22:42:02+00:00",
  "source_file": "lessons/4-ComputerVision/10-GANs/README.md",
  "language_code": "uk"
}
-->
# Генеративно-змагальні мережі

У попередньому розділі ми дізналися про **генеративні моделі**: моделі, які можуть створювати нові зображення, схожі на ті, що є в навчальному наборі даних. VAE був гарним прикладом генеративної моделі.

## [Тест перед лекцією](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/110)

Однак, якщо ми спробуємо створити щось дійсно значуще, наприклад, картину з розумною роздільною здатністю, використовуючи VAE, ми побачимо, що навчання не сходиться добре. Для цього випадку використання нам слід дізнатися про іншу архітектуру, спеціально орієнтовану на генеративні моделі - **Генеративно-змагальні мережі**, або GAN.

Основна ідея GAN полягає в тому, щоб мати дві нейронні мережі, які будуть навчатися одна проти одної:

<img src="images/gan_architecture.png" width="70%"/>

> Зображення від [Dmitry Soshnikov](http://soshnikov.com)

> ✅ Невеликий словник:
> * **Генератор** — це мережа, яка бере випадковий вектор і створює зображення як результат.
> * **Дискримінатор** — це мережа, яка бере зображення і повинна визначити, чи є воно реальним (з навчального набору даних), чи було створене генератором. Це, по суті, класифікатор зображень.

### Дискримінатор

Архітектура дискримінатора не відрізняється від звичайної мережі класифікації зображень. У найпростішому випадку це може бути повністю зв’язаний класифікатор, але найімовірніше це буде [згорткова мережа](../07-ConvNets/README.md).

> ✅ GAN, заснований на згорткових мережах, називається [DCGAN](https://arxiv.org/pdf/1511.06434.pdf)

Дискримінатор CNN складається з таких шарів: кілька згорток+пулінгів (з зменшенням просторового розміру) і одного або кількох повністю зв’язаних шарів для отримання "вектору ознак", фінального бінарного класифікатора.

> ✅ "Пулінг" у цьому контексті — це техніка, яка зменшує розмір зображення. "Шари пулінгу зменшують розміри даних, об’єднуючи виходи кластерів нейронів на одному шарі в один нейрон на наступному шарі." - [джерело](https://wikipedia.org/wiki/Convolutional_neural_network#Pooling_layers)

### Генератор

Генератор трохи складніший. Його можна вважати перевернутим дискримінатором. Починаючи з латентного вектора (замість вектора ознак), він має повністю зв’язаний шар для перетворення його у потрібний розмір/форму, а потім деконволюції+масштабування. Це схоже на *декодер* частини [автокодувальника](../09-Autoencoders/README.md).

> ✅ Оскільки згортковий шар реалізується як лінійний фільтр, що проходить через зображення, деконволюція по суті схожа на згортку і може бути реалізована за допомогою тієї ж логіки шару.

<img src="images/gan_arch_detail.png" width="70%"/>

> Зображення від [Dmitry Soshnikov](http://soshnikov.com)

### Навчання GAN

GAN називаються **змагальними**, тому що між генератором і дискримінатором постійно триває конкуренція. Під час цієї конкуренції і генератор, і дискримінатор покращуються, таким чином мережа навчається створювати все кращі й кращі зображення.

Навчання відбувається у два етапи:

* **Навчання дискримінатора**. Це завдання досить просте: ми генеруємо пакет зображень за допомогою генератора, позначаючи їх як 0, що означає фальшиве зображення, і беремо пакет зображень із вхідного набору даних (з міткою 1, реальне зображення). Ми отримуємо *втрати дискримінатора* і виконуємо зворотне поширення.
* **Навчання генератора**. Це трохи складніше, тому що ми не знаємо очікуваного виходу для генератора безпосередньо. Ми беремо всю мережу GAN, що складається з генератора, за яким слідує дискримінатор, подаємо їй випадкові вектори і очікуємо, що результат буде 1 (відповідно до реальних зображень). Потім ми заморожуємо параметри дискримінатора (ми не хочемо, щоб він навчався на цьому етапі) і виконуємо зворотне поширення.

Під час цього процесу втрати як генератора, так і дискримінатора не зменшуються значно. У ідеальній ситуації вони повинні коливатися, що відповідає покращенню продуктивності обох мереж.

## ✍️ Вправи: GAN

* [Ноутбук GAN у TensorFlow/Keras](../../../../../lessons/4-ComputerVision/10-GANs/GANTF.ipynb)
* [Ноутбук GAN у PyTorch](../../../../../lessons/4-ComputerVision/10-GANs/GANPyTorch.ipynb)

### Проблеми з навчанням GAN

GAN відомі тим, що їх особливо складно навчати. Ось кілька проблем:

* **Колапс моди**. Цей термін означає, що генератор навчається створювати одне успішне зображення, яке обманює дискримінатор, а не різноманітність різних зображень.
* **Чутливість до гіперпараметрів**. Часто можна побачити, що GAN взагалі не сходиться, а потім раптово зменшення швидкості навчання призводить до сходження.
* Збереження **балансу** між генератором і дискримінатором. У багатьох випадках втрати дискримінатора можуть швидко впасти до нуля, що призводить до того, що генератор більше не може навчатися. Щоб подолати це, ми можемо спробувати встановити різні швидкості навчання для генератора і дискримінатора або пропустити навчання дискримінатора, якщо втрати вже занадто низькі.
* Навчання для **високої роздільної здатності**. Відображаючи ту саму проблему, що й з автокодувальниками, ця проблема виникає через те, що реконструкція занадто багатьох шарів згорткової мережі призводить до артефактів. Цю проблему зазвичай вирішують за допомогою так званого **прогресивного зростання**, коли спочатку кілька шарів навчаються на зображеннях низької роздільної здатності, а потім шари "розблоковуються" або додаються. Інше рішення — додати додаткові з’єднання між шарами та навчати кілька роздільних здатностей одночасно — див. цю [Multi-Scale Gradient GANs paper](https://arxiv.org/abs/1903.06048) для деталей.

## Перенесення стилю

GAN — чудовий спосіб створювати художні зображення. Ще одна цікава техніка — так зване **перенесення стилю**, яке бере одне **зображення контенту** і перемальовує його в іншому стилі, застосовуючи фільтри із **зображення стилю**.

Як це працює:
* Ми починаємо з випадкового шумового зображення (або із зображення контенту, але для розуміння легше почати з випадкового шуму).
* Нашою метою буде створити таке зображення, яке буде близьким як до зображення контенту, так і до зображення стилю. Це визначатиметься двома функціями втрат:
   - **Втрати контенту** обчислюються на основі ознак, отриманих CNN на деяких шарах із поточного зображення та зображення контенту.
   - **Втрати стилю** обчислюються між поточним зображенням і зображенням стилю хитрим способом за допомогою матриць Грама (детальніше в [прикладі ноутбука](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)).
* Щоб зробити зображення більш гладким і прибрати шум, ми також вводимо **Втрати варіації**, які обчислюють середню відстань між сусідніми пікселями.
* Основний цикл оптимізації коригує поточне зображення за допомогою градієнтного спуску (або іншого алгоритму оптимізації), щоб мінімізувати загальні втрати, які є зваженою сумою всіх трьох втрат.

## ✍️ Приклад: [Перенесення стилю](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)

## [Тест після лекції](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/210)

## Висновок

У цьому уроці ви дізналися про GAN і як їх навчати. Ви також дізналися про особливі виклики, з якими може зіткнутися цей тип нейронної мережі, і деякі стратегії, як їх подолати.

## 🚀 Виклик

Пройдіть через [ноутбук перенесення стилю](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb), використовуючи власні зображення.

## Огляд і самостійне навчання

Для довідки прочитайте більше про GAN у цих ресурсах:

* Marco Pasini, [10 Lessons I Learned Training GANs for one Year](https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628)
* [StyleGAN](https://en.wikipedia.org/wiki/StyleGAN), *де-факто* архітектура GAN, яку варто розглянути.
* [Creating Generative Art using GANs on Azure ML](https://soshnikov.com/scienceart/creating-generative-art-using-gan-on-azureml/)

## Завдання

Перегляньте один із двох ноутбуків, пов’язаних із цим уроком, і перенавчіть GAN на власних зображеннях. Що ви можете створити?

**Відмова від відповідальності**:  
Цей документ був перекладений за допомогою сервісу автоматичного перекладу [Co-op Translator](https://github.com/Azure/co-op-translator). Хоча ми прагнемо до точності, звертаємо вашу увагу, що автоматичні переклади можуть містити помилки або неточності. Оригінальний документ на його рідній мові слід вважати авторитетним джерелом. Для критично важливої інформації рекомендується професійний переклад людиною. Ми не несемо відповідальності за будь-які непорозуміння або неправильне тлумачення, що виникли внаслідок використання цього перекладу.