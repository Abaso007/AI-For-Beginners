<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "717775c4050ccbffbe0c961ad8bf7bf7",
  "translation_date": "2025-08-24T20:35:04+00:00",
  "source_file": "lessons/4-ComputerVision/08-TransferLearning/README.md",
  "language_code": "zh"
}
-->
# 预训练网络与迁移学习

训练 CNN 需要耗费大量时间，并且需要大量数据。然而，大部分时间都花在学习网络可以用来从图像中提取模式的最佳低级滤波器上。一个自然的问题是：我们能否使用在一个数据集上训练好的神经网络，并将其适配到不同的图像分类任务，而无需完整的训练过程？

## [课前测验](https://ff-quizzes.netlify.app/en/ai/quiz/15)

这种方法被称为**迁移学习**，因为我们将一个神经网络模型中的部分知识转移到另一个模型中。在迁移学习中，我们通常从一个预训练模型开始，该模型已经在某个大型图像数据集（如 **ImageNet**）上进行了训练。这些模型已经能够很好地从通用图像中提取不同的特征，在许多情况下，仅仅在这些提取的特征上构建一个分类器就能取得不错的效果。

> ✅ 迁移学习是一个在其他学术领域（如教育学）中也会遇到的术语，它指的是将一个领域的知识应用到另一个领域的过程。

## 预训练模型作为特征提取器

我们在上一节中讨论的卷积网络包含多个层，每一层都旨在从图像中提取某些特征，从低级像素组合（如水平/垂直线条或笔画）到更高级的特征组合（如火焰的眼睛）。如果我们在足够大的通用和多样化的图像数据集上训练 CNN，网络应该能够学会提取这些常见特征。

Keras 和 PyTorch 都包含了方便加载一些常见架构的预训练神经网络权重的函数，这些模型大多是在 ImageNet 图像上训练的。最常用的模型在上一课的 [CNN 架构](../07-ConvNets/CNN_Architectures.md) 页面中有描述。特别是，你可能会考虑使用以下模型之一：

* **VGG-16/VGG-19**：这些是相对简单的模型，但仍然能提供不错的准确率。通常，使用 VGG 作为第一次尝试是一个不错的选择，可以看看迁移学习的效果如何。
* **ResNet**：这是微软研究院在 2015 年提出的一系列模型。它们有更多的层，因此需要更多的资源。
* **MobileNet**：这是适用于移动设备的一系列小型模型。如果资源有限并且可以牺牲一些准确率，可以使用它们。

以下是 VGG-16 网络从一张猫的图片中提取的示例特征：

![VGG-16 提取的特征](../../../../../translated_images/features.6291f9c7ba3a0b951af88fc9864632b9115365410765680680d30c927dd67354.zh.png)

## 猫与狗数据集

在这个例子中，我们将使用一个[猫与狗](https://www.microsoft.com/download/details.aspx?id=54765&WT.mc_id=academic-77998-cacaste)数据集，这非常接近真实的图像分类场景。

## ✍️ 练习：迁移学习

让我们在相应的笔记本中看看迁移学习的实际应用：

* [迁移学习 - PyTorch](../../../../../lessons/4-ComputerVision/08-TransferLearning/TransferLearningPyTorch.ipynb)
* [迁移学习 - TensorFlow](../../../../../lessons/4-ComputerVision/08-TransferLearning/TransferLearningTF.ipynb)

## 可视化对抗性猫

预训练的神经网络在其“脑海”中包含了不同的模式，包括**理想的猫**（以及理想的狗、理想的斑马等）。我们可以尝试**可视化这些图像**，但这并不简单，因为这些模式分布在网络权重的各个部分，并且以层次结构组织。

一种方法是从一张随机图像开始，然后尝试使用**梯度下降优化**技术调整这张图像，使得网络认为它是一只猫。

![图像优化循环](../../../../../translated_images/ideal-cat-loop.999fbb8ff306e044f997032f4eef9152b453e6a990e449bbfb107de2493cc37e.zh.png)

然而，如果我们这样做，得到的结果会非常接近随机噪声。这是因为*有很多方法可以让网络认为输入图像是一只猫*，其中一些方法在视觉上并不合理。虽然这些图像包含了许多典型的猫的模式，但没有任何约束使它们在视觉上具有辨识度。

为了改善结果，我们可以在损失函数中添加另一个项，称为**变化损失**。它是一种度量，用于显示图像中相邻像素的相似程度。最小化变化损失可以使图像更平滑，去除噪声，从而显现出更具视觉吸引力的模式。以下是一些“理想”图像的示例，它们被高概率分类为猫和斑马：

![理想的猫](../../../../../translated_images/ideal-cat.203dd4597643d6b0bd73038b87f9c0464322725e3a06ab145d25d4a861c70592.zh.png) | ![理想的斑马](../../../../../translated_images/ideal-zebra.7f70e8b54ee15a7a314000bb5df38a6cfe086ea04d60df4d3ef313d046b98a2b.zh.png)
-----|-----
*理想的猫* | *理想的斑马*

类似的方法可以用来对神经网络进行所谓的**对抗性攻击**。假设我们想欺骗一个神经网络，让一只狗看起来像一只猫。如果我们拿一张被网络识别为狗的狗的图片，然后稍微调整它，直到网络开始将其分类为猫：

![狗的图片](../../../../../translated_images/original-dog.8f68a67d2fe0911f33041c0f7fce8aa4ea919f9d3917ec4b468298522aeb6356.zh.png) | ![被分类为猫的狗的图片](../../../../../translated_images/adversarial-dog.d9fc7773b0142b89752539bfbf884118de845b3851c5162146ea0b8809fc820f.zh.png)
-----|-----
*原始狗的图片* | *被分类为猫的狗的图片*

查看以下笔记本中的代码以重现上述结果：

* [理想与对抗性猫 - TensorFlow](../../../../../lessons/4-ComputerVision/08-TransferLearning/AdversarialCat_TF.ipynb)

## 总结

通过迁移学习，你可以快速构建一个用于自定义对象分类任务的分类器，并获得较高的准确率。你可以看到，我们现在解决的更复杂的任务需要更高的计算能力，无法轻松地在 CPU 上完成。在下一单元中，我们将尝试使用更轻量级的实现来训练相同的模型，使用更少的计算资源，尽管准确率会略有下降。

## 🚀 挑战

在配套的笔记本中，底部有关于迁移知识在某些相似训练数据（例如一种新类型的动物）上效果最佳的注释。尝试使用完全新类型的图像进行实验，看看你的迁移知识模型表现得有多好或多差。

## [课后测验](https://ff-quizzes.netlify.app/en/ai/quiz/16)

## 复习与自学

阅读 [TrainingTricks.md](TrainingTricks.md)，加深对其他模型训练方法的理解。

## [作业](lab/README.md)

在本实验中，我们将使用真实的 [Oxford-IIIT](https://www.robots.ox.ac.uk/~vgg/data/pets/) 宠物数据集，其中包含 35 种猫和狗的品种，并构建一个迁移学习分类器。

**免责声明**：  
本文档使用AI翻译服务 [Co-op Translator](https://github.com/Azure/co-op-translator) 进行翻译。尽管我们努力确保翻译的准确性，但请注意，自动翻译可能包含错误或不准确之处。应以原文档的原始语言版本为权威来源。对于关键信息，建议使用专业人工翻译。因使用本翻译而导致的任何误解或误读，我们概不负责。