<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7bd8dc72040e98e35e7225e34058cd4e",
  "translation_date": "2025-08-24T20:37:15+00:00",
  "source_file": "lessons/6-Other/22-DeepRL/lab/README.md",
  "language_code": "zh"
}
-->
## 环境

Mountain Car 环境中，汽车被困在一个山谷中。你的目标是跳出山谷并到达旗帜处。你可以执行的动作包括向左加速、向右加速或保持不动。你可以观察汽车在 x 轴上的位置以及速度。

## 起始笔记本

通过打开 [MountainCar.ipynb](../../../../../../lessons/6-Other/22-DeepRL/lab/MountainCar.ipynb) 开始实验。

## 收获

在整个实验过程中，你应该学到将 RL 算法应用到一个新环境通常是非常直接的，因为 OpenAI Gym 对所有环境都提供了统一的接口，而算法本身并不太依赖于环境的具体性质。你甚至可以重新组织 Python 代码，以便将任何环境作为参数传递给 RL 算法。

**免责声明**：  
本文档使用AI翻译服务 [Co-op Translator](https://github.com/Azure/co-op-translator) 进行翻译。尽管我们努力确保翻译的准确性，但请注意，自动翻译可能包含错误或不准确之处。应以原始语言的文档作为权威来源。对于关键信息，建议使用专业人工翻译。因使用本翻译而引起的任何误解或误读，我们概不负责。