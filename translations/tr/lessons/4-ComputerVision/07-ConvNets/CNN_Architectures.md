<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "2f7b97b375358cb51a1e098df306bf73",
  "translation_date": "2025-08-26T07:28:38+00:00",
  "source_file": "lessons/4-ComputerVision/07-ConvNets/CNN_Architectures.md",
  "language_code": "tr"
}
-->
# Bilinen CNN Mimarileri

### VGG-16

VGG-16, 2014 yÄ±lÄ±nda ImageNet top-5 sÄ±nÄ±flandÄ±rmasÄ±nda %92.7 doÄŸruluk oranÄ±na ulaÅŸan bir aÄŸdÄ±r. AÅŸaÄŸÄ±daki katman yapÄ±sÄ±na sahiptir:

![ImageNet KatmanlarÄ±](../../../../../translated_images/vgg-16-arch1.d901a5583b3a51baeaab3e768567d921e5d54befa46e1e642616c5458c934028.tr.jpg)

GÃ¶rdÃ¼ÄŸÃ¼nÃ¼z gibi, VGG geleneksel bir piramit mimarisini takip eder; bu, bir dizi evriÅŸim-havuzlama katmanÄ±dÄ±r.

![ImageNet Piramidi](../../../../../translated_images/vgg-16-arch.64ff2137f50dd49fdaa786e3f3a975b3f22615efd13efb19c5d22f12e01451a1.tr.jpg)

> GÃ¶rsel [Researchgate](https://www.researchgate.net/figure/Vgg16-model-structure-To-get-the-VGG-NIN-model-we-replace-the-2-nd-4-th-6-th-7-th_fig2_335194493) kaynaÄŸÄ±ndan alÄ±nmÄ±ÅŸtÄ±r.

### ResNet

ResNet, 2015 yÄ±lÄ±nda Microsoft Research tarafÄ±ndan Ã¶nerilen bir model ailesidir. ResNet'in ana fikri, **artÄ±k bloklarÄ±** kullanmaktÄ±r:

<img src="images/resnet-block.png" width="300"/>

> GÃ¶rsel [bu makaleden](https://arxiv.org/pdf/1512.03385.pdf) alÄ±nmÄ±ÅŸtÄ±r.

Kimlik geÃ§iÅŸini kullanmanÄ±n nedeni, katmanÄ±mÄ±zÄ±n bir Ã¶nceki katmanÄ±n sonucu ile artÄ±k bloÄŸun Ã§Ä±ktÄ±sÄ± arasÄ±ndaki **farkÄ±** tahmin etmesini saÄŸlamaktÄ±r - bu nedenle adÄ±na *artÄ±k* denir. Bu bloklar eÄŸitilmesi Ã§ok daha kolaydÄ±r ve bu bloklardan yÃ¼zlercesiyle aÄŸlar oluÅŸturulabilir (en yaygÄ±n varyantlar ResNet-52, ResNet-101 ve ResNet-152'dir).

Bu aÄŸÄ±, veri setine gÃ¶re karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± ayarlayabilen bir yapÄ± olarak da dÃ¼ÅŸÃ¼nebilirsiniz. BaÅŸlangÄ±Ã§ta, aÄŸÄ± eÄŸitmeye baÅŸladÄ±ÄŸÄ±nÄ±zda, aÄŸÄ±rlÄ±k deÄŸerleri kÃ¼Ã§Ã¼ktÃ¼r ve sinyalin Ã§oÄŸu kimlik geÃ§iÅŸ katmanlarÄ±ndan geÃ§er. EÄŸitim ilerledikÃ§e ve aÄŸÄ±rlÄ±klar bÃ¼yÃ¼dÃ¼kÃ§e, aÄŸ parametrelerinin Ã¶nemi artar ve aÄŸ, eÄŸitim gÃ¶rÃ¼ntÃ¼lerini doÄŸru bir ÅŸekilde sÄ±nÄ±flandÄ±rmak iÃ§in gereken ifade gÃ¼cÃ¼nÃ¼ karÅŸÄ±layacak ÅŸekilde kendini ayarlar.

### Google Inception

Google Inception mimarisi bu fikri bir adÄ±m Ã¶teye taÅŸÄ±r ve her aÄŸ katmanÄ±nÄ± birkaÃ§ farklÄ± yolun bir kombinasyonu olarak inÅŸa eder:

<img src="images/inception.png" width="400"/>

> GÃ¶rsel [Researchgate](https://www.researchgate.net/figure/Inception-module-with-dimension-reductions-left-and-schema-for-Inception-ResNet-v1_fig2_355547454) kaynaÄŸÄ±ndan alÄ±nmÄ±ÅŸtÄ±r.

Burada, 1x1 evriÅŸimlerin rolÃ¼nÃ¼ vurgulamak gerekir, Ã§Ã¼nkÃ¼ ilk bakÄ±ÅŸta mantÄ±klÄ± gÃ¶rÃ¼nmeyebilir. GÃ¶rÃ¼ntÃ¼yÃ¼ neden 1x1 filtreyle taramamÄ±z gerekiyor? Ancak, evriÅŸim filtrelerinin aynÄ± zamanda birkaÃ§ derinlik kanalÄ±nda (baÅŸlangÄ±Ã§ta - RGB renkleri, sonraki katmanlarda - farklÄ± filtreler iÃ§in kanallar) Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± unutmamalÄ±sÄ±nÄ±z ve 1x1 evriÅŸim, bu giriÅŸ kanallarÄ±nÄ± farklÄ± eÄŸitilebilir aÄŸÄ±rlÄ±klarla birleÅŸtirmek iÃ§in kullanÄ±lÄ±r. AyrÄ±ca kanal boyutunda bir alt Ã¶rnekleme (havuzlama) olarak da gÃ¶rÃ¼lebilir.

Bu konuda [iyi bir blog yazÄ±sÄ±](https://medium.com/analytics-vidhya/talented-mr-1x1-comprehensive-look-at-1x1-convolution-in-deep-learning-f6b355825578) ve [orijinal makale](https://arxiv.org/pdf/1312.4400.pdf) bulunmaktadÄ±r.

### MobileNet

MobileNet, mobil cihazlar iÃ§in uygun, boyutlarÄ± kÃ¼Ã§Ã¼ltÃ¼lmÃ¼ÅŸ bir model ailesidir. KaynaklarÄ±nÄ±z sÄ±nÄ±rlÄ±ysa ve biraz doÄŸruluk kaybÄ±nÄ± gÃ¶ze alabiliyorsanÄ±z, bu modelleri kullanabilirsiniz. Bu modellerin arkasÄ±ndaki ana fikir, **derinlik ayrÄ±labilir evriÅŸim** olarak adlandÄ±rÄ±lan bir tekniktir. Bu teknik, evriÅŸim filtrelerini, uzaysal evriÅŸimlerin ve derinlik kanallarÄ± Ã¼zerinde 1x1 evriÅŸimlerin bir bileÅŸimi olarak temsil etmeye olanak tanÄ±r. Bu, parametre sayÄ±sÄ±nÄ± Ã¶nemli Ã¶lÃ§Ã¼de azaltÄ±r, aÄŸÄ± daha kÃ¼Ã§Ã¼k hale getirir ve daha az veriyle eÄŸitilmesini kolaylaÅŸtÄ±rÄ±r.

Ä°ÅŸte [MobileNet hakkÄ±nda iyi bir blog yazÄ±sÄ±](https://medium.com/analytics-vidhya/image-classification-with-mobilenet-cc6fbb2cd470).

## SonuÃ§

Bu bÃ¶lÃ¼mde, bilgisayarla gÃ¶rme sinir aÄŸlarÄ±nÄ±n temel konseptini - evriÅŸimli aÄŸlarÄ± Ã¶ÄŸrendiniz. GÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rma, nesne algÄ±lama ve hatta gÃ¶rÃ¼ntÃ¼ oluÅŸturma aÄŸlarÄ±nÄ± destekleyen gerÃ§ek yaÅŸam mimarilerinin hepsi CNN'lere dayanÄ±r, sadece daha fazla katman ve bazÄ± ek eÄŸitim hileleriyle.

## ğŸš€ Meydan Okuma

EÅŸlik eden defterlerde, daha yÃ¼ksek doÄŸruluk elde etmenin yollarÄ± hakkÄ±nda notlar bulunmaktadÄ±r. Daha yÃ¼ksek doÄŸruluk elde edip edemeyeceÄŸinizi gÃ¶rmek iÃ§in bazÄ± deneyler yapÄ±n.

## [Ders SonrasÄ± Test](https://ff-quizzes.netlify.app/en/ai/quiz/14)

## GÃ¶zden GeÃ§irme ve Kendi Kendine Ã‡alÄ±ÅŸma

CNN'ler genellikle Bilgisayarla GÃ¶rme gÃ¶revlerinde kullanÄ±lsa da, sabit boyutlu desenleri Ã§Ä±karmada genel olarak iyidirler. Ã–rneÄŸin, seslerle Ã§alÄ±ÅŸÄ±yorsak, ses sinyalinde bazÄ± belirli desenleri aramak iÃ§in de CNN'leri kullanmak isteyebiliriz - bu durumda filtreler 1 boyutlu olur (ve bu CNN'e 1D-CNN denir). AyrÄ±ca, bazen Ã§ok boyutlu uzayda Ã¶zellikleri Ã§Ä±karmak iÃ§in 3D-CNN kullanÄ±lÄ±r, Ã¶rneÄŸin videoda meydana gelen belirli olaylar - CNN, zaman iÃ§inde deÄŸiÅŸen belirli Ã¶zellik desenlerini yakalayabilir. CNN'lerle yapÄ±labilecek diÄŸer gÃ¶revler hakkÄ±nda biraz araÅŸtÄ±rma ve kendi kendine Ã§alÄ±ÅŸma yapÄ±n.

## [GÃ¶rev](lab/README.md)

Bu laboratuvarda, farklÄ± kedi ve kÃ¶pek Ä±rklarÄ±nÄ± sÄ±nÄ±flandÄ±rma gÃ¶revi verilmektedir. Bu gÃ¶rÃ¼ntÃ¼ler, MNIST veri setinden daha karmaÅŸÄ±ktÄ±r, daha yÃ¼ksek boyutlardadÄ±r ve 10'dan fazla sÄ±nÄ±f bulunmaktadÄ±r.

**Feragatname**:  
Bu belge, AI Ã§eviri hizmeti [Co-op Translator](https://github.com/Azure/co-op-translator) kullanÄ±larak Ã§evrilmiÅŸtir. DoÄŸruluk iÃ§in Ã§aba gÃ¶stersek de, otomatik Ã§evirilerin hata veya yanlÄ±ÅŸlÄ±klar iÃ§erebileceÄŸini lÃ¼tfen unutmayÄ±n. Belgenin orijinal dili, yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler iÃ§in profesyonel insan Ã§evirisi Ã¶nerilir. Bu Ã§evirinin kullanÄ±mÄ±ndan kaynaklanan yanlÄ±ÅŸ anlamalar veya yanlÄ±ÅŸ yorumlamalar iÃ§in sorumluluk kabul edilmez.