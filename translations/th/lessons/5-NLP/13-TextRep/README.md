<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "4522e22e150be0845e03aa41209a39d5",
  "translation_date": "2025-08-29T09:27:52+00:00",
  "source_file": "lessons/5-NLP/13-TextRep/README.md",
  "language_code": "th"
}
-->
# การแสดงข้อความในรูปแบบเทนเซอร์

## [แบบทดสอบก่อนเรียน](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/113)

## การจัดประเภทข้อความ

ในส่วนแรกของบทนี้ เราจะมุ่งเน้นไปที่งาน **การจัดประเภทข้อความ** โดยเราจะใช้ชุดข้อมูล [AG News](https://www.kaggle.com/amananandrai/ag-news-classification-dataset) ซึ่งประกอบด้วยบทความข่าว เช่นตัวอย่างต่อไปนี้:

* หมวดหมู่: วิทยาศาสตร์/เทคโนโลยี  
* หัวข้อ: Ky. Company Wins Grant to Study Peptides (AP)  
* เนื้อหา: AP - บริษัทที่ก่อตั้งโดยนักวิจัยเคมีจากมหาวิทยาลัย Louisville ได้รับทุนเพื่อพัฒนา...

เป้าหมายของเราคือการจัดประเภทข่าวให้อยู่ในหนึ่งในหมวดหมู่ตามข้อความที่ให้มา

## การแสดงข้อความ

หากเราต้องการแก้ปัญหาการประมวลผลภาษาธรรมชาติ (NLP) ด้วยเครือข่ายประสาทเทียม เราจำเป็นต้องมีวิธีการแสดงข้อความในรูปแบบเทนเซอร์ คอมพิวเตอร์มีการแสดงตัวอักษรในรูปแบบตัวเลขอยู่แล้ว ซึ่งแปลงเป็นฟอนต์บนหน้าจอของคุณโดยใช้การเข้ารหัส เช่น ASCII หรือ UTF-8

<img alt="ภาพแสดงแผนภาพการแปลงตัวอักษรเป็น ASCII และการแสดงในรูปแบบไบนารี" src="images/ascii-character-map.png" width="50%"/>

> [แหล่งที่มาของภาพ](https://www.seobility.net/en/wiki/ASCII)

ในฐานะมนุษย์ เราเข้าใจว่าตัวอักษรแต่ละตัว **แสดงถึงอะไร** และตัวอักษรทั้งหมดรวมกันเพื่อสร้างคำในประโยคอย่างไร อย่างไรก็ตาม คอมพิวเตอร์เองไม่มีความเข้าใจเช่นนั้น และเครือข่ายประสาทเทียมต้องเรียนรู้ความหมายระหว่างการฝึก

ดังนั้น เราสามารถใช้วิธีการต่าง ๆ ในการแสดงข้อความ:

* **การแสดงในระดับตัวอักษร** ซึ่งเราจะแสดงข้อความโดยการแปลงตัวอักษรแต่ละตัวเป็นตัวเลข หากเรามีตัวอักษร *C* ต่าง ๆ ในชุดข้อความ คำว่า *Hello* จะถูกแสดงในรูปแบบเทนเซอร์ขนาด 5x*C* โดยตัวอักษรแต่ละตัวจะสอดคล้องกับคอลัมน์เทนเซอร์ในรูปแบบการเข้ารหัสแบบ one-hot  
* **การแสดงในระดับคำ** ซึ่งเราสร้าง **คำศัพท์** ของคำทั้งหมดในข้อความ และแสดงคำโดยใช้การเข้ารหัสแบบ one-hot วิธีนี้ดีกว่าในบางแง่ เพราะตัวอักษรแต่ละตัวไม่มีความหมายมากนัก ดังนั้นการใช้แนวคิดเชิงความหมายระดับสูง เช่นคำ จะช่วยลดความซับซ้อนของงานสำหรับเครือข่ายประสาทเทียม อย่างไรก็ตาม เนื่องจากขนาดของพจนานุกรมที่ใหญ่ เราจำเป็นต้องจัดการกับเทนเซอร์ที่มีมิติสูงและเบาบาง

ไม่ว่าจะใช้การแสดงแบบใด เราต้องแปลงข้อความเป็นลำดับของ **โทเค็น** ก่อน โดยโทเค็นหนึ่งอาจเป็นตัวอักษร คำ หรือแม้แต่ส่วนหนึ่งของคำ จากนั้นเราจะแปลงโทเค็นเป็นตัวเลข โดยปกติจะใช้ **คำศัพท์** และตัวเลขนี้สามารถป้อนเข้าสู่เครือข่ายประสาทเทียมโดยใช้การเข้ารหัสแบบ one-hot

## N-Grams

ในภาษาธรรมชาติ ความหมายที่ชัดเจนของคำสามารถกำหนดได้จากบริบทเท่านั้น ตัวอย่างเช่น ความหมายของ *neural network* และ *fishing network* แตกต่างกันโดยสิ้นเชิง วิธีหนึ่งในการคำนึงถึงสิ่งนี้คือการสร้างโมเดลของเราบนคู่คำ และพิจารณาคู่คำเป็นโทเค็นคำศัพท์แยกกัน ด้วยวิธีนี้ ประโยค *I like to go fishing* จะถูกแสดงในรูปแบบลำดับโทเค็นดังนี้: *I like*, *like to*, *to go*, *go fishing* ปัญหาของวิธีนี้คือขนาดของพจนานุกรมเพิ่มขึ้นอย่างมาก และการรวมกันเช่น *go fishing* และ *go shopping* ถูกแสดงโดยโทเค็นที่แตกต่างกัน ซึ่งไม่มีความคล้ายคลึงกันทางความหมายแม้จะใช้คำกริยาเดียวกัน  

ในบางกรณี เราอาจพิจารณาใช้ tri-grams -- การรวมกันของสามคำ -- ด้วยเช่นกัน ดังนั้นวิธีนี้จึงมักเรียกว่า **n-grams** นอกจากนี้ยังมีเหตุผลที่จะใช้ n-grams กับการแสดงในระดับตัวอักษร ซึ่งในกรณีนี้ n-grams จะสอดคล้องกับพยางค์ต่าง ๆ

## Bag-of-Words และ TF/IDF

เมื่อแก้ปัญหาเช่นการจัดประเภทข้อความ เราจำเป็นต้องสามารถแสดงข้อความในรูปแบบเวกเตอร์ขนาดคงที่ ซึ่งเราจะใช้เป็นข้อมูลนำเข้าให้กับตัวจำแนกแบบ dense วิธีที่ง่ายที่สุดวิธีหนึ่งคือการรวมการแสดงคำแต่ละคำ เช่นโดยการบวกกัน หากเราบวกการเข้ารหัสแบบ one-hot ของแต่ละคำ เราจะได้เวกเตอร์ที่แสดงความถี่ ซึ่งแสดงจำนวนครั้งที่คำแต่ละคำปรากฏในข้อความ การแสดงข้อความในรูปแบบนี้เรียกว่า **bag of words** (BoW)

<img src="images/bow.png" width="90%"/>

> ภาพโดยผู้เขียน

BoW แสดงให้เห็นว่าคำใดปรากฏในข้อความและในปริมาณเท่าใด ซึ่งสามารถบ่งบอกได้ดีว่าข้อความเกี่ยวกับอะไร ตัวอย่างเช่น บทความข่าวเกี่ยวกับการเมืองมักจะมีคำเช่น *president* และ *country* ในขณะที่สิ่งพิมพ์ทางวิทยาศาสตร์อาจมีคำเช่น *collider*, *discovered* เป็นต้น ดังนั้นความถี่ของคำในหลายกรณีสามารถเป็นตัวบ่งชี้ที่ดีของเนื้อหาข้อความ

ปัญหาของ BoW คือคำทั่วไปบางคำ เช่น *and*, *is* เป็นต้น ปรากฏในข้อความส่วนใหญ่ และมีความถี่สูงสุด ซึ่งบดบังคำที่สำคัญจริง ๆ เราอาจลดความสำคัญของคำเหล่านั้นโดยคำนึงถึงความถี่ที่คำปรากฏในชุดเอกสารทั้งหมด นี่คือแนวคิดหลักของวิธี TF/IDF ซึ่งครอบคลุมรายละเอียดเพิ่มเติมในสมุดบันทึกที่แนบมากับบทเรียนนี้

อย่างไรก็ตาม วิธีเหล่านี้ไม่สามารถคำนึงถึง **ความหมาย** ของข้อความได้อย่างเต็มที่ เราจำเป็นต้องใช้โมเดลเครือข่ายประสาทเทียมที่ทรงพลังมากขึ้นเพื่อทำสิ่งนี้ ซึ่งเราจะพูดถึงในภายหลังในบทนี้

## ✍️ แบบฝึกหัด: การแสดงข้อความ

เรียนรู้เพิ่มเติมในสมุดบันทึกต่อไปนี้:

* [การแสดงข้อความด้วย PyTorch](TextRepresentationPyTorch.ipynb)  
* [การแสดงข้อความด้วย TensorFlow](TextRepresentationTF.ipynb)  

## สรุป

จนถึงตอนนี้ เราได้ศึกษาวิธีการที่สามารถเพิ่มน้ำหนักความถี่ให้กับคำต่าง ๆ อย่างไรก็ตาม วิธีเหล่านี้ไม่สามารถแสดงความหมายหรือลำดับได้ ดังที่นักภาษาศาสตร์ชื่อดัง J. R. Firth กล่าวไว้ในปี 1935 ว่า "ความหมายที่สมบูรณ์ของคำมักจะขึ้นอยู่กับบริบท และการศึกษาความหมายที่แยกออกจากบริบทไม่สามารถถือเป็นเรื่องจริงจังได้" เราจะเรียนรู้ในภายหลังในหลักสูตรนี้เกี่ยวกับวิธีการจับข้อมูลบริบทจากข้อความโดยใช้การสร้างแบบจำลองภาษา

## 🚀 ความท้าทาย

ลองทำแบบฝึกหัดอื่น ๆ โดยใช้ bag-of-words และโมเดลข้อมูลต่าง ๆ คุณอาจได้รับแรงบันดาลใจจาก [การแข่งขันนี้บน Kaggle](https://www.kaggle.com/competitions/word2vec-nlp-tutorial/overview/part-1-for-beginners-bag-of-words)

## [แบบทดสอบหลังเรียน](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/213)

## ทบทวนและศึกษาด้วยตนเอง

ฝึกฝนทักษะของคุณด้วยเทคนิคการฝังข้อความและ bag-of-words บน [Microsoft Learn](https://docs.microsoft.com/learn/modules/intro-natural-language-processing-pytorch/?WT.mc_id=academic-77998-cacaste)

## [งานที่มอบหมาย: สมุดบันทึก](assignment.md)

---

**ข้อจำกัดความรับผิดชอบ**:  
เอกสารนี้ได้รับการแปลโดยใช้บริการแปลภาษา AI [Co-op Translator](https://github.com/Azure/co-op-translator) แม้ว่าเราจะพยายามให้การแปลมีความถูกต้อง แต่โปรดทราบว่าการแปลอัตโนมัติอาจมีข้อผิดพลาดหรือความไม่แม่นยำ เอกสารต้นฉบับในภาษาต้นทางควรถือเป็นแหล่งข้อมูลที่เชื่อถือได้ สำหรับข้อมูลที่สำคัญ ขอแนะนำให้ใช้บริการแปลภาษามนุษย์มืออาชีพ เราจะไม่รับผิดชอบต่อความเข้าใจผิดหรือการตีความที่ผิดพลาดซึ่งเกิดจากการใช้การแปลนี้