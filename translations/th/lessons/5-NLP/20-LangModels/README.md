<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "2efbb183384a50f0fc0cde02534d912f",
  "translation_date": "2025-08-29T09:21:54+00:00",
  "source_file": "lessons/5-NLP/20-LangModels/README.md",
  "language_code": "th"
}
-->
# โมเดลภาษาขนาดใหญ่ที่ผ่านการฝึกฝนล่วงหน้า

ในงานก่อนหน้านี้ทั้งหมด เราได้ฝึกฝนโครงข่ายประสาทเทียมเพื่อทำงานเฉพาะโดยใช้ชุดข้อมูลที่มีการติดป้ายกำกับ สำหรับโมเดลทรานส์ฟอร์มเมอร์ขนาดใหญ่ เช่น BERT เราใช้การสร้างแบบจำลองภาษาในลักษณะการเรียนรู้ด้วยตนเอง (self-supervised) เพื่อสร้างโมเดลภาษา ซึ่งจากนั้นจะถูกปรับให้เหมาะสมสำหรับงานเฉพาะทางด้วยการฝึกฝนเพิ่มเติมในโดเมนเฉพาะ อย่างไรก็ตาม มีการแสดงให้เห็นว่าโมเดลภาษาขนาดใหญ่สามารถแก้ปัญหาหลายงานได้โดยไม่ต้องฝึกฝนในโดเมนเฉพาะเลย โมเดลในกลุ่มนี้เรียกว่า **GPT**: Generative Pre-Trained Transformer

## [แบบทดสอบก่อนการบรรยาย](https://ff-quizzes.netlify.app/en/ai/quiz/39)

## การสร้างข้อความและความซับซ้อน (Perplexity)

แนวคิดที่ว่าโครงข่ายประสาทเทียมสามารถทำงานทั่วไปได้โดยไม่ต้องฝึกฝนเพิ่มเติมถูกนำเสนอในเอกสาร [Language Models are Unsupervised Multitask Learners](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf) แนวคิดหลักคือหลายงานอื่น ๆ สามารถถูกจำลองโดยใช้ **การสร้างข้อความ** เพราะการเข้าใจข้อความหมายถึงการสามารถสร้างข้อความได้ เนื่องจากโมเดลได้รับการฝึกฝนด้วยข้อความจำนวนมหาศาลที่ครอบคลุมความรู้ของมนุษย์ มันจึงมีความรู้ในหลากหลายหัวข้อ

> การเข้าใจและสามารถสร้างข้อความได้ยังหมายถึงการรู้บางสิ่งเกี่ยวกับโลกของเราอีกด้วย มนุษย์เองก็เรียนรู้จากการอ่านในระดับมาก และเครือข่าย GPT ก็คล้ายคลึงในแง่นี้

เครือข่ายการสร้างข้อความทำงานโดยการทำนายความน่าจะเป็นของคำถัดไป $$P(w_N)$$ อย่างไรก็ตาม ความน่าจะเป็นแบบไม่มีเงื่อนไขของคำถัดไปเท่ากับความถี่ของคำนี้ในคลังข้อความ GPT สามารถให้ **ความน่าจะเป็นแบบมีเงื่อนไข** ของคำถัดไป โดยพิจารณาจากคำก่อนหน้า: $$P(w_N | w_{n-1}, ..., w_0)$$

> คุณสามารถอ่านเพิ่มเติมเกี่ยวกับความน่าจะเป็นใน [หลักสูตร Data Science for Beginners](https://github.com/microsoft/Data-Science-For-Beginners/tree/main/1-Introduction/04-stats-and-probability)

คุณภาพของโมเดลการสร้างภาษาสามารถวัดได้โดยใช้ **ความซับซ้อน (perplexity)** ซึ่งเป็นตัวชี้วัดภายในที่ช่วยให้เราวัดคุณภาพของโมเดลโดยไม่ต้องใช้ชุดข้อมูลเฉพาะงาน มันอิงตามแนวคิดของ *ความน่าจะเป็นของประโยค* - โมเดลจะให้ความน่าจะเป็นสูงกับประโยคที่มีแนวโน้มว่าจะเป็นจริง (เช่น โมเดลไม่ **สับสน** กับมัน) และให้ความน่าจะเป็นต่ำกับประโยคที่ดูไม่มีเหตุผล (เช่น *Can it does what?*) เมื่อเราให้โมเดลของเราประโยคจากคลังข้อความจริง เราคาดหวังว่ามันจะมีความน่าจะเป็นสูง และมี **ความซับซ้อนต่ำ** ในเชิงคณิตศาสตร์ มันถูกนิยามเป็นความน่าจะเป็นผกผันที่ถูกทำให้เป็นมาตรฐานของชุดทดสอบ:
$$
\mathrm{Perplexity}(W) = \sqrt[N]{1\over P(W_1,...,W_N)}
$$ 

**คุณสามารถทดลองสร้างข้อความโดยใช้ [ตัวแก้ไขข้อความที่ขับเคลื่อนด้วย GPT จาก Hugging Face](https://transformer.huggingface.co/doc/gpt2-large)** ในตัวแก้ไขนี้ คุณเริ่มเขียนข้อความของคุณ และเมื่อกด **[TAB]** จะมีตัวเลือกการเติมข้อความให้คุณ หากข้อความสั้นเกินไป หรือคุณไม่พอใจกับมัน - กด [TAB] อีกครั้ง และคุณจะมีตัวเลือกเพิ่มเติม รวมถึงข้อความที่ยาวขึ้น

## GPT คือกลุ่มของโมเดล

GPT ไม่ใช่โมเดลเดียว แต่เป็นกลุ่มของโมเดลที่พัฒนาและฝึกฝนโดย [OpenAI](https://openai.com)

ภายใต้โมเดล GPT มี:

| [GPT-2](https://huggingface.co/docs/transformers/model_doc/gpt2#openai-gpt2) | [GPT 3](https://openai.com/research/language-models-are-few-shot-learners) | [GPT-4](https://openai.com/gpt-4) |
| -- | -- | -- |
|โมเดลภาษาที่มีพารามิเตอร์สูงสุด 1.5 พันล้านตัว | โมเดลภาษาที่มีพารามิเตอร์สูงสุด 175 พันล้านตัว | 100 ล้านล้านพารามิเตอร์ และรองรับทั้งอินพุตภาพและข้อความ และให้ผลลัพธ์เป็นข้อความ |

โมเดล GPT-3 และ GPT-4 มีให้บริการ [ในรูปแบบบริการปัญญาประดิษฐ์จาก Microsoft Azure](https://azure.microsoft.com/en-us/services/cognitive-services/openai-service/#overview?WT.mc_id=academic-77998-cacaste) และในรูปแบบ [OpenAI API](https://openai.com/api/)

## การออกแบบคำสั่ง (Prompt Engineering)

เนื่องจาก GPT ได้รับการฝึกฝนด้วยข้อมูลจำนวนมหาศาลเพื่อเข้าใจภาษาและโค้ด มันจึงให้ผลลัพธ์เพื่อตอบสนองต่ออินพุต (คำสั่ง) คำสั่งคืออินพุตหรือคำถามที่ให้กับ GPT โดยที่เรามอบคำแนะนำให้โมเดลเกี่ยวกับงานที่ต้องการให้ทำสำเร็จ เพื่อให้ได้ผลลัพธ์ที่ต้องการ คุณจำเป็นต้องมีคำสั่งที่มีประสิทธิภาพที่สุด ซึ่งเกี่ยวข้องกับการเลือกคำ รูปแบบ วลี หรือแม้แต่สัญลักษณ์ที่เหมาะสม วิธีการนี้เรียกว่า [Prompt Engineering](https://learn.microsoft.com/en-us/shows/ai-show/the-basics-of-prompt-engineering-with-azure-openai-service?WT.mc_id=academic-77998-bethanycheum)

[เอกสารนี้](https://learn.microsoft.com/en-us/semantic-kernel/prompt-engineering/?WT.mc_id=academic-77998-bethanycheum) ให้ข้อมูลเพิ่มเติมเกี่ยวกับการออกแบบคำสั่ง

## ✍️ ตัวอย่างโน้ตบุ๊ก: [การทดลองกับ OpenAI-GPT](GPT-PyTorch.ipynb)

เรียนรู้เพิ่มเติมในโน้ตบุ๊กต่อไปนี้:

* [การสร้างข้อความด้วย OpenAI-GPT และ Hugging Face Transformers](GPT-PyTorch.ipynb)

## สรุป

โมเดลภาษาที่ผ่านการฝึกฝนล่วงหน้าทั่วไปใหม่ไม่ได้เพียงแค่จำลองโครงสร้างภาษา แต่ยังมีความรู้ในภาษาธรรมชาติในปริมาณมหาศาล ดังนั้น พวกมันจึงสามารถถูกใช้แก้ปัญหางาน NLP บางงานได้อย่างมีประสิทธิภาพในรูปแบบ zero-shot หรือ few-shot

## [แบบทดสอบหลังการบรรยาย](https://ff-quizzes.netlify.app/en/ai/quiz/40)

---

**ข้อจำกัดความรับผิดชอบ**:  
เอกสารนี้ได้รับการแปลโดยใช้บริการแปลภาษา AI [Co-op Translator](https://github.com/Azure/co-op-translator) แม้ว่าเราจะพยายามให้การแปลมีความถูกต้อง แต่โปรดทราบว่าการแปลอัตโนมัติอาจมีข้อผิดพลาดหรือความไม่แม่นยำ เอกสารต้นฉบับในภาษาต้นทางควรถือเป็นแหล่งข้อมูลที่เชื่อถือได้ สำหรับข้อมูลที่สำคัญ ขอแนะนำให้ใช้บริการแปลภาษามนุษย์ที่เป็นมืออาชีพ เราจะไม่รับผิดชอบต่อความเข้าใจผิดหรือการตีความที่ผิดพลาดซึ่งเกิดจากการใช้การแปลนี้