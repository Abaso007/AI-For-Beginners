<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7bd8dc72040e98e35e7225e34058cd4e",
  "translation_date": "2025-08-29T08:41:58+00:00",
  "source_file": "lessons/6-Other/22-DeepRL/lab/README.md",
  "language_code": "th"
}
-->
## สภาพแวดล้อม

สภาพแวดล้อม Mountain Car ประกอบด้วยรถที่ติดอยู่ในหุบเขา เป้าหมายของคุณคือการกระโดดออกจากหุบเขาและไปถึงธง การกระทำที่คุณสามารถทำได้คือเร่งไปทางซ้าย เร่งไปทางขวา หรือไม่ทำอะไรเลย คุณสามารถสังเกตตำแหน่งของรถตามแกน x และความเร็ว

## เริ่มต้น Notebook

เริ่มต้นการทดลองโดยเปิด [MountainCar.ipynb](MountainCar.ipynb)

## สิ่งที่ได้เรียนรู้

คุณควรเรียนรู้จากการทดลองนี้ว่า การปรับใช้อัลกอริทึม RL ให้เข้ากับสภาพแวดล้อมใหม่มักจะค่อนข้างตรงไปตรงมา เนื่องจาก OpenAI Gym มีอินเทอร์เฟซเดียวกันสำหรับทุกสภาพแวดล้อม และอัลกอริทึมโดยทั่วไปไม่ได้ขึ้นอยู่กับลักษณะของสภาพแวดล้อมมากนัก คุณยังสามารถปรับโครงสร้างโค้ด Python ในลักษณะที่สามารถส่งผ่านสภาพแวดล้อมใดๆ ไปยังอัลกอริทึม RL เป็นพารามิเตอร์ได้

---

**ข้อจำกัดความรับผิดชอบ**:  
เอกสารนี้ได้รับการแปลโดยใช้บริการแปลภาษา AI [Co-op Translator](https://github.com/Azure/co-op-translator) แม้ว่าเราจะพยายามให้การแปลมีความถูกต้อง แต่โปรดทราบว่าการแปลอัตโนมัติอาจมีข้อผิดพลาดหรือความไม่แม่นยำ เอกสารต้นฉบับในภาษาต้นทางควรถือเป็นแหล่งข้อมูลที่เชื่อถือได้ สำหรับข้อมูลที่สำคัญ ขอแนะนำให้ใช้บริการแปลภาษามนุษย์มืออาชีพ เราจะไม่รับผิดชอบต่อความเข้าใจผิดหรือการตีความที่ผิดพลาดซึ่งเกิดจากการใช้การแปลนี้