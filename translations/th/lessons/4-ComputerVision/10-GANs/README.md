<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f07c85bbf05a1f67505da98f4ecc124c",
  "translation_date": "2025-08-29T08:58:12+00:00",
  "source_file": "lessons/4-ComputerVision/10-GANs/README.md",
  "language_code": "th"
}
-->
# เครือข่าย Generative Adversarial Networks

ในส่วนก่อนหน้านี้ เราได้เรียนรู้เกี่ยวกับ **โมเดลการสร้าง (generative models)**: โมเดลที่สามารถสร้างภาพใหม่ที่คล้ายกับภาพในชุดข้อมูลการฝึกฝน VAE เป็นตัวอย่างที่ดีของโมเดลการสร้าง

## [แบบทดสอบก่อนเรียน](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/110)

อย่างไรก็ตาม หากเราพยายามสร้างสิ่งที่มีความหมายจริงๆ เช่น ภาพวาดที่มีความละเอียดสมเหตุสมผลด้วย VAE เราจะพบว่าการฝึกฝนไม่ค่อยจะบรรลุผลดีนัก สำหรับกรณีนี้ เราควรเรียนรู้เกี่ยวกับสถาปัตยกรรมอีกแบบหนึ่งที่ออกแบบมาเพื่อโมเดลการสร้างโดยเฉพาะ - **Generative Adversarial Networks** หรือ GANs

แนวคิดหลักของ GAN คือการมีเครือข่ายประสาทสองเครือข่ายที่ถูกฝึกให้แข่งขันกัน:

<img src="images/gan_architecture.png" width="70%"/>

> ภาพโดย [Dmitry Soshnikov](http://soshnikov.com)

> ✅ คำศัพท์เล็กน้อย:
> * **Generator** คือเครือข่ายที่รับเวกเตอร์สุ่มและสร้างภาพเป็นผลลัพธ์
> * **Discriminator** คือเครือข่ายที่รับภาพและต้องบอกได้ว่าภาพนั้นเป็นภาพจริง (จากชุดข้อมูลการฝึกฝน) หรือเป็นภาพที่สร้างโดย Generator โดยพื้นฐานแล้วมันคือเครื่องจำแนกภาพ

### Discriminator

สถาปัตยกรรมของ Discriminator ไม่แตกต่างจากเครือข่ายการจำแนกภาพทั่วไป ในกรณีที่ง่ายที่สุด มันอาจเป็นเครื่องจำแนกแบบ fully-connected แต่ส่วนใหญ่มักจะเป็น [เครือข่ายคอนโวลูชัน](../07-ConvNets/README.md)

> ✅ GAN ที่ใช้เครือข่ายคอนโวลูชันเรียกว่า [DCGAN](https://arxiv.org/pdf/1511.06434.pdf)

Discriminator แบบ CNN ประกอบด้วยเลเยอร์ดังนี้: การคอนโวลูชัน+การลดขนาด (convolutions+poolings) หลายครั้ง (โดยลดขนาดเชิงพื้นที่) และเลเยอร์ fully-connected หนึ่งหรือมากกว่าเพื่อสร้าง "เวกเตอร์คุณลักษณะ" และสุดท้ายเป็นเครื่องจำแนกแบบไบนารี

> ✅ 'Pooling' ในบริบทนี้คือเทคนิคที่ลดขนาดของภาพ "Pooling layers ลดมิติของข้อมูลโดยการรวมผลลัพธ์ของกลุ่มนิวรอนในเลเยอร์หนึ่งให้เป็นนิวรอนเดียวในเลเยอร์ถัดไป" - [source](https://wikipedia.org/wiki/Convolutional_neural_network#Pooling_layers)

### Generator

Generator มีความซับซ้อนกว่าเล็กน้อย คุณสามารถมองว่ามันเป็น Discriminator ที่กลับด้าน โดยเริ่มจากเวกเตอร์แฝง (แทนที่จะเป็นเวกเตอร์คุณลักษณะ) มันมีเลเยอร์ fully-connected เพื่อแปลงเป็นขนาด/รูปร่างที่ต้องการ ตามด้วยการ deconvolutions+การขยายขนาด ซึ่งคล้ายกับส่วน *decoder* ของ [autoencoder](../09-Autoencoders/README.md)

> ✅ เนื่องจากเลเยอร์คอนโวลูชันถูกนำมาใช้เป็นฟิลเตอร์เชิงเส้นที่เคลื่อนที่ผ่านภาพ การ deconvolution จึงคล้ายกับการคอนโวลูชัน และสามารถนำมาใช้ด้วยตรรกะเลเยอร์เดียวกัน

<img src="images/gan_arch_detail.png" width="70%"/>

> ภาพโดย [Dmitry Soshnikov](http://soshnikov.com)

### การฝึก GAN

GAN ถูกเรียกว่า **adversarial** เพราะมีการแข่งขันกันอย่างต่อเนื่องระหว่าง Generator และ Discriminator ในระหว่างการแข่งขันนี้ ทั้ง Generator และ Discriminator จะพัฒนาขึ้น ทำให้เครือข่ายเรียนรู้ที่จะสร้างภาพที่ดีขึ้นเรื่อยๆ

การฝึกฝนเกิดขึ้นในสองขั้นตอน:

* **การฝึก Discriminator**. งานนี้ค่อนข้างตรงไปตรงมา: เราสร้างชุดภาพโดย Generator และติดป้ายกำกับว่า 0 ซึ่งหมายถึงภาพปลอม และนำชุดภาพจากชุดข้อมูลอินพุต (ที่มีป้ายกำกับ 1, ภาพจริง) เราได้ *discriminator loss* และทำ backprop
* **การฝึก Generator**. ขั้นตอนนี้ซับซ้อนกว่าเล็กน้อย เพราะเราไม่ทราบผลลัพธ์ที่คาดหวังสำหรับ Generator โดยตรง เรานำเครือข่าย GAN ทั้งหมดที่ประกอบด้วย Generator ตามด้วย Discriminator ใส่เวกเตอร์สุ่มเข้าไป และคาดหวังผลลัพธ์เป็น 1 (สอดคล้องกับภาพจริง) จากนั้นเราจะตรึงพารามิเตอร์ของ Discriminator (เราไม่ต้องการให้มันถูกฝึกในขั้นตอนนี้) และทำ backprop

ในกระบวนการนี้ ทั้ง Generator และ Discriminator loss จะไม่ลดลงอย่างมีนัยสำคัญ ในสถานการณ์ที่เหมาะสม พวกมันควรแกว่งไปมา ซึ่งแสดงถึงการพัฒนาของทั้งสองเครือข่าย

## ✍️ แบบฝึกหัด: GANs

* [สมุดบันทึก GAN ใน TensorFlow/Keras](GANTF.ipynb)
* [สมุดบันทึก GAN ใน PyTorch](GANPyTorch.ipynb)

### ปัญหาในการฝึก GAN

GAN เป็นที่รู้กันว่าฝึกได้ยากเป็นพิเศษ นี่คือปัญหาบางประการ:

* **Mode Collapse**. หมายถึง Generator เรียนรู้ที่จะสร้างภาพที่ประสบความสำเร็จเพียงภาพเดียวที่หลอก Discriminator ได้ และไม่สร้างภาพที่หลากหลาย
* **ความไวต่อ hyperparameters**. บ่อยครั้งที่ GAN ไม่สามารถบรรลุผลได้เลย และจู่ๆ ก็ลดอัตราการเรียนรู้ลงจนเกิดการบรรลุผล
* การรักษา **สมดุล** ระหว่าง Generator และ Discriminator. ในหลายกรณี Discriminator loss อาจลดลงจนถึงศูนย์อย่างรวดเร็ว ซึ่งทำให้ Generator ไม่สามารถฝึกต่อได้ เพื่อแก้ปัญหานี้ เราอาจลองตั้งค่าอัตราการเรียนรู้ที่แตกต่างกันสำหรับ Generator และ Discriminator หรือข้ามการฝึก Discriminator หาก loss ต่ำเกินไป
* การฝึกสำหรับ **ความละเอียดสูง**. ปัญหาเดียวกับ autoencoders ปัญหานี้เกิดขึ้นเพราะการสร้างเลเยอร์คอนโวลูชันจำนวนมากเกินไปนำไปสู่สิ่งประดิษฐ์ ปัญหานี้มักแก้ด้วย **progressive growing** โดยเริ่มฝึกเลเยอร์บางส่วนบนภาพความละเอียดต่ำก่อน แล้วค่อย "ปลดล็อก" หรือเพิ่มเลเยอร์ อีกวิธีหนึ่งคือเพิ่มการเชื่อมต่อระหว่างเลเยอร์และฝึกหลายความละเอียดพร้อมกัน - ดูรายละเอียดใน [Multi-Scale Gradient GANs paper](https://arxiv.org/abs/1903.06048)

## การถ่ายโอนสไตล์ (Style Transfer)

GAN เป็นวิธีที่ยอดเยี่ยมในการสร้างภาพศิลปะ อีกเทคนิคที่น่าสนใจคือ **การถ่ายโอนสไตล์ (style transfer)** ซึ่งใช้ **ภาพเนื้อหา (content image)** และวาดใหม่ในสไตล์ที่แตกต่าง โดยใช้ฟิลเตอร์จาก **ภาพสไตล์ (style image)**

วิธีการทำงานคือ:
* เราเริ่มต้นด้วยภาพสุ่ม (หรือภาพเนื้อหา แต่เพื่อความเข้าใจง่าย เราเริ่มจากภาพสุ่ม)
* เป้าหมายของเราคือการสร้างภาพที่ใกล้เคียงกับทั้งภาพเนื้อหาและภาพสไตล์ ซึ่งจะถูกกำหนดโดยฟังก์ชัน loss สองตัว:
   - **Content loss** คำนวณจากคุณลักษณะที่ CNN สกัดจากภาพปัจจุบันและภาพเนื้อหาในบางเลเยอร์
   - **Style loss** คำนวณระหว่างภาพปัจจุบันและภาพสไตล์โดยใช้เมทริกซ์แกรม (รายละเอียดเพิ่มเติมใน [สมุดบันทึกตัวอย่าง](StyleTransfer.ipynb))
* เพื่อทำให้ภาพเรียบขึ้นและลดสัญญาณรบกวน เราเพิ่ม **Variation loss** ซึ่งคำนวณระยะทางเฉลี่ยระหว่างพิกเซลที่อยู่ติดกัน
* วงจรการปรับแต่งหลักจะปรับภาพปัจจุบันโดยใช้ gradient descent (หรืออัลกอริทึมการปรับแต่งอื่นๆ) เพื่อลด total loss ซึ่งเป็นผลรวมแบบถ่วงน้ำหนักของ loss ทั้งสาม

## ✍️ ตัวอย่าง: [Style Transfer](StyleTransfer.ipynb)

## [แบบทดสอบหลังเรียน](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/210)

## สรุป

ในบทเรียนนี้ คุณได้เรียนรู้เกี่ยวกับ GAN และวิธีการฝึกฝน นอกจากนี้คุณยังได้เรียนรู้เกี่ยวกับความท้าทายพิเศษที่เครือข่ายประสาทประเภทนี้อาจเผชิญ และกลยุทธ์บางอย่างในการก้าวข้ามปัญหาเหล่านั้น

## 🚀 ความท้าทาย

ลองทำ [สมุดบันทึก Style Transfer](StyleTransfer.ipynb) โดยใช้ภาพของคุณเอง

## การทบทวนและการศึกษาด้วยตนเอง

สำหรับการอ้างอิง อ่านเพิ่มเติมเกี่ยวกับ GAN ได้จากแหล่งข้อมูลเหล่านี้:

* Marco Pasini, [10 Lessons I Learned Training GANs for one Year](https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628)
* [StyleGAN](https://en.wikipedia.org/wiki/StyleGAN), สถาปัตยกรรม GAN ที่ถือเป็นมาตรฐาน
* [Creating Generative Art using GANs on Azure ML](https://soshnikov.com/scienceart/creating-generative-art-using-gan-on-azureml/)

## งานที่ได้รับมอบหมาย

กลับไปที่สมุดบันทึกสองเล่มที่เกี่ยวข้องกับบทเรียนนี้และฝึก GAN ใหม่โดยใช้ภาพของคุณเอง คุณสามารถสร้างอะไรได้บ้าง?

---

**ข้อจำกัดความรับผิดชอบ**:  
เอกสารนี้ได้รับการแปลโดยใช้บริการแปลภาษา AI [Co-op Translator](https://github.com/Azure/co-op-translator) แม้ว่าเราจะพยายามให้การแปลมีความถูกต้อง แต่โปรดทราบว่าการแปลอัตโนมัติอาจมีข้อผิดพลาดหรือความไม่แม่นยำ เอกสารต้นฉบับในภาษาต้นทางควรถือเป็นแหล่งข้อมูลที่เชื่อถือได้ สำหรับข้อมูลที่สำคัญ ขอแนะนำให้ใช้บริการแปลภาษามนุษย์มืออาชีพ เราจะไม่รับผิดชอบต่อความเข้าใจผิดหรือการตีความที่ผิดพลาดซึ่งเกิดจากการใช้การแปลนี้