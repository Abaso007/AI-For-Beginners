<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "0b306c04f5337b6e7430e5c0b16bb5c0",
  "translation_date": "2025-08-26T09:05:25+00:00",
  "source_file": "lessons/4-ComputerVision/09-Autoencoders/README.md",
  "language_code": "bn"
}
-->
# অটোএনকোডার

সিএনএন প্রশিক্ষণের সময়, একটি বড় সমস্যা হলো প্রচুর লেবেলযুক্ত ডেটার প্রয়োজন হয়। উদাহরণস্বরূপ, ইমেজ ক্লাসিফিকেশনের ক্ষেত্রে, আমাদের ইমেজগুলোকে বিভিন্ন শ্রেণিতে ভাগ করতে হয়, যা একটি ম্যানুয়াল প্রচেষ্টা।

## [পূর্ব-লেকচার কুইজ](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/109)

তবে, আমরা সিএনএন ফিচার এক্সট্রাক্টর প্রশিক্ষণের জন্য কাঁচা (লেবেলবিহীন) ডেটা ব্যবহার করতে চাইতে পারি, যাকে **স্ব-পরিচালিত শেখা** (self-supervised learning) বলা হয়। লেবেলের পরিবর্তে, আমরা প্রশিক্ষণের জন্য ইমেজগুলোকে নেটওয়ার্কের ইনপুট এবং আউটপুট উভয় হিসেবেই ব্যবহার করব। **অটোএনকোডার** এর মূল ধারণা হলো, আমরা একটি **এনকোডার নেটওয়ার্ক** ব্যবহার করব যা ইনপুট ইমেজকে কিছু **ল্যাটেন্ট স্পেস**-এ রূপান্তর করবে (সাধারণত এটি একটি ছোট আকারের ভেক্টর), তারপর একটি **ডিকোডার নেটওয়ার্ক**, যার লক্ষ্য হবে মূল ইমেজটি পুনর্গঠন করা।

> ✅ একটি [অটোএনকোডার](https://wikipedia.org/wiki/Autoencoder) হলো "এক ধরনের কৃত্রিম নিউরাল নেটওয়ার্ক যা লেবেলবিহীন ডেটার কার্যকর কোডিং শিখতে ব্যবহৃত হয়।"

যেহেতু আমরা অটোএনকোডারকে মূল ইমেজ থেকে যতটা সম্ভব তথ্য ধারণ করতে প্রশিক্ষণ দিচ্ছি, যাতে সঠিকভাবে পুনর্গঠন করা যায়, নেটওয়ার্কটি ইনপুট ইমেজগুলোর সেরা **এম্বেডিং** খুঁজে বের করার চেষ্টা করে যা অর্থপূর্ণ তথ্য ধারণ করে।

![অটোএনকোডার ডায়াগ্রাম](../../../../../translated_images/autoencoder_schema.5e6fc9ad98a5eb6197f3513cf3baf4dfbe1389a6ae74daebda64de9f1c99f142.bn.jpg)

> চিত্র [Keras ব্লগ](https://blog.keras.io/building-autoencoders-in-keras.html) থেকে

## অটোএনকোডার ব্যবহারের পরিস্থিতি

মূল ইমেজ পুনর্গঠন নিজে থেকে খুব বেশি কার্যকর মনে না হলেও, কিছু পরিস্থিতিতে অটোএনকোডার বিশেষভাবে কার্যকর:

* **ভিজ্যুয়ালাইজেশনের জন্য ইমেজের মাত্রা হ্রাস করা** বা **ইমেজ এম্বেডিং প্রশিক্ষণ**। সাধারণত অটোএনকোডার PCA-এর চেয়ে ভালো ফলাফল দেয়, কারণ এটি ইমেজের স্থানিক প্রকৃতি এবং স্তরবিন্যাস বৈশিষ্ট্যগুলিকে বিবেচনায় নেয়।
* **ডিনয়জিং**, অর্থাৎ ইমেজ থেকে শব্দ (noise) সরানো। শব্দ অনেক অপ্রয়োজনীয় তথ্য বহন করে, যা অটোএনকোডার তুলনামূলক ছোট ল্যাটেন্ট স্পেসে ধারণ করতে পারে না, ফলে এটি কেবল গুরুত্বপূর্ণ অংশটি ধারণ করে। ডিনয়জার প্রশিক্ষণের সময়, আমরা মূল ইমেজ দিয়ে শুরু করি এবং কৃত্রিমভাবে যোগ করা শব্দসহ ইমেজগুলোকে অটোএনকোডারের ইনপুট হিসেবে ব্যবহার করি।
* **সুপার-রেজোলিউশন**, অর্থাৎ ইমেজের রেজোলিউশন বৃদ্ধি করা। আমরা উচ্চ-রেজোলিউশনের ইমেজ দিয়ে শুরু করি এবং নিম্ন রেজোলিউশনের ইমেজকে অটোএনকোডারের ইনপুট হিসেবে ব্যবহার করি।
* **জেনারেটিভ মডেল**। একবার অটোএনকোডার প্রশিক্ষণ দেওয়া হলে, ডিকোডার অংশটি এলোমেলো ল্যাটেন্ট ভেক্টর থেকে নতুন অবজেক্ট তৈরি করতে ব্যবহার করা যায়।

## ভ্যারিয়েশনাল অটোএনকোডার (VAE)

প্রথাগত অটোএনকোডার ইনপুট ডেটার মাত্রা হ্রাস করে এবং ইনপুট ইমেজের গুরুত্বপূর্ণ বৈশিষ্ট্যগুলো বের করে। তবে, ল্যাটেন্ট ভেক্টরগুলো প্রায়ই খুব অর্থবহ হয় না। উদাহরণস্বরূপ, MNIST ডেটাসেটের ক্ষেত্রে, বিভিন্ন ল্যাটেন্ট ভেক্টরের সাথে কোন সংখ্যাগুলো মিলে যায় তা বোঝা সহজ নয়, কারণ কাছাকাছি ল্যাটেন্ট ভেক্টরগুলো প্রয়োজনীয়ভাবে একই সংখ্যার প্রতিনিধিত্ব করে না।

অন্যদিকে, *জেনারেটিভ* মডেল প্রশিক্ষণের জন্য ল্যাটেন্ট স্পেস সম্পর্কে কিছুটা বোঝাপড়া থাকা ভালো। এই ধারণা আমাদের **ভ্যারিয়েশনাল অটোএনকোডার** (VAE)-এর দিকে নিয়ে যায়।

VAE হলো এমন একটি অটোএনকোডার যা ল্যাটেন্ট প্যারামিটারগুলোর *পরিসংখ্যানগত বণ্টন* (statistical distribution) পূর্বাভাস করতে শেখে, যাকে **ল্যাটেন্ট ডিস্ট্রিবিউশন** বলা হয়। উদাহরণস্বরূপ, আমরা চাইতে পারি যে ল্যাটেন্ট ভেক্টরগুলো z<sub>mean</sub> এবং z<sub>sigma</sub> (যেখানে mean এবং standard deviation হলো নির্দিষ্ট মাত্রার ভেক্টর) এর সাথে স্বাভাবিকভাবে বিতরণিত হোক। VAE-তে এনকোডার এই প্যারামিটারগুলো পূর্বাভাস করতে শেখে, এবং তারপর ডিকোডার এই বণ্টন থেকে একটি এলোমেলো ভেক্টর নিয়ে অবজেক্ট পুনর্গঠন করে।

সংক্ষেপে:

 * ইনপুট ভেক্টর থেকে, আমরা `z_mean` এবং `z_log_sigma` পূর্বাভাস করি (স্ট্যান্ডার্ড ডেভিয়েশন নিজে পূর্বাভাস করার পরিবর্তে, আমরা এর লগারিদম পূর্বাভাস করি)
 * আমরা বণ্টন N(z<sub>mean</sub>,exp(z<sub>log\_sigma</sub>)) থেকে একটি ভেক্টর `sample` নিই
 * ডিকোডার `sample` কে ইনপুট ভেক্টর হিসেবে ব্যবহার করে মূল ইমেজটি ডিকোড করার চেষ্টা করে

 <img src="images/vae.png" width="50%">

> চিত্র [এই ব্লগ পোস্ট](https://ijdykeman.github.io/ml/2016/12/21/cvae.html) থেকে, লেখক: আইজাক ডাইকম্যান

ভ্যারিয়েশনাল অটোএনকোডার একটি জটিল লস ফাংশন ব্যবহার করে, যা দুটি অংশ নিয়ে গঠিত:

* **পুনর্গঠন লস** হলো সেই লস ফাংশন যা দেখায় পুনর্গঠিত ইমেজ কতটা লক্ষ্য ইমেজের কাছাকাছি (এটি Mean Squared Error বা MSE হতে পারে)। এটি সাধারণ অটোএনকোডারের মতোই লস ফাংশন।
* **KL লস**, যা নিশ্চিত করে যে ল্যাটেন্ট ভেরিয়েবল বণ্টন স্বাভাবিক বণ্টনের কাছাকাছি থাকে। এটি [কুলব্যাক-লেইবলার ডাইভারজেন্স](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained)-এর ধারণার উপর ভিত্তি করে তৈরি - এটি দুটি পরিসংখ্যানগত বণ্টনের সাদৃশ্য পরিমাপের একটি মেট্রিক।

VAE-এর একটি গুরুত্বপূর্ণ সুবিধা হলো এটি আমাদের নতুন ইমেজ তুলনামূলক সহজে তৈরি করতে দেয়, কারণ আমরা জানি কোন বণ্টন থেকে ল্যাটেন্ট ভেক্টরগুলো নিতে হবে। উদাহরণস্বরূপ, যদি আমরা MNIST-এ 2D ল্যাটেন্ট ভেক্টর দিয়ে VAE প্রশিক্ষণ দিই, তবে আমরা ল্যাটেন্ট ভেক্টরের উপাদানগুলো পরিবর্তন করে বিভিন্ন সংখ্যা পেতে পারি:

<img alt="vaemnist" src="images/vaemnist.png" width="50%"/>

> চিত্র [দিমিত্রি সশনিকভ](http://soshnikov.com) দ্বারা

লক্ষ্য করুন কিভাবে ইমেজগুলো একে অপরের সাথে মিশে যাচ্ছে, কারণ আমরা ল্যাটেন্ট প্যারামিটার স্পেসের বিভিন্ন অংশ থেকে ল্যাটেন্ট ভেক্টর নিচ্ছি। আমরা এই স্পেসটি 2D-তে ভিজ্যুয়ালাইজও করতে পারি:

<img alt="vaemnist cluster" src="images/vaemnist-diag.png" width="50%"/> 

> চিত্র [দিমিত্রি সশনিকভ](http://soshnikov.com) দ্বারা

## ✍️ অনুশীলন: অটোএনকোডার

এই সম্পর্কিত নোটবুকগুলোতে অটোএনকোডার সম্পর্কে আরও জানুন:

* [টেনসরফ্লোতে অটোএনকোডার](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb)
* [পাইটোর্চে অটোএনকোডার](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoEncodersPyTorch.ipynb)

## অটোএনকোডারের বৈশিষ্ট্য

* **ডেটা নির্দিষ্ট** - এগুলো কেবল সেই ধরনের ইমেজের সাথে ভালো কাজ করে, যেগুলো দিয়ে এগুলো প্রশিক্ষিত হয়েছে। উদাহরণস্বরূপ, যদি আমরা একটি সুপার-রেজোলিউশন নেটওয়ার্ক ফুলের উপর প্রশিক্ষণ দিই, এটি পোর্ট্রেটের উপর ভালো কাজ করবে না। কারণ নেটওয়ার্কটি প্রশিক্ষণ ডেটাসেট থেকে শেখা বৈশিষ্ট্যগুলো ব্যবহার করে উচ্চ রেজোলিউশনের ইমেজ তৈরি করতে পারে।
* **লসি** - পুনর্গঠিত ইমেজটি মূল ইমেজের মতো নয়। লসের প্রকৃতি নির্ধারিত হয় প্রশিক্ষণের সময় ব্যবহৃত *লস ফাংশন* দ্বারা।
* **লেবেলবিহীন ডেটা**-তে কাজ করে

## [পোস্ট-লেকচার কুইজ](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/209)

## উপসংহার

এই পাঠে, আপনি একজন এআই বিজ্ঞানীর জন্য উপলব্ধ বিভিন্ন ধরনের অটোএনকোডার সম্পর্কে শিখেছেন। আপনি এগুলো কীভাবে তৈরি করবেন এবং কীভাবে ইমেজ পুনর্গঠনের জন্য ব্যবহার করবেন তা শিখেছেন। আপনি VAE এবং এটি ব্যবহার করে নতুন ইমেজ তৈরি করার পদ্ধতিও শিখেছেন।

## 🚀 চ্যালেঞ্জ

এই পাঠে, আপনি ইমেজের জন্য অটোএনকোডার ব্যবহারের কথা শিখেছেন। তবে এগুলো সঙ্গীতের জন্যও ব্যবহার করা যেতে পারে! ম্যাজেন্টা প্রকল্পের [MusicVAE](https://magenta.tensorflow.org/music-vae) প্রকল্পটি দেখুন, যা সঙ্গীত পুনর্গঠনের জন্য অটোএনকোডার ব্যবহার করে। এই লাইব্রেরি দিয়ে কিছু [পরীক্ষা](https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/Multitrack_MusicVAE.ipynb) করুন এবং দেখুন আপনি কী তৈরি করতে পারেন।

## [পোস্ট-লেকচার কুইজ](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/208)

## পর্যালোচনা ও স্ব-অধ্যয়ন

তথ্যের জন্য, এই সম্পদগুলোতে অটোএনকোডার সম্পর্কে আরও পড়ুন:

* [Keras-এ অটোএনকোডার তৈরি](https://blog.keras.io/building-autoencoders-in-keras.html)
* [NeuroHive-এ ব্লগ পোস্ট](https://neurohive.io/ru/osnovy-data-science/variacionnyj-avtojenkoder-vae/)
* [ভ্যারিয়েশনাল অটোএনকোডার ব্যাখ্যা](https://kvfrans.com/variational-autoencoders-explained/)
* [কন্ডিশনাল ভ্যারিয়েশনাল অটোএনকোডার](https://ijdykeman.github.io/ml/2016/12/21/cvae.html)

## অ্যাসাইনমেন্ট

[এই নোটবুকটি](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb) ব্যবহার করে টেনসরফ্লোতে 'টাস্ক' অংশটি খুঁজুন - এটি আপনার অ্যাসাইনমেন্ট হিসেবে ব্যবহার করুন।

**অস্বীকৃতি**:  
এই নথিটি AI অনুবাদ পরিষেবা [Co-op Translator](https://github.com/Azure/co-op-translator) ব্যবহার করে অনুবাদ করা হয়েছে। আমরা যথাসম্ভব সঠিক অনুবাদের চেষ্টা করি, তবে অনুগ্রহ করে মনে রাখবেন যে স্বয়ংক্রিয় অনুবাদে ত্রুটি বা অসঙ্গতি থাকতে পারে। নথিটির মূল ভাষায় লেখা সংস্করণটিকেই প্রামাণিক উৎস হিসেবে বিবেচনা করা উচিত। গুরুত্বপূর্ণ তথ্যের জন্য, পেশাদার মানব অনুবাদ ব্যবহার করার পরামর্শ দেওয়া হয়। এই অনুবাদ ব্যবহারের ফলে সৃষ্ট কোনো ভুল বোঝাবুঝি বা ভুল ব্যাখ্যার জন্য আমরা দায়ী নই।