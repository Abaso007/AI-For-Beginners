<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "4522e22e150be0845e03aa41209a39d5",
  "translation_date": "2025-08-26T08:25:06+00:00",
  "source_file": "lessons/5-NLP/13-TextRep/README.md",
  "language_code": "bn"
}
-->
# টেক্সটকে টেনসরে উপস্থাপন করা

## [পূর্ব-লেকচার কুইজ](https://ff-quizzes.netlify.app/en/ai/quiz/25)

## টেক্সট শ্রেণীবিন্যাস

এই অংশের প্রথম ভাগে আমরা **টেক্সট শ্রেণীবিন্যাস** কাজের উপর মনোযোগ দেব। আমরা [AG News](https://www.kaggle.com/amananandrai/ag-news-classification-dataset) ডেটাসেট ব্যবহার করব, যেখানে নিম্নলিখিত ধরনের সংবাদ নিবন্ধ রয়েছে:

* বিভাগ: বিজ্ঞান/প্রযুক্তি  
* শিরোনাম: Ky. কোম্পানি পেপটাইড গবেষণার জন্য অনুদান জিতেছে (AP)  
* বডি: AP - লুইসভিল বিশ্ববিদ্যালয়ের একজন রসায়ন গবেষকের দ্বারা প্রতিষ্ঠিত একটি কোম্পানি একটি অনুদান জিতেছে...

আমাদের লক্ষ্য হবে টেক্সটের ভিত্তিতে সংবাদটি কোন বিভাগে পড়ে তা শ্রেণীবদ্ধ করা।

## টেক্সট উপস্থাপন

যদি আমরা নিউরাল নেটওয়ার্ক ব্যবহার করে প্রাকৃতিক ভাষা প্রক্রিয়াকরণ (NLP) কাজ সমাধান করতে চাই, তবে আমাদের টেক্সটকে টেনসরে উপস্থাপন করার একটি পদ্ধতি প্রয়োজন। কম্পিউটার ইতিমধ্যেই ASCII বা UTF-8 এর মতো এনকোডিং ব্যবহার করে আপনার স্ক্রিনে ফন্টে মানচিত্রিত সংখ্যার মাধ্যমে টেক্সট চরিত্র উপস্থাপন করে।

<img alt="চরিত্রকে ASCII এবং বাইনারি উপস্থাপনার সাথে মানচিত্রিত করার ডায়াগ্রাম দেখানো চিত্র" src="images/ascii-character-map.png" width="50%"/>

> [চিত্র উৎস](https://www.seobility.net/en/wiki/ASCII)

মানুষ হিসেবে আমরা বুঝি প্রতিটি অক্ষর **কী বোঝায়**, এবং কীভাবে সমস্ত অক্ষর একত্রে একটি বাক্যের শব্দ তৈরি করে। তবে, কম্পিউটার নিজেরাই এমন বোঝাপড়া রাখে না, এবং নিউরাল নেটওয়ার্ককে প্রশিক্ষণের সময় অর্থ শিখতে হয়।

তাই, টেক্সট উপস্থাপনের জন্য আমরা বিভিন্ন পদ্ধতি ব্যবহার করতে পারি:

* **চরিত্র-স্তরের উপস্থাপন**, যেখানে আমরা প্রতিটি চরিত্রকে একটি সংখ্যা হিসেবে বিবেচনা করে টেক্সট উপস্থাপন করি। যদি আমাদের টেক্সট কর্পাসে *C* ভিন্ন চরিত্র থাকে, তবে শব্দ *Hello* কে 5x*C* টেনসর হিসেবে উপস্থাপন করা হবে। প্রতিটি অক্ষর এক-হট এনকোডিংয়ে একটি টেনসর কলামের সাথে সম্পর্কিত হবে।  
* **শব্দ-স্তরের উপস্থাপন**, যেখানে আমরা আমাদের টেক্সটের সমস্ত শব্দের একটি **ভোকাবুলারি** তৈরি করি এবং তারপর এক-হট এনকোডিং ব্যবহার করে শব্দ উপস্থাপন করি। এই পদ্ধতিটি কিছুটা ভালো, কারণ প্রতিটি অক্ষর নিজের মধ্যে খুব বেশি অর্থ বহন করে না, এবং উচ্চ-স্তরের অর্থপূর্ণ ধারণা - শব্দ - ব্যবহার করে আমরা নিউরাল নেটওয়ার্কের জন্য কাজটি সহজ করি। তবে, বৃহৎ ডিকশনারি আকারের কারণে আমাদের উচ্চ-মাত্রার স্পার্স টেনসরের সাথে কাজ করতে হয়।

যে কোনো উপস্থাপনের জন্য, প্রথমে আমাদের টেক্সটকে **টোকেন**গুলোর একটি ক্রমে রূপান্তর করতে হবে, যেখানে একটি টোকেন একটি চরিত্র, একটি শব্দ, বা কখনও কখনও একটি শব্দের অংশ হতে পারে। তারপর, আমরা টোকেনকে একটি সংখ্যা হিসেবে রূপান্তর করি, সাধারণত **ভোকাবুলারি** ব্যবহার করে, এবং এই সংখ্যাটি এক-হট এনকোডিং ব্যবহার করে নিউরাল নেটওয়ার্কে খাওয়ানো যেতে পারে।

## এন-গ্রাম

প্রাকৃতিক ভাষায়, শব্দের সঠিক অর্থ কেবল প্রসঙ্গেই নির্ধারণ করা যায়। উদাহরণস্বরূপ, *neural network* এবং *fishing network* এর অর্থ সম্পূর্ণ ভিন্ন। এটি বিবেচনায় নেওয়ার একটি উপায় হল আমাদের মডেলটি শব্দ জোড়ার উপর ভিত্তি করে তৈরি করা এবং শব্দ জোড়াগুলোকে আলাদা ভোকাবুলারি টোকেন হিসেবে বিবেচনা করা। এইভাবে, বাক্য *I like to go fishing* নিম্নলিখিত টোকেন ক্রম দ্বারা উপস্থাপিত হবে: *I like*, *like to*, *to go*, *go fishing*। এই পদ্ধতির সমস্যা হল ডিকশনারি আকার উল্লেখযোগ্যভাবে বৃদ্ধি পায়, এবং *go fishing* এবং *go shopping* এর মতো সংমিশ্রণগুলো ভিন্ন টোকেন দ্বারা উপস্থাপিত হয়, যা একই ক্রিয়াপদ থাকা সত্ত্বেও কোনো অর্থগত সাদৃশ্য ভাগ করে না।

কিছু ক্ষেত্রে, আমরা তিনটি শব্দের সংমিশ্রণ -- ট্রাই-গ্রাম -- ব্যবহার করার কথা বিবেচনা করতে পারি। তাই এই পদ্ধতিকে প্রায়ই **এন-গ্রাম** বলা হয়। এছাড়াও, চরিত্র-স্তরের উপস্থাপনের সাথে এন-গ্রাম ব্যবহার করাও অর্থবহ হতে পারে, যেখানে এন-গ্রাম প্রায় বিভিন্ন শব্দাংশের সাথে মিলে যায়।

## ব্যাগ-অফ-ওয়ার্ডস এবং TF/IDF

যখন টেক্সট শ্রেণীবিন্যাসের মতো কাজ সমাধান করতে হয়, তখন আমাদের একটি নির্দিষ্ট আকারের ভেক্টর দ্বারা টেক্সট উপস্থাপন করতে হয়, যা আমরা চূড়ান্ত ঘন শ্রেণীবিন্যাসকারীতে ইনপুট হিসেবে ব্যবহার করব। এটি করার সবচেয়ে সহজ উপায় হল সমস্ত পৃথক শব্দ উপস্থাপনাগুলোকে একত্রিত করা, যেমন তাদের যোগ করে। যদি আমরা প্রতিটি শব্দের এক-হট এনকোডিং যোগ করি, তবে আমরা একটি ফ্রিকোয়েন্সি ভেক্টর পাব, যা দেখায় যে টেক্সটের মধ্যে প্রতিটি শব্দ কতবার উপস্থিত হয়েছে। টেক্সটের এই ধরনের উপস্থাপনাকে **ব্যাগ অফ ওয়ার্ডস** (BoW) বলা হয়।

<img src="images/bow.png" width="90%"/>

> লেখকের তৈরি চিত্র

একটি BoW মূলত কোন শব্দগুলো টেক্সটে উপস্থিত এবং কোন পরিমাণে তা উপস্থাপন করে, যা সত্যিই টেক্সটটি কী সম্পর্কে তা বোঝার একটি ভালো ইঙ্গিত হতে পারে। উদাহরণস্বরূপ, রাজনীতির উপর একটি সংবাদ নিবন্ধে *president* এবং *country* এর মতো শব্দ থাকতে পারে, যেখানে একটি বৈজ্ঞানিক প্রকাশনায় *collider*, *discovered* ইত্যাদি থাকতে পারে। তাই, অনেক ক্ষেত্রে শব্দের ফ্রিকোয়েন্সি টেক্সটের বিষয়বস্তু বোঝার একটি ভালো সূচক হতে পারে।

BoW-এর সমস্যা হল কিছু সাধারণ শব্দ, যেমন *and*, *is* ইত্যাদি বেশিরভাগ টেক্সটে উপস্থিত হয় এবং তাদের ফ্রিকোয়েন্সি সর্বোচ্চ হয়, যা সত্যিই গুরুত্বপূর্ণ শব্দগুলোকে আড়াল করে। আমরা এই শব্দগুলোর গুরুত্ব কমাতে পারি যদি আমরা পুরো ডকুমেন্ট সংগ্রহে শব্দগুলো কতবার উপস্থিত হয় তা বিবেচনায় নিই। এটি TF/IDF পদ্ধতির মূল ধারণা, যা এই পাঠের সাথে সংযুক্ত নোটবুকে আরও বিস্তারিতভাবে আলোচনা করা হয়েছে।

তবে, এই পদ্ধতিগুলো টেক্সটের **অর্থ** পুরোপুরি বিবেচনায় নিতে পারে না। এটি করার জন্য আমাদের আরও শক্তিশালী নিউরাল নেটওয়ার্ক মডেলের প্রয়োজন, যা আমরা এই অংশে পরে আলোচনা করব।

## ✍️ অনুশীলন: টেক্সট উপস্থাপন

নিম্নলিখিত নোটবুকে আপনার শেখা চালিয়ে যান:

* [PyTorch দিয়ে টেক্সট উপস্থাপন](../../../../../lessons/5-NLP/13-TextRep/TextRepresentationPyTorch.ipynb)  
* [TensorFlow দিয়ে টেক্সট উপস্থাপন](../../../../../lessons/5-NLP/13-TextRep/TextRepresentationTF.ipynb)  

## উপসংহার

এখন পর্যন্ত, আমরা এমন কৌশলগুলো অধ্যয়ন করেছি যা বিভিন্ন শব্দের ফ্রিকোয়েন্সি ওজন যোগ করতে পারে। তবে, এগুলো অর্থ বা ক্রম উপস্থাপন করতে অক্ষম। বিখ্যাত ভাষাবিদ জে. আর. ফার্থ ১৯৩৫ সালে বলেছিলেন, "একটি শব্দের সম্পূর্ণ অর্থ সর্বদা প্রসঙ্গগত, এবং প্রসঙ্গ ছাড়া অর্থের কোনো অধ্যয়নকে গুরুত্ব সহকারে নেওয়া যায় না।" আমরা এই কোর্সে পরে শিখব কীভাবে ভাষা মডেলিং ব্যবহার করে টেক্সট থেকে প্রসঙ্গগত তথ্য ধারণ করা যায়।

## 🚀 চ্যালেঞ্জ

ব্যাগ-অফ-ওয়ার্ডস এবং বিভিন্ন ডেটা মডেল ব্যবহার করে কিছু অন্যান্য অনুশীলন চেষ্টা করুন। আপনি এই [কাগল প্রতিযোগিতা](https://www.kaggle.com/competitions/word2vec-nlp-tutorial/overview/part-1-for-beginners-bag-of-words) থেকে অনুপ্রাণিত হতে পারেন।

## [পোস্ট-লেকচার কুইজ](https://ff-quizzes.netlify.app/en/ai/quiz/26)

## পুনরালোচনা ও স্ব-অধ্যয়ন

[Microsoft Learn](https://docs.microsoft.com/learn/modules/intro-natural-language-processing-pytorch/?WT.mc_id=academic-77998-cacaste) এ টেক্সট এমবেডিং এবং ব্যাগ-অফ-ওয়ার্ডস কৌশল নিয়ে আপনার দক্ষতা অনুশীলন করুন।

## [অ্যাসাইনমেন্ট: নোটবুক](assignment.md)  

**অস্বীকৃতি**:  
এই নথিটি AI অনুবাদ পরিষেবা [Co-op Translator](https://github.com/Azure/co-op-translator) ব্যবহার করে অনুবাদ করা হয়েছে। আমরা যথাসাধ্য সঠিকতার জন্য চেষ্টা করি, তবে অনুগ্রহ করে মনে রাখবেন যে স্বয়ংক্রিয় অনুবাদে ত্রুটি বা অসঙ্গতি থাকতে পারে। এর মূল ভাষায় থাকা নথিটিকে প্রামাণিক উৎস হিসেবে বিবেচনা করা উচিত। গুরুত্বপূর্ণ তথ্যের জন্য, পেশাদার মানব অনুবাদ সুপারিশ করা হয়। এই অনুবাদ ব্যবহারের ফলে কোনো ভুল বোঝাবুঝি বা ভুল ব্যাখ্যা হলে আমরা দায়বদ্ধ থাকব না।