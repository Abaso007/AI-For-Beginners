<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "0b306c04f5337b6e7430e5c0b16bb5c0",
  "translation_date": "2025-08-25T22:31:08+00:00",
  "source_file": "lessons/4-ComputerVision/09-Autoencoders/README.md",
  "language_code": "sr"
}
-->
# Аутоенкодери

При тренингу CNN-а, један од проблема је то што нам је потребно много означених података. У случају класификације слика, морамо ручно раздвојити слике у различите класе.

## [Квиз пре предавања](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/109)

Међутим, можда желимо да користимо необрађене (неозначене) податке за тренинг CNN екстрактора карактеристика, што се назива **само-надгледано учење**. Уместо ознака, користићемо тренинг слике као и улаз и излаз мреже. Главна идеја **аутоенкодера** је да имамо **енкодер мрежу** која претвара улазну слику у неки **латентни простор** (обично је то само вектор мање величине), а затим **декодер мрежу**, чији је циљ реконструкција оригиналне слике.

> ✅ [Аутоенкодер](https://wikipedia.org/wiki/Autoencoder) је "тип вештачке неуронске мреже која се користи за учење ефикасног кодирања неозначених података."

Пошто тренирамо аутоенкодер да ухвати што више информација из оригиналне слике ради тачне реконструкције, мрежа покушава да пронађе најбоље **уграђивање** улазних слика како би ухватила њихово значење.

![Шема аутоенкодера](../../../../../translated_images/autoencoder_schema.5e6fc9ad98a5eb6197f3513cf3baf4dfbe1389a6ae74daebda64de9f1c99f142.sr.jpg)

> Слика са [Keras блога](https://blog.keras.io/building-autoencoders-in-keras.html)

## Сценарији за коришћење аутоенкодера

Иако реконструкција оригиналних слика сама по себи не изгледа корисно, постоји неколико сценарија где су аутоенкодери посебно корисни:

* **Смањење димензије слика ради визуализације** или **тренинг уграђивања слика**. Обично аутоенкодери дају боље резултате од PCA, јер узимају у обзир просторну природу слика и хијерархијске карактеристике.
* **Уклањање шума**, тј. уклањање шума са слике. Пошто шум носи много бескорисних информација, аутоенкодер не може све то да уклопи у релативно мали латентни простор, па хвата само важан део слике. При тренингу за уклањање шума, почињемо са оригиналним сликама, а користимо слике са вештачки додатим шумом као улаз за аутоенкодер.
* **Супер-резолуција**, повећање резолуције слике. Почињемо са сликама високе резолуције, а користимо слике са нижом резолуцијом као улаз за аутоенкодер.
* **Генеративни модели**. Када тренирамо аутоенкодер, део декодера може се користити за креирање нових објеката почевши од случајних латентних вектора.

## Варијациони аутоенкодери (VAE)

Традиционални аутоенкодери на неки начин смањују димензију улазних података, откривајући важне карактеристике улазних слика. Међутим, латентни вектори често немају много смисла. Другим речима, узимајући MNIST датасет као пример, откривање који бројеви одговарају различитим латентним векторима није лак задатак, јер блиски латентни вектори не морају нужно одговарати истим бројевима.

С друге стране, за тренинг *генеративних* модела боље је имати неко разумевање латентног простора. Ова идеја нас води до **варијационог аутоенкодера** (VAE).

VAE је аутоенкодер који учи да предвиђа *статистичку дистрибуцију* латентних параметара, такозвану **латентну дистрибуцију**. На пример, можемо желети да латентни вектори буду нормално распоређени са неком средњом вредношћу z<sub>mean</sub> и стандардном девијацијом z<sub>sigma</sub> (и средња вредност и стандардна девијација су вектори неке димензије d). Енкодер у VAE учи да предвиђа те параметре, а затим декодер узима случајни вектор из те дистрибуције да реконструише објекат.

Укратко:

 * Из улазног вектора предвиђамо `z_mean` и `z_log_sigma` (уместо да предвиђамо саму стандардну девијацију, предвиђамо њен логаритам)
 * Узимамо узорак вектора `sample` из дистрибуције N(z<sub>mean</sub>,exp(z<sub>log\_sigma</sub>))
 * Декодер покушава да декодира оригиналну слику користећи `sample` као улазни вектор

 <img src="images/vae.png" width="50%">

> Слика из [овог блога](https://ijdykeman.github.io/ml/2016/12/21/cvae.html) аутора Исака Дајкемана

Варијациони аутоенкодери користе сложену функцију губитка која се састоји из два дела:

* **Губитак реконструкције** је функција губитка која показује колико је реконструисана слика близу циљу (може бити Mean Squared Error, или MSE). То је иста функција губитка као код нормалних аутоенкодера.
* **KL губитак**, који осигурава да дистрибуција латентних променљивих остане близу нормалне дистрибуције. Заснован је на концепту [Кулбак-Лајблерове дивергенције](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained) - метрици за процену сличности две статистичке дистрибуције.

Једна важна предност VAE-а је то што нам омогућава да релативно лако генеришемо нове слике, јер знамо из које дистрибуције узимамо узорке латентних вектора. На пример, ако тренирамо VAE са 2D латентним вектором на MNIST-у, можемо затим мењати компоненте латентног вектора да добијемо различите бројеве:

<img alt="vaemnist" src="images/vaemnist.png" width="50%"/>

> Слика аутора [Дмитрија Сошњикова](http://soshnikov.com)

Приметите како се слике међусобно стапају, док почињемо добијати латентне векторе из различитих делова латентног параметарског простора. Такође можемо визуализовати овај простор у 2D:

<img alt="vaemnist cluster" src="images/vaemnist-diag.png" width="50%"/> 

> Слика аутора [Дмитрија Сошњикова](http://soshnikov.com)

## ✍️ Вежбе: Аутоенкодери

Сазнајте више о аутоенкодерима у овим одговарајућим нотебуцима:

* [Аутоенкодери у TensorFlow-у](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb)
* [Аутоенкодери у PyTorch-у](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoEncodersPyTorch.ipynb)

## Карактеристике аутоенкодера

* **Специфични за податке** - добро раде само са типом слика на којима су тренирани. На пример, ако тренирамо мрежу за супер-резолуцију на цветовима, она неће добро радити на портретима. То је зато што мрежа може произвести слику више резолуције узимајући фине детаље из карактеристика научених из тренинг скупа.
* **Губитак информација** - реконструисана слика није иста као оригинална слика. Природа губитка дефинисана је *функцијом губитка* коришћеном током тренинга.
* Ради на **неозначеним подацима**

## [Квиз после предавања](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/209)

## Закључак

У овој лекцији, научили сте о различитим типовима аутоенкодера доступним AI научницима. Научили сте како да их изградите и како да их користите за реконструкцију слика. Такође сте научили о VAE-у и како да га користите за генерисање нових слика.

## 🚀 Изазов

У овој лекцији, научили сте о коришћењу аутоенкодера за слике. Али они се могу користити и за музику! Погледајте пројекат Magenta [MusicVAE](https://magenta.tensorflow.org/music-vae), који користи аутоенкодере за учење реконструкције музике. Урадите неке [експерименте](https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/Multitrack_MusicVAE.ipynb) са овом библиотеком да видите шта можете да креирате.

## [Квиз после предавања](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/208)

## Преглед и самостално учење

За референцу, прочитајте више о аутоенкодерима у овим ресурсима:

* [Изградња аутоенкодера у Keras-у](https://blog.keras.io/building-autoencoders-in-keras.html)
* [Блог пост на NeuroHive](https://neurohive.io/ru/osnovy-data-science/variacionnyj-avtojenkoder-vae/)
* [Објашњење варијационих аутоенкодера](https://kvfrans.com/variational-autoencoders-explained/)
* [Условни варијациони аутоенкодери](https://ijdykeman.github.io/ml/2016/12/21/cvae.html)

## Задатак

На крају [овог нотебука користећи TensorFlow](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb), наћи ћете 'задатак' - користите то као свој задатак.

**Одрицање од одговорности**:  
Овај документ је преведен коришћењем услуге за превођење помоћу вештачке интелигенције [Co-op Translator](https://github.com/Azure/co-op-translator). Иако настојимо да обезбедимо тачност, молимо вас да имате у виду да аутоматски преводи могу садржати грешке или нетачности. Оригинални документ на његовом изворном језику треба сматрати меродавним извором. За критичне информације препоручује се професионални превод од стране људског преводиоца. Не преузимамо одговорност за било каква погрешна тумачења или неспоразуме који могу настати услед коришћења овог превода.