<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f07c85bbf05a1f67505da98f4ecc124c",
  "translation_date": "2025-08-25T22:40:34+00:00",
  "source_file": "lessons/4-ComputerVision/10-GANs/README.md",
  "language_code": "sr"
}
-->
# Генеративне Адверзаријалне Мреже

У претходном делу, научили смо о **генеративним моделима**: моделима који могу да генеришу нове слике сличне онима из скупа за обуку. Варијациони аутоенкодер (VAE) је био добар пример генеративног модела.

## [Квиз пре предавања](https://ff-quizzes.netlify.app/en/ai/quiz/19)

Међутим, ако покушамо да генеришемо нешто заиста значајно, попут слике у разумној резолуцији, користећи VAE, видећемо да обука не конвергира добро. За овај случај, требало би да научимо о другој архитектури која је посебно усмерена на генеративне моделе - **Генеративне Адверзаријалне Мреже**, или GAN-ове.

Главна идеја GAN-а је да има две неуронске мреже које ће се обучавати једна против друге:

<img src="images/gan_architecture.png" width="70%"/>

> Слика од [Дмитрија Сошњикова](http://soshnikov.com)

> ✅ Мали речник:
> * **Генератор** је мрежа која узима неки случајни вектор и производи слику као резултат.
> * **Дискриминатор** је мрежа која узима слику и треба да одреди да ли је то права слика (из скупа за обуку) или је генерисана од стране генератора. У суштини, то је класификатор слика.

### Дискриминатор

Архитектура дискриминатора се не разликује од обичне мреже за класификацију слика. У најједноставнијем случају, то може бити потпуно повезан класификатор, али највероватније ће бити [конволуциона мрежа](../07-ConvNets/README.md).

> ✅ GAN заснован на конволуционим мрежама назива се [DCGAN](https://arxiv.org/pdf/1511.06434.pdf)

Дискриминатор CNN-а се састоји од следећих слојева: неколико конволуција+пулинга (са смањењем просторне величине) и једног или више потпуно повезаних слојева за добијање "векторa карактеристика", и завршног бинарног класификатора.

> ✅ 'Пулинг' у овом контексту је техника која смањује величину слике. "Пулинг слојеви смањују димензије података комбиновањем излаза кластера неурона у једном слоју у један неурон у следећем слоју." - [извор](https://wikipedia.org/wiki/Convolutional_neural_network#Pooling_layers)

### Генератор

Генератор је мало сложенији. Можете га сматрати обрнутим дискриминатором. Почевши од латентног вектора (уместо вектора карактеристика), он има потпуно повезан слој који га претвара у потребну величину/облик, након чега следе деконволуције+увећање. Ово је слично *декодеру* дела [аутоенкодера](../09-Autoencoders/README.md).

> ✅ Пошто је конволуциони слој имплементиран као линеарни филтер који пролази кроз слику, деконволуција је у суштини слична конволуцији и може се имплементирати користећи исту логику слоја.

<img src="images/gan_arch_detail.png" width="70%"/>

> Слика од [Дмитрија Сошњикова](http://soshnikov.com)

### Обука GAN-а

GAN-ови се називају **адверзаријалним** јер постоји стално надметање између генератора и дискриминатора. Током овог надметања, и генератор и дискриминатор се побољшавају, тако да мрежа учи да производи све боље и боље слике.

Обука се одвија у две фазе:

* **Обука дискриминатора**. Овај задатак је прилично једноставан: генеришемо серију слика помоћу генератора, означавајући их са 0, што означава лажну слику, и узимамо серију слика из улазног скупа података (са ознаком 1, права слика). Добијамо неки *губитак дискриминатора* и изводимо backprop.
* **Обука генератора**. Ово је мало сложеније, јер директно не знамо очекивани излаз за генератор. Узимамо целу GAN мрежу која се састоји од генератора праћеног дискриминатором, напајамо је неким случајним векторима и очекујемо да резултат буде 1 (што одговара правим сликама). Затим замрзавамо параметре дискриминатора (не желимо да се он обучава у овом кораку) и изводимо backprop.

Током овог процеса, губици генератора и дискриминатора не опадају значајно. У идеалној ситуацији, они би требало да осцилују, што одговара побољшању перформанси обе мреже.

## ✍️ Вежбе: GAN-ови

* [GAN бележница у TensorFlow/Keras](../../../../../lessons/4-ComputerVision/10-GANs/GANTF.ipynb)
* [GAN бележница у PyTorch](../../../../../lessons/4-ComputerVision/10-GANs/GANPyTorch.ipynb)

### Проблеми са обуком GAN-ова

Познато је да су GAN-ови посебно тешки за обуку. Ево неколико проблема:

* **Колапс модела**. Овим термином означавамо да генератор научи да производи једну успешну слику која завара дискриминатор, али не и разноврсност различитих слика.
* **Осетљивост на хиперпараметре**. Често можете видети да GAN уопште не конвергира, а затим изненада смањење стопе учења доводи до конвергенције.
* Одржавање **равнотеже** између генератора и дискриминатора. У многим случајевима губитак дискриминатора може брзо пасти на нулу, што резултира тиме да генератор не може да настави са обуком. Да бисмо ово превазишли, можемо покушати да поставимо различите стопе учења за генератор и дискриминатор или да прескочимо обуку дискриминатора ако је губитак већ превише низак.
* Обука за **високу резолуцију**. Одражавајући исти проблем као код аутоенкодера, овај проблем се јавља јер реконструкција превише слојева конволуционе мреже доводи до артефаката. Овај проблем се обично решава такозваним **прогресивним растом**, када се прво неколико слојева обучава на сликама ниске резолуције, а затим се слојеви "откључавају" или додају. Друго решење би било додавање додатних веза између слојева и обука на више резолуција истовремено - погледајте овај [Multi-Scale Gradient GANs рад](https://arxiv.org/abs/1903.06048) за детаље.

## Трансфер стила

GAN-ови су одличан начин за генерисање уметничких слика. Још једна занимљива техника је такозвани **трансфер стила**, који узима једну **слику садржаја** и поново је црта у другом стилу, примењујући филтере из **слике стила**.

Како то функционише:

* Почињемо са случајном шумском сликом (или са сликом садржаја, али ради разумевања је лакше почети са случајним шумом).
* Наш циљ би био да створимо такву слику која би била блиска и слици садржаја и слици стила. Ово би се одредило помоћу две функције губитка:
   - **Губитак садржаја** се израчунава на основу карактеристика које CNN извлачи на неким слојевима из тренутне слике и слике садржаја.
   - **Губитак стила** се израчунава између тренутне слике и слике стила на паметан начин користећи Грамове матрице (више детаља у [примеру бележнице](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)).
* Да би слика била глаткија и уклонио шум, уводимо и **губитак варијације**, који израчунава просечно растојање између суседних пиксела.
* Главна оптимизациона петља прилагођава тренутну слику користећи градијентни спуст (или неки други алгоритам оптимизације) како би минимизовала укупни губитак, који је пондерисани збир сва три губитка.

## ✍️ Пример: [Трансфер стила](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)

## [Квиз после предавања](https://ff-quizzes.netlify.app/en/ai/quiz/20)

## Закључак

У овој лекцији, научили сте о GAN-овима и како их обучавати. Такође сте научили о посебним изазовима са којима се ова врста неуронских мрежа може суочити и неким стратегијама како их превазићи.

## 🚀 Изазов

Прођите кроз [бележницу за трансфер стила](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb) користећи своје слике.

## Преглед и самостално учење

За референцу, прочитајте више о GAN-овима у овим ресурсима:

* Марко Пасини, [10 лекција које сам научио тренирајући GAN-ове годину дана](https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628)
* [StyleGAN](https://en.wikipedia.org/wiki/StyleGAN), *де факто* GAN архитектура коју треба размотрити
* [Креирање генеративне уметности користећи GAN-ове на Azure ML](https://soshnikov.com/scienceart/creating-generative-art-using-gan-on-azureml/)

## Задатак

Поново посетите једну од две бележнице повезане са овом лекцијом и поново обучите GAN на својим сликама. Шта можете да креирате?

**Одрицање од одговорности**:  
Овај документ је преведен коришћењем услуге за превођење помоћу вештачке интелигенције [Co-op Translator](https://github.com/Azure/co-op-translator). Иако се трудимо да обезбедимо тачност, молимо вас да имате у виду да аутоматски преводи могу садржати грешке или нетачности. Оригинални документ на његовом изворном језику треба сматрати ауторитативним извором. За критичне информације препоручује се професионални превод од стране људи. Не преузимамо одговорност за било каква погрешна тумачења или неспоразуме који могу настати услед коришћења овог превода.