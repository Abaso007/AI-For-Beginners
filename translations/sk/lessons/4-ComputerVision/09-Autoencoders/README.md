<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "0b306c04f5337b6e7430e5c0b16bb5c0",
  "translation_date": "2025-08-25T22:29:32+00:00",
  "source_file": "lessons/4-ComputerVision/09-Autoencoders/README.md",
  "language_code": "sk"
}
-->
# Autoenkod√©ry

Pri tr√©novan√≠ CNN je jedn√Ωm z probl√©mov, ≈æe potrebujeme veƒæa oznaƒçen√Ωch d√°t. V pr√≠pade klasifik√°cie obr√°zkov mus√≠me obr√°zky rozdeli≈• do r√¥znych tried, ƒço je manu√°lna pr√°ca.

## [Kv√≠z pred predn√°≈°kou](https://ff-quizzes.netlify.app/en/ai/quiz/17)

M√¥≈æeme v≈°ak chcie≈• pou≈æi≈• surov√© (neoznaƒçen√©) d√°ta na tr√©novanie CNN extraktorov vlastnost√≠, ƒço sa naz√Ωva **samoriaden√© uƒçenie**. Namiesto oznaƒçen√≠ pou≈æijeme tr√©novacie obr√°zky ako vstup aj v√Ωstup siete. Hlavnou my≈°lienkou **autoenkod√©ra** je, ≈æe budeme ma≈• **enkod√©rov√∫ sie≈•**, ktor√° konvertuje vstupn√Ω obr√°zok do nejak√©ho **latentn√©ho priestoru** (zvyƒçajne je to len vektor men≈°ej veƒækosti), a potom **dekod√©rov√∫ sie≈•**, ktorej cieƒæom bude rekon≈°truova≈• p√¥vodn√Ω obr√°zok.

> ‚úÖ [Autoenkod√©r](https://wikipedia.org/wiki/Autoencoder) je "typ umelej neur√≥novej siete, ktor√° sa pou≈æ√≠va na uƒçenie efekt√≠vneho k√≥dovania neoznaƒçen√Ωch d√°t."

Keƒè≈æe tr√©nujeme autoenkod√©r, aby zachytil ƒço najviac inform√°ci√≠ z p√¥vodn√©ho obr√°zku pre presn√∫ rekon≈°trukciu, sie≈• sa sna≈æ√≠ n√°js≈• najlep≈°ie **zobrazenie** vstupn√Ωch obr√°zkov, aby zachytila ich v√Ωznam.

![Sch√©ma Autoenkod√©ra](../../../../../translated_images/autoencoder_schema.5e6fc9ad98a5eb6197f3513cf3baf4dfbe1389a6ae74daebda64de9f1c99f142.sk.jpg)

> Obr√°zok z [Keras blogu](https://blog.keras.io/building-autoencoders-in-keras.html)

## Scen√°re pou≈æitia autoenkod√©rov

Aj keƒè rekon≈°trukcia p√¥vodn√Ωch obr√°zkov sama o sebe nemus√≠ by≈• u≈æitoƒçn√°, existuje niekoƒæko scen√°rov, kde s√∫ autoenkod√©ry obzvl√°≈°≈• u≈æitoƒçn√©:

* **Zni≈æovanie dimenzie obr√°zkov pre vizualiz√°ciu** alebo **tr√©novanie obrazov√Ωch zobrazen√≠**. Autoenkod√©ry zvyƒçajne poskytuj√∫ lep≈°ie v√Ωsledky ako PCA, preto≈æe ber√∫ do √∫vahy priestorov√∫ povahu obr√°zkov a hierarchick√© vlastnosti.
* **Odstra≈àovanie ≈°umu**, t.j. odstr√°nenie ≈°umu z obr√°zku. Keƒè≈æe ≈°um obsahuje veƒæa zbytoƒçn√Ωch inform√°ci√≠, autoenkod√©r ho nedok√°≈æe v≈°etok zahrn√∫≈• do relat√≠vne mal√©ho latentn√©ho priestoru, a tak zachyt√≠ iba d√¥le≈æit√∫ ƒças≈• obr√°zku. Pri tr√©novan√≠ odstra≈àovaƒçov ≈°umu zaƒç√≠name s p√¥vodn√Ωmi obr√°zkami a pou≈æ√≠vame obr√°zky s umelo pridan√Ωm ≈°umom ako vstup pre autoenkod√©r.
* **Superrozl√≠≈°enie**, zvy≈°ovanie rozl√≠≈°enia obr√°zkov. Zaƒç√≠name s obr√°zkami vo vysokom rozl√≠≈°en√≠ a pou≈æ√≠vame obr√°zky s ni≈æ≈°√≠m rozl√≠≈°en√≠m ako vstup pre autoenkod√©r.
* **Generat√≠vne modely**. Po natr√©novan√≠ autoenkod√©ra m√¥≈æeme dekod√©rov√∫ ƒças≈• pou≈æi≈• na vytv√°ranie nov√Ωch objektov zaƒç√≠naj√∫c od n√°hodn√Ωch latentn√Ωch vektorov.

## Variabiln√© autoenkod√©ry (VAE)

Tradiƒçn√© autoenkod√©ry nejako zni≈æuj√∫ dimenziu vstupn√Ωch d√°t a zis≈•uj√∫ d√¥le≈æit√© vlastnosti vstupn√Ωch obr√°zkov. Latentn√© vektory v≈°ak ƒçasto ned√°vaj√∫ veƒæk√Ω zmysel. In√Ωmi slovami, ak vezmeme dataset MNIST ako pr√≠klad, zis≈•ovanie, ktor√© ƒç√≠slice zodpovedaj√∫ r√¥znym latentn√Ωm vektorom, nie je jednoduch√° √∫loha, preto≈æe bl√≠zke latentn√© vektory nemusia nevyhnutne zodpoveda≈• rovnak√Ωm ƒç√≠sliciam.

Na druhej strane, na tr√©novanie *generat√≠vnych* modelov je lep≈°ie ma≈• nejak√© pochopenie latentn√©ho priestoru. T√°to my≈°lienka n√°s priv√°dza k **variabiln√©mu autoenkod√©ru** (VAE).

VAE je autoenkod√©r, ktor√Ω sa uƒç√≠ predpoveda≈• *≈°tatistick√© rozdelenie* latentn√Ωch parametrov, tzv. **latentn√© rozdelenie**. Napr√≠klad m√¥≈æeme chcie≈•, aby latentn√© vektory boli norm√°lne rozdelen√© s nejak√Ωm priemerom z<sub>mean</sub> a ≈°tandardnou odch√Ωlkou z<sub>sigma</sub> (obidva, priemer aj ≈°tandardn√° odch√Ωlka, s√∫ vektory nejakej dimenzie d). Enkod√©r vo VAE sa uƒç√≠ predpoveda≈• tieto parametre a dekod√©r potom vezme n√°hodn√Ω vektor z tohto rozdelenia na rekon≈°trukciu objektu.

Zhrnutie:

 * Zo vstupn√©ho vektora predpoved√°me `z_mean` a `z_log_sigma` (namiesto predpovedania samotnej ≈°tandardnej odch√Ωlky predpoved√°me jej logaritmus)
 * Vzorkujeme vektor `sample` z rozdelenia N(z<sub>mean</sub>,exp(z<sub>log\_sigma</sub>))
 * Dekod√©r sa sna≈æ√≠ dek√≥dova≈• p√¥vodn√Ω obr√°zok pomocou `sample` ako vstupn√©ho vektora

 <img src="images/vae.png" width="50%">

> Obr√°zok z [tohto blogov√©ho pr√≠spevku](https://ijdykeman.github.io/ml/2016/12/21/cvae.html) od Isaaka Dykemana

Variabiln√© autoenkod√©ry pou≈æ√≠vaj√∫ komplexn√∫ stratu, ktor√° pozost√°va z dvoch ƒçast√≠:

* **Rekon≈°trukƒçn√° strata** je funkcia straty, ktor√° ukazuje, ako bl√≠zko je rekon≈°truovan√Ω obr√°zok k cieƒæu (m√¥≈æe to by≈• Mean Squared Error, alebo MSE). Je to rovnak√° funkcia straty ako pri be≈æn√Ωch autoenkod√©roch.
* **KL strata**, ktor√° zabezpeƒçuje, ≈æe rozdelenie latentn√Ωch premenn√Ωch zost√°va bl√≠zke norm√°lnemu rozdeleniu. Je zalo≈æen√° na pojme [Kullback-Leiblerovej divergencie](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained) - metriky na odhad, ako podobn√© s√∫ dve ≈°tatistick√© rozdelenia.

Jednou d√¥le≈æitou v√Ωhodou VAE je, ≈æe n√°m umo≈æ≈àuj√∫ relat√≠vne ƒæahko generova≈• nov√© obr√°zky, preto≈æe vieme, z ktor√©ho rozdelenia vzorkova≈• latentn√© vektory. Napr√≠klad, ak tr√©nujeme VAE s 2D latentn√Ωm vektorom na MNIST, m√¥≈æeme potom meni≈• komponenty latentn√©ho vektora, aby sme z√≠skali r√¥zne ƒç√≠slice:

<img alt="vaemnist" src="images/vaemnist.png" width="50%"/>

> Obr√°zok od [Dmitry Soshnikov](http://soshnikov.com)

Pozorujte, ako sa obr√°zky prel√≠naj√∫, keƒè zaƒç√≠name z√≠skava≈• latentn√© vektory z r√¥znych ƒçast√≠ latentn√©ho priestoru parametrov. Tento priestor m√¥≈æeme tie≈æ vizualizova≈• v 2D:

<img alt="vaemnist cluster" src="images/vaemnist-diag.png" width="50%"/> 

> Obr√°zok od [Dmitry Soshnikov](http://soshnikov.com)

## ‚úçÔ∏è Cviƒçenia: Autoenkod√©ry

Zistite viac o autoenkod√©roch v t√Ωchto pr√≠slu≈°n√Ωch notebookoch:

* [Autoenkod√©ry v TensorFlow](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb)
* [Autoenkod√©ry v PyTorch](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoEncodersPyTorch.ipynb)

## Vlastnosti autoenkod√©rov

* **≈†pecifick√© pre d√°ta** - funguj√∫ dobre iba s typom obr√°zkov, na ktor√Ωch boli tr√©novan√©. Napr√≠klad, ak tr√©nujeme sie≈• na superrozl√≠≈°enie na kvetoch, nebude dobre fungova≈• na portr√©toch. Je to preto, ≈æe sie≈• dok√°≈æe vytvori≈• obr√°zok vo vy≈°≈°om rozl√≠≈°en√≠ t√Ωm, ≈æe berie jemn√© detaily z vlastnost√≠ nauƒçen√Ωch z tr√©novacej mno≈æiny.
* **Stratov√©** - rekon≈°truovan√Ω obr√°zok nie je rovnak√Ω ako p√¥vodn√Ω obr√°zok. Povaha straty je definovan√° *funkciou straty* pou≈æitou poƒças tr√©novania.
* Funguje na **neoznaƒçen√Ωch d√°tach**

## [Kv√≠z po predn√°≈°ke](https://ff-quizzes.netlify.app/en/ai/quiz/18)

## Z√°ver

V tejto lekcii ste sa nauƒçili o r√¥znych typoch autoenkod√©rov dostupn√Ωch pre vedca v oblasti AI. Nauƒçili ste sa, ako ich vytvori≈• a ako ich pou≈æi≈• na rekon≈°trukciu obr√°zkov. Tie≈æ ste sa nauƒçili o VAE a ako ich pou≈æi≈• na generovanie nov√Ωch obr√°zkov.

## üöÄ V√Ωzva

V tejto lekcii ste sa nauƒçili pou≈æ√≠va≈• autoenkod√©ry na obr√°zky. Ale m√¥≈æu sa pou≈æi≈• aj na hudbu! Pozrite si projekt Magenta [MusicVAE](https://magenta.tensorflow.org/music-vae), ktor√Ω pou≈æ√≠va autoenkod√©ry na uƒçenie rekon≈°trukcie hudby. Urobte niekoƒæko [experimentov](https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/Multitrack_MusicVAE.ipynb) s touto kni≈ænicou a zistite, ƒço dok√°≈æete vytvori≈•.

## [Kv√≠z po predn√°≈°ke](https://ff-quizzes.netlify.app/en/ai/quiz/16)

## Prehƒæad a samo≈°t√∫dium

Pre referenciu si preƒç√≠tajte viac o autoenkod√©roch v t√Ωchto zdrojoch:

* [Building Autoencoders in Keras](https://blog.keras.io/building-autoencoders-in-keras.html)
* [Blogov√Ω pr√≠spevok na NeuroHive](https://neurohive.io/ru/osnovy-data-science/variacionnyj-avtojenkoder-vae/)
* [Variational Autoencoders Explained](https://kvfrans.com/variational-autoencoders-explained/)
* [Conditional Variational Autoencoders](https://ijdykeman.github.io/ml/2016/12/21/cvae.html)

## Zadanie

Na konci [tohto notebooku s TensorFlow](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb) n√°jdete '√∫lohu' - pou≈æite ju ako svoje zadanie.

**Zrieknutie sa zodpovednosti**:  
Tento dokument bol prelo≈æen√Ω pomocou slu≈æby AI prekladu [Co-op Translator](https://github.com/Azure/co-op-translator). Hoci sa sna≈æ√≠me o presnos≈•, pros√≠m, berte na vedomie, ≈æe automatizovan√© preklady m√¥≈æu obsahova≈• chyby alebo nepresnosti. P√¥vodn√Ω dokument v jeho rodnom jazyku by mal by≈• pova≈æovan√Ω za autoritat√≠vny zdroj. Pre kritick√© inform√°cie sa odpor√∫ƒça profesion√°lny ƒæudsk√Ω preklad. Nenesieme zodpovednos≈• za ak√©koƒævek nedorozumenia alebo nespr√°vne interpret√°cie vypl√Ωvaj√∫ce z pou≈æitia tohto prekladu.