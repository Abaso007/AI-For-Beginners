<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "97836d30a6bec736f8e3b4411c572bc2",
  "translation_date": "2025-10-11T11:44:12+00:00",
  "source_file": "lessons/5-NLP/20-LangModels/README.md",
  "language_code": "ta"
}
-->
# முன்பே பயிற்சி பெற்ற பெரிய மொழி மாதிரிகள்

முந்தைய பணிகளில், குறிப்பிட்ட பணியைச் செய்ய நரம்பியல் வலையமைப்பை லேபிள் செய்யப்பட்ட தரவுத்தொகுப்பைப் பயன்படுத்தி பயிற்சி செய்தோம். BERT போன்ற பெரிய டிரான்ஸ்ஃபார்மர் மாதிரிகளைப் பயன்படுத்தி, மொழி மாதிரியை உருவாக்க சுய-மேற்பார்வை முறையில் மொழி மாதிரியாக்கத்தைப் பயன்படுத்துகிறோம், பின்னர் குறிப்பிட்ட துறைக்கு உரிய பயிற்சியுடன் குறிப்பிட்ட பணிக்காக சிறப்பம்சமாக்கப்படுகிறது. ஆனால், பெரிய மொழி மாதிரிகள் எந்த துறைக்கு உரிய பயிற்சியின்றியும் பல பணிகளைத் தீர்க்க முடியும் என்று நிரூபிக்கப்பட்டுள்ளது. இதைச் செய்யும் திறன் கொண்ட மாதிரிகளின் குடும்பம் **GPT**: Generative Pre-Trained Transformer என்று அழைக்கப்படுகிறது.

## [முன்-வகுப்பு வினாடி வினா](https://ff-quizzes.netlify.app/en/ai/quiz/39)

## உரை உருவாக்கம் மற்றும் Perplexity

கீழ்மட்ட பயிற்சியின்றி பொதுப் பணிகளைச் செய்யும் நரம்பியல் வலையமைப்பின் யோசனை [Language Models are Unsupervised Multitask Learners](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf) என்ற ஆவணத்தில் முன்வைக்கப்பட்டுள்ளது. முக்கிய யோசனை என்னவென்றால், பல பணிகளை **உரை உருவாக்கம்** மூலம் மாதிரியாக்க முடியும், ஏனெனில் உரையைப் புரிந்துகொள்வது அதைப் உருவாக்கும் திறனை கொண்டிருப்பதைக் குறிக்கிறது. மாதிரி மனித அறிவை உள்ளடக்கிய மிகப்பெரிய உரை தொகுப்பில் பயிற்சி பெறுவதால், இது பல்வேறு தலைப்புகள் பற்றிய அறிவை கொண்டதாகவும் மாறுகிறது.

> உரையைப் புரிந்துகொள்வதும் அதை உருவாக்கும் திறனை கொண்டிருப்பதும் உலகத்தைப் பற்றிய சிலவற்றை அறிந்திருப்பதையும் குறிக்கிறது. மனிதர்கள் பெரும்பாலும் வாசிப்பதன் மூலம் கற்றுக்கொள்கிறார்கள், GPT வலையமைப்பும் இதேபோன்றது.

உரை உருவாக்க வலையமைப்புகள் $$P(w_N)$$ என்ற அடுத்த வார்த்தையின் சாத்தியத்தை கணிக்கின்றன. ஆனால், அடுத்த வார்த்தையின் நிபந்தனையற்ற சாத்தியம் உரை தொகுப்பில் அந்த வார்த்தையின் அடிக்கடி தோன்றும் அளவுக்கு சமமாக இருக்கும். GPT, முந்தைய வார்த்தைகளைத் தரப்பட்ட நிலையில் அடுத்த வார்த்தையின் **நிபந்தனை சாத்தியத்தை** வழங்குகிறது: $$P(w_N | w_{n-1}, ..., w_0)$$

> சாத்தியங்களைப் பற்றிய மேலும் தகவல்களை [Data Science for Beginners Curriculum](https://github.com/microsoft/Data-Science-For-Beginners/tree/main/1-Introduction/04-stats-and-probability) இல் படிக்கலாம்.

மொழி உருவாக்க மாதிரியின் தரத்தை **perplexity** மூலம் வரையறுக்கலாம். இது எந்த பணிக்குறிப்பிட்ட தரவுத்தொகுப்பின்றியும் மாதிரியின் தரத்தை அளவிட உதவும் உள்ளக அளவீடு. இது *ஒரு வாக்கியத்தின் சாத்தியம்* என்ற கருத்தின் அடிப்படையில் உள்ளது - மாதிரி உண்மையானதாக இருக்கக்கூடிய ஒரு வாக்கியத்திற்கு அதிக சாத்தியத்தை அளிக்கிறது (அதாவது, மாதிரி அதனால் **perplexed** ஆகவில்லை), மற்றும் குறைவாக அர்த்தமுள்ள வாக்கியங்களுக்கு குறைந்த சாத்தியத்தை அளிக்கிறது (எ.கா. *Can it does what?*). மாதிரிக்கு உண்மையான உரை தொகுப்பிலிருந்து வாக்கியங்களை வழங்கும்போது, அவை அதிக சாத்தியத்தை, மற்றும் குறைந்த **perplexity** ஐ கொண்டிருக்க வேண்டும் என்று எதிர்பார்க்கிறோம். கணித ரீதியாக, இது சோதனை தொகுப்பின் சாத்தியத்தின் மாறுபட்ட எதிர்மாறான மதிப்பாக வரையறுக்கப்படுகிறது:
$$
\mathrm{Perplexity}(W) = \sqrt[N]{1\over P(W_1,...,W_N)}
$$ 

**[Hugging Face](https://transformer.huggingface.co/doc/gpt2-large) இல் GPT-இயக்கப்பட்ட உரை தொகுப்பை பயன்படுத்தி உரை உருவாக்கத்தை பரிசோதிக்கலாம்**. இந்த தொகுப்பில், உங்கள் உரையை எழுதத் தொடங்குங்கள், மற்றும் **[TAB]** அழுத்துவதன் மூலம் பல முடிவு விருப்பங்களைப் பெறலாம். அவை மிகவும் குறுகியதாக இருந்தால், அல்லது நீங்கள் திருப்தியடையவில்லை என்றால் - [TAB] ஐ மீண்டும் அழுத்தவும், மேலும் விருப்பங்களைப் பெறலாம், அதில் நீண்ட உரை துண்டுகளும் அடங்கும்.

## GPT என்பது ஒரு குடும்பம்

GPT என்பது ஒரு மாதிரி மட்டுமல்ல, மாறாக [OpenAI](https://openai.com) மூலம் உருவாக்கப்பட்ட மற்றும் பயிற்சி பெற்ற மாதிரிகளின் தொகுப்பாகும்.

GPT மாதிரிகளின் கீழ், நமக்கு உள்ளவை:

| [GPT-2](https://huggingface.co/docs/transformers/model_doc/gpt2#openai-gpt2) | [GPT 3](https://openai.com/research/language-models-are-few-shot-learners) | [GPT-4](https://openai.com/gpt-4) |
| -- | -- | -- |
|1.5 பில்லியன் அளவுகோல்களுடன் மொழி மாதிரி | 175 பில்லியன் அளவுகோல்களுடன் மொழி மாதிரி | 100T அளவுகோல்கள் மற்றும் படங்கள் மற்றும் உரை உள்ளீடுகளை ஏற்கிறது மற்றும் உரை வெளியீடுகளை வழங்குகிறது. |

GPT-3 மற்றும் GPT-4 மாதிரிகள் [Microsoft Azure இல் ஒரு cognitive service ஆக](https://azure.microsoft.com/en-us/services/cognitive-services/openai-service/#overview?WT.mc_id=academic-77998-cacaste) மற்றும் [OpenAI API](https://openai.com/api/) ஆக கிடைக்கின்றன.

## Prompt Engineering

GPT மிகப்பெரிய அளவிலான தரவுகளில் மொழி மற்றும் குறியீட்டை புரிந்துகொள்ள பயிற்சி பெற்றதால், அவை உள்ளீடுகளுக்கு பதிலளிக்கின்றன (prompts). Prompts என்பது GPT இன் உள்ளீடுகள் அல்லது கேள்விகள், இதில் ஒருவர் மாதிரிகளுக்கு பணிகளை முடிக்க வழிகாட்டுதல்களை வழங்குகிறார். விரும்பிய முடிவை பெற, மிகச் சிறந்த prompt தேவைப்படுகிறது, இது சரியான வார்த்தைகள், வடிவங்கள், சொற்றொடர்கள் அல்லது கூட சின்னங்களைத் தேர்ந்தெடுப்பதை உள்ளடக்கியது. இந்த அணுகுமுறை [Prompt Engineering](https://learn.microsoft.com/en-us/shows/ai-show/the-basics-of-prompt-engineering-with-azure-openai-service?WT.mc_id=academic-77998-bethanycheum) என்று அழைக்கப்படுகிறது.

[இந்த ஆவணம்](https://learn.microsoft.com/en-us/semantic-kernel/prompt-engineering/?WT.mc_id=academic-77998-bethanycheum) prompt engineering பற்றிய மேலும் தகவல்களை வழங்குகிறது.

## ✍️ உதாரண நோட்புக்: [OpenAI-GPT உடன் விளையாடுதல்](GPT-PyTorch.ipynb)

பின்வரும் நோட்புக்குகளில் உங்கள் கற்றலை தொடருங்கள்:

* [OpenAI-GPT மற்றும் Hugging Face Transformers உடன் உரை உருவாக்கம்](GPT-PyTorch.ipynb)

## முடிவு

புதிய பொதுப் பயிற்சி பெற்ற மொழி மாதிரிகள் மொழி அமைப்பை மாதிரியாக்குவதுடன் மட்டுமல்லாமல், இயற்கை மொழியின் மிகப்பெரிய அளவையும் கொண்டுள்ளன. எனவே, அவை சில NLP பணிகளை zero-shot அல்லது few-shot அமைப்புகளில் திறமையாக பயன்படுத்தப்படலாம்.

## [பின்-வகுப்பு வினாடி வினா](https://ff-quizzes.netlify.app/en/ai/quiz/40)

---

**குறிப்பு**:  
இந்த ஆவணம் [Co-op Translator](https://github.com/Azure/co-op-translator) என்ற AI மொழிபெயர்ப்பு சேவையைப் பயன்படுத்தி மொழிபெயர்க்கப்பட்டுள்ளது. நாங்கள் துல்லியத்திற்காக முயற்சிக்கின்றோம், ஆனால் தானியங்கி மொழிபெயர்ப்புகளில் பிழைகள் அல்லது தவறான தகவல்கள் இருக்கக்கூடும் என்பதை தயவுசெய்து கவனத்தில் கொள்ளவும். அதன் தாய்மொழியில் உள்ள மூல ஆவணம் அதிகாரப்பூர்வ ஆதாரமாக கருதப்பட வேண்டும். முக்கியமான தகவல்களுக்கு, தொழில்முறை மனித மொழிபெயர்ப்பு பரிந்துரைக்கப்படுகிறது. இந்த மொழிபெயர்ப்பைப் பயன்படுத்துவதால் ஏற்படும் எந்த தவறான புரிதல்கள் அல்லது தவறான விளக்கங்களுக்கு நாங்கள் பொறுப்பல்ல.