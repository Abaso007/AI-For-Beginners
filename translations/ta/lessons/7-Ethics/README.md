<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "437c988596e751072e41a5aad3fcc5d9",
  "translation_date": "2025-10-11T11:33:58+00:00",
  "source_file": "lessons/7-Ethics/README.md",
  "language_code": "ta"
}
-->
# நெறிமுறை மற்றும் பொறுப்பான AI

இந்த பாடத்தை நீங்கள் முடிக்கவிருப்பதாக உள்ளது, மற்றும் இதுவரை நீங்கள் AI என்பது தரவுகளில் உறவுகளை கண்டறிந்து, மனித நடத்தை சில அம்சங்களை மீண்டும் உருவாக்க மாடல்களை பயிற்சி செய்ய அனுமதிக்கும் பல்வேறு கணித முறைகளின் அடிப்படையில் அமைந்துள்ளது என்பதை தெளிவாகப் புரிந்துகொண்டிருப்பீர்கள் என்று நம்புகிறேன். தற்போதைய வரலாற்று தருணத்தில், AI என்பது தரவிலிருந்து முறைமைகளை எடுக்கவும், புதிய பிரச்சினைகளை தீர்க்கவும் அந்த முறைமைகளை பயன்படுத்தவும் ஒரு மிக சக்திவாய்ந்த கருவியாக கருதப்படுகிறது.

## [முன்-பாடம் வினாடி வினா](https://white-water-09ec41f0f.azurestaticapps.net/quiz/5/)

ஆனால், அறிவியல் கற்பனையில், AI மனிதகுலத்திற்கு ஆபத்தை ஏற்படுத்தும் கதைகளை நாம் அடிக்கடி பார்க்கிறோம். பொதுவாக, அந்த கதைகள் ஏதோ ஒரு AI கிளர்ச்சியை மையமாகக் கொண்டிருக்கும், அதில் AI மனிதர்களுக்கு எதிராக செயல்பட முடிவு செய்கிறது. இது AI-க்கு ஏதோ ஒரு உணர்வு உள்ளது அல்லது அதன் உருவாக்குநர்களால் எதிர்பார்க்கப்படாத முடிவுகளை எடுக்க முடியும் என்பதை குறிக்கிறது.

இந்த பாடத்தில் நாம் கற்ற AI என்பது பெரிய மடிக்கணக்கீடுகளுக்கு மேல் எதுவும் இல்லை. இது நமது பிரச்சினைகளை தீர்க்க உதவும் ஒரு மிக சக்திவாய்ந்த கருவி, மற்றும் எந்த சக்திவாய்ந்த கருவி போலவே - இது நல்ல மற்றும் கெட்ட நோக்கங்களுக்காக பயன்படுத்தப்படலாம். முக்கியமாக, இது *தவறாக பயன்படுத்தப்படலாம்*.

## பொறுப்பான AI-யின் கொள்கைகள்

AI-யின் தவறான அல்லது நோக்கமுள்ள தவறான பயன்பாட்டை தவிர்க்க, Microsoft முக்கியமான [பொறுப்பான AI-யின் கொள்கைகளை](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-77998-cacaste) குறிப்பிடுகிறது. இந்த கொள்கைகளை ஆதரிக்கும் கருத்துக்கள் பின்வருமாறு:

* **நியாயம்** என்பது *மாடல் பாகுபாடுகள்* என்ற முக்கிய பிரச்சினையைப் பற்றியது, இது பயிற்சிக்கான பாகுபாடான தரவுகளைப் பயன்படுத்துவதால் ஏற்படலாம். உதாரணமாக, ஒரு நபருக்கு மென்பொருள் டெவலப்பர் வேலை கிடைக்கும் சாத்தியத்தை கணிக்க முயற்சிக்கும் போது, மாடல் ஆண்களுக்கு அதிக முன்னுரிமை அளிக்க வாய்ப்பு உள்ளது - ஏனெனில் பயிற்சி தரவுத்தொகுப்பு ஆண் பார்வையாளர்களை நோக்கி பாகுபாடாக இருக்க வாய்ப்பு உள்ளது. பயிற்சி தரவுகளை கவனமாக சமநிலைப்படுத்தி, மாடலை ஆராய்ந்து பாகுபாடுகளைத் தவிர்க்கவும், மாடல் தொடர்புடைய அம்சங்களைப் பொருத்தமாகக் கணக்கில் எடுத்துக்கொள்ளவும் நாம் உறுதிப்படுத்த வேண்டும்.
* **நம்பகத்தன்மை மற்றும் பாதுகாப்பு**. தங்களின் இயல்பால், AI மாடல்கள் தவறுகளைச் செய்யக்கூடும். ஒரு நரம்பியல் வலைப்பின்னல் சாத்தியங்களைத் திருப்புகிறது, மற்றும் நாம் முடிவுகளை எடுக்கும் போது அதை கணக்கில் எடுத்துக்கொள்ள வேண்டும். ஒவ்வொரு மாடலுக்கும் சில துல்லியமும் மீளப்பெறுதலும் உள்ளது, மற்றும் தவறான ஆலோசனைகள் ஏற்படுத்தும் பாதிப்பைத் தவிர்க்க நாம் அதை புரிந்துகொள்ள வேண்டும்.
* **தனியுரிமை மற்றும் பாதுகாப்பு** சில AI-க்கு தனித்துவமான விளைவுகளை உள்ளடக்கியது. உதாரணமாக, ஒரு மாடலை பயிற்சி செய்ய சில தரவுகளைப் பயன்படுத்தும்போது, அந்த தரவு ஏதோவொரு வகையில் "ஒருங்கிணைக்கப்பட்ட"தாக மாறுகிறது. ஒரு பக்கம், அது பாதுகாப்பு மற்றும் தனியுரிமையை அதிகரிக்கிறது, மற்றொரு பக்கம் - மாடல் எந்த தரவின் மூலம் பயிற்சி செய்யப்பட்டது என்பதை நாம் நினைவில் கொள்ள வேண்டும்.
* **ஒன்றிணைவு** என்பது நாம் AI-யை மனிதர்களை மாற்றுவதற்காக உருவாக்கவில்லை, மாறாக மனிதர்களை மேம்படுத்தவும், நமது பணியை மேலும் படைப்பாற்றலாக மாற்றவும் என்பதைக் குறிக்கிறது. இது நியாயத்துடன் தொடர்புடையது, ஏனெனில் குறைந்த அளவில் பிரதிநிதித்துவம் பெறும் சமூகங்களைச் சமாளிக்கும் போது, நாம் சேகரிக்கும் பெரும்பாலான தரவுத்தொகுப்புகள் பாகுபாடாக இருக்க வாய்ப்பு உள்ளது, மற்றும் அந்த சமூகங்கள் AI மூலம் சரியாக கையாளப்படுவதை உறுதிப்படுத்த வேண்டும்.
* **தெளிவுத்தன்மை**. இது AI பயன்படுத்தப்படுவதை எப்போதும் தெளிவாகக் கூறுவதை உறுதிப்படுத்துவதை உள்ளடக்கியது. மேலும், wherever possible, நாம் *விளக்கக்கூடிய* AI அமைப்புகளைப் பயன்படுத்த விரும்புகிறோம்.
* **பொறுப்புத்தன்மை**. AI மாடல்கள் சில முடிவுகளை எடுக்கும் போது, அந்த முடிவுகளுக்கு யார் பொறுப்பானவர் என்பது எப்போதும் தெளிவாக இருக்காது. AI முடிவுகளின் பொறுப்புத்தன்மை எங்கு உள்ளது என்பதை நாம் புரிந்துகொள்ள வேண்டும். பெரும்பாலான சந்தர்ப்பங்களில், முக்கிய முடிவுகளை எடுப்பதில் மனிதர்களைச் சேர்க்க விரும்புவோம், அதனால் உண்மையான மனிதர்கள் பொறுப்பேற்கப்படுவார்கள்.

## பொறுப்பான AI-க்கு கருவிகள்

Microsoft [Responsible AI Toolbox](https://github.com/microsoft/responsible-ai-toolbox) என்ற கருவிகளின் தொகுப்பை உருவாக்கியுள்ளது:

* Interpretability Dashboard (InterpretML)
* Fairness Dashboard (FairLearn)
* Error Analysis Dashboard
* Responsible AI Dashboard, இதில் அடங்கும்:

   - EconML - காரணப்பகுப்புக்கான கருவி, இது "என்ன ஆகும்?" என்ற கேள்விகளை மையமாகக் கொண்டது
   - DiCE - Counterfactual Analysis கருவி, இது மாடலின் முடிவை பாதிக்க எந்த அம்சங்களை மாற்ற வேண்டும் என்பதை நீங்கள் காண அனுமதிக்கிறது

AI நெறிமுறைகள் பற்றிய மேலும் தகவலுக்கு, [இந்த பாடத்தை](https://github.com/microsoft/ML-For-Beginners/tree/main/1-Introduction/3-fairness?WT.mc_id=academic-77998-cacaste) பார்வையிடவும், இது இயந்திரக் கற்றல் பாடத்திட்டத்தில் பணிகளை உள்ளடக்கியது.

## மதிப்பீடு மற்றும் சுயபயிற்சி

பொறுப்பான AI பற்றி மேலும் அறிய இந்த [Learn Path](https://docs.microsoft.com/learn/modules/responsible-ai-principles/?WT.mc_id=academic-77998-cacaste) ஐ எடுத்துக்கொள்ளுங்கள்.

## [பாடத்திற்குப் பின் வினாடி வினா](https://white-water-09ec41f0f.azurestaticapps.net/quiz/6/)

---

**குறிப்பு**:  
இந்த ஆவணம் [Co-op Translator](https://github.com/Azure/co-op-translator) என்ற AI மொழிபெயர்ப்பு சேவையை பயன்படுத்தி மொழிபெயர்க்கப்பட்டுள்ளது. எங்கள் தரச்செயல்முறையை உறுதிப்படுத்த முயற்சிக்கிறோம், ஆனால் தானியக்க மொழிபெயர்ப்புகளில் பிழைகள் அல்லது தவறுகள் இருக்கக்கூடும் என்பதை கவனத்தில் கொள்ளவும். அதன் தாய்மொழியில் உள்ள மூல ஆவணம் அதிகாரப்பூர்வ ஆதாரமாக கருதப்பட வேண்டும். முக்கியமான தகவல்களுக்கு, தொழில்முறை மனித மொழிபெயர்ப்பு பரிந்துரைக்கப்படுகிறது. இந்த மொழிபெயர்ப்பைப் பயன்படுத்துவதால் ஏற்படும் எந்த தவறான புரிதல்கள் அல்லது தவறான விளக்கங்களுக்கு நாங்கள் பொறுப்பல்ல.