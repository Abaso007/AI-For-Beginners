<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f862a99d88088163df12270e2f2ad6c3",
  "translation_date": "2025-10-03T12:42:25+00:00",
  "source_file": "lessons/3-NeuralNetworks/README.md",
  "language_code": "fa"
}
-->
# مقدمه‌ای بر شبکه‌های عصبی

![خلاصه‌ای از محتوای مقدمه شبکه‌های عصبی در یک طرح](../../../../translated_images/ai-neuralnetworks.1c687ae40bc86e834f497844866a26d3e0886650a67a4bbe29442e2f157d3b18.fa.png)

همان‌طور که در مقدمه بحث کردیم، یکی از راه‌های دستیابی به هوش، آموزش یک **مدل کامپیوتری** یا یک **مغز مصنوعی** است. از اواسط قرن بیستم، پژوهشگران مدل‌های ریاضی مختلفی را امتحان کردند تا اینکه در سال‌های اخیر این مسیر به موفقیت چشمگیری دست یافت. این مدل‌های ریاضی مغز را **شبکه‌های عصبی** می‌نامند.

> گاهی شبکه‌های عصبی را *شبکه‌های عصبی مصنوعی* یا ANNs می‌نامند تا مشخص شود که درباره مدل‌ها صحبت می‌کنیم، نه شبکه‌های واقعی نورون‌ها.

## یادگیری ماشین

شبکه‌های عصبی بخشی از یک حوزه بزرگ‌تر به نام **یادگیری ماشین** هستند که هدف آن استفاده از داده‌ها برای آموزش مدل‌های کامپیوتری است که قادر به حل مسائل باشند. یادگیری ماشین بخش بزرگی از هوش مصنوعی را تشکیل می‌دهد، اما در این دوره آموزشی به یادگیری ماشین کلاسیک نمی‌پردازیم.

> برای یادگیری بیشتر درباره یادگیری ماشین کلاسیک، به دوره آموزشی جداگانه **[یادگیری ماشین برای مبتدیان](http://github.com/microsoft/ml-for-beginners)** مراجعه کنید.

در یادگیری ماشین، فرض می‌کنیم که یک مجموعه داده از نمونه‌ها **X** و مقادیر خروجی متناظر **Y** داریم. نمونه‌ها اغلب بردارهای N-بعدی هستند که شامل **ویژگی‌ها** می‌شوند و خروجی‌ها **برچسب‌ها** نامیده می‌شوند.

ما به دو مسئله رایج یادگیری ماشین می‌پردازیم:

* **طبقه‌بندی**، که در آن باید یک شیء ورودی را به دو یا چند کلاس دسته‌بندی کنیم.
* **رگرسیون**، که در آن باید یک عدد عددی را برای هر یک از نمونه‌های ورودی پیش‌بینی کنیم.

> هنگامی که ورودی‌ها و خروجی‌ها به صورت تنسورها نمایش داده می‌شوند، مجموعه داده ورودی یک ماتریس با اندازه M&times;N است، که M تعداد نمونه‌ها و N تعداد ویژگی‌ها است. برچسب‌های خروجی Y یک بردار با اندازه M است.

در این دوره آموزشی، فقط بر مدل‌های شبکه عصبی تمرکز خواهیم کرد.

## مدل یک نورون

از زیست‌شناسی می‌دانیم که مغز ما از سلول‌های عصبی (نورون‌ها) تشکیل شده است، که هر کدام دارای چندین "ورودی" (دندریت‌ها) و یک "خروجی" (آکسون) هستند. هم دندریت‌ها و هم آکسون‌ها می‌توانند سیگنال‌های الکتریکی را منتقل کنند، و اتصالات بین آن‌ها — که به عنوان سیناپس شناخته می‌شوند — می‌توانند درجات مختلفی از رسانایی را نشان دهند که توسط انتقال‌دهنده‌های عصبی تنظیم می‌شوند.

![مدل یک نورون](../../../../translated_images/synapse-wikipedia.ed20a9e4726ea1c6a3ce8fec51c0b9bec6181946dca0fe4e829bc12fa3bacf01.fa.jpg) | ![مدل یک نورون](../../../../translated_images/artneuron.1a5daa88d20ebe6f5824ddb89fba0bdaaf49f67e8230c1afbec42909df1fc17e.fa.png)
----|----
نورون واقعی *([تصویر](https://en.wikipedia.org/wiki/Synapse#/media/File:SynapseSchematic_lines.svg) از ویکی‌پدیا)* | نورون مصنوعی *(تصویر توسط نویسنده)*

بنابراین، ساده‌ترین مدل ریاضی یک نورون شامل چندین ورودی X<sub>1</sub>, ..., X<sub>N</sub> و یک خروجی Y، و مجموعه‌ای از وزن‌ها W<sub>1</sub>, ..., W<sub>N</sub> است. خروجی به صورت زیر محاسبه می‌شود:

<img src="../../../../translated_images/netout.1eb15eb76fd767313e067719f400cec4b0e5090239c3e997c29f6789d4c3c263.fa.png" alt="Y = f\left(\sum_{i=1}^N X_iW_i\right)" width="131" height="53" align="center"/>

که در آن f یک **تابع فعال‌سازی** غیرخطی است.

> مدل‌های اولیه نورون در مقاله کلاسیک [A logical calculus of the ideas immanent in nervous activity](https://www.cs.cmu.edu/~./epxing/Class/10715/reading/McCulloch.and.Pitts.pdf) توسط وارن مک‌کالاک و والتر پیتس در سال 1943 توصیف شدند. دونالد هب در کتاب خود "[The Organization of Behavior: A Neuropsychological Theory](https://books.google.com/books?id=VNetYrB8EBoC)" روش آموزش این شبکه‌ها را پیشنهاد کرد.

## در این بخش

در این بخش درباره موارد زیر یاد خواهیم گرفت:
* [پرسیپترون](03-Perceptron/README.md)، یکی از اولین مدل‌های شبکه عصبی برای طبقه‌بندی دوکلاسه
* [شبکه‌های چندلایه](04-OwnFramework/README.md) همراه با دفترچه [چگونه چارچوب خودمان را بسازیم](04-OwnFramework/OwnFramework.ipynb)
* [چارچوب‌های شبکه عصبی](05-Frameworks/README.md)، همراه با این دفترچه‌ها: [PyTorch](05-Frameworks/IntroPyTorch.ipynb) و [Keras/Tensorflow](05-Frameworks/IntroKerasTF.ipynb)
* [بیش‌برازش](../../../../lessons/3-NeuralNetworks/05-Frameworks)

---

**سلب مسئولیت**:  
این سند با استفاده از سرویس ترجمه هوش مصنوعی [Co-op Translator](https://github.com/Azure/co-op-translator) ترجمه شده است. در حالی که ما تلاش می‌کنیم دقت را حفظ کنیم، لطفاً توجه داشته باشید که ترجمه‌های خودکار ممکن است شامل خطاها یا نادرستی‌ها باشند. سند اصلی به زبان اصلی آن باید به عنوان منبع معتبر در نظر گرفته شود. برای اطلاعات حساس، توصیه می‌شود از ترجمه انسانی حرفه‌ای استفاده کنید. ما مسئولیتی در قبال سوء تفاهم‌ها یا تفسیرهای نادرست ناشی از استفاده از این ترجمه نداریم.