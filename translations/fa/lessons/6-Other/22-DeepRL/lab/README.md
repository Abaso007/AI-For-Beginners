<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7bd8dc72040e98e35e7225e34058cd4e",
  "translation_date": "2025-08-24T10:38:25+00:00",
  "source_file": "lessons/6-Other/22-DeepRL/lab/README.md",
  "language_code": "fa"
}
-->
## محیط

محیط Mountain Car شامل یک ماشین است که درون یک دره گرفتار شده است. هدف شما این است که از دره بیرون بپرید و به پرچم برسید. اقداماتی که می‌توانید انجام دهید شامل شتاب دادن به سمت چپ، شتاب دادن به سمت راست، یا انجام ندادن هیچ کاری است. شما می‌توانید موقعیت ماشین را در امتداد محور x و سرعت آن را مشاهده کنید.

## شروع دفترچه

برای شروع این آزمایش، [MountainCar.ipynb](../../../../../../lessons/6-Other/22-DeepRL/lab/MountainCar.ipynb) را باز کنید.

## نکته کلیدی

در طول این آزمایش باید یاد بگیرید که تطبیق الگوریتم‌های RL با یک محیط جدید اغلب بسیار ساده است، زیرا OpenAI Gym برای تمام محیط‌ها یک رابط یکسان دارد و الگوریتم‌ها به طور کلی به ماهیت محیط وابستگی زیادی ندارند. حتی می‌توانید کد پایتون را به گونه‌ای بازسازی کنید که هر محیطی را به عنوان یک پارامتر به الگوریتم RL ارسال کنید.

**سلب مسئولیت**:  
این سند با استفاده از سرویس ترجمه هوش مصنوعی [Co-op Translator](https://github.com/Azure/co-op-translator) ترجمه شده است. در حالی که ما تلاش می‌کنیم دقت را حفظ کنیم، لطفاً توجه داشته باشید که ترجمه‌های خودکار ممکن است حاوی خطاها یا نادرستی‌هایی باشند. سند اصلی به زبان اصلی آن باید به عنوان منبع معتبر در نظر گرفته شود. برای اطلاعات حساس، ترجمه حرفه‌ای انسانی توصیه می‌شود. ما هیچ مسئولیتی در قبال سوءتفاهم‌ها یا تفسیرهای نادرست ناشی از استفاده از این ترجمه نداریم.