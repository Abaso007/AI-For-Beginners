<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "717775c4050ccbffbe0c961ad8bf7bf7",
  "translation_date": "2025-08-24T10:32:49+00:00",
  "source_file": "lessons/4-ComputerVision/08-TransferLearning/README.md",
  "language_code": "fa"
}
-->
# شبکه‌های از پیش آموزش‌دیده و یادگیری انتقالی

آموزش شبکه‌های عصبی پیچشی (CNN) می‌تواند زمان زیادی ببرد و نیازمند داده‌های زیادی باشد. با این حال، بخش عمده‌ای از زمان صرف یادگیری بهترین فیلترهای سطح پایین می‌شود که شبکه می‌تواند برای استخراج الگوها از تصاویر استفاده کند. یک سؤال طبیعی مطرح می‌شود - آیا می‌توانیم از یک شبکه عصبی که روی یک مجموعه داده آموزش دیده است استفاده کنیم و آن را برای طبقه‌بندی تصاویر مختلف بدون نیاز به فرآیند کامل آموزش تطبیق دهیم؟

## [پیش‌زمینه درس](https://ff-quizzes.netlify.app/en/ai/quiz/15)

این روش **یادگیری انتقالی** نامیده می‌شود، زیرا ما بخشی از دانش یک مدل شبکه عصبی را به مدل دیگری منتقل می‌کنیم. در یادگیری انتقالی، معمولاً با یک مدل از پیش آموزش‌دیده شروع می‌کنیم که روی یک مجموعه داده بزرگ تصویری مانند **ImageNet** آموزش دیده است. این مدل‌ها می‌توانند ویژگی‌های مختلفی را از تصاویر عمومی استخراج کنند و در بسیاری از موارد، تنها با ساخت یک طبقه‌بند بر روی این ویژگی‌های استخراج‌شده می‌توان به نتایج خوبی دست یافت.

> ✅ یادگیری انتقالی اصطلاحی است که در سایر حوزه‌های علمی مانند آموزش نیز یافت می‌شود. این اصطلاح به فرآیند انتقال دانش از یک حوزه و اعمال آن در حوزه دیگر اشاره دارد.

## مدل‌های از پیش آموزش‌دیده به عنوان استخراج‌کننده ویژگی‌ها

شبکه‌های پیچشی که در بخش قبلی درباره آن‌ها صحبت کردیم شامل تعدادی لایه بودند که هر کدام وظیفه استخراج ویژگی‌هایی از تصویر را داشتند، از ترکیب‌های پیکسلی سطح پایین (مانند خطوط افقی/عمودی یا ضربه‌ها) تا ترکیب‌های سطح بالاتر ویژگی‌ها که به چیزهایی مانند چشم یا شعله مربوط می‌شوند. اگر یک CNN را روی مجموعه داده‌ای به اندازه کافی بزرگ و متنوع آموزش دهیم، شبکه باید بتواند این ویژگی‌های عمومی را استخراج کند.

هم Keras و هم PyTorch شامل توابعی هستند که به راحتی وزن‌های شبکه عصبی از پیش آموزش‌دیده را برای برخی معماری‌های رایج بارگذاری می‌کنند، که بیشتر آن‌ها روی تصاویر ImageNet آموزش دیده‌اند. رایج‌ترین مدل‌ها در صفحه [معماری‌های CNN](../07-ConvNets/CNN_Architectures.md) از درس قبلی توضیح داده شده‌اند. به طور خاص، ممکن است بخواهید یکی از موارد زیر را در نظر بگیرید:

* **VGG-16/VGG-19** که مدل‌های نسبتاً ساده‌ای هستند و همچنان دقت خوبی ارائه می‌دهند. استفاده از VGG به عنوان اولین تلاش برای بررسی عملکرد یادگیری انتقالی انتخاب خوبی است.
* **ResNet** خانواده‌ای از مدل‌ها است که توسط Microsoft Research در سال ۲۰۱۵ پیشنهاد شده‌اند. این مدل‌ها لایه‌های بیشتری دارند و بنابراین منابع بیشتری مصرف می‌کنند.
* **MobileNet** خانواده‌ای از مدل‌ها با اندازه کاهش‌یافته هستند که برای دستگاه‌های موبایل مناسب‌اند. از آن‌ها استفاده کنید اگر منابع محدودی دارید و می‌توانید کمی دقت را قربانی کنید.

در اینجا نمونه‌ای از ویژگی‌هایی که توسط شبکه VGG-16 از تصویر یک گربه استخراج شده است آورده شده است:

![ویژگی‌های استخراج‌شده توسط VGG-16](../../../../../lessons/4-ComputerVision/08-TransferLearning/images/features.png)

## مجموعه داده گربه‌ها و سگ‌ها

در این مثال، از مجموعه داده [گربه‌ها و سگ‌ها](https://www.microsoft.com/download/details.aspx?id=54765&WT.mc_id=academic-77998-cacaste) استفاده خواهیم کرد که بسیار نزدیک به یک سناریوی واقعی طبقه‌بندی تصویر است.

## ✍️ تمرین: یادگیری انتقالی

بیایید یادگیری انتقالی را در عمل در نوت‌بوک‌های مربوطه مشاهده کنیم:

* [یادگیری انتقالی - PyTorch](../../../../../lessons/4-ComputerVision/08-TransferLearning/TransferLearningPyTorch.ipynb)
* [یادگیری انتقالی - TensorFlow](../../../../../lessons/4-ComputerVision/08-TransferLearning/TransferLearningTF.ipynb)

## تجسم گربه ایده‌آل

شبکه عصبی از پیش آموزش‌دیده شامل الگوهای مختلفی در "مغز" خود است، از جمله مفاهیمی از **گربه ایده‌آل** (و همچنین سگ ایده‌آل، گورخر ایده‌آل و غیره). جالب خواهد بود که به نوعی **این تصویر را تجسم کنیم**. با این حال، این کار ساده نیست، زیرا الگوها در سراسر وزن‌های شبکه پراکنده شده‌اند و همچنین در یک ساختار سلسله‌مراتبی سازماندهی شده‌اند.

یک رویکردی که می‌توانیم اتخاذ کنیم این است که با یک تصویر تصادفی شروع کنیم و سپس از تکنیک **بهینه‌سازی نزول گرادیان** استفاده کنیم تا آن تصویر را به گونه‌ای تنظیم کنیم که شبکه شروع به فکر کردن کند که این تصویر یک گربه است.

![حلقه بهینه‌سازی تصویر](../../../../../lessons/4-ComputerVision/08-TransferLearning/images/ideal-cat-loop.png)

با این حال، اگر این کار را انجام دهیم، چیزی بسیار شبیه به نویز تصادفی دریافت خواهیم کرد. این به این دلیل است که *راه‌های زیادی وجود دارد که شبکه فکر کند تصویر ورودی یک گربه است*، از جمله برخی که از نظر بصری منطقی نیستند. در حالی که این تصاویر شامل بسیاری از الگوهای معمولی برای یک گربه هستند، هیچ چیزی آن‌ها را محدود نمی‌کند که از نظر بصری متمایز باشند.

برای بهبود نتیجه، می‌توانیم یک عبارت دیگر به تابع زیان اضافه کنیم که **زیان تغییرات** نامیده می‌شود. این معیار نشان می‌دهد که پیکسل‌های مجاور تصویر چقدر مشابه هستند. به حداقل رساندن زیان تغییرات باعث می‌شود تصویر صاف‌تر شود و نویز را از بین ببرد - بنابراین الگوهای بصری جذاب‌تری را آشکار می‌کند. در اینجا نمونه‌ای از چنین تصاویر "ایده‌آل" آورده شده است که با احتمال بالا به عنوان گربه و گورخر طبقه‌بندی شده‌اند:

![گربه ایده‌آل](../../../../../lessons/4-ComputerVision/08-TransferLearning/images/ideal-cat.png) | ![گورخر ایده‌آل](../../../../../lessons/4-ComputerVision/08-TransferLearning/images/ideal-zebra.png)
-----|-----
 *گربه ایده‌آل* | *گورخر ایده‌آل*

رویکرد مشابهی می‌تواند برای انجام **حملات خصمانه** روی یک شبکه عصبی استفاده شود. فرض کنید می‌خواهیم یک شبکه عصبی را فریب دهیم و یک سگ را شبیه به گربه کنیم. اگر تصویر سگ را که توسط شبکه به عنوان سگ شناخته می‌شود بگیریم، می‌توانیم آن را کمی تنظیم کنیم با استفاده از بهینه‌سازی نزول گرادیان، تا زمانی که شبکه شروع به طبقه‌بندی آن به عنوان گربه کند:

![تصویر سگ](../../../../../lessons/4-ComputerVision/08-TransferLearning/images/original-dog.png) | ![تصویر سگی که به عنوان گربه طبقه‌بندی شده است](../../../../../lessons/4-ComputerVision/08-TransferLearning/images/adversarial-dog.png)
-----|-----
*تصویر اصلی سگ* | *تصویر سگی که به عنوان گربه طبقه‌بندی شده است*

کد برای بازتولید نتایج بالا را در نوت‌بوک زیر مشاهده کنید:

* [گربه ایده‌آل و خصمانه - TensorFlow](../../../../../lessons/4-ComputerVision/08-TransferLearning/AdversarialCat_TF.ipynb)

## نتیجه‌گیری

با استفاده از یادگیری انتقالی، می‌توانید به سرعت یک طبقه‌بند برای یک وظیفه طبقه‌بندی اشیاء سفارشی ایجاد کنید و به دقت بالایی دست یابید. می‌بینید که وظایف پیچیده‌تر که اکنون در حال حل آن‌ها هستیم نیازمند قدرت محاسباتی بالاتری هستند و نمی‌توانند به راحتی روی CPU حل شوند. در واحد بعدی، سعی خواهیم کرد از یک پیاده‌سازی سبک‌تر برای آموزش همان مدل با منابع محاسباتی کمتر استفاده کنیم، که منجر به دقت کمی پایین‌تر می‌شود.

## 🚀 چالش

در نوت‌بوک‌های همراه، یادداشت‌هایی در پایین وجود دارد که توضیح می‌دهد چگونه دانش انتقالی با داده‌های آموزشی نسبتاً مشابه بهتر عمل می‌کند (شاید نوع جدیدی از حیوان). با تصاویر کاملاً جدید آزمایش کنید تا ببینید مدل‌های دانش انتقالی شما چقدر خوب یا ضعیف عمل می‌کنند.

## [آزمون پس از درس](https://ff-quizzes.netlify.app/en/ai/quiz/16)

## مرور و مطالعه خودآموز

از طریق [TrainingTricks.md](TrainingTricks.md) مطالعه کنید تا دانش خود را درباره روش‌های دیگر آموزش مدل‌ها عمیق‌تر کنید.

## [تکلیف](lab/README.md)

در این آزمایش، از مجموعه داده واقعی [Oxford-IIIT](https://www.robots.ox.ac.uk/~vgg/data/pets/) حیوانات خانگی با ۳۵ نژاد گربه و سگ استفاده خواهیم کرد و یک طبقه‌بند یادگیری انتقالی خواهیم ساخت.

**سلب مسئولیت**:  
این سند با استفاده از سرویس ترجمه هوش مصنوعی [Co-op Translator](https://github.com/Azure/co-op-translator) ترجمه شده است. در حالی که ما تلاش می‌کنیم دقت را حفظ کنیم، لطفاً توجه داشته باشید که ترجمه‌های خودکار ممکن است حاوی خطاها یا نادرستی‌هایی باشند. سند اصلی به زبان اصلی آن باید به عنوان منبع معتبر در نظر گرفته شود. برای اطلاعات حساس، ترجمه حرفه‌ای انسانی توصیه می‌شود. ما هیچ مسئولیتی در قبال سوءتفاهم‌ها یا تفسیرهای نادرست ناشی از استفاده از این ترجمه نداریم.