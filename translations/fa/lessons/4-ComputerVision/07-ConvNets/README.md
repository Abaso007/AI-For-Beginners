<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "088837b42b7d99198bf62db8a42411e0",
  "translation_date": "2025-08-24T10:29:29+00:00",
  "source_file": "lessons/4-ComputerVision/07-ConvNets/README.md",
  "language_code": "fa"
}
-->
# شبکه‌های عصبی پیچشی

قبلاً دیده‌ایم که شبکه‌های عصبی در پردازش تصاویر بسیار خوب عمل می‌کنند، حتی یک پرسپترون تک‌لایه قادر است اعداد دست‌نویس مجموعه داده MNIST را با دقت قابل قبولی تشخیص دهد. با این حال، مجموعه داده MNIST بسیار خاص است و همه اعداد در مرکز تصویر قرار دارند، که این کار را ساده‌تر می‌کند.

## [آزمون پیش از درس](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/107)

در زندگی واقعی، ما می‌خواهیم بتوانیم اشیاء را در یک تصویر تشخیص دهیم، بدون توجه به مکان دقیق آن‌ها در تصویر. بینایی کامپیوتری با طبقه‌بندی عمومی متفاوت است، زیرا وقتی سعی می‌کنیم یک شیء خاص را در تصویر پیدا کنیم، تصویر را اسکن می‌کنیم و به دنبال **الگوهای** خاص و ترکیب‌های آن‌ها می‌گردیم. برای مثال، وقتی به دنبال یک گربه هستیم، ممکن است ابتدا به دنبال خطوط افقی بگردیم که می‌توانند سبیل‌ها را تشکیل دهند، و سپس ترکیب خاصی از سبیل‌ها می‌تواند به ما بگوید که این واقعاً تصویر یک گربه است. موقعیت نسبی و حضور الگوهای خاص مهم است، نه موقعیت دقیق آن‌ها در تصویر.

برای استخراج الگوها، از مفهوم **فیلترهای پیچشی** استفاده خواهیم کرد. همان‌طور که می‌دانید، یک تصویر به صورت یک ماتریس دو‌بعدی یا یک تنسور سه‌بعدی با عمق رنگ نمایش داده می‌شود. اعمال یک فیلتر به این معناست که یک ماتریس کوچک به نام **هسته فیلتر** را می‌گیریم و برای هر پیکسل در تصویر اصلی میانگین وزنی با نقاط همسایه را محاسبه می‌کنیم. می‌توان این فرآیند را به صورت یک پنجره کوچک تصور کرد که روی کل تصویر حرکت می‌کند و همه پیکسل‌ها را بر اساس وزن‌های موجود در ماتریس هسته فیلتر میانگین‌گیری می‌کند.

![فیلتر لبه عمودی](../../../../../lessons/4-ComputerVision/07-ConvNets/images/filter-vert.png) | ![فیلتر لبه افقی](../../../../../lessons/4-ComputerVision/07-ConvNets/images/filter-horiz.png)
----|----

> تصویر از دیمیتری سوشنیکوف

برای مثال، اگر فیلترهای لبه عمودی و افقی ۳x۳ را به اعداد MNIST اعمال کنیم، می‌توانیم نقاط برجسته (مانند مقادیر بالا) را در جایی که لبه‌های عمودی و افقی در تصویر اصلی وجود دارند، دریافت کنیم. بنابراین این دو فیلتر می‌توانند برای "جستجوی" لبه‌ها استفاده شوند. به همین ترتیب، می‌توانیم فیلترهای مختلفی طراحی کنیم تا به دنبال سایر الگوهای سطح پایین بگردیم:

> تصویر از [بانک فیلتر Leung-Malik](https://www.robots.ox.ac.uk/~vgg/research/texclass/filters.html)

با این حال، در حالی که می‌توانیم فیلترها را برای استخراج برخی الگوها به صورت دستی طراحی کنیم، می‌توانیم شبکه را نیز به گونه‌ای طراحی کنیم که الگوها را به صورت خودکار یاد بگیرد. این یکی از ایده‌های اصلی پشت شبکه‌های عصبی پیچشی است.

## ایده‌های اصلی پشت شبکه‌های عصبی پیچشی

نحوه عملکرد شبکه‌های عصبی پیچشی بر اساس ایده‌های مهم زیر است:

* فیلترهای پیچشی می‌توانند الگوها را استخراج کنند.
* می‌توانیم شبکه را به گونه‌ای طراحی کنیم که فیلترها به صورت خودکار آموزش ببینند.
* می‌توانیم از همین روش برای یافتن الگوها در ویژگی‌های سطح بالا استفاده کنیم، نه فقط در تصویر اصلی. بنابراین استخراج ویژگی‌های CNN بر روی سلسله مراتبی از ویژگی‌ها کار می‌کند، از ترکیب‌های پیکسلی سطح پایین تا ترکیب‌های سطح بالاتر از بخش‌های تصویر.

![استخراج ویژگی سلسله‌مراتبی](../../../../../lessons/4-ComputerVision/07-ConvNets/images/FeatureExtractionCNN.png)

> تصویر از [مقاله‌ای توسط Hislop-Lynch](https://www.semanticscholar.org/paper/Computer-vision-based-pedestrian-trajectory-Hislop-Lynch/26e6f74853fc9bbb7487b06dc2cf095d36c9021d)، بر اساس [تحقیقات آن‌ها](https://dl.acm.org/doi/abs/10.1145/1553374.1553453)

## ✍️ تمرین‌ها: شبکه‌های عصبی پیچشی

بیایید به بررسی نحوه عملکرد شبکه‌های عصبی پیچشی و چگونگی دستیابی به فیلترهای قابل آموزش ادامه دهیم، با کار کردن بر روی نوت‌بوک‌های مربوطه:

* [شبکه‌های عصبی پیچشی - PyTorch](../../../../../lessons/4-ComputerVision/07-ConvNets/ConvNetsPyTorch.ipynb)
* [شبکه‌های عصبی پیچشی - TensorFlow](../../../../../lessons/4-ComputerVision/07-ConvNets/ConvNetsTF.ipynb)

## معماری هرمی

بیشتر شبکه‌های عصبی پیچشی که برای پردازش تصویر استفاده می‌شوند از معماری موسوم به هرمی پیروی می‌کنند. اولین لایه پیچشی که به تصاویر اصلی اعمال می‌شود معمولاً تعداد نسبتاً کمی فیلتر (۸-۱۶) دارد، که به ترکیب‌های مختلف پیکسلی مانند خطوط افقی/عمودی مربوط می‌شود. در سطح بعدی، ابعاد فضایی شبکه کاهش می‌یابد و تعداد فیلترها افزایش می‌یابد، که به ترکیب‌های بیشتری از ویژگی‌های ساده مربوط می‌شود. با هر لایه، همان‌طور که به سمت طبقه‌بند نهایی حرکت می‌کنیم، ابعاد فضایی تصویر کاهش می‌یابد و تعداد فیلترها افزایش می‌یابد.

به عنوان مثال، بیایید به معماری VGG-16 نگاه کنیم، شبکه‌ای که در سال ۲۰۱۴ به دقت ۹۲.۷٪ در طبقه‌بندی پنج‌تایی ImageNet دست یافت:

![لایه‌های ImageNet](../../../../../lessons/4-ComputerVision/07-ConvNets/images/vgg-16-arch1.jpg)

![هرم ImageNet](../../../../../lessons/4-ComputerVision/07-ConvNets/images/vgg-16-arch.jpg)

> تصویر از [Researchgate](https://www.researchgate.net/figure/Vgg16-model-structure-To-get-the-VGG-NIN-model-we-replace-the-2-nd-4-th-6-th-7-th_fig2_335194493)

## معروف‌ترین معماری‌های شبکه‌های عصبی پیچشی

[مطالعه خود درباره معروف‌ترین معماری‌های شبکه‌های عصبی پیچشی را ادامه دهید](CNN_Architectures.md)

**سلب مسئولیت**:  
این سند با استفاده از سرویس ترجمه هوش مصنوعی [Co-op Translator](https://github.com/Azure/co-op-translator) ترجمه شده است. در حالی که ما تلاش می‌کنیم دقت را حفظ کنیم، لطفاً توجه داشته باشید که ترجمه‌های خودکار ممکن است حاوی خطاها یا نادرستی‌هایی باشند. سند اصلی به زبان اصلی آن باید به عنوان منبع معتبر در نظر گرفته شود. برای اطلاعات حساس، ترجمه حرفه‌ای انسانی توصیه می‌شود. ما هیچ مسئولیتی در قبال سوءتفاهم‌ها یا تفسیرهای نادرست ناشی از استفاده از این ترجمه نداریم.