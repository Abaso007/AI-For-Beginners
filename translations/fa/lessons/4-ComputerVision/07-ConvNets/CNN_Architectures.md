<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "2f7b97b375358cb51a1e098df306bf73",
  "translation_date": "2025-08-24T10:30:04+00:00",
  "source_file": "lessons/4-ComputerVision/07-ConvNets/CNN_Architectures.md",
  "language_code": "fa"
}
-->
# معماری‌های معروف شبکه‌های عصبی کانولوشنی (CNN)

### VGG-16

VGG-16 یک شبکه است که در سال ۲۰۱۴ به دقت ۹۲.۷٪ در طبقه‌بندی ImageNet (در دسته‌بندی ۵ برتر) دست یافت. ساختار لایه‌های آن به صورت زیر است:

![لایه‌های ImageNet](../../../../../lessons/4-ComputerVision/07-ConvNets/images/vgg-16-arch1.jpg)

همان‌طور که می‌بینید، VGG از یک معماری هرمی سنتی پیروی می‌کند که شامل توالی‌ای از لایه‌های کانولوشن-پولینگ است.

![هرم ImageNet](../../../../../lessons/4-ComputerVision/07-ConvNets/images/vgg-16-arch.jpg)

> تصویر از [Researchgate](https://www.researchgate.net/figure/Vgg16-model-structure-To-get-the-VGG-NIN-model-we-replace-the-2-nd-4-th-6-th-7-th_fig2_335194493)

### ResNet

ResNet خانواده‌ای از مدل‌ها است که توسط Microsoft Research در سال ۲۰۱۵ پیشنهاد شد. ایده اصلی ResNet استفاده از **بلوک‌های باقیمانده (residual blocks)** است:

<img src="images/resnet-block.png" width="300"/>

> تصویر از [این مقاله](https://arxiv.org/pdf/1512.03385.pdf)

دلیل استفاده از مسیر عبور هویتی (identity pass-through) این است که لایه ما **تفاوت** بین نتیجه لایه قبلی و خروجی بلوک باقیمانده را پیش‌بینی کند - به همین دلیل به آن *باقیمانده* گفته می‌شود. این بلوک‌ها بسیار آسان‌تر برای آموزش هستند و می‌توان شبکه‌هایی با صدها بلوک از این نوع ساخت (رایج‌ترین نسخه‌ها ResNet-52، ResNet-101 و ResNet-152 هستند).

همچنین می‌توانید این شبکه را به‌گونه‌ای تصور کنید که پیچیدگی خود را با داده‌های مجموعه تنظیم می‌کند. در ابتدا، زمانی که آموزش شبکه را شروع می‌کنید، مقادیر وزن‌ها کوچک هستند و بیشتر سیگنال از طریق لایه‌های هویتی عبور می‌کند. با پیشرفت آموزش و بزرگ‌تر شدن وزن‌ها، اهمیت پارامترهای شبکه افزایش می‌یابد و شبکه خود را برای تطبیق با قدرت بیانی مورد نیاز برای طبقه‌بندی صحیح تصاویر آموزشی تنظیم می‌کند.

### Google Inception

معماری Google Inception این ایده را یک قدم جلوتر می‌برد و هر لایه شبکه را به‌عنوان ترکیبی از چند مسیر مختلف می‌سازد:

<img src="images/inception.png" width="400"/>

> تصویر از [Researchgate](https://www.researchgate.net/figure/Inception-module-with-dimension-reductions-left-and-schema-for-Inception-ResNet-v1_fig2_355547454)

اینجا باید به نقش کانولوشن‌های ۱x1 تأکید کنیم، زیرا در ابتدا ممکن است بی‌معنی به نظر برسند. چرا باید تصویر را با یک فیلتر ۱x1 پردازش کنیم؟ اما باید به یاد داشته باشید که فیلترهای کانولوشن با چندین کانال عمقی (در ابتدا - رنگ‌های RGB، و در لایه‌های بعدی - کانال‌هایی برای فیلترهای مختلف) کار می‌کنند و کانولوشن ۱x1 برای ترکیب این کانال‌های ورودی با استفاده از وزن‌های قابل آموزش مختلف استفاده می‌شود. همچنین می‌توان آن را به‌عنوان نمونه‌برداری پایین (pooling) در بعد کانال در نظر گرفت.

[این پست وبلاگ خوب](https://medium.com/analytics-vidhya/talented-mr-1x1-comprehensive-look-at-1x1-convolution-in-deep-learning-f6b355825578) و [مقاله اصلی](https://arxiv.org/pdf/1312.4400.pdf) منابع خوبی برای مطالعه بیشتر هستند.

### MobileNet

MobileNet خانواده‌ای از مدل‌ها با اندازه کاهش‌یافته است که برای دستگاه‌های موبایل مناسب هستند. از آن‌ها استفاده کنید اگر منابع محدودی دارید و می‌توانید کمی از دقت صرف‌نظر کنید. ایده اصلی پشت این مدل‌ها **کانولوشن تفکیک‌پذیر عمقی (depthwise separable convolution)** است که امکان نمایش فیلترهای کانولوشن را به‌صورت ترکیبی از کانولوشن‌های فضایی و کانولوشن ۱x1 بر روی کانال‌های عمقی فراهم می‌کند. این کار به‌طور قابل‌توجهی تعداد پارامترها را کاهش می‌دهد، اندازه شبکه را کوچک‌تر می‌کند و همچنین آموزش آن را با داده‌های کمتر آسان‌تر می‌سازد.

[این پست وبلاگ خوب درباره MobileNet](https://medium.com/analytics-vidhya/image-classification-with-mobilenet-cc6fbb2cd470) را مطالعه کنید.

## نتیجه‌گیری

در این بخش، شما مفهوم اصلی شبکه‌های عصبی کانولوشنی در بینایی کامپیوتری را یاد گرفتید. معماری‌های واقعی که قدرت طبقه‌بندی تصویر، تشخیص اشیاء و حتی تولید تصویر را دارند، همگی بر اساس CNN‌ها ساخته شده‌اند، فقط با لایه‌های بیشتر و برخی ترفندهای آموزشی اضافی.

## 🚀 چالش

در نوت‌بوک‌های همراه، یادداشت‌هایی در پایین درباره چگونگی دستیابی به دقت بیشتر وجود دارد. چند آزمایش انجام دهید تا ببینید آیا می‌توانید دقت بالاتری به دست آورید.

## [آزمون پس از درس](https://ff-quizzes.netlify.app/en/ai/quiz/14)

## مرور و مطالعه شخصی

در حالی که CNN‌ها بیشتر برای وظایف بینایی کامپیوتری استفاده می‌شوند، به‌طور کلی برای استخراج الگوهای با اندازه ثابت مناسب هستند. به‌عنوان مثال، اگر با صداها سروکار داریم، ممکن است بخواهیم از CNN‌ها برای جستجوی برخی الگوهای خاص در سیگنال صوتی استفاده کنیم - که در این صورت فیلترها یک‌بعدی خواهند بود (و این CNN به‌عنوان 1D-CNN شناخته می‌شود). همچنین، گاهی اوقات از 3D-CNN برای استخراج ویژگی‌ها در فضای چندبعدی استفاده می‌شود، مانند رویدادهای خاصی که در ویدیو رخ می‌دهند - CNN می‌تواند الگوهای خاصی از تغییر ویژگی‌ها در طول زمان را ثبت کند. درباره وظایف دیگری که می‌توان با CNN‌ها انجام داد، مرور و مطالعه شخصی انجام دهید.

## [تکلیف](lab/README.md)

در این آزمایشگاه، وظیفه شما طبقه‌بندی نژادهای مختلف گربه و سگ است. این تصاویر پیچیده‌تر از مجموعه داده MNIST هستند، ابعاد بالاتری دارند و بیش از ۱۰ کلاس وجود دارد.

**سلب مسئولیت**:  
این سند با استفاده از سرویس ترجمه هوش مصنوعی [Co-op Translator](https://github.com/Azure/co-op-translator) ترجمه شده است. در حالی که ما تلاش می‌کنیم دقت را حفظ کنیم، لطفاً توجه داشته باشید که ترجمه‌های خودکار ممکن است حاوی خطاها یا نادرستی‌هایی باشند. سند اصلی به زبان اصلی آن باید به عنوان منبع معتبر در نظر گرفته شود. برای اطلاعات حساس، ترجمه حرفه‌ای انسانی توصیه می‌شود. ما هیچ مسئولیتی در قبال سوءتفاهم‌ها یا تفسیرهای نادرست ناشی از استفاده از این ترجمه نداریم.