<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f07c85bbf05a1f67505da98f4ecc124c",
  "translation_date": "2025-08-24T10:27:01+00:00",
  "source_file": "lessons/4-ComputerVision/10-GANs/README.md",
  "language_code": "fa"
}
-->
# شبکه‌های مولد تخاصمی

در بخش قبلی، درباره **مدل‌های مولد** یاد گرفتیم: مدل‌هایی که می‌توانند تصاویر جدیدی مشابه تصاویر موجود در مجموعه داده آموزشی تولید کنند. VAE نمونه‌ای خوب از یک مدل مولد بود.

## [پیش‌از-درس آزمون](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/110)

با این حال، اگر بخواهیم چیزی واقعاً معنادار، مانند یک نقاشی با وضوح مناسب، تولید کنیم، با استفاده از VAE متوجه می‌شویم که آموزش به خوبی همگرا نمی‌شود. برای این مورد استفاده، باید درباره معماری دیگری که به طور خاص برای مدل‌های مولد طراحی شده است یاد بگیریم - **شبکه‌های مولد تخاصمی** یا GANs.

ایده اصلی GAN این است که دو شبکه عصبی داشته باشیم که در برابر یکدیگر آموزش ببینند:

<img src="images/gan_architecture.png" width="70%"/>

> تصویر از [دمیتری سوشنیکوف](http://soshnikov.com)

> ✅ کمی واژگان:
> * **مولد (Generator)** شبکه‌ای است که یک بردار تصادفی را می‌گیرد و به عنوان نتیجه تصویر تولید می‌کند.
> * **تمایزدهنده (Discriminator)** شبکه‌ای است که یک تصویر را می‌گیرد و باید تشخیص دهد که آیا این تصویر واقعی است (از مجموعه داده آموزشی) یا توسط مولد تولید شده است. این اساساً یک طبقه‌بند تصویر است.

### تمایزدهنده

معماری تمایزدهنده با یک شبکه طبقه‌بندی تصویر معمولی تفاوتی ندارد. در ساده‌ترین حالت، می‌تواند یک طبقه‌بند کاملاً متصل باشد، اما به احتمال زیاد یک [شبکه کانولوشنی](../07-ConvNets/README.md) خواهد بود.

> ✅ یک GAN مبتنی بر شبکه‌های کانولوشنی به نام [DCGAN](https://arxiv.org/pdf/1511.06434.pdf) شناخته می‌شود.

یک تمایزدهنده CNN شامل لایه‌های زیر است: چندین کانولوشن+پولینگ (با کاهش اندازه فضایی) و یک یا چند لایه کاملاً متصل برای به دست آوردن "بردار ویژگی"، و در نهایت یک طبقه‌بند دودویی.

> ✅ "پولینگ" در این زمینه تکنیکی است که اندازه تصویر را کاهش می‌دهد. "لایه‌های پولینگ ابعاد داده را با ترکیب خروجی‌های خوشه‌های نورون در یک لایه به یک نورون در لایه بعدی کاهش می‌دهند." - [منبع](https://wikipedia.org/wiki/Convolutional_neural_network#Pooling_layers)

### مولد

مولد کمی پیچیده‌تر است. می‌توانید آن را به عنوان یک تمایزدهنده معکوس در نظر بگیرید. از یک بردار نهفته (به جای بردار ویژگی) شروع می‌کند، یک لایه کاملاً متصل دارد تا آن را به اندازه/شکل مورد نیاز تبدیل کند، و سپس با دکانولوشن‌ها+بزرگ‌نمایی ادامه می‌دهد. این شبیه به بخش *رمزگشا* در [خودرمزگذار](../09-Autoencoders/README.md) است.

> ✅ از آنجا که لایه کانولوشن به عنوان یک فیلتر خطی که تصویر را طی می‌کند پیاده‌سازی می‌شود، دکانولوشن اساساً مشابه کانولوشن است و می‌تواند با همان منطق لایه پیاده‌سازی شود.

<img src="images/gan_arch_detail.png" width="70%"/>

> تصویر از [دمیتری سوشنیکوف](http://soshnikov.com)

### آموزش GAN

GANها **تخاصمی** نامیده می‌شوند زیرا یک رقابت مداوم بین مولد و تمایزدهنده وجود دارد. در طول این رقابت، هم مولد و هم تمایزدهنده بهبود می‌یابند و در نتیجه شبکه یاد می‌گیرد تصاویر بهتر و بهتری تولید کند.

آموزش در دو مرحله انجام می‌شود:

* **آموزش تمایزدهنده**. این کار نسبتاً ساده است: یک دسته از تصاویر را توسط مولد تولید می‌کنیم، آن‌ها را با برچسب 0 (که نشان‌دهنده تصویر جعلی است) برچسب‌گذاری می‌کنیم و یک دسته از تصاویر را از مجموعه داده ورودی می‌گیریم (با برچسب 1، تصویر واقعی). سپس یک *تابع خطای تمایزدهنده* به دست می‌آوریم و بازپراکنش انجام می‌دهیم.
* **آموزش مولد**. این کمی پیچیده‌تر است، زیرا خروجی مورد انتظار برای مولد را مستقیماً نمی‌دانیم. کل شبکه GAN شامل یک مولد و یک تمایزدهنده را می‌گیریم، آن را با بردارهای تصادفی تغذیه می‌کنیم و انتظار داریم نتیجه 1 باشد (که مربوط به تصاویر واقعی است). سپس پارامترهای تمایزدهنده را ثابت می‌کنیم (نمی‌خواهیم در این مرحله آموزش ببیند) و بازپراکنش انجام می‌دهیم.

در طول این فرآیند، خطاهای مولد و تمایزدهنده به طور قابل توجهی کاهش نمی‌یابند. در حالت ایده‌آل، آن‌ها باید نوسان کنند، که نشان‌دهنده بهبود عملکرد هر دو شبکه است.

## ✍️ تمرین‌ها: GANها

* [دفترچه GAN در TensorFlow/Keras](../../../../../lessons/4-ComputerVision/10-GANs/GANTF.ipynb)
* [دفترچه GAN در PyTorch](../../../../../lessons/4-ComputerVision/10-GANs/GANPyTorch.ipynb)

### مشکلات آموزش GAN

GANها به طور خاص به سختی آموزش داده می‌شوند. در اینجا چند مشکل وجود دارد:

* **فروپاشی حالت (Mode Collapse)**. این اصطلاح به این معناست که مولد یاد می‌گیرد یک تصویر موفق تولید کند که تمایزدهنده را فریب دهد، اما تنوعی از تصاویر مختلف تولید نمی‌کند.
* **حساسیت به ابرپارامترها**. اغلب می‌بینید که یک GAN اصلاً همگرا نمی‌شود و سپس با کاهش ناگهانی نرخ یادگیری به همگرایی می‌رسد.
* حفظ **تعادل** بین مولد و تمایزدهنده. در بسیاری از موارد، خطای تمایزدهنده می‌تواند نسبتاً سریع به صفر برسد، که باعث می‌شود مولد نتواند بیشتر آموزش ببیند. برای غلبه بر این مشکل، می‌توانیم نرخ‌های یادگیری متفاوتی برای مولد و تمایزدهنده تنظیم کنیم یا آموزش تمایزدهنده را متوقف کنیم اگر خطا از قبل خیلی کم باشد.
* آموزش برای **وضوح بالا**. این مشکل مشابه مشکل خودرمزگذارها است و زمانی ایجاد می‌شود که بازسازی لایه‌های بیش از حد شبکه کانولوشنی منجر به مصنوعات شود. این مشکل معمولاً با روش **رشد تدریجی** حل می‌شود، که در آن ابتدا چند لایه روی تصاویر با وضوح پایین آموزش داده می‌شوند و سپس لایه‌ها "باز می‌شوند" یا اضافه می‌شوند. راه‌حل دیگر اضافه کردن اتصالات اضافی بین لایه‌ها و آموزش چند وضوح به طور همزمان است - برای جزئیات بیشتر به این [مقاله Multi-Scale Gradient GANs](https://arxiv.org/abs/1903.06048) مراجعه کنید.

## انتقال سبک

GANها راهی عالی برای تولید تصاویر هنری هستند. تکنیک جالب دیگر **انتقال سبک** است که یک **تصویر محتوا** را می‌گیرد و آن را در یک سبک متفاوت بازطراحی می‌کند، با استفاده از فیلترهایی از **تصویر سبک**.

روش کار به این صورت است:
* با یک تصویر نویز تصادفی شروع می‌کنیم (یا با یک تصویر محتوا، اما برای درک بهتر بهتر است از نویز تصادفی شروع کنیم)
* هدف ما ایجاد تصویری است که به هر دو تصویر محتوا و تصویر سبک نزدیک باشد. این کار با دو تابع خطا تعیین می‌شود:
   - **خطای محتوا** بر اساس ویژگی‌هایی که توسط CNN در برخی لایه‌ها از تصویر فعلی و تصویر محتوا استخراج شده‌اند محاسبه می‌شود.
   - **خطای سبک** بین تصویر فعلی و تصویر سبک به روشی هوشمندانه با استفاده از ماتریس‌های گرام محاسبه می‌شود (جزئیات بیشتر در [دفترچه مثال](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)).
* برای صاف‌تر کردن تصویر و حذف نویز، **خطای تغییرات** نیز معرفی می‌شود، که فاصله میانگین بین پیکسل‌های همسایه را محاسبه می‌کند.
* حلقه اصلی بهینه‌سازی تصویر فعلی را با استفاده از نزول گرادیان (یا برخی الگوریتم‌های بهینه‌سازی دیگر) تنظیم می‌کند تا خطای کل، که مجموع وزنی همه خطاها است، به حداقل برسد.

## ✍️ مثال: [انتقال سبک](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)

## [پس‌از-درس آزمون](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/210)

## نتیجه‌گیری

در این درس، درباره GANها و نحوه آموزش آن‌ها یاد گرفتید. همچنین با چالش‌های خاصی که این نوع شبکه عصبی ممکن است با آن مواجه شود و برخی استراتژی‌ها برای غلبه بر آن‌ها آشنا شدید.

## 🚀 چالش

دفترچه [انتقال سبک](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb) را با استفاده از تصاویر خودتان اجرا کنید.

## مرور و مطالعه شخصی

برای مرجع، درباره GANها در این منابع بیشتر بخوانید:

* مارکو پاسینی، [10 درسی که از آموزش GANها در یک سال یاد گرفتم](https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628)
* [StyleGAN](https://en.wikipedia.org/wiki/StyleGAN)، یک معماری GAN *de facto* برای بررسی
* [ایجاد هنر مولد با استفاده از GANها در Azure ML](https://soshnikov.com/scienceart/creating-generative-art-using-gan-on-azureml/)

## تکلیف

یکی از دو دفترچه مرتبط با این درس را مرور کنید و GAN را روی تصاویر خودتان دوباره آموزش دهید. چه چیزی می‌توانید ایجاد کنید؟

**سلب مسئولیت**:  
این سند با استفاده از سرویس ترجمه هوش مصنوعی [Co-op Translator](https://github.com/Azure/co-op-translator) ترجمه شده است. در حالی که ما تلاش می‌کنیم دقت را حفظ کنیم، لطفاً توجه داشته باشید که ترجمه‌های خودکار ممکن است حاوی خطاها یا نادرستی‌هایی باشند. سند اصلی به زبان بومی آن باید به عنوان منبع معتبر در نظر گرفته شود. برای اطلاعات حساس، ترجمه حرفه‌ای انسانی توصیه می‌شود. ما هیچ مسئولیتی در قبال سوءتفاهم‌ها یا تفسیرهای نادرست ناشی از استفاده از این ترجمه نداریم.