<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "5d1cbc67a9690adb5b33adf297794087",
  "translation_date": "2025-08-24T10:23:32+00:00",
  "source_file": "lessons/1-Intro/README.md",
  "language_code": "fa"
}
-->
> تصویر از [دمیتری سوشنیکوف](http://soshnikov.com)

با گذشت زمان، منابع محاسباتی ارزان‌تر شدند و داده‌های بیشتری در دسترس قرار گرفتند، بنابراین روش‌های شبکه عصبی شروع به نشان دادن عملکرد عالی در رقابت با انسان‌ها در بسیاری از زمینه‌ها مانند بینایی کامپیوتری یا درک گفتار کردند. در دهه گذشته، اصطلاح هوش مصنوعی عمدتاً به عنوان مترادف شبکه‌های عصبی استفاده شده است، زیرا بیشتر موفقیت‌های هوش مصنوعی که درباره آن‌ها می‌شنویم بر اساس این روش‌ها هستند.

می‌توانیم مشاهده کنیم که چگونه رویکردها تغییر کرده‌اند، به عنوان مثال، در ایجاد یک برنامه کامپیوتری برای بازی شطرنج:

* برنامه‌های اولیه شطرنج بر اساس جستجو بودند – برنامه به طور صریح تلاش می‌کرد حرکات احتمالی حریف را برای تعداد مشخصی از حرکات آینده تخمین بزند و بر اساس موقعیت بهینه‌ای که می‌توان در چند حرکت به دست آورد، حرکت بهینه را انتخاب کند. این منجر به توسعه الگوریتم جستجوی [alpha-beta pruning](https://en.wikipedia.org/wiki/Alpha%E2%80%93beta_pruning) شد.
* استراتژی‌های جستجو در انتهای بازی که فضای جستجو محدود به تعداد کمی از حرکات ممکن است، خوب عمل می‌کنند. اما در ابتدای بازی، فضای جستجو بسیار بزرگ است و الگوریتم می‌تواند با یادگیری از مسابقات موجود بین بازیکنان انسانی بهبود یابد. آزمایش‌های بعدی از روش [case-based reasoning](https://en.wikipedia.org/wiki/Case-based_reasoning) استفاده کردند، جایی که برنامه به دنبال مواردی در پایگاه دانش می‌گشت که بسیار مشابه موقعیت فعلی در بازی بودند.
* برنامه‌های مدرن که بر بازیکنان انسانی غلبه می‌کنند، بر اساس شبکه‌های عصبی و [یادگیری تقویتی](https://en.wikipedia.org/wiki/Reinforcement_learning) هستند، جایی که برنامه‌ها تنها با بازی طولانی‌مدت با خودشان و یادگیری از اشتباهات خود، یاد می‌گیرند – درست مانند انسان‌ها که هنگام یادگیری بازی شطرنج عمل می‌کنند. با این حال، یک برنامه کامپیوتری می‌تواند بازی‌های بیشتری را در زمان بسیار کمتری انجام دهد و بنابراین می‌تواند بسیار سریع‌تر یاد بگیرد.

✅ کمی تحقیق کنید درباره بازی‌های دیگری که توسط هوش مصنوعی انجام شده‌اند.

به همین ترتیب، می‌توانیم ببینیم که رویکرد ایجاد برنامه‌های "گفتگو کننده" (که ممکن است آزمون تورینگ را بگذرانند) چگونه تغییر کرده است:

* برنامه‌های اولیه از این نوع مانند [Eliza](https://en.wikipedia.org/wiki/ELIZA)، بر اساس قوانین گرامری بسیار ساده و بازفرمول‌بندی جمله ورودی به یک سؤال بودند.
* دستیارهای مدرن مانند Cortana، Siri یا Google Assistant همگی سیستم‌های ترکیبی هستند که از شبکه‌های عصبی برای تبدیل گفتار به متن و تشخیص قصد ما استفاده می‌کنند و سپس از برخی استدلال‌ها یا الگوریتم‌های صریح برای انجام اقدامات مورد نیاز بهره می‌برند.
* در آینده، ممکن است انتظار داشته باشیم که یک مدل کاملاً مبتنی بر شبکه عصبی بتواند به طور کامل گفتگو را مدیریت کند. خانواده‌های اخیر GPT و [Turing-NLG](https://turing.microsoft.com/) از شبکه‌های عصبی موفقیت‌های بزرگی در این زمینه نشان داده‌اند.

> تصویر از دیمیتری سوشنیکوف، [عکس](https://unsplash.com/photos/r8LmVbUKgns) از [مارینا آبروسیمووا](https://unsplash.com/@abrosimova_marina_foto)، Unsplash

## تحقیقات اخیر در زمینه هوش مصنوعی

رشد چشمگیر تحقیقات شبکه‌های عصبی از حدود سال ۲۰۱۰ آغاز شد، زمانی که مجموعه‌های داده عمومی بزرگ در دسترس قرار گرفتند. مجموعه عظیمی از تصاویر به نام [ImageNet](https://en.wikipedia.org/wiki/ImageNet)، که شامل حدود ۱۴ میلیون تصویر حاشیه‌نویسی شده است، منجر به ایجاد [چالش شناسایی بصری در مقیاس بزرگ ImageNet](https://image-net.org/challenges/LSVRC/) شد.

![دقت ILSVRC](../../../../lessons/1-Intro/images/ilsvrc.gif)

> تصویر از [دیمیتری سوشنیکوف](http://soshnikov.com)

در سال ۲۰۱۲، [شبکه‌های عصبی کانولوشن](../4-ComputerVision/07-ConvNets/README.md) برای اولین بار در طبقه‌بندی تصاویر استفاده شدند، که منجر به کاهش قابل توجه خطاهای طبقه‌بندی شد (از تقریباً ۳۰٪ به ۱۶.۴٪). در سال ۲۰۱۵، معماری ResNet از تحقیقات مایکروسافت [به دقت در سطح انسان دست یافت](https://doi.org/10.1109/ICCV.2015.123).

از آن زمان، شبکه‌های عصبی در بسیاری از وظایف عملکرد بسیار موفقی از خود نشان داده‌اند:

---

سال | دستیابی به برابری با انسان
-----|--------
۲۰۱۵ | [طبقه‌بندی تصاویر](https://doi.org/10.1109/ICCV.2015.123)
۲۰۱۶ | [تشخیص گفتار مکالمه‌ای](https://arxiv.org/abs/1610.05256)
۲۰۱۸ | [ترجمه ماشینی خودکار](https://arxiv.org/abs/1803.05567) (چینی به انگلیسی)
۲۰۲۰ | [توصیف تصاویر](https://arxiv.org/abs/2009.13682)

در چند سال گذشته شاهد موفقیت‌های چشمگیری با مدل‌های زبانی بزرگ مانند BERT و GPT-3 بوده‌ایم. این موفقیت‌ها عمدتاً به دلیل وجود حجم زیادی از داده‌های متنی عمومی است که به ما امکان می‌دهد مدل‌ها را برای درک ساختار و معنای متن‌ها آموزش دهیم، آن‌ها را بر روی مجموعه‌های عمومی متن پیش‌آموزش دهیم و سپس این مدل‌ها را برای وظایف خاص‌تر تخصصی کنیم. در ادامه این دوره، درباره [پردازش زبان طبیعی](../5-NLP/README.md) بیشتر یاد خواهیم گرفت.

## 🚀 چالش

یک گشت و گذار در اینترنت انجام دهید تا مشخص کنید به نظر شما هوش مصنوعی در کجا به طور مؤثرتر استفاده می‌شود. آیا در یک اپلیکیشن نقشه‌برداری، یا یک سرویس تبدیل گفتار به متن، یا یک بازی ویدیویی؟ تحقیق کنید که این سیستم چگونه ساخته شده است.

## [آزمون پس از درس](https://ff-quizzes.netlify.app/en/ai/quiz/2)

## مرور و مطالعه شخصی

تاریخچه هوش مصنوعی و یادگیری ماشین را با مطالعه [این درس](https://github.com/microsoft/ML-For-Beginners/tree/main/1-Introduction/2-history-of-ML) مرور کنید. یکی از عناصر موجود در اسکیچ‌نوت بالای آن درس یا این درس را انتخاب کنید و آن را به طور عمیق‌تر بررسی کنید تا زمینه فرهنگی تأثیرگذار بر تکامل آن را درک کنید.

**تکلیف**: [Game Jam](assignment.md)

**سلب مسئولیت**:  
این سند با استفاده از سرویس ترجمه هوش مصنوعی [Co-op Translator](https://github.com/Azure/co-op-translator) ترجمه شده است. در حالی که ما تلاش می‌کنیم دقت را حفظ کنیم، لطفاً توجه داشته باشید که ترجمه‌های خودکار ممکن است شامل خطاها یا نادرستی‌هایی باشند. سند اصلی به زبان اصلی آن باید به عنوان منبع معتبر در نظر گرفته شود. برای اطلاعات حساس، ترجمه حرفه‌ای انسانی توصیه می‌شود. ما هیچ مسئولیتی در قبال سوءتفاهم‌ها یا تفسیرهای نادرست ناشی از استفاده از این ترجمه نداریم.