<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6522312ff835796ca34136a9462fafb2",
  "translation_date": "2025-09-23T09:46:53+00:00",
  "source_file": "lessons/5-NLP/19-NER/README.md",
  "language_code": "no"
}
-->
# Navngitt Enhetsgjenkjenning

Hittil har vi stort sett fokusert p√• √©n NLP-oppgave - klassifisering. Det finnes imidlertid ogs√• andre NLP-oppgaver som kan l√∏ses med nevrale nettverk. En av disse oppgavene er **[Navngitt Enhetsgjenkjenning](https://wikipedia.org/wiki/Named-entity_recognition)** (NER), som handler om √• gjenkjenne spesifikke enheter i tekst, som steder, personnavn, tidsintervaller, kjemiske formler og lignende.

## [Quiz f√∏r forelesning](https://ff-quizzes.netlify.app/en/ai/quiz/37)

## Eksempel p√• bruk av NER

La oss si at du √∏nsker √• utvikle en naturlig spr√•k-chatbot, lik Amazon Alexa eller Google Assistant. Intelligente chatboter fungerer ved √• *forst√•* hva brukeren √∏nsker, gjennom tekstklassifisering av den innsendte setningen. Resultatet av denne klassifiseringen er den s√•kalte **intensjonen**, som avgj√∏r hva chatboten skal gj√∏re.

<img alt="Bot NER" src="images/bot-ner.png" width="50%"/>

> Bilde av forfatteren

En bruker kan imidlertid oppgi noen parametere som en del av setningen. For eksempel, n√•r hun sp√∏r om v√¶ret, kan hun spesifisere et sted eller en dato. En bot b√∏r kunne forst√• disse enhetene og fylle ut parameterfeltene tilsvarende f√∏r den utf√∏rer handlingen. Det er nettopp her NER kommer inn.

> ‚úÖ Et annet eksempel kan v√¶re [analyse av vitenskapelige medisinske artikler](https://soshnikov.com/science/analyzing-medical-papers-with-azure-and-text-analytics-for-health/). En av hovedoppgavene er √• finne spesifikke medisinske termer, som sykdommer og medisinske stoffer. Mens et lite antall sykdommer kanskje kan trekkes ut ved hjelp av substring-s√∏k, krever mer komplekse enheter, som kjemiske forbindelser og medikamentnavn, en mer avansert tiln√¶rming.

## NER som Tokenklassifisering

NER-modeller er i hovedsak **tokenklassifiseringsmodeller**, fordi vi for hver av input-tokenene m√• avgj√∏re om den tilh√∏rer en enhet eller ikke, og hvis den gj√∏r det - hvilken enhetsklasse den tilh√∏rer.

Se for deg f√∏lgende artikkeltittel:

**Trikuspidalklaff-regurgitasjon** og **litiumkarbonat** **toksisitet** hos et nyf√∏dt barn.

Enhetene her er:

* Trikuspidalklaff-regurgitasjon er en sykdom (`DIS`)
* Litiumkarbonat er et kjemisk stoff (`CHEM`)
* Toksisitet er ogs√• en sykdom (`DIS`)

Merk at √©n enhet kan strekke seg over flere tokens. Og, som i dette tilfellet, m√• vi skille mellom to p√•f√∏lgende enheter. Derfor er det vanlig √• bruke to klasser for hver enhet - √©n som spesifiserer den f√∏rste tokenen i enheten (ofte brukes prefikset `B-` for **b**egynnelse), og en annen for fortsettelsen av en enhet (`I-`, for **i**nner token). Vi bruker ogs√• `O` som en klasse for √• representere alle **a**ndre tokens. Slik tokenmerking kalles [BIO-merking](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)) (eller IOB). N√•r merket, vil tittelen v√•r se slik ut:

Token | Tag
------|-----
Trikuspidalklaff | B-DIS
regurgitasjon | I-DIS
og | O
litium | B-CHEM
karbonat | I-CHEM
toksisitet | B-DIS
hos | O
et | O
nyf√∏dt | O
barn | O
. | O

Siden vi m√• bygge en √©n-til-√©n korrespondanse mellom tokens og klasser, kan vi trene en h√∏yreorientert **mange-til-mange** nevralt nettverksmodell fra dette bildet:

![Bilde som viser vanlige m√∏nstre for rekurrente nevrale nettverk.](../../../../../translated_images/unreasonable-effectiveness-of-rnn.541ead816778f42dce6c42d8a56c184729aa2378d059b851be4ce12b993033df.no.jpg)

> *Bilde fra [denne bloggposten](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) av [Andrej Karpathy](http://karpathy.github.io/). NER-tokenklassifiseringsmodeller tilsvarer nettverksarkitekturen lengst til h√∏yre p√• dette bildet.*

## Trening av NER-modeller

Siden en NER-modell i hovedsak er en tokenklassifiseringsmodell, kan vi bruke RNN-er som vi allerede er kjent med for denne oppgaven. I dette tilfellet vil hver blokk i det rekurrente nettverket returnere token-ID-en. F√∏lgende eksempelnotatbok viser hvordan man trener en LSTM for tokenklassifisering.

## ‚úçÔ∏è Eksempelnotatb√∏ker: NER

Fortsett l√¶ringen i f√∏lgende notatbok:

* [NER med TensorFlow](NER-TF.ipynb)

## Konklusjon

En NER-modell er en **tokenklassifiseringsmodell**, noe som betyr at den kan brukes til √• utf√∏re tokenklassifisering. Dette er en sv√¶rt vanlig oppgave innen NLP, som hjelper til med √• gjenkjenne spesifikke enheter i tekst, inkludert steder, navn, datoer og mer.

## üöÄ Utfordring

Fullf√∏r oppgaven som er lenket nedenfor for √• trene en modell for navngitt enhetsgjenkjenning av medisinske termer, og pr√∏v den deretter p√• et annet datasett.

## [Quiz etter forelesning](https://ff-quizzes.netlify.app/en/ai/quiz/38)

## Gjennomgang og Selvstudium

Les gjennom bloggen [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) og f√∏lg med p√• delen for videre lesing i den artikkelen for √• fordype kunnskapen din.

## [Oppgave](lab/README.md)

I oppgaven for denne leksjonen skal du trene en modell for medisinsk enhetsgjenkjenning. Du kan starte med √• trene en LSTM-modell som beskrevet i denne leksjonen, og deretter g√• videre til √• bruke BERT-transformermodellen. Les [instruksjonene](lab/README.md) for √• f√• alle detaljene.

---

