<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "bd10f434e444bce61b7f97eeb1ff6a55",
  "translation_date": "2025-08-28T15:57:46+00:00",
  "source_file": "lessons/5-NLP/19-NER/README.md",
  "language_code": "no"
}
-->
# Navngitt enhetsgjenkjenning

S√• langt har vi stort sett fokusert p√• √©n NLP-oppgave - klassifisering. Det finnes imidlertid ogs√• andre NLP-oppgaver som kan l√∏ses med nevrale nettverk. En av disse oppgavene er **[Navngitt enhetsgjenkjenning](https://wikipedia.org/wiki/Named-entity_recognition)** (NER), som handler om √• gjenkjenne spesifikke enheter i tekst, som steder, personnavn, tidsintervaller, kjemiske formler og s√• videre.

## [Quiz f√∏r forelesning](https://ff-quizzes.netlify.app/en/ai/quiz/37)

## Eksempel p√• bruk av NER

La oss si at du √∏nsker √• utvikle en naturlig spr√•k-chatbot, lik Amazon Alexa eller Google Assistant. M√•ten intelligente chatboter fungerer p√• er √• *forst√•* hva brukeren √∏nsker ved √• utf√∏re tekstklassifisering p√• innsetningen. Resultatet av denne klassifiseringen er den s√•kalte **intensjonen**, som avgj√∏r hva chatboten skal gj√∏re.

<img alt="Bot NER" src="images/bot-ner.png" width="50%"/>

> Bilde av forfatteren

En bruker kan imidlertid gi noen parametere som en del av setningen. For eksempel, n√•r hun sp√∏r om v√¶ret, kan hun spesifisere et sted eller en dato. En bot b√∏r kunne forst√• disse enhetene og fylle inn parameterplassene deretter f√∏r den utf√∏rer handlingen. Det er akkurat her NER kommer inn.

> ‚úÖ Et annet eksempel kan v√¶re [analyse av vitenskapelige medisinske artikler](https://soshnikov.com/science/analyzing-medical-papers-with-azure-and-text-analytics-for-health/). En av hovedtingene vi m√• se etter er spesifikke medisinske termer, som sykdommer og medisinske stoffer. Mens et lite antall sykdommer sannsynligvis kan trekkes ut ved hjelp av substring-s√∏k, krever mer komplekse enheter, som kjemiske forbindelser og medikamentnavn, en mer avansert tiln√¶rming.

## NER som tokenklassifisering

NER-modeller er i hovedsak **tokenklassifiseringsmodeller**, fordi vi for hver av input-tokenene m√• avgj√∏re om den tilh√∏rer en enhet eller ikke, og hvis den gj√∏r det - hvilken enhetsklasse.

Se p√• f√∏lgende artikkeltittel:

**Trikuspidalklaff-regurgitasjon** og **litiumkarbonat** **toksisitet** hos et nyf√∏dt barn.

Enhetene her er:

* Trikuspidalklaff-regurgitasjon er en sykdom (`DIS`)
* Litiumkarbonat er et kjemisk stoff (`CHEM`)
* Toksisitet er ogs√• en sykdom (`DIS`)

Legg merke til at √©n enhet kan strekke seg over flere token. Og, som i dette tilfellet, m√• vi skille mellom to p√•f√∏lgende enheter. Derfor er det vanlig √• bruke to klasser for hver enhet - √©n som spesifiserer den f√∏rste token i enheten (ofte brukes prefikset `B-` for **b**egynnelse), og en annen for fortsettelsen av en enhet (`I-`, for **i**nner token). Vi bruker ogs√• `O` som en klasse for √• representere alle **a**ndre token. Slik tokenmerking kalles [BIO-merking](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)) (eller IOB). N√•r merket, vil tittelen v√•r se slik ut:

Token | Tag
------|-----
Trikuspidalklaff | B-DIS
regurgitasjon | I-DIS
og | O
litium | B-CHEM
karbonat | I-CHEM
toksisitet | B-DIS
hos | O
et | O
nyf√∏dt | O
barn | O
. | O

Siden vi m√• bygge en √©n-til-√©n-korrespondanse mellom token og klasser, kan vi trene en h√∏yreorientert **mange-til-mange** nevralt nettverksmodell fra dette bildet:

![Bilde som viser vanlige m√∏nstre for rekurrente nevrale nettverk.](../../../../../translated_images/unreasonable-effectiveness-of-rnn.541ead816778f42dce6c42d8a56c184729aa2378d059b851be4ce12b993033df.no.jpg)

> *Bilde fra [denne bloggposten](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) av [Andrej Karpathy](http://karpathy.github.io/). NER-tokenklassifiseringsmodeller tilsvarer den h√∏yreorienterte nettverksarkitekturen p√• dette bildet.*

## Trening av NER-modeller

Siden en NER-modell i hovedsak er en tokenklassifiseringsmodell, kan vi bruke RNN-er som vi allerede er kjent med for denne oppgaven. I dette tilfellet vil hver blokk av det rekurrente nettverket returnere token-ID-en. F√∏lgende eksempelnotatbok viser hvordan man trener LSTM for tokenklassifisering.

## ‚úçÔ∏è Eksempelnotatb√∏ker: NER

Fortsett l√¶ringen i f√∏lgende notatbok:

* [NER med TensorFlow](NER-TF.ipynb)

## Konklusjon

En NER-modell er en **tokenklassifiseringsmodell**, noe som betyr at den kan brukes til √• utf√∏re tokenklassifisering. Dette er en sv√¶rt vanlig oppgave innen NLP, som hjelper til med √• gjenkjenne spesifikke enheter i tekst, inkludert steder, navn, datoer og mer.

## üöÄ Utfordring

Fullf√∏r oppgaven som er lenket nedenfor for √• trene en navngitt enhetsgjenkjenningsmodell for medisinske termer, og pr√∏v den deretter p√• et annet datasett.

## [Quiz etter forelesning](https://ff-quizzes.netlify.app/en/ai/quiz/38)

## Gjennomgang og selvstudium

Les gjennom bloggen [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) og f√∏lg med p√• delen for videre lesing i den artikkelen for √• utdype kunnskapen din.

## [Oppgave](lab/README.md)

I oppgaven for denne leksjonen skal du trene en modell for gjenkjenning av medisinske enheter. Du kan starte med √• trene en LSTM-modell som beskrevet i denne leksjonen, og deretter g√• videre til √• bruke BERT-transformermodellen. Les [instruksjonene](lab/README.md) for √• f√• alle detaljene.

---

**Ansvarsfraskrivelse**:  
Dette dokumentet er oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi streber etter n√∏yaktighet, v√¶r oppmerksom p√• at automatiserte oversettelser kan inneholde feil eller un√∏yaktigheter. Det originale dokumentet p√• sitt opprinnelige spr√•k b√∏r anses som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for misforst√•elser eller feiltolkninger som oppst√•r ved bruk av denne oversettelsen.