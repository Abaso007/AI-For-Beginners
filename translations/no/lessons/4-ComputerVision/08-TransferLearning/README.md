<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "717775c4050ccbffbe0c961ad8bf7bf7",
  "translation_date": "2025-08-28T15:15:19+00:00",
  "source_file": "lessons/4-ComputerVision/08-TransferLearning/README.md",
  "language_code": "no"
}
-->
# Forh√•ndstrente nettverk og overf√∏ringsl√¶ring

√Ö trene CNN-er kan ta mye tid, og det kreves mye data for denne oppgaven. Imidlertid brukes mye av tiden p√• √• l√¶re de beste lavniv√•filtrene som et nettverk kan bruke for √• trekke ut m√∏nstre fra bilder. Et naturlig sp√∏rsm√•l oppst√•r - kan vi bruke et nevralt nettverk trent p√• ett datasett og tilpasse det til √• klassifisere forskjellige bilder uten √• kreve en full treningsprosess?

## [Quiz f√∏r forelesning](https://ff-quizzes.netlify.app/en/ai/quiz/15)

Denne tiln√¶rmingen kalles **overf√∏ringsl√¶ring**, fordi vi overf√∏rer noe kunnskap fra √©n nevralt nettverksmodell til en annen. I overf√∏ringsl√¶ring starter vi vanligvis med en forh√•ndstrent modell, som har blitt trent p√• et stort bildedatasett, som for eksempel **ImageNet**. Disse modellene kan allerede gj√∏re en god jobb med √• trekke ut ulike funksjoner fra generiske bilder, og i mange tilfeller kan det √• bygge en klassifiserer p√• toppen av disse funksjonene gi gode resultater.

> ‚úÖ Overf√∏ringsl√¶ring er et begrep du finner i andre akademiske felt, som utdanning. Det refererer til prosessen med √• ta kunnskap fra ett omr√•de og anvende det p√• et annet.

## Forh√•ndstrente modeller som funksjonsekstraktorer

De konvolusjonsnettverkene vi har snakket om i forrige seksjon inneholder flere lag, hvor hvert lag skal trekke ut noen funksjoner fra bildet, fra lavniv√• pikselkombinasjoner (som horisontale/vertikale linjer eller str√∏k), til h√∏yere niv√• kombinasjoner av funksjoner, som tilsvarer ting som et √∏ye eller en flamme. Hvis vi trener CNN p√• et tilstrekkelig stort datasett med generiske og mangfoldige bilder, b√∏r nettverket l√¶re √• trekke ut disse vanlige funksjonene.

B√•de Keras og PyTorch inneholder funksjoner for enkelt √• laste inn forh√•ndstrente nevrale nettverksvekter for noen vanlige arkitekturer, de fleste av dem er trent p√• ImageNet-bilder. De mest brukte er beskrevet p√• siden [CNN Architectures](../07-ConvNets/CNN_Architectures.md) fra forrige leksjon. Spesielt kan du vurdere √• bruke en av f√∏lgende:

* **VGG-16/VGG-19**, som er relativt enkle modeller som fortsatt gir god n√∏yaktighet. Ofte er det et godt valg √• bruke VGG som et f√∏rste fors√∏k for √• se hvordan overf√∏ringsl√¶ring fungerer.
* **ResNet** er en familie av modeller foresl√•tt av Microsoft Research i 2015. De har flere lag og krever derfor mer ressurser.
* **MobileNet** er en familie av modeller med redusert st√∏rrelse, egnet for mobile enheter. Bruk dem hvis du har begrensede ressurser og kan ofre litt n√∏yaktighet.

Her er eksempler p√• funksjoner som er trukket ut fra et bilde av en katt av VGG-16-nettverket:

![Funksjoner trukket ut av VGG-16](../../../../../translated_images/features.6291f9c7ba3a0b951af88fc9864632b9115365410765680680d30c927dd67354.no.png)

## Dataset for katter og hunder

I dette eksemplet vil vi bruke et datasett med [Katter og Hunder](https://www.microsoft.com/download/details.aspx?id=54765&WT.mc_id=academic-77998-cacaste), som er veldig n√¶rt en reell bildeklassifiseringsscenario.

## ‚úçÔ∏è √òvelse: Overf√∏ringsl√¶ring

La oss se overf√∏ringsl√¶ring i praksis i de tilh√∏rende notatb√∏kene:

* [Overf√∏ringsl√¶ring - PyTorch](TransferLearningPyTorch.ipynb)
* [Overf√∏ringsl√¶ring - TensorFlow](TransferLearningTF.ipynb)

## Visualisering av en "ideell katt"

Et forh√•ndstrent nevralt nettverk inneholder ulike m√∏nstre i sin *hjerne*, inkludert forestillinger om **ideell katt** (samt ideell hund, ideell sebra, osv.). Det ville v√¶re interessant √• p√• en eller annen m√•te **visualisere dette bildet**. Men det er ikke enkelt, fordi m√∏nstrene er spredt over hele nettverkets vekter og ogs√• organisert i en hierarkisk struktur.

En tiln√¶rming vi kan ta er √• starte med et tilfeldig bilde, og deretter pr√∏ve √• bruke **gradient descent-optimalisering** for √• justere det bildet p√• en slik m√•te at nettverket begynner √• tro at det er en katt.

![Bildeoptimaliseringssl√∏yfe](../../../../../translated_images/ideal-cat-loop.999fbb8ff306e044f997032f4eef9152b453e6a990e449bbfb107de2493cc37e.no.png)

Men hvis vi gj√∏r dette, vil vi f√• noe som ligner veldig p√• tilfeldig st√∏y. Dette er fordi *det er mange m√•ter √• f√• nettverket til √• tro at inngangsbilde er en katt*, inkludert noen som ikke gir mening visuelt. Selv om disse bildene inneholder mange m√∏nstre som er typiske for en katt, er det ingenting som begrenser dem til √• v√¶re visuelt distinkte.

For √• forbedre resultatet kan vi legge til et annet ledd i tapfunksjonen, som kalles **varians-tap**. Det er en metrikk som viser hvor like nabopiksler i bildet er. √Ö minimere varians-tap gj√∏r bildet jevnere og fjerner st√∏y - og avsl√∏rer dermed mer visuelt tiltalende m√∏nstre. Her er et eksempel p√• slike "ideelle" bilder, som klassifiseres som katt og som sebra med h√∏y sannsynlighet:

![Ideell katt](../../../../../translated_images/ideal-cat.203dd4597643d6b0bd73038b87f9c0464322725e3a06ab145d25d4a861c70592.no.png) | ![Ideell sebra](../../../../../translated_images/ideal-zebra.7f70e8b54ee15a7a314000bb5df38a6cfe086ea04d60df4d3ef313d046b98a2b.no.png)
-----|-----
 *Ideell katt* | *Ideell sebra*

En lignende tiln√¶rming kan brukes til √• utf√∏re s√•kalte **adversarielle angrep** p√• et nevralt nettverk. Anta at vi √∏nsker √• lure et nevralt nettverk og f√• en hund til √• se ut som en katt. Hvis vi tar et bilde av en hund, som er gjenkjent av nettverket som en hund, kan vi deretter justere det litt ved hjelp av gradient descent-optimalisering, til nettverket begynner √• klassifisere det som en katt:

![Bilde av en hund](../../../../../translated_images/original-dog.8f68a67d2fe0911f33041c0f7fce8aa4ea919f9d3917ec4b468298522aeb6356.no.png) | ![Bilde av en hund klassifisert som en katt](../../../../../translated_images/adversarial-dog.d9fc7773b0142b89752539bfbf884118de845b3851c5162146ea0b8809fc820f.no.png)
-----|-----
*Originalt bilde av en hund* | *Bilde av en hund klassifisert som en katt*

Se koden for √• gjenskape resultatene ovenfor i f√∏lgende notatbok:

* [Ideell og Adversariell Katt - TensorFlow](AdversarialCat_TF.ipynb)

## Konklusjon

Ved √• bruke overf√∏ringsl√¶ring kan du raskt sette sammen en klassifiserer for en tilpasset objektklassifiseringsoppgave og oppn√• h√∏y n√∏yaktighet. Du kan se at mer komplekse oppgaver som vi l√∏ser n√• krever h√∏yere datakraft og ikke enkelt kan l√∏ses p√• CPU. I neste enhet vil vi pr√∏ve √• bruke en mer lettvektsimplementasjon for √• trene den samme modellen ved hjelp av lavere datakraft, noe som resulterer i bare litt lavere n√∏yaktighet.

## üöÄ Utfordring

I de tilh√∏rende notatb√∏kene er det notater nederst om hvordan overf√∏ringskunnskap fungerer best med noe lignende treningsdata (en ny type dyr, kanskje). Gj√∏r noen eksperimenter med helt nye typer bilder for √• se hvor godt eller d√•rlig dine modeller for overf√∏ringskunnskap presterer.

## [Quiz etter forelesning](https://ff-quizzes.netlify.app/en/ai/quiz/16)

## Gjennomgang og selvstudium

Les gjennom [TrainingTricks.md](TrainingTricks.md) for √• utdype kunnskapen din om andre m√•ter √• trene modellene dine p√•.

## [Oppgave](lab/README.md)

I denne laben vil vi bruke det virkelige [Oxford-IIIT](https://www.robots.ox.ac.uk/~vgg/data/pets/) kj√¶ledyrdatasettet med 35 raser av katter og hunder, og vi vil bygge en klassifiserer basert p√• overf√∏ringsl√¶ring.

---

**Ansvarsfraskrivelse**:  
Dette dokumentet er oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi streber etter n√∏yaktighet, v√¶r oppmerksom p√• at automatiserte oversettelser kan inneholde feil eller un√∏yaktigheter. Det originale dokumentet p√• sitt opprinnelige spr√•k b√∏r anses som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for misforst√•elser eller feiltolkninger som oppst√•r ved bruk av denne oversettelsen.