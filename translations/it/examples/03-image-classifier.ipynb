{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificatore di Immagini Semplice\n",
    "\n",
    "Questo notebook ti mostra come classificare immagini utilizzando una rete neurale pre-addestrata.\n",
    "\n",
    "**Cosa imparerai:**\n",
    "- Come caricare e utilizzare un modello pre-addestrato\n",
    "- Pre-elaborazione delle immagini\n",
    "- Fare previsioni sulle immagini\n",
    "- Comprendere i punteggi di confidenza\n",
    "\n",
    "**Caso d'uso:** Identificare oggetti nelle immagini (come \"gatto\", \"cane\", \"auto\", ecc.)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passaggio 1: Importa le librerie necessarie\n",
    "\n",
    "Importiamo gli strumenti di cui abbiamo bisogno. Non preoccuparti se non comprendi ancora tutti questi!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# TensorFlow for deep learning\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.applications import MobileNetV2\n",
    "    from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, decode_predictions\n",
    "    print(\"‚úÖ TensorFlow loaded successfully!\")\n",
    "    print(f\"   Version: {tf.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå Please install TensorFlow: pip install tensorflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passaggio 2: Carica il Modello Pre-addestrato\n",
    "\n",
    "Utilizzeremo **MobileNetV2**, una rete neurale gi√† addestrata su milioni di immagini.\n",
    "\n",
    "Questo si chiama **Transfer Learning** - utilizzare un modello che qualcun altro ha gi√† addestrato!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üì¶ Loading pre-trained MobileNetV2 model...\")\n",
    "print(\"   This may take a minute on first run (downloading weights)...\")\n",
    "\n",
    "# Load the model\n",
    "# include_top=True means we use the classification layer\n",
    "# weights='imagenet' means it was trained on ImageNet dataset\n",
    "model = MobileNetV2(weights='imagenet', include_top=True)\n",
    "\n",
    "print(\"‚úÖ Model loaded!\")\n",
    "print(f\"   The model can recognize 1000 different object categories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passaggio 3: Funzioni di Supporto\n",
    "\n",
    "Creiamo funzioni per caricare e preparare le immagini per il nostro modello.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_from_url(url):\n",
    "    \"\"\"\n",
    "    Load an image from a URL.\n",
    "    \n",
    "    Args:\n",
    "        url: Web address of the image\n",
    "        \n",
    "    Returns:\n",
    "        PIL Image object\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    return img\n",
    "\n",
    "\n",
    "def prepare_image(img):\n",
    "    \"\"\"\n",
    "    Prepare an image for the model.\n",
    "    \n",
    "    Steps:\n",
    "    1. Resize to 224x224 (model's expected size)\n",
    "    2. Convert to array\n",
    "    3. Add batch dimension\n",
    "    4. Preprocess for MobileNetV2\n",
    "    \n",
    "    Args:\n",
    "        img: PIL Image\n",
    "        \n",
    "    Returns:\n",
    "        Preprocessed image array\n",
    "    \"\"\"\n",
    "    # Resize to 224x224 pixels\n",
    "    img = img.resize((224, 224))\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    img_array = np.array(img)\n",
    "    \n",
    "    # Add batch dimension (model expects multiple images)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    # Preprocess for MobileNetV2\n",
    "    img_array = preprocess_input(img_array)\n",
    "    \n",
    "    return img_array\n",
    "\n",
    "\n",
    "def classify_image(img):\n",
    "    \"\"\"\n",
    "    Classify an image and return top predictions.\n",
    "    \n",
    "    Args:\n",
    "        img: PIL Image\n",
    "        \n",
    "    Returns:\n",
    "        List of (class_name, confidence) tuples\n",
    "    \"\"\"\n",
    "    # Prepare the image\n",
    "    img_array = prepare_image(img)\n",
    "    \n",
    "    # Make prediction\n",
    "    predictions = model.predict(img_array, verbose=0)\n",
    "    \n",
    "    # Decode predictions to human-readable labels\n",
    "    # top=5 means we get the top 5 most likely classes\n",
    "    decoded = decode_predictions(predictions, top=5)[0]\n",
    "    \n",
    "    # Convert to simpler format\n",
    "    results = [(label, float(confidence)) for (_, label, confidence) in decoded]\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"‚úÖ Helper functions ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passaggio 4: Test su immagini di esempio\n",
    "\n",
    "Proviamo a classificare alcune immagini prese da internet!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample images to classify\n",
    "# These are from Unsplash (free stock photos)\n",
    "test_images = [\n",
    "    {\n",
    "        \"url\": \"https://images.unsplash.com/photo-1514888286974-6c03e2ca1dba?w=400\",\n",
    "        \"description\": \"A cat\"\n",
    "    },\n",
    "    {\n",
    "        \"url\": \"https://images.unsplash.com/photo-1552053831-71594a27632d?w=400\",\n",
    "        \"description\": \"A dog\"\n",
    "    },\n",
    "    {\n",
    "        \"url\": \"https://images.unsplash.com/photo-1511919884226-fd3cad34687c?w=400\",\n",
    "        \"description\": \"A car\"\n",
    "    },\n",
    "]\n",
    "\n",
    "print(f\"üß™ Testing on {len(test_images)} images...\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifica ogni immagine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, img_data in enumerate(test_images, 1):\n",
    "    print(f\"\\nüì∏ Image {i}: {img_data['description']}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    try:\n",
    "        # Load image\n",
    "        img = load_image_from_url(img_data['url'])\n",
    "        \n",
    "        # Display image\n",
    "        display(img.resize((200, 200)))  # Show smaller version\n",
    "        \n",
    "        # Classify\n",
    "        results = classify_image(img)\n",
    "        \n",
    "        # Show predictions\n",
    "        print(\"\\nüéØ Top 5 Predictions:\")\n",
    "        for rank, (label, confidence) in enumerate(results, 1):\n",
    "            # Create a visual bar\n",
    "            bar_length = int(confidence * 50)\n",
    "            bar = \"‚ñà\" * bar_length\n",
    "            \n",
    "            print(f\"  {rank}. {label:20s} {confidence*100:5.2f}% {bar}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passaggio 5: Prova con le tue immagini!\n",
    "\n",
    "Sostituisci l'URL qui sotto con qualsiasi URL di immagine che desideri classificare.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try your own image!\n",
    "# Replace this URL with any image URL\n",
    "custom_image_url = \"https://images.unsplash.com/photo-1472491235688-bdc81a63246e?w=400\"  # A flower\n",
    "\n",
    "print(\"üñºÔ∏è  Classifying your custom image...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    # Load and show image\n",
    "    img = load_image_from_url(custom_image_url)\n",
    "    display(img.resize((300, 300)))\n",
    "    \n",
    "    # Classify\n",
    "    results = classify_image(img)\n",
    "    \n",
    "    # Show results\n",
    "    print(\"\\nüéØ Top 5 Predictions:\")\n",
    "    print(\"-\" * 70)\n",
    "    for rank, (label, confidence) in enumerate(results, 1):\n",
    "        bar_length = int(confidence * 50)\n",
    "        bar = \"‚ñà\" * bar_length\n",
    "        print(f\"  {rank}. {label:20s} {confidence*100:5.2f}% {bar}\")\n",
    "    \n",
    "    # Highlight top prediction\n",
    "    top_label, top_confidence = results[0]\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"\\nüèÜ Best guess: {top_label} ({top_confidence*100:.2f}% confident)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    print(\"   Make sure the URL points to a valid image!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° Cosa √® appena successo?\n",
    "\n",
    "1. **Abbiamo caricato un modello pre-addestrato** - MobileNetV2 √® stato addestrato su milioni di immagini  \n",
    "2. **Abbiamo preprocessato le immagini** - Ridimensionate e formattate per il modello  \n",
    "3. **Il modello ha fatto previsioni** - Ha fornito probabilit√† per 1000 classi di oggetti  \n",
    "4. **Abbiamo decodificato i risultati** - Convertito i numeri in etichette comprensibili  \n",
    "\n",
    "### Comprendere i punteggi di confidenza\n",
    "\n",
    "- **90-100%**: Molto sicuro (quasi certamente corretto)  \n",
    "- **70-90%**: Sicuro (probabilmente corretto)  \n",
    "- **50-70%**: Moderatamente sicuro (potrebbe essere corretto)  \n",
    "- **Sotto il 50%**: Poco sicuro (incerto)  \n",
    "\n",
    "### Perch√© le previsioni potrebbero essere sbagliate?\n",
    "\n",
    "- **Angolazione o illuminazione insolita** - Il modello √® stato addestrato su foto tipiche  \n",
    "- **Oggetti multipli** - Il modello si aspetta un oggetto principale  \n",
    "- **Oggetti rari** - Il modello conosce solo 1000 categorie  \n",
    "- **Immagine di bassa qualit√†** - Immagini sfocate o pixelate sono pi√π difficili da analizzare  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Prossimi Passi\n",
    "\n",
    "1. **Prova immagini diverse:**\n",
    "   - Trova immagini su [Unsplash](https://unsplash.com)\n",
    "   - Clic destro ‚Üí \"Copia indirizzo immagine\" per ottenere l'URL\n",
    "\n",
    "2. **Sperimenta:**\n",
    "   - Cosa succede con l'arte astratta?\n",
    "   - Pu√≤ riconoscere oggetti da angolazioni diverse?\n",
    "   - Come gestisce pi√π oggetti contemporaneamente?\n",
    "\n",
    "3. **Approfondisci:**\n",
    "   - Esplora le [lezioni di Visione Artificiale](../lessons/4-ComputerVision/README.md)\n",
    "   - Impara a creare il tuo classificatore di immagini\n",
    "   - Comprendi come funzionano le CNN (Reti Neurali Convoluzionali)\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ Congratulazioni!\n",
    "\n",
    "Hai appena costruito un classificatore di immagini utilizzando una rete neurale all'avanguardia!\n",
    "\n",
    "Questa stessa tecnica alimenta:\n",
    "- Google Foto (organizzazione delle tue foto)\n",
    "- Auto a guida autonoma (riconoscimento degli oggetti)\n",
    "- Diagnosi medica (analisi delle radiografie)\n",
    "- Controllo qualit√† (rilevamento dei difetti)\n",
    "\n",
    "Continua a esplorare e imparare! üöÄ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Disclaimer**:  \nQuesto documento √® stato tradotto utilizzando il servizio di traduzione automatica [Co-op Translator](https://github.com/Azure/co-op-translator). Sebbene ci impegniamo per garantire l'accuratezza, si prega di notare che le traduzioni automatiche possono contenere errori o imprecisioni. Il documento originale nella sua lingua nativa dovrebbe essere considerato la fonte autorevole. Per informazioni critiche, si raccomanda una traduzione professionale effettuata da un traduttore umano. Non siamo responsabili per eventuali incomprensioni o interpretazioni errate derivanti dall'uso di questa traduzione.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "coopTranslator": {
   "original_hash": "1d472141d9df46b751542b3c29f88677",
   "translation_date": "2025-10-03T11:44:49+00:00",
   "source_file": "examples/03-image-classifier.ipynb",
   "language_code": "it"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}