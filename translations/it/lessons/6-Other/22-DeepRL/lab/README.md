<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7bd8dc72040e98e35e7225e34058cd4e",
  "translation_date": "2025-08-26T07:07:24+00:00",
  "source_file": "lessons/6-Other/22-DeepRL/lab/README.md",
  "language_code": "it"
}
-->
# Addestrare Mountain Car a Fuggire

Compito del laboratorio tratto da [AI for Beginners Curriculum](https://github.com/microsoft/ai-for-beginners).

## Obiettivo

Il tuo obiettivo è addestrare l'agente RL a controllare [Mountain Car](https://www.gymlibrary.ml/environments/classic_control/mountain_car/) nell'ambiente OpenAI.

## L'Ambiente

L'ambiente Mountain Car consiste in un'auto intrappolata in una valle. Il tuo obiettivo è saltare fuori dalla valle e raggiungere la bandiera. Le azioni che puoi compiere sono accelerare a sinistra, a destra o non fare nulla. Puoi osservare la posizione dell'auto lungo l'asse x e la velocità.

## Notebook di Partenza

Inizia il laboratorio aprendo [MountainCar.ipynb](../../../../../../lessons/6-Other/22-DeepRL/lab/MountainCar.ipynb)

## Conclusione

Durante questo laboratorio dovresti imparare che adattare gli algoritmi RL a un nuovo ambiente è spesso piuttosto semplice, poiché OpenAI Gym ha la stessa interfaccia per tutti gli ambienti, e gli algoritmi in quanto tali non dipendono in gran parte dalla natura dell'ambiente. Puoi persino ristrutturare il codice Python in modo da passare qualsiasi ambiente all'algoritmo RL come parametro.

**Disclaimer**:  
Questo documento è stato tradotto utilizzando il servizio di traduzione automatica [Co-op Translator](https://github.com/Azure/co-op-translator). Sebbene ci impegniamo per garantire l'accuratezza, si prega di notare che le traduzioni automatiche potrebbero contenere errori o imprecisioni. Il documento originale nella sua lingua nativa dovrebbe essere considerato la fonte autorevole. Per informazioni critiche, si raccomanda una traduzione professionale effettuata da un traduttore umano. Non siamo responsabili per eventuali fraintendimenti o interpretazioni errate derivanti dall'uso di questa traduzione.