<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1b8d9e1b3a6f1daa864b1ff3dfc3076d",
  "translation_date": "2025-09-23T07:17:36+00:00",
  "source_file": "lessons/4-ComputerVision/09-Autoencoders/README.md",
  "language_code": "ne"
}
-->
# अटोएनकोडरहरू

CNNs प्रशिक्षण गर्दा, एउटा समस्या यो हो कि हामीलाई धेरै लेबल गरिएको डाटा चाहिन्छ। छवि वर्गीकरणको अवस्थामा, हामीले छविहरूलाई विभिन्न वर्गहरूमा छुट्याउनुपर्छ, जुन एक म्यानुअल प्रयास हो।

## [पाठ अघि क्विज](https://ff-quizzes.netlify.app/en/ai/quiz/17)

तर, हामी कच्चा (लेबल नगरिएको) डाटा CNN फीचर एक्स्ट्र्याक्टरहरू प्रशिक्षण गर्न प्रयोग गर्न चाहन सक्छौं, जसलाई **स्व-नियन्त्रित शिक्षण** भनिन्छ। लेबलहरूको सट्टा, हामी प्रशिक्षण छविहरूलाई नेटवर्क इनपुट र आउटपुट दुवैको रूपमा प्रयोग गर्नेछौं। **अटोएनकोडर** को मुख्य विचार यो हो कि हामीसँग एउटा **एन्कोडर नेटवर्क** हुनेछ जसले इनपुट छविलाई केही **गुप्त स्थान** मा रूपान्तरण गर्छ (सामान्यतया यो केही सानो आकारको भेक्टर मात्र हो), त्यसपछि **डिकोडर नेटवर्क**, जसको लक्ष्य मूल छवि पुनर्निर्माण गर्नु हुनेछ।

> ✅ [अटोएनकोडर](https://wikipedia.org/wiki/Autoencoder) भनेको "एक प्रकारको कृत्रिम न्यूरल नेटवर्क हो जसले लेबल नगरिएको डाटाको कुशल कोडिङ सिक्न प्रयोग गरिन्छ।"

किनकि हामी अटोएनकोडरलाई मूल छविबाट सकेसम्म धेरै जानकारी समात्न प्रशिक्षण गर्दैछौं ताकि सही पुनर्निर्माण गर्न सकियोस्, नेटवर्कले इनपुट छविहरूको उत्तम **एम्बेडिङ** पत्ता लगाउन प्रयास गर्छ।

![अटोएनकोडर आरेख](../../../../../translated_images/autoencoder_schema.5e6fc9ad98a5eb6197f3513cf3baf4dfbe1389a6ae74daebda64de9f1c99f142.ne.jpg)

> छवि [Keras ब्लग](https://blog.keras.io/building-autoencoders-in-keras.html) बाट

## अटोएनकोडर प्रयोग गर्ने परिदृश्यहरू

मूल छविहरू पुनर्निर्माण गर्नु आफैंमा उपयोगी नदेखिए पनि, केही परिदृश्यहरू छन् जहाँ अटोएनकोडरहरू विशेष रूपमा उपयोगी छन्:

* **छविहरूको आयाम घटाउने** वा **छवि एम्बेडिङ प्रशिक्षण गर्ने**। सामान्यतया अटोएनकोडरहरूले PCA भन्दा राम्रो परिणाम दिन्छन्, किनकि यसले छविहरूको स्थानिक प्रकृति र पदानुक्रमिक विशेषताहरूलाई ध्यानमा राख्छ।
* **डिनोइजिङ**, अर्थात् छविबाट आवाज हटाउने। किनकि आवाजले धेरै अनावश्यक जानकारी बोक्छ, अटोएनकोडरले यसलाई सानो गुप्त स्थानमा फिट गर्न सक्दैन, र यसले छविको मात्र महत्त्वपूर्ण भाग समात्छ। डिनोइजरहरू प्रशिक्षण गर्दा, हामी मूल छविहरूबाट सुरु गर्छौं, र कृत्रिम रूपमा थपिएको आवाज भएको छविहरूलाई अटोएनकोडरको इनपुटको रूपमा प्रयोग गर्छौं।
* **सुपर-रेजोल्युसन**, छविको रिजोल्युसन बढाउने। हामी उच्च रिजोल्युसन छविहरूबाट सुरु गर्छौं, र कम रिजोल्युसन भएको छविलाई अटोएनकोडर इनपुटको रूपमा प्रयोग गर्छौं।
* **जनरेटिभ मोडेलहरू**। एकपटक हामीले अटोएनकोडर प्रशिक्षण गरेपछि, डिकोडर भागलाई नयाँ वस्तुहरू सिर्जना गर्न प्रयोग गर्न सकिन्छ, गुप्त भेक्टरहरूबाट सुरु गर्दै।

## भेरिएशनल अटोएनकोडरहरू (VAE)

परम्परागत अटोएनकोडरहरूले इनपुट डाटाको आयामलाई कुनै प्रकारले घटाउँछन्, इनपुट छविहरूका महत्त्वपूर्ण विशेषताहरू पत्ता लगाउँदै। तर, गुप्त भेक्टरहरू प्रायः धेरै अर्थपूर्ण हुँदैनन्। अन्य शब्दमा, MNIST डेटासेटलाई उदाहरणको रूपमा लिँदा, विभिन्न गुप्त भेक्टरहरू कुन अंकसँग मेल खान्छन् भनेर पत्ता लगाउनु सजिलो काम होइन, किनकि नजिकका गुप्त भेक्टरहरूले अनिवार्य रूपमा उही अंकलाई प्रतिनिधित्व गर्दैनन्।

अर्कोतर्फ, *जनरेटिभ* मोडेलहरू प्रशिक्षण गर्न गुप्त स्थानको केही समझ हुनु राम्रो हुन्छ। यो विचारले हामीलाई **भेरिएशनल अटोएनकोडर** (VAE) तर्फ लैजान्छ।

VAE भनेको अटोएनकोडर हो जसले गुप्त प्यारामिटरहरूको *सांख्यिकीय वितरण* (जसलाई **गुप्त वितरण** भनिन्छ) भविष्यवाणी गर्न सिक्छ। उदाहरणका लागि, हामी चाहन सक्छौं कि गुप्त भेक्टरहरू सामान्य रूपमा वितरण गरिएका होस्, केही औसत z<sub>mean</sub> र मानक विचलन z<sub>sigma</sub> (दुवै औसत र मानक विचलन केही आयामको भेक्टर हुन्)। VAE मा एन्कोडरले ती प्यारामिटरहरू भविष्यवाणी गर्न सिक्छ, र त्यसपछि डिकोडरले यस वितरणबाट एउटा र्यान्डम भेक्टर लिन्छ ताकि वस्तु पुनर्निर्माण गर्न सकियोस्।

सारांशमा:

 * इनपुट भेक्टरबाट, हामी `z_mean` र `z_log_sigma` भविष्यवाणी गर्छौं (मानक विचलन आफैं भविष्यवाणी गर्ने सट्टा, हामी यसको लघुगणक भविष्यवाणी गर्छौं)
 * हामी वितरण N(z<sub>mean</sub>,exp(z<sub>log\_sigma</sub>)) बाट `sample` भेक्टर लिन्छौं
 * डिकोडरले `sample` लाई इनपुट भेक्टरको रूपमा प्रयोग गरेर मूल छवि डिकोड गर्न प्रयास गर्छ

 <img src="images/vae.png" width="50%">

> छवि [यो ब्लग पोस्ट](https://ijdykeman.github.io/ml/2016/12/21/cvae.html) बाट, लेखक: इसाक डाइकमन

भेरिएशनल अटोएनकोडरहरूले जटिल हानिको कार्य प्रयोग गर्छन्, जसमा दुई भागहरू हुन्छन्:

* **पुनर्निर्माण हानि** भनेको हानिको कार्य हो जसले पुनर्निर्मित छवि लक्ष्यसँग कति नजिक छ भनेर देखाउँछ (यो Mean Squared Error, वा MSE हुन सक्छ)। यो सामान्य अटोएनकोडरहरूमा प्रयोग गरिने हानिको कार्य जस्तै हो।
* **KL हानि**, जसले सुनिश्चित गर्छ कि गुप्त भेरिएबल वितरणहरू सामान्य वितरणको नजिक रहन्छ। यो [कुलब्याक-लिबलर विचलन](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained) को धारणा आधारित छ - दुई सांख्यिकीय वितरणहरू कति समान छन् भनेर अनुमान गर्न मेट्रिक।

VAE को एउटा महत्त्वपूर्ण फाइदा यो हो कि यसले नयाँ छविहरू तुलनात्मक रूपमा सजिलै सिर्जना गर्न अनुमति दिन्छ, किनकि हामीलाई थाहा छ कुन वितरणबाट गुप्त भेक्टरहरू नमूना गर्नुपर्छ। उदाहरणका लागि, यदि हामीले MNIST मा 2D गुप्त भेक्टरको साथ VAE प्रशिक्षण गर्छौं भने, हामी गुप्त भेक्टरका घटकहरू फरक पारेर विभिन्न अंकहरू प्राप्त गर्न सक्छौं:

<img alt="vaemnist" src="images/vaemnist.png" width="50%"/>

> छवि [दिमित्री सश्निकोभ](http://soshnikov.com) द्वारा

ध्यान दिनुहोस् कि छविहरू एकअर्कामा कसरी मिसिन्छन्, किनकि हामी गुप्त प्यारामिटर स्थानको विभिन्न भागहरूबाट गुप्त भेक्टरहरू प्राप्त गर्न थाल्छौं। हामी यस स्थानलाई 2D मा पनि दृश्यात्मक बनाउन सक्छौं:

<img alt="vaemnist cluster" src="images/vaemnist-diag.png" width="50%"/> 

> छवि [दिमित्री सश्निकोभ](http://soshnikov.com) द्वारा

## ✍️ अभ्यासहरू: अटोएनकोडरहरू

यी सम्बन्धित नोटबुकहरूमा अटोएनकोडरहरूको बारेमा थप जान्नुहोस्:

* [TensorFlow मा अटोएनकोडरहरू](AutoencodersTF.ipynb)
* [PyTorch मा अटोएनकोडरहरू](AutoEncodersPyTorch.ipynb)

## अटोएनकोडरहरूको विशेषताहरू

* **डाटा विशेष** - तिनीहरूले केवल तिनीहरूले प्रशिक्षण गरिएको छविहरूको प्रकारमा राम्रोसँग काम गर्छन्। उदाहरणका लागि, यदि हामीले फूलहरूमा सुपर-रेजोल्युसन नेटवर्क प्रशिक्षण गर्छौं भने, यो पोर्ट्रेटहरूमा राम्रोसँग काम गर्नेछैन। यो किनभने नेटवर्कले उच्च रिजोल्युसन छवि उत्पादन गर्न प्रशिक्षण डेटासेटबाट सिकिएका सूक्ष्म विवरणहरू लिन्छ।
* **हानिपूर्ण** - पुनर्निर्मित छवि मूल छविको जस्तै हुँदैन। हानिको प्रकृति प्रशिक्षणको क्रममा प्रयोग गरिएको *हानिको कार्य* द्वारा परिभाषित हुन्छ।
* **लेबल नगरिएको डाटा** मा काम गर्छ

## [पाठ पछि क्विज](https://ff-quizzes.netlify.app/en/ai/quiz/18)

## निष्कर्ष

यस पाठमा, तपाईंले AI वैज्ञानिकका लागि उपलब्ध विभिन्न प्रकारका अटोएनकोडरहरूको बारेमा सिक्नुभयो। तपाईंले तिनीहरूलाई कसरी निर्माण गर्ने र छविहरू पुनर्निर्माण गर्न कसरी प्रयोग गर्ने भन्ने कुरा सिक्नुभयो। तपाईंले VAE को बारेमा पनि सिक्नुभयो र नयाँ छविहरू सिर्जना गर्न यसलाई कसरी प्रयोग गर्ने भन्ने कुरा सिक्नुभयो।

## 🚀 चुनौती

यस पाठमा, तपाईंले छविहरूका लागि अटोएनकोडरहरू प्रयोग गर्ने बारेमा सिक्नुभयो। तर तिनीहरू संगीतका लागि पनि प्रयोग गर्न सकिन्छ! Magenta परियोजनाको [MusicVAE](https://magenta.tensorflow.org/music-vae) परियोजना हेर्नुहोस्, जसले अटोएनकोडरहरूलाई संगीत पुनर्निर्माण गर्न सिक्न प्रयोग गर्छ। यस पुस्तकालयसँग [प्रयोगहरू](https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/Multitrack_MusicVAE.ipynb) गर्नुहोस् र तपाईंले के सिर्जना गर्न सक्नुहुन्छ हेर्नुहोस्।

## [पाठ पछि क्विज](https://ff-quizzes.netlify.app/en/ai/quiz/16)

## समीक्षा र आत्म अध्ययन

सन्दर्भका लागि, यी स्रोतहरूमा अटोएनकोडरहरूको बारेमा थप पढ्नुहोस्:

* [Keras मा अटोएनकोडरहरू निर्माण गर्दै](https://blog.keras.io/building-autoencoders-in-keras.html)
* [NeuroHive मा ब्लग पोस्ट](https://neurohive.io/ru/osnovy-data-science/variacionnyj-avtojenkoder-vae/)
* [भेरिएशनल अटोएनकोडरहरू व्याख्या गरिएको](https://kvfrans.com/variational-autoencoders-explained/)
* [सशर्त भेरिएशनल अटोएनकोडरहरू](https://ijdykeman.github.io/ml/2016/12/21/cvae.html)

## असाइनमेन्ट

[TensorFlow प्रयोग गर्दै यो नोटबुक](AutoencodersTF.ipynb) को अन्त्यमा, तपाईंले एउटा 'कार्य' पाउनुहुनेछ - यसलाई आफ्नो असाइनमेन्टको रूपमा प्रयोग गर्नुहोस्।

---

