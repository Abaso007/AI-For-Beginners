<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f07c85bbf05a1f67505da98f4ecc124c",
  "translation_date": "2025-08-26T09:16:04+00:00",
  "source_file": "lessons/4-ComputerVision/10-GANs/README.md",
  "language_code": "ne"
}
-->
# जेनेरेटिभ एड्भर्सेरियल नेटवर्कहरू

अघिल्लो खण्डमा, हामीले **जेनेरेटिभ मोडेलहरू** को बारेमा सिक्यौं: यस्ता मोडेलहरू जसले प्रशिक्षण डेटासेटमा भएका छविहरू जस्तै नयाँ छविहरू सिर्जना गर्न सक्छ। VAE जेनेरेटिभ मोडेलको राम्रो उदाहरण थियो।

## [Pre-lecture quiz](https://ff-quizzes.netlify.app/en/ai/quiz/19)

तर, यदि हामी कुनै अर्थपूर्ण कुरा, जस्तै उचित रिजोल्युसनको चित्र सिर्जना गर्न प्रयास गर्छौं भने, VAE प्रयोग गर्दा प्रशिक्षण राम्रोसँग सँग्लो हुँदैन। यस प्रयोगको लागि, हामीले जेनेरेटिभ मोडेलहरूका लागि विशेष रूपमा लक्षित अर्को आर्किटेक्चर सिक्नुपर्छ - **जेनेरेटिभ एड्भर्सेरियल नेटवर्कहरू**, वा GANs।

GAN को मुख्य विचार दुई न्यूरल नेटवर्कहरूलाई एक-अर्काविरुद्ध प्रशिक्षण गराउनु हो:

<img src="images/gan_architecture.png" width="70%"/>

> चित्र: [Dmitry Soshnikov](http://soshnikov.com)

> ✅ केही शब्दावली:
> * **जेनेरेटर**: यो नेटवर्क हो जसले केही र्यान्डम भेक्टर लिन्छ र परिणामस्वरूप छवि उत्पादन गर्छ।
> * **डिस्क्रिमिनेटर**: यो नेटवर्क हो जसले छवि लिन्छ, र यो बताउनुपर्छ कि यो वास्तविक छवि हो (प्रशिक्षण डेटासेटबाट) वा यो जेनेरेटरले सिर्जना गरेको हो। यो मूलतः छवि वर्गीकरणकर्ता हो।

### डिस्क्रिमिनेटर

डिस्क्रिमिनेटरको आर्किटेक्चर साधारण छवि वर्गीकरण नेटवर्कबाट फरक छैन। सबैभन्दा साधारण अवस्थामा, यो पूर्ण रूपमा जडित वर्गीकरणकर्ता हुन सक्छ, तर सम्भवतः यो [कन्भोल्युसनल नेटवर्क](../07-ConvNets/README.md) हुनेछ।

> ✅ कन्भोल्युसनल नेटवर्कमा आधारित GAN लाई [DCGAN](https://arxiv.org/pdf/1511.06434.pdf) भनिन्छ।

CNN डिस्क्रिमिनेटरमा निम्न तहहरू हुन्छन्: धेरै कन्भोल्युसन+पूलिङ (स्पेसियल साइज घट्दै जाने) र, "फिचर भेक्टर" प्राप्त गर्न एक वा धेरै पूर्ण रूपमा जडित तहहरू, अन्तिम बाइनरी वर्गीकरणकर्ता।

> ✅ 'पूलिङ' भनेको छवि आकार घटाउने प्रविधि हो। "पूलिङ तहहरूले डाटाको आयाम घटाउँछन्, एक तहमा न्यूरोन क्लस्टरहरूको आउटपुटलाई अर्को तहमा एकल न्यूरोनमा मिलाएर।" - [स्रोत](https://wikipedia.org/wiki/Convolutional_neural_network#Pooling_layers)

### जेनेरेटर

जेनेरेटर अलि जटिल छ। तपाईं यसलाई उल्टो डिस्क्रिमिनेटरको रूपमा विचार गर्न सक्नुहुन्छ। लेटेन्ट भेक्टरबाट सुरु गर्दै (फिचर भेक्टरको ठाउँमा), यसले आवश्यक आकार/आकारमा रूपान्तरण गर्न पूर्ण रूपमा जडित तह हुन्छ, त्यसपछि डिकन्भोल्युसन+अपस्केलिङ। यो [अटोइन्कोडर](../09-Autoencoders/README.md) को *डिकोडर* भागसँग मिल्दोजुल्दो छ।

> ✅ किनभने कन्भोल्युसन तह छवि पार गर्दै लिने रेखीय फिल्टरको रूपमा कार्यान्वयन गरिन्छ, डिकन्भोल्युसन कन्भोल्युसनसँग मिल्दोजुल्दो छ, र समान तह तर्क प्रयोग गरेर कार्यान्वयन गर्न सकिन्छ।

<img src="images/gan_arch_detail.png" width="70%"/>

> चित्र: [Dmitry Soshnikov](http://soshnikov.com)

### GAN प्रशिक्षण

GAN लाई **एड्भर्सेरियल** भनिन्छ किनभने जेनेरेटर र डिस्क्रिमिनेटर बीच निरन्तर प्रतिस्पर्धा हुन्छ। यस प्रतिस्पर्धाको क्रममा, दुबै जेनेरेटर र डिस्क्रिमिनेटर सुधार हुन्छन्, जसले नेटवर्कलाई राम्रो छविहरू उत्पादन गर्न सिकाउँछ।

प्रशिक्षण दुई चरणमा हुन्छ:

* **डिस्क्रिमिनेटर प्रशिक्षण**। यो कार्य धेरै सरल छ: हामी जेनेरेटरद्वारा छविहरूको ब्याच सिर्जना गर्छौं, तिनीहरूलाई 0 लेबल गर्छौं, जसले नक्कली छवि जनाउँछ, र इनपुट डेटासेटबाट छविहरूको ब्याच लिन्छौं (लेबल 1, वास्तविक छवि)। हामी केही *डिस्क्रिमिनेटर हानि* प्राप्त गर्छौं, र ब्याकप्रोप गर्छौं।
* **जेनेरेटर प्रशिक्षण**। यो अलि जटिल छ, किनभने हामीले जेनेरेटरको लागि प्रत्यक्ष अपेक्षित आउटपुट थाहा छैन। हामी जेनेरेटर र डिस्क्रिमिनेटर मिलेर बनेको सम्पूर्ण GAN नेटवर्क लिन्छौं, यसलाई केही र्यान्डम भेक्टरहरू खुवाउँछौं, र परिणामलाई 1 (वास्तविक छविहरूको लागि) अपेक्षा गर्छौं। त्यसपछि हामी डिस्क्रिमिनेटरको प्यारामिटरहरू स्थिर गर्छौं (हामी यस चरणमा यसलाई प्रशिक्षण गर्न चाहँदैनौं), र ब्याकप्रोप गर्छौं।

यस प्रक्रियाको क्रममा, दुबै जेनेरेटर र डिस्क्रिमिनेटर हानिहरू उल्लेखनीय रूपमा तल झर्दैनन्। आदर्श अवस्थामा, तिनीहरूले कम्पन गर्नुपर्छ, जसले दुबै नेटवर्कको प्रदर्शन सुधार भएको जनाउँछ।

## ✍️ अभ्यास: GANs

* [GAN नोटबुक TensorFlow/Keras मा](../../../../../lessons/4-ComputerVision/10-GANs/GANTF.ipynb)
* [GAN नोटबुक PyTorch मा](../../../../../lessons/4-ComputerVision/10-GANs/GANPyTorch.ipynb)

### GAN प्रशिक्षणका समस्या

GAN प्रशिक्षण गर्न विशेष रूपमा कठिन मानिन्छ। यहाँ केही समस्या छन्:

* **मोड कोलाप्स**। यसले जनाउँछ कि जेनेरेटरले एक सफल छवि उत्पादन गर्न सिक्छ, जसले डिस्क्रिमिनेटरलाई झुक्याउँछ, तर विभिन्न छविहरूको विविधता उत्पादन गर्दैन।
* **हाइपरप्यारामिटरहरूमा संवेदनशीलता**। प्रायः तपाईं देख्न सक्नुहुन्छ कि GAN बिल्कुलै सँग्लो हुँदैन, र त्यसपछि अचानक सिकाइ दर घटाउँदा सँग्लो हुन्छ।
* जेनेरेटर र डिस्क्रिमिनेटर बीच **सन्तुलन** राख्नु। धेरै अवस्थामा डिस्क्रिमिनेटर हानि अपेक्षाकृत छिटो शून्यमा झर्न सक्छ, जसले जेनेरेटरलाई थप प्रशिक्षण गर्न असमर्थ बनाउँछ। यसलाई पार गर्न, हामी जेनेरेटर र डिस्क्रिमिनेटरका लागि फरक सिकाइ दर सेट गर्न प्रयास गर्न सक्छौं, वा यदि हानि पहिले नै धेरै कम छ भने डिस्क्रिमिनेटर प्रशिक्षण छोड्न सक्छौं।
* **उच्च रिजोल्युसनको लागि प्रशिक्षण**। अटोइन्कोडरहरूमा जस्तै समस्या प्रतिबिम्बित गर्दै, यो समस्या धेरै तहहरू पुनर्निर्माण गर्दा कलाकृतिहरू उत्पन्न हुने कारणले उत्पन्न हुन्छ। यो समस्या सामान्यतया **प्रोग्रेसिभ ग्रोइङ** द्वारा समाधान गरिन्छ, जहाँ सुरुमा केही तहहरू कम-रिजोल्युसन छविहरूमा प्रशिक्षण गरिन्छ, र त्यसपछि तहहरू "अनब्लक" वा थपिन्छ। अर्को समाधान भनेको तहहरू बीच अतिरिक्त जडानहरू थप्नु र एकै समयमा धेरै रिजोल्युसनहरू प्रशिक्षण गर्नु हो - यस [मल्टि-स्केल ग्रेडियन्ट GANs पेपर](https://arxiv.org/abs/1903.06048) मा विवरणहरू हेर्नुहोस्।

## शैली ट्रान्सफर

GANs कलात्मक छविहरू सिर्जना गर्नको लागि उत्कृष्ट तरिका हो। अर्को रोचक प्रविधि भनेको **शैली ट्रान्सफर** हो, जसले एक **कन्टेन्ट छवि** लिन्छ, र यसलाई फरक शैलीमा पुनःचित्रण गर्छ, **शैली छवि** बाट फिल्टरहरू लागू गर्दै।

यसले निम्न तरिकाले काम गर्छ:
* हामी र्यान्डम न्वाइज छवि (वा कन्टेन्ट छवि, तर बुझ्नको लागि र्यान्डम न्वाइजबाट सुरु गर्नु सजिलो हुन्छ) बाट सुरु गर्छौं।
* हाम्रो लक्ष्य यस्तो छवि सिर्जना गर्नु हो, जुन कन्टेन्ट छवि र शैली छवि दुवैसँग नजिक हुनेछ। यो दुई हानि कार्यहरूद्वारा निर्धारण गरिन्छ:
   - **कन्टेन्ट हानि**: यो CNN द्वारा केही तहहरूमा वर्तमान छवि र कन्टेन्ट छवि बाट निकालिएका फिचरहरूमा आधारित गणना गरिन्छ।
   - **शैली हानि**: यो वर्तमान छवि र शैली छवि बीचमा ग्राम म्याट्रिक्स प्रयोग गरेर चतुर तरिकाले गणना गरिन्छ (थप विवरण [उदाहरण नोटबुक](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb) मा हेर्नुहोस्)।
* छवि चिल्लो बनाउन र न्वाइज हटाउन, हामी **भेरिएसन हानि** पनि परिचय गराउँछौं, जसले छिमेकी पिक्सेलहरू बीचको औसत दूरी गणना गर्छ।
* मुख्य अनुकूलन लूपले वर्तमान छवि समायोजन गर्छ, कुल हानि (तीनवटै हानिहरूको भारित योग) न्यून गर्न ग्रेडियन्ट डिसेन्ट (वा अन्य अनुकूलन एल्गोरिदम) प्रयोग गरेर।

## ✍️ उदाहरण: [शैली ट्रान्सफर](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)

## [Post-lecture quiz](https://ff-quizzes.netlify.app/en/ai/quiz/20)

## निष्कर्ष

यस पाठमा, तपाईंले GANs र तिनीहरूलाई कसरी प्रशिक्षण गर्ने भन्ने बारे सिक्नुभयो। तपाईंले यस प्रकारको न्यूरल नेटवर्कले सामना गर्न सक्ने विशेष चुनौतीहरू र तिनीहरूलाई पार गर्न केही रणनीतिहरू पनि सिक्नुभयो।

## 🚀 चुनौती

[शैली ट्रान्सफर नोटबुक](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb) आफ्नै छविहरू प्रयोग गरेर चलाउनुहोस्।

## समीक्षा र आत्म अध्ययन

सन्दर्भको लागि, यी स्रोतहरूमा GANs को बारेमा थप पढ्नुहोस्:

* Marco Pasini, [10 Lessons I Learned Training GANs for one Year](https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628)
* [StyleGAN](https://en.wikipedia.org/wiki/StyleGAN), विचार गर्न लायक *de facto* GAN आर्किटेक्चर
* [Creating Generative Art using GANs on Azure ML](https://soshnikov.com/scienceart/creating-generative-art-using-gan-on-azureml/)

## असाइनमेन्ट

यस पाठसँग सम्बन्धित दुई नोटबुकमध्ये एकलाई पुनः हेर्नुहोस् र GAN लाई आफ्नै छविहरूमा पुनः प्रशिक्षण गर्नुहोस्। तपाईं के सिर्जना गर्न सक्नुहुन्छ?

**अस्वीकरण**:  
यो दस्तावेज़ AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) प्रयोग गरी अनुवाद गरिएको हो। हामी यथासम्भव सटीकता सुनिश्चित गर्न प्रयास गर्छौं, तर कृपया ध्यान दिनुहोस् कि स्वचालित अनुवादहरूमा त्रुटिहरू वा अशुद्धताहरू हुन सक्छन्। यसको मूल भाषामा रहेको मूल दस्तावेज़लाई आधिकारिक स्रोत मानिनुपर्छ। महत्त्वपूर्ण जानकारीका लागि, व्यावसायिक मानव अनुवाद सिफारिस गरिन्छ। यस अनुवादको प्रयोगबाट उत्पन्न हुने कुनै पनि गलतफहमी वा गलत व्याख्याका लागि हामी जिम्मेवार हुने छैनौं।