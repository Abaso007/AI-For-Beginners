<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ae074cd940fc2f4dc24fc07b66ccbd99",
  "translation_date": "2025-08-26T09:49:36+00:00",
  "source_file": "lessons/4-ComputerVision/08-TransferLearning/TrainingTricks.md",
  "language_code": "ne"
}
-->
# डीप लर्निङ प्रशिक्षणका तरिकाहरू

जति जति न्यूरल नेटवर्कहरू गहिरो हुँदै जान्छन्, तिनीहरूको प्रशिक्षण प्रक्रिया झन् चुनौतीपूर्ण बन्दै जान्छ। एउटा मुख्य समस्या भनेको [vanishing gradients](https://en.wikipedia.org/wiki/Vanishing_gradient_problem) वा [exploding gradients](https://deepai.org/machine-learning-glossary-and-terms/exploding-gradient-problem#:~:text=Exploding%20gradients%20are%20a%20problem,updates%20are%20small%20and%20controlled.) हो। [यो पोस्ट](https://towardsdatascience.com/the-vanishing-exploding-gradient-problem-in-deep-neural-networks-191358470c11) ले यी समस्याहरूको राम्रो परिचय दिन्छ।

गहिरो नेटवर्कहरूको प्रशिक्षणलाई प्रभावकारी बनाउनका लागि केही प्रविधिहरू प्रयोग गर्न सकिन्छ।

## मानहरूलाई उपयुक्त दायरामा राख्ने

संख्यात्मक गणनाहरूलाई स्थिर बनाउनका लागि, हामी चाहन्छौं कि हाम्रो न्यूरल नेटवर्कभित्रका सबै मानहरू उपयुक्त स्केलमा रहून्, सामान्यतया [-1..1] वा [0..1]। यो धेरै कडा आवश्यकता होइन, तर फ्लोटिङ पोइन्ट गणनाहरूको प्रकृति यस्तो छ कि विभिन्न परिमाणका मानहरूलाई सँगै सही रूपमा हेरफेर गर्न सकिँदैन। उदाहरणका लागि, यदि हामी 10<sup>-10</sup> र 10<sup>10</sup> जोड्छौं भने, हामी सम्भवतः 10<sup>10</sup> पाउँछौं, किनकि सानो मानलाई ठूलो मानको समान क्रममा "परिवर्तित" गरिन्छ, र यसरी म्यान्टिसा हराउँछ।

धेरैजसो एक्टिभेसन फङ्सनहरू [-1..1] वरिपरि गैर-रेखीयता राख्छन्, त्यसैले सबै इनपुट डाटालाई [-1..1] वा [0..1] दायरामा स्केल गर्नु उपयुक्त हुन्छ।

## सुरुवाती वजनको प्रारम्भिककरण

आदर्श रूपमा, हामी चाहन्छौं कि नेटवर्क लेयरहरू पार गरेपछि मानहरू समान दायरामा रहून्। त्यसैले वजनहरूलाई यस्तो तरिकाले प्रारम्भिककरण गर्नु महत्त्वपूर्ण छ जसले मानहरूको वितरणलाई कायम राख्न सकोस्।

सामान्य वितरण **N(0,1)** राम्रो विचार होइन, किनकि यदि हामीसँग *n* इनपुटहरू छन् भने, आउटपुटको मानक विचलन *n* हुनेछ, र मानहरू [0..1] दायराबाट बाहिर जान सक्ने सम्भावना हुन्छ।

निम्न प्रारम्भिककरणहरू प्रायः प्रयोग गरिन्छ:

 * समान वितरण -- `uniform`
 * **N(0,1/n)** -- `gaussian`
 * **N(0,1/√n_in)** यसले सुनिश्चित गर्छ कि शून्य औसत र मानक विचलन 1 भएका इनपुटहरूको औसत/मानक विचलन समान रहन्छ
 * **N(0,√2/(n_in+n_out))** -- जसलाई **Xavier initialization** (`glorot`) भनिन्छ, यसले अगाडि र पछाडि प्रसारको क्रममा संकेतहरूलाई दायरामा राख्न मद्दत गर्छ

## ब्याच नर्मलाइजेसन

सही वजन प्रारम्भिककरण भए पनि, प्रशिक्षणको क्रममा वजनहरू अत्यधिक ठूलो वा सानो हुन सक्छन्, जसले संकेतहरूलाई उपयुक्त दायराबाट बाहिर लैजान्छ। हामी संकेतहरूलाई पुनः उपयुक्त दायरामा ल्याउन **नर्मलाइजेसन** प्रविधिहरू प्रयोग गर्न सक्छौं। यस्ता धेरै प्रविधिहरू छन् (Weight normalization, Layer Normalization), तर प्रायः प्रयोग गरिने भनेको ब्याच नर्मलाइजेसन हो।

**ब्याच नर्मलाइजेसन** को विचार भनेको मिनिब्याचभरिका सबै मानहरूलाई ध्यानमा राखेर नर्मलाइजेसन गर्नु हो (जस्तै औसत घटाउने र मानक विचलनले भाग गर्ने)। यो नेटवर्क लेयरको रूपमा कार्यान्वयन गरिन्छ, जसले वजनहरू लागू गरेपछि तर एक्टिभेसन फङ्सन अघि नर्मलाइजेसन गर्छ। परिणामस्वरूप, हामी उच्च अन्तिम सटीकता र छिटो प्रशिक्षण देख्न सक्छौं।

यहाँ ब्याच नर्मलाइजेसनको [मूल पेपर](https://arxiv.org/pdf/1502.03167.pdf), [विकिपीडियामा व्याख्या](https://en.wikipedia.org/wiki/Batch_normalization), र [एक राम्रो परिचयात्मक ब्लग पोस्ट](https://towardsdatascience.com/batch-normalization-in-3-levels-of-understanding-14c2da90a338) (र [रूसी भाषामा](https://habrahabr.ru/post/309302/)) उपलब्ध छ।

## ड्रपआउट

**ड्रपआउट** एउटा रोचक प्रविधि हो जसले प्रशिक्षणको क्रममा केही प्रतिशत र्यान्डम न्यूरनहरू हटाउँछ। यो एउटा लेयरको रूपमा कार्यान्वयन गरिन्छ जसमा एउटा प्यारामिटर हुन्छ (हटाउनुपर्ने न्यूरनहरूको प्रतिशत, सामान्यतया 10%-50%), र प्रशिक्षणको क्रममा यो इनपुट भेक्टरका र्यान्डम तत्वहरूलाई शून्य बनाउँछ, त्यसपछि अर्को लेयरमा पठाउँछ।

यो विचार अचम्म लाग्दो भए पनि, तपाईं [`Dropout.ipynb`](../../../../../lessons/4-ComputerVision/08-TransferLearning/Dropout.ipynb) नोटबुकमा MNIST अंक वर्गीकरणकर्ता प्रशिक्षणमा ड्रपआउटको प्रभाव देख्न सक्नुहुन्छ। यसले प्रशिक्षणलाई छिटो बनाउँछ र कम प्रशिक्षण इपोक्समा उच्च सटीकता प्राप्त गर्न मद्दत गर्छ।

यस प्रभावलाई विभिन्न तरिकाले व्याख्या गर्न सकिन्छ:

 * यसलाई मोडेलमा र्यान्डम झट्काको रूपमा मान्न सकिन्छ, जसले अनुकूलनलाई स्थानीय न्यूनतमबाट बाहिर लैजान्छ
 * यसलाई *अप्रत्यक्ष मोडेल औसतकरण* को रूपमा मान्न सकिन्छ, किनकि ड्रपआउटको क्रममा हामी थोरै फरक मोडेल प्रशिक्षण गरिरहेका हुन्छौं

> *केही मानिसहरू भन्छन् कि जब कुनै मातेको व्यक्तिले केही सिक्न प्रयास गर्छ, उसले अर्को बिहान यो राम्रोसँग सम्झन्छ, तुलनात्मक रूपमा एक sober व्यक्तिसँग, किनकि केही खराबी भएका न्यूरनहरू भएको मस्तिष्कले अर्थलाई राम्रोसँग बुझ्न अनुकूलन गर्छ। हामीले यो सत्य हो कि होइन भनेर कहिल्यै परीक्षण गरेका छैनौं।*

## ओभरफिटिङ रोक्ने

डीप लर्निङको एउटा महत्त्वपूर्ण पक्ष भनेको [ओभरफिटिङ](../../3-NeuralNetworks/05-Frameworks/Overfitting.md) रोक्न सक्षम हुनु हो। जबकि धेरै शक्तिशाली न्यूरल नेटवर्क मोडेल प्रयोग गर्ने लोभ लाग्न सक्छ, हामीले सधैं मोडेल प्यारामिटरहरूको संख्या र प्रशिक्षण नमूनाहरूको संख्या बीच सन्तुलन राख्नुपर्छ।

> हामीले पहिले प्रस्तुत गरेको [ओभरफिटिङ](../../3-NeuralNetworks/05-Frameworks/Overfitting.md) को अवधारणा बुझ्न सुनिश्चित गर्नुहोस्!

ओभरफिटिङ रोक्नका लागि केही तरिकाहरू छन्:

 * प्रारम्भिक रोकावट -- मान्यकरण सेटमा त्रुटि निरन्तर निगरानी गर्नुहोस् र जब मान्यकरण त्रुटि बढ्न थाल्छ, प्रशिक्षण रोक्नुहोस्।
 * स्पष्ट वजन क्षय / नियमितीकरण -- उच्च वजनहरूको लागि हानि फङ्सनमा अतिरिक्त दण्ड थप्ने, जसले मोडेललाई धेरै अस्थिर परिणामहरू प्राप्त गर्नबाट रोक्छ
 * मोडेल औसतकरण -- धेरै मोडेलहरू प्रशिक्षण गर्ने र त्यसपछि परिणाम औसत गर्ने। यसले भिन्नतालाई न्यूनतम गर्न मद्दत गर्छ।
 * ड्रपआउट (अप्रत्यक्ष मोडेल औसतकरण)

## अप्टिमाइजरहरू / प्रशिक्षण एल्गोरिदमहरू

प्रशिक्षणको अर्को महत्त्वपूर्ण पक्ष भनेको राम्रो प्रशिक्षण एल्गोरिदम चयन गर्नु हो। जबकि शास्त्रीय **gradient descent** एक उचित विकल्प हो, यो कहिलेकाहीँ धेरै ढिलो हुन सक्छ, वा अन्य समस्याहरू उत्पन्न गर्न सक्छ।

डीप लर्निङमा, हामी **Stochastic Gradient Descent** (SGD) प्रयोग गर्छौं, जुन प्रशिक्षण सेटबाट र्यान्डम रूपमा चयन गरिएका मिनिब्याचहरूमा लागू गरिएको gradient descent हो। वजनहरू निम्न सूत्र प्रयोग गरेर समायोजन गरिन्छ:

w<sup>t+1</sup> = w<sup>t</sup> - η∇ℒ

### मोमेन्टम

**momentum SGD** मा, हामी अघिल्लो चरणहरूको ग्रेडियन्टको केही अंश राख्छौं। यो त्यस्तै हो जब हामी कुनै ठाउँमा जडत्वका साथ गइरहेका हुन्छौं, र हामीलाई फरक दिशामा धक्का दिइन्छ, हाम्रो मार्ग तुरुन्त परिवर्तन हुँदैन, तर मूल गति केही भाग राख्छ। यहाँ हामी *गति* प्रतिनिधित्व गर्न अर्को भेक्टर v परिचय गराउँछौं:

* v<sup>t+1</sup> = γ v<sup>t</sup> - η∇ℒ
* w<sup>t+1</sup> = w<sup>t</sup>+v<sup>t+1</sup>

यहाँ प्यारामिटर γ ले जडत्वलाई कति हदसम्म ध्यानमा राखिन्छ भन्ने संकेत गर्दछ: γ=0 शास्त्रीय SGD सँग मेल खान्छ; γ=1 शुद्ध गति समीकरण हो।

### एडम, एडाग्राड, आदि

किनकि प्रत्येक लेयरमा हामी संकेतहरूलाई केही म्याट्रिक्स W<sub>i</sub> द्वारा गुणन गर्छौं, ||W<sub>i</sub>|| मा निर्भर गर्दै, ग्रेडियन्ट या त घट्न सक्छ र 0 नजिक हुन सक्छ, या अनिश्चित रूपमा बढ्न सक्छ। यो Exploding/Vanishing Gradients समस्याको सार हो।

यस समस्याको समाधानमध्ये एक भनेको समीकरणमा ग्रेडियन्टको दिशा मात्र प्रयोग गर्नु हो, र पूर्ण मानलाई बेवास्ता गर्नु हो, अर्थात्

w<sup>t+1</sup> = w<sup>t</sup> - η(∇ℒ/||∇ℒ||), जहाँ ||∇ℒ|| = √∑(∇ℒ)<sup>2</sup>

यो एल्गोरिदमलाई **Adagrad** भनिन्छ। यसै विचार प्रयोग गर्ने अन्य एल्गोरिदमहरू: **RMSProp**, **Adam**

> **Adam** धेरै अनुप्रयोगहरूको लागि एकदम प्रभावकारी एल्गोरिदम मानिन्छ, त्यसैले यदि तपाईंलाई कुन प्रयोग गर्ने निश्चित छैन भने - Adam प्रयोग गर्नुहोस्।

### ग्रेडियन्ट क्लिपिङ

ग्रेडियन्ट क्लिपिङ माथिको विचारको विस्तार हो। जब ||∇ℒ|| ≤ θ हुन्छ, हामी वजन अनुकूलनमा मूल ग्रेडियन्टलाई विचार गर्छौं, र जब ||∇ℒ|| > θ हुन्छ - हामी ग्रेडियन्टलाई यसको नर्मले भाग गर्छौं। यहाँ θ एउटा प्यारामिटर हो, अधिकांश अवस्थामा हामी θ=1 वा θ=10 लिन सक्छौं।

### सिकाइ दर क्षय

प्रशिक्षणको सफलता प्रायः सिकाइ दर प्यारामिटर η मा निर्भर गर्दछ। यो तर्कसंगत छ कि ठूलो मानहरू η ले छिटो प्रशिक्षण परिणाम दिन्छ, जुन हामी सामान्यतया प्रशिक्षणको सुरुवातमा चाहन्छौं, र त्यसपछि सानो मानहरू η ले नेटवर्कलाई राम्रोसँग परिमार्जन गर्न अनुमति दिन्छ। त्यसैले, अधिकांश अवस्थामा हामी प्रशिक्षणको प्रक्रियामा η घटाउन चाहन्छौं।

यो प्रत्येक प्रशिक्षण इपोक पछि η लाई केही संख्याले (जस्तै 0.98) गुणन गरेर, या अधिक जटिल **सिकाइ दर तालिका** प्रयोग गरेर गर्न सकिन्छ।

## विभिन्न नेटवर्क आर्किटेक्चरहरू

तपाईंको समस्याको लागि सही नेटवर्क आर्किटेक्चर चयन गर्नु चुनौतीपूर्ण हुन सक्छ। सामान्यतया, हामी हाम्रो विशिष्ट कार्य (वा समान कार्य) को लागि काम गरेको आर्किटेक्चर लिन्छौं। यहाँ कम्प्युटर भिजनका लागि न्यूरल नेटवर्क आर्किटेक्चरहरूको [राम्रो अवलोकन](https://www.topbots.com/a-brief-history-of-neural-network-architectures/) छ।

> यो महत्त्वपूर्ण छ कि हामीसँग भएका प्रशिक्षण नमूनाहरूको संख्याका लागि पर्याप्त शक्तिशाली आर्किटेक्चर चयन गरौं। धेरै शक्तिशाली मोडेल चयन गर्दा [ओभरफिटिङ](../../3-NeuralNetworks/05-Frameworks/Overfitting.md) हुन सक्छ।

अर्को राम्रो तरिका भनेको आवश्यक जटिलतामा स्वतः समायोजन गर्ने आर्किटेक्चर प्रयोग गर्नु हो। केही हदसम्म, **ResNet** आर्किटेक्चर र **Inception** स्व-समायोजन छन्। [कम्प्युटर भिजन आर्किटेक्चरहरूमा थप जानकारी](../07-ConvNets/CNN_Architectures.md)।

**अस्वीकरण**:  
यो दस्तावेज़ AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) प्रयोग गरी अनुवाद गरिएको हो। हामी यथासम्भव सटीकता सुनिश्चित गर्न प्रयास गर्छौं, तर कृपया ध्यान दिनुहोस् कि स्वचालित अनुवादहरूमा त्रुटिहरू वा अशुद्धताहरू हुन सक्छन्। यसको मूल भाषामा रहेको मूल दस्तावेज़लाई आधिकारिक स्रोत मानिनुपर्छ। महत्त्वपूर्ण जानकारीका लागि, व्यावसायिक मानव अनुवाद सिफारिस गरिन्छ। यस अनुवादको प्रयोगबाट उत्पन्न हुने कुनै पनि गलतफहमी वा गलत व्याख्याका लागि हामी जिम्मेवार हुने छैनौं।