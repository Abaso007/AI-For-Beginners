<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "178c0b5ee5395733eb18aec51e71a0a9",
  "translation_date": "2025-09-23T07:16:08+00:00",
  "source_file": "lessons/4-ComputerVision/08-TransferLearning/README.md",
  "language_code": "ne"
}
-->
# प्रि-ट्रेन गरिएको नेटवर्कहरू र ट्रान्सफर लर्निङ

CNN प्रशिक्षण गर्न धेरै समय लाग्न सक्छ, र त्यसका लागि धेरै डेटा आवश्यक हुन्छ। तर, धेरै समय नेटवर्कले तल्लो-स्तरका फिल्टरहरू सिक्नमा खर्च हुन्छ, जसले छविबाट ढाँचा निकाल्न मद्दत गर्छ। एउटा स्वाभाविक प्रश्न उठ्छ - के हामी एउटा डेटासेटमा प्रशिक्षित न्यूरल नेटवर्कलाई प्रयोग गरेर फरक छविहरू वर्गीकरण गर्न अनुकूलित गर्न सक्छौं, पूर्ण प्रशिक्षण प्रक्रिया बिना?

## [Pre-lecture quiz](https://ff-quizzes.netlify.app/en/ai/quiz/15)

यो विधिलाई **ट्रान्सफर लर्निङ** भनिन्छ, किनभने हामी एउटा न्यूरल नेटवर्क मोडेलबाट अर्कोमा केही ज्ञान ट्रान्सफर गर्छौं। ट्रान्सफर लर्निङमा, हामी सामान्यतया एउटा प्रि-ट्रेन गरिएको मोडेलबाट सुरु गर्छौं, जुन ठूलो छवि डेटासेटमा प्रशिक्षित गरिएको हुन्छ, जस्तै **ImageNet**। ती मोडेलहरूले सामान्य छविहरूबाट विभिन्न विशेषताहरू निकाल्न राम्रो काम गर्न सक्छन्, र धेरै अवस्थामा ती विशेषताहरूको आधारमा क्लासिफायर निर्माण गर्दा राम्रो नतिजा प्राप्त गर्न सकिन्छ।

> ✅ ट्रान्सफर लर्निङ अन्य शैक्षिक क्षेत्रहरूमा पनि पाइन्छ, जस्तै शिक्षा। यसले एउटा क्षेत्रबाट ज्ञान लिएर अर्को क्षेत्रमा लागू गर्ने प्रक्रियालाई जनाउँछ।

## प्रि-ट्रेन गरिएको मोडेलहरूलाई विशेषता निकाल्न प्रयोग गर्ने

पछिल्लो खण्डमा हामीले चर्चा गरेका कन्भोल्युसनल नेटवर्कहरूमा धेरै तहहरू हुन्छन्, जसले छविबाट विशेषताहरू निकाल्न काम गर्छन्। तल्लो-स्तरका पिक्सेल संयोजनहरू (जस्तै तेर्सो/ठाडो रेखा वा स्ट्रोक) बाट सुरु गरेर, उच्च-स्तरका विशेषताहरू (जस्तै आगोको आँखा) सम्म पुग्छ। यदि हामी CNN लाई पर्याप्त ठूलो र विविध छविहरूको डेटासेटमा प्रशिक्षित गर्छौं भने, नेटवर्कले ती सामान्य विशेषताहरू निकाल्न सिक्नुपर्छ।

Keras र PyTorch दुवैमा सामान्य आर्किटेक्चरहरूको लागि प्रि-ट्रेन गरिएको न्यूरल नेटवर्क वेटहरू सजिलै लोड गर्ने फङ्सनहरू छन्, जसलाई प्रायः ImageNet छविहरूमा प्रशिक्षित गरिएको हुन्छ। प्रायः प्रयोग गरिने मोडेलहरू [CNN Architectures](../07-ConvNets/CNN_Architectures.md) पृष्ठमा वर्णन गरिएको छ। विशेष गरी, तपाईं निम्न मोडेलहरू प्रयोग गर्न विचार गर्न सक्नुहुन्छ:

* **VGG-16/VGG-19**: यी तुलनात्मक रूपमा सरल मोडेलहरू हुन् जसले अझै राम्रो शुद्धता दिन्छ। ट्रान्सफर लर्निङ कसरी काम गरिरहेको छ हेर्न पहिलो प्रयासको रूपमा VGG प्रयोग गर्नु राम्रो विकल्प हो।
* **ResNet**: Microsoft Research द्वारा २०१५ मा प्रस्ताव गरिएको मोडेलहरूको परिवार। यी मोडेलहरूमा धेरै तहहरू हुन्छन्, जसले गर्दा बढी स्रोतहरू आवश्यक पर्छ।
* **MobileNet**: सानो आकारका मोडेलहरूको परिवार, मोबाइल उपकरणहरूको लागि उपयुक्त। यदि तपाईं स्रोतहरूमा कमी हुनुहुन्छ र थोरै शुद्धता त्याग गर्न सक्नुहुन्छ भने प्रयोग गर्नुहोस्।

यहाँ VGG-16 नेटवर्कले बिरालोको तस्बिरबाट निकालेका विशेषताहरूको उदाहरण छ:

![Features extracted by VGG-16](../../../../../translated_images/features.6291f9c7ba3a0b951af88fc9864632b9115365410765680680d30c927dd67354.ne.png)

## बिरालो र कुकुर डेटासेट

यस उदाहरणमा, हामी [Cats and Dogs](https://www.microsoft.com/download/details.aspx?id=54765&WT.mc_id=academic-77998-cacaste) डेटासेट प्रयोग गर्नेछौं, जुन वास्तविक जीवनको छवि वर्गीकरण परिदृश्यसँग धेरै नजिक छ।

## ✍️ अभ्यास: ट्रान्सफर लर्निङ

आउनुहोस्, सम्बन्धित नोटबुकहरूमा ट्रान्सफर लर्निङलाई व्यवहारमा हेर्नुहोस्:

* [Transfer Learning - PyTorch](TransferLearningPyTorch.ipynb)
* [Transfer Learning - TensorFlow](TransferLearningTF.ipynb)

## बिरालोको आदर्श छवि देखाउने

प्रि-ट्रेन गरिएको न्यूरल नेटवर्कको *मस्तिष्क* भित्र विभिन्न ढाँचाहरू हुन्छन्, जसमा **आदर्श बिरालो** (साथै आदर्श कुकुर, आदर्श जेब्रा, आदि) को धारणा समावेश हुन्छ। यो छवि **दृश्य रूपमा देखाउन** रोचक हुनेछ। तर, यो सजिलो छैन, किनभने ढाँचाहरू नेटवर्क वेटहरूमा फैलिएका छन्, र पनि तिनीहरू पदानुक्रमित संरचनामा व्यवस्थित छन्।

हामी एउटा विधि लिन सक्छौं, जहाँ हामी एउटा र्यान्डम छविबाट सुरु गर्छौं, र त्यसपछि **ग्रेडियन्ट डिसेन्ट अप्टिमाइजेसन** प्रविधि प्रयोग गरेर त्यो छवि समायोजन गर्ने प्रयास गर्छौं, ताकि नेटवर्कले सोच्न थाल्छ कि यो बिरालो हो।

![Image Optimization Loop](../../../../../translated_images/ideal-cat-loop.999fbb8ff306e044f997032f4eef9152b453e6a990e449bbfb107de2493cc37e.ne.png)

तर, यदि हामी यसो गर्छौं भने, हामीले र्यान्डम आवाजसँग धेरै मिल्दोजुल्दो केही प्राप्त गर्नेछौं। यसको कारण हो कि *नेटवर्कलाई इनपुट छवि बिरालो हो भनेर सोच्न बनाउने धेरै तरिकाहरू छन्*, जसमा केही दृश्य रूपमा अर्थपूर्ण छैनन्। ती छविहरूमा बिरालोको लागि सामान्य ढाँचाहरू धेरै हुन्छन्, तर तिनीहरूलाई दृश्य रूपमा विशिष्ट बनाउने कुनै बाध्यता छैन।

नतिजा सुधार गर्न, हामी हानि कार्यमा अर्को पद थप्न सक्छौं, जसलाई **भेरिएसन हानि** भनिन्छ। यो एउटा मेट्रिक हो, जसले छविको छेउछाउका पिक्सेलहरू कति समान छन् भनेर देखाउँछ। भेरिएसन हानि न्यूनतम गर्दा छवि चिल्लो हुन्छ, र आवाज हट्छ - जसले दृश्य रूपमा आकर्षक ढाँचाहरू प्रकट गर्छ। यहाँ उच्च सम्भावनाका साथ बिरालो र जेब्रा भनेर वर्गीकृत गरिएका "आदर्श" छविहरूको उदाहरण छ:

![Ideal Cat](../../../../../translated_images/ideal-cat.203dd4597643d6b0bd73038b87f9c0464322725e3a06ab145d25d4a861c70592.ne.png) | ![Ideal Zebra](../../../../../translated_images/ideal-zebra.7f70e8b54ee15a7a314000bb5df38a6cfe086ea04d60df4d3ef313d046b98a2b.ne.png)
-----|-----
 *आदर्श बिरालो* | *आदर्श जेब्रा*

यस्तै विधि प्रयोग गरेर न्यूरल नेटवर्कमा **adversarial attacks** गर्न सकिन्छ। मानौं हामी न्यूरल नेटवर्कलाई मूर्ख बनाउन चाहन्छौं र कुकुरलाई बिरालो जस्तो देखाउन चाहन्छौं। यदि हामी कुकुरको छवि लिन्छौं, जुन नेटवर्कले कुकुर भनेर पहिचान गर्छ, हामी त्यसलाई थोरै समायोजन गर्न सक्छौं ग्रेडियन्ट डिसेन्ट अप्टिमाइजेसन प्रयोग गरेर, जबसम्म नेटवर्कले यसलाई बिरालो भनेर वर्गीकृत गर्न थाल्दैन:

![Picture of a Dog](../../../../../translated_images/original-dog.8f68a67d2fe0911f33041c0f7fce8aa4ea919f9d3917ec4b468298522aeb6356.ne.png) | ![Picture of a dog classified as a cat](../../../../../translated_images/adversarial-dog.d9fc7773b0142b89752539bfbf884118de845b3851c5162146ea0b8809fc820f.ne.png)
-----|-----
*कुकुरको मूल छवि* | *कुकुरको छवि बिरालो भनेर वर्गीकृत गरिएको*

माथिको नतिजा पुन: उत्पादन गर्न कोड निम्न नोटबुकमा हेर्नुहोस्:

* [Ideal and Adversarial Cat - TensorFlow](AdversarialCat_TF.ipynb)

## निष्कर्ष

ट्रान्सफर लर्निङ प्रयोग गरेर, तपाईं कस्टम वस्तु वर्गीकरण कार्यको लागि छिटो क्लासिफायर निर्माण गर्न र उच्च शुद्धता प्राप्त गर्न सक्षम हुनुहुन्छ। तपाईं देख्न सक्नुहुन्छ कि हामी अहिले समाधान गरिरहेका जटिल कार्यहरू उच्च कम्प्युटेशनल शक्ति आवश्यक छ, र CPU मा सजिलै समाधान गर्न सकिँदैन। अर्को खण्डमा, हामी समान मोडेललाई कम कम्प्युट स्रोतहरू प्रयोग गरेर प्रशिक्षण गर्न हल्का कार्यान्वयन प्रयोग गर्ने प्रयास गर्नेछौं, जसले थोरै कम शुद्धता परिणाम दिन्छ।

## 🚀 चुनौती

साथी नोटबुकहरूमा, तल नोटहरू छन् कि ट्रान्सफर ज्ञान समान प्रशिक्षण डेटा (नयाँ प्रकारको जनावर, सम्भवतः) संग राम्रोसँग काम गर्छ। पूर्ण रूपमा नयाँ प्रकारका छविहरूको साथ केही प्रयोग गरेर हेर्नुहोस् कि तपाईंको ट्रान्सफर ज्ञान मोडेलहरू कत्तिको राम्रो वा खराब प्रदर्शन गर्छन्।

## [Post-lecture quiz](https://ff-quizzes.netlify.app/en/ai/quiz/16)

## समीक्षा र आत्म अध्ययन

[TrainingTricks.md](TrainingTricks.md) पढेर आफ्नो मोडेलहरू प्रशिक्षण गर्ने अन्य तरिकाहरूको ज्ञानलाई गहिरो बनाउनुहोस्।

## [Assignment](lab/README.md)

यस प्रयोगशालामा, हामी वास्तविक जीवनको [Oxford-IIIT](https://www.robots.ox.ac.uk/~vgg/data/pets/) पालतू जनावर डेटासेट प्रयोग गर्नेछौं, जसमा बिरालो र कुकुरका ३५ प्रजातिहरू छन्, र हामी ट्रान्सफर लर्निङ क्लासिफायर निर्माण गर्नेछौं।

---

