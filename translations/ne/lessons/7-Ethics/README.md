<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "437c988596e751072e41a5aad3fcc5d9",
  "translation_date": "2025-08-26T08:00:01+00:00",
  "source_file": "lessons/7-Ethics/README.md",
  "language_code": "ne"
}
-->
# नैतिक र जिम्मेवार एआई

तपाईंले यो पाठ्यक्रम लगभग समाप्त गर्नुभएको छ, र आशा छ कि अहिले सम्म तपाईंले स्पष्ट रूपमा देख्नुभएको छ कि एआई धेरै औपचारिक गणितीय विधिहरूमा आधारित छ जसले हामीलाई डाटामा सम्बन्धहरू पत्ता लगाउन र केही मानव व्यवहारको पक्षहरू पुन: निर्माण गर्न मोडेलहरू प्रशिक्षण दिन अनुमति दिन्छ। अहिलेको समयमा, हामी एआईलाई डाटाबाट ढाँचा निकाल्न र ती ढाँचाहरूलाई नयाँ समस्याहरू समाधान गर्न लागू गर्न एक धेरै शक्तिशाली उपकरण मान्छौं।

## [Pre-lecture quiz](https://white-water-09ec41f0f.azurestaticapps.net/quiz/5/)

तर, विज्ञान कथामा हामी प्रायः कथाहरू देख्छौं जहाँ एआई मानव जातिका लागि खतरा प्रस्तुत गर्दछ। सामान्यतया ती कथाहरू कुनै प्रकारको एआई विद्रोहको वरिपरि केन्द्रित हुन्छन्, जब एआईले मानवसँग सामना गर्ने निर्णय लिन्छ। यसले संकेत गर्दछ कि एआईसँग कुनै प्रकारको भावना छ वा यसको विकासकर्ताहरूले पूर्वानुमान गर्न नसक्ने निर्णय लिन सक्छ।

यो पाठ्यक्रममा हामीले सिकेको एआई ठूलो म्याट्रिक्स गणित बाहेक केही होइन। यो हाम्रो समस्याहरू समाधान गर्न मद्दत गर्ने एक धेरै शक्तिशाली उपकरण हो, र कुनै पनि अन्य शक्तिशाली उपकरण जस्तै - यसलाई राम्रो र नराम्रो उद्देश्यका लागि प्रयोग गर्न सकिन्छ। महत्वपूर्ण कुरा, यसलाई *दुरुपयोग* गर्न सकिन्छ।

## जिम्मेवार एआईका सिद्धान्तहरू

एआईको यो अनियन्त्रित वा उद्देश्यपूर्ण दुरुपयोग रोक्न, माइक्रोसफ्टले महत्वपूर्ण [जिम्मेवार एआईका सिद्धान्तहरू](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-77998-cacaste) प्रस्तुत गर्दछ। यी सिद्धान्तहरू निम्न अवधारणाहरूमा आधारित छन्:

* **न्याय** *मोडेल पूर्वाग्रहहरू* को महत्त्वपूर्ण समस्यासँग सम्बन्धित छ, जुन प्रशिक्षणको लागि पूर्वाग्रही डाटा प्रयोग गर्दा उत्पन्न हुन सक्छ। उदाहरणका लागि, जब हामी कसैलाई सफ्टवेयर डेभलपरको जागिर प्राप्त गर्ने सम्भावना भविष्यवाणी गर्न प्रयास गर्छौं, मोडेलले पुरुषलाई उच्च प्राथमिकता दिन सक्छ - किनभने प्रशिक्षण डाटासेट सम्भवतः पुरुष दर्शकहरूको लागि पूर्वाग्रही थियो। हामीले प्रशिक्षण डाटालाई सावधानीपूर्वक सन्तुलन गर्न र पूर्वाग्रहहरू रोक्न मोडेलको अनुसन्धान गर्न आवश्यक छ, र सुनिश्चित गर्न आवश्यक छ कि मोडेलले थप सान्दर्भिक विशेषताहरूलाई ध्यानमा राख्छ।
* **विश्वसनीयता र सुरक्षा**। यसको प्रकृतिले गर्दा, एआई मोडेलहरूले गल्ती गर्न सक्छ। न्युरल नेटवर्कले सम्भावनाहरू फर्काउँछ, र हामीले निर्णय गर्दा यसलाई ध्यानमा राख्न आवश्यक छ। प्रत्येक मोडेलसँग केही शुद्धता र पुनःप्राप्ति हुन्छ, र गलत सल्लाहले निम्त्याउन सक्ने हानि रोक्न हामीले यसलाई बुझ्न आवश्यक छ।
* **गोपनीयता र सुरक्षा**मा केही एआई-विशिष्ट प्रभावहरू छन्। उदाहरणका लागि, जब हामी मोडेल प्रशिक्षणको लागि केही डाटा प्रयोग गर्छौं, यो डाटा कुनै प्रकारले मोडेलमा "समाहित" हुन्छ। एकातिर, यसले सुरक्षा र गोपनीयता बढाउँछ, अर्कोतर्फ - हामीले मोडेल कुन डाटामा प्रशिक्षण गरिएको थियो भन्ने कुरा सम्झनु आवश्यक छ।
* **समावेशिता**को अर्थ हामी मानिसलाई प्रतिस्थापन गर्न एआई निर्माण गरिरहेका छैनौं, बरु मानिसलाई सहयोग गर्न र हाम्रो कामलाई थप रचनात्मक बनाउन। यो न्यायसँग पनि सम्बन्धित छ, किनभने जब हामी कम प्रतिनिधित्व भएका समुदायहरूसँग व्यवहार गर्छौं, हामीले सङ्कलन गरेका अधिकांश डाटासेटहरू सम्भवतः पूर्वाग्रही हुनेछन्, र हामीले सुनिश्चित गर्न आवश्यक छ कि ती समुदायहरू समावेश गरिएका छन् र एआईद्वारा सही रूपमा ह्यान्डल गरिएका छन्।
* **पारदर्शिता**। यसमा एआई प्रयोग भइरहेको कुरा स्पष्ट पार्न सुनिश्चित गर्नु समावेश छ। साथै, जहाँ सम्भव छ, हामी *व्याख्यात्मक* एआई प्रणालीहरू प्रयोग गर्न चाहन्छौं।
* **जवाफदेहिता**। जब एआई मोडेलहरूले केही निर्णयहरू लिन्छन्, ती निर्णयहरूको जिम्मेवारी कसको हो भन्ने कुरा सधैं स्पष्ट हुँदैन। हामीले सुनिश्चित गर्न आवश्यक छ कि एआई निर्णयहरूको जिम्मेवारी कहाँ छ भन्ने कुरा बुझ्छौं। अधिकांश अवस्थामा हामी चाहन्छौं कि महत्त्वपूर्ण निर्णयहरू लिन मानवलाई समावेश गरियोस्, ताकि वास्तविक व्यक्तिहरूलाई जिम्मेवार बनाइयोस्।

## जिम्मेवार एआईका उपकरणहरू

माइक्रोसफ्टले [जिम्मेवार एआई टूलबक्स](https://github.com/microsoft/responsible-ai-toolbox) विकास गरेको छ जसमा उपकरणहरूको सेट समावेश छ:

* Interpretability Dashboard (InterpretML)
* Fairness Dashboard (FairLearn)
* Error Analysis Dashboard
* जिम्मेवार एआई ड्यासबोर्ड जसमा समावेश छ:

   - EconML - कारण विश्लेषणको लागि उपकरण, जसले के-भए प्रश्नहरूमा केन्द्रित गर्दछ
   - DiCE - Counterfactual विश्लेषणको लागि उपकरण जसले मोडेलको निर्णयलाई प्रभाव पार्न आवश्यक विशेषताहरू परिवर्तन गर्न देख्न अनुमति दिन्छ

एआई नैतिकताबारे थप जानकारीको लागि, कृपया [यो पाठ](https://github.com/microsoft/ML-For-Beginners/tree/main/1-Introduction/3-fairness?WT.mc_id=academic-77998-cacaste) हेर्नुहोस् जुन मेसिन लर्निङ पाठ्यक्रममा असाइनमेन्टहरू समावेश गर्दछ।

## समीक्षा र आत्म अध्ययन

जिम्मेवार एआईबारे थप जान्नको लागि यो [Learn Path](https://docs.microsoft.com/learn/modules/responsible-ai-principles/?WT.mc_id=academic-77998-cacaste) लिनुहोस्।

## [Post-lecture quiz](https://white-water-09ec41f0f.azurestaticapps.net/quiz/6/)

**अस्वीकरण**:  
यो दस्तावेज़ AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) प्रयोग गरेर अनुवाद गरिएको छ। हामी शुद्धताको लागि प्रयास गर्छौं, तर कृपया ध्यान दिनुहोस् कि स्वचालित अनुवादमा त्रुटिहरू वा अशुद्धताहरू हुन सक्छ। यसको मूल भाषा मा रहेको मूल दस्तावेज़लाई आधिकारिक स्रोत मानिनुपर्छ। महत्वपूर्ण जानकारीको लागि, व्यावसायिक मानव अनुवाद सिफारिस गरिन्छ। यस अनुवादको प्रयोगबाट उत्पन्न हुने कुनै पनि गलतफहमी वा गलत व्याख्याको लागि हामी जिम्मेवार हुने छैनौं।