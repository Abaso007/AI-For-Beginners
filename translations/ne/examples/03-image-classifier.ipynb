{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‡§∏‡§æ‡§ß‡§æ‡§∞‡§£ ‡§õ‡§µ‡§ø ‡§µ‡§∞‡•ç‡§ó‡•Ä‡§ï‡§∞‡§£‡§ï‡§∞‡•ç‡§§‡§æ\n",
    "\n",
    "‡§Ø‡•ã ‡§®‡•ã‡§ü‡§¨‡•Å‡§ï‡§≤‡•á ‡§§‡§™‡§æ‡§à‡§Ç‡§≤‡§æ‡§à ‡§™‡•Ç‡§∞‡•ç‡§µ-‡§™‡•ç‡§∞‡§∂‡§ø‡§ï‡•ç‡§∑‡§ø‡§§ ‡§®‡•ç‡§Ø‡•Ç‡§∞‡§≤ ‡§®‡•á‡§ü‡§µ‡§∞‡•ç‡§ï ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ó‡§∞‡•á‡§∞ ‡§õ‡§µ‡§ø‡§π‡§∞‡•Ç ‡§µ‡§∞‡•ç‡§ó‡•Ä‡§ï‡•É‡§§ ‡§ó‡§∞‡•ç‡§®‡•á ‡§§‡§∞‡§ø‡§ï‡§æ ‡§¶‡•á‡§ñ‡§æ‡§â‡§Å‡§õ‡•§\n",
    "\n",
    "**‡§§‡§™‡§æ‡§à‡§Ç‡§≤‡•á ‡§ï‡•á ‡§∏‡§ø‡§ï‡•ç‡§®‡•Å‡§π‡•Å‡§®‡•á‡§õ:**\n",
    "- ‡§™‡•Ç‡§∞‡•ç‡§µ-‡§™‡•ç‡§∞‡§∂‡§ø‡§ï‡•ç‡§∑‡§ø‡§§ ‡§Æ‡•ã‡§°‡•á‡§≤ ‡§ï‡§∏‡§∞‡•Ä ‡§≤‡•ã‡§° ‡§ó‡§∞‡•ç‡§®‡•á ‡§∞ ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ó‡§∞‡•ç‡§®‡•á\n",
    "- ‡§õ‡§µ‡§ø ‡§™‡•Ç‡§∞‡•ç‡§µ-‡§™‡•ç‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ\n",
    "- ‡§õ‡§µ‡§ø‡§π‡§∞‡•Ç‡§Æ‡§æ ‡§≠‡§µ‡§ø‡§∑‡•ç‡§Ø‡§µ‡§æ‡§£‡•Ä ‡§ó‡§∞‡•ç‡§®‡•á ‡§§‡§∞‡§ø‡§ï‡§æ\n",
    "- ‡§Ü‡§§‡•ç‡§Æ‡§µ‡§ø‡§∂‡•ç‡§µ‡§æ‡§∏ ‡§∏‡•ç‡§ï‡•ã‡§∞ ‡§¨‡•Å‡§ù‡•ç‡§®‡•á\n",
    "\n",
    "**‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡§ï‡•ã ‡§Æ‡§æ‡§Æ‡§≤‡§æ:** ‡§õ‡§µ‡§ø‡§π‡§∞‡•Ç‡§Æ‡§æ ‡§µ‡§∏‡•ç‡§§‡•Å‡§π‡§∞‡•Ç ‡§™‡§π‡§ø‡§ö‡§æ‡§® ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç (‡§ú‡§∏‡•ç‡§§‡•à \"‡§¨‡§ø‡§∞‡§æ‡§≤‡•ã\", \"‡§ï‡•Å‡§ï‡•Å‡§∞\", \"‡§ï‡§æ‡§∞\", ‡§Ü‡§¶‡§ø) \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‡§ö‡§∞‡§£ ‡•ß: ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï ‡§≤‡§æ‡§á‡§¨‡•ç‡§∞‡•á‡§∞‡•Ä‡§π‡§∞‡•Ç ‡§Ü‡§Ø‡§æ‡§§ ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç\n",
    "\n",
    "‡§π‡§æ‡§Æ‡•Ä‡§≤‡§æ‡§à ‡§ö‡§æ‡§π‡§ø‡§®‡•á ‡§â‡§™‡§ï‡§∞‡§£‡§π‡§∞‡•Ç ‡§Ü‡§Ø‡§æ‡§§ ‡§ó‡§∞‡•å‡§Ç‡•§ ‡§Ø‡§¶‡§ø ‡§§‡§™‡§æ‡§à‡§Ç‡§≤‡§æ‡§à ‡§Ø‡•Ä ‡§∏‡§¨‡•à ‡§¨‡•Å‡§ù‡•ç‡§® ‡§ó‡§æ‡§π‡•ç‡§∞‡•ã ‡§≠‡§Ø‡•ã ‡§≠‡§®‡•á ‡§ö‡§ø‡§®‡•ç‡§§‡§æ ‡§®‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# TensorFlow for deep learning\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.applications import MobileNetV2\n",
    "    from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, decode_predictions\n",
    "    print(\"‚úÖ TensorFlow loaded successfully!\")\n",
    "    print(f\"   Version: {tf.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå Please install TensorFlow: pip install tensorflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‡§ö‡§∞‡§£ ‡•®: ‡§™‡•ç‡§∞‡§ø-‡§ü‡•ç‡§∞‡•á‡§® ‡§ó‡§∞‡§ø‡§è‡§ï‡•ã ‡§Æ‡•ã‡§°‡•á‡§≤ ‡§≤‡•ã‡§° ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç\n",
    "\n",
    "‡§π‡§æ‡§Æ‡•Ä **MobileNetV2** ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ó‡§∞‡•ç‡§®‡•á‡§õ‡•å‡§Ç, ‡§ú‡•Å‡§® ‡§≤‡§æ‡§ñ‡•å‡§Ç ‡§§‡§∏‡•ç‡§¨‡§ø‡§∞‡§π‡§∞‡•Ç‡§Æ‡§æ ‡§™‡§π‡§ø‡§≤‡•á ‡§®‡•à ‡§™‡•ç‡§∞‡§∂‡§ø‡§ï‡•ç‡§∑‡§ø‡§§ ‡§ó‡§∞‡§ø‡§è‡§ï‡•ã ‡§®‡•ç‡§Ø‡•Å‡§∞‡§≤ ‡§®‡•á‡§ü‡§µ‡§∞‡•ç‡§ï ‡§π‡•ã‡•§\n",
    "\n",
    "‡§Ø‡§∏‡§≤‡§æ‡§à **‡§ü‡•ç‡§∞‡§æ‡§®‡•ç‡§∏‡§´‡§∞ ‡§≤‡§∞‡•ç‡§®‡§ø‡§ô** ‡§≠‡§®‡§ø‡§®‡•ç‡§õ - ‡§Ö‡§∞‡•Ç‡§≤‡•á ‡§™‡•ç‡§∞‡§∂‡§ø‡§ï‡•ç‡§∑‡§ø‡§§ ‡§ó‡§∞‡•á‡§ï‡•ã ‡§Æ‡•ã‡§°‡•á‡§≤ ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ó‡§∞‡•ç‡§®‡•Å!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üì¶ Loading pre-trained MobileNetV2 model...\")\n",
    "print(\"   This may take a minute on first run (downloading weights)...\")\n",
    "\n",
    "# Load the model\n",
    "# include_top=True means we use the classification layer\n",
    "# weights='imagenet' means it was trained on ImageNet dataset\n",
    "model = MobileNetV2(weights='imagenet', include_top=True)\n",
    "\n",
    "print(\"‚úÖ Model loaded!\")\n",
    "print(f\"   The model can recognize 1000 different object categories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‡§ö‡§∞‡§£ ‡•©: ‡§∏‡§π‡§æ‡§Ø‡§ï ‡§´‡§ô‡•ç‡§∏‡§®‡§π‡§∞‡•Ç\n",
    "\n",
    "‡§π‡§æ‡§Æ‡•Ä ‡§π‡§æ‡§Æ‡•ç‡§∞‡•ã ‡§Æ‡•ã‡§°‡•á‡§≤‡§ï‡§æ ‡§≤‡§æ‡§ó‡§ø ‡§õ‡§µ‡§ø‡§π‡§∞‡•Ç ‡§≤‡•ã‡§° ‡§ó‡§∞‡•ç‡§® ‡§∞ ‡§§‡§Ø‡§æ‡§∞ ‡§ó‡§∞‡•ç‡§® ‡§´‡§ô‡•ç‡§∏‡§®‡§π‡§∞‡•Ç ‡§¨‡§®‡§æ‡§â‡§Å‡§õ‡•å‡§Ç‡•§\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_from_url(url):\n",
    "    \"\"\"\n",
    "    Load an image from a URL.\n",
    "    \n",
    "    Args:\n",
    "        url: Web address of the image\n",
    "        \n",
    "    Returns:\n",
    "        PIL Image object\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    return img\n",
    "\n",
    "\n",
    "def prepare_image(img):\n",
    "    \"\"\"\n",
    "    Prepare an image for the model.\n",
    "    \n",
    "    Steps:\n",
    "    1. Resize to 224x224 (model's expected size)\n",
    "    2. Convert to array\n",
    "    3. Add batch dimension\n",
    "    4. Preprocess for MobileNetV2\n",
    "    \n",
    "    Args:\n",
    "        img: PIL Image\n",
    "        \n",
    "    Returns:\n",
    "        Preprocessed image array\n",
    "    \"\"\"\n",
    "    # Resize to 224x224 pixels\n",
    "    img = img.resize((224, 224))\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    img_array = np.array(img)\n",
    "    \n",
    "    # Add batch dimension (model expects multiple images)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    # Preprocess for MobileNetV2\n",
    "    img_array = preprocess_input(img_array)\n",
    "    \n",
    "    return img_array\n",
    "\n",
    "\n",
    "def classify_image(img):\n",
    "    \"\"\"\n",
    "    Classify an image and return top predictions.\n",
    "    \n",
    "    Args:\n",
    "        img: PIL Image\n",
    "        \n",
    "    Returns:\n",
    "        List of (class_name, confidence) tuples\n",
    "    \"\"\"\n",
    "    # Prepare the image\n",
    "    img_array = prepare_image(img)\n",
    "    \n",
    "    # Make prediction\n",
    "    predictions = model.predict(img_array, verbose=0)\n",
    "    \n",
    "    # Decode predictions to human-readable labels\n",
    "    # top=5 means we get the top 5 most likely classes\n",
    "    decoded = decode_predictions(predictions, top=5)[0]\n",
    "    \n",
    "    # Convert to simpler format\n",
    "    results = [(label, float(confidence)) for (_, label, confidence) in decoded]\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"‚úÖ Helper functions ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‡§ö‡§∞‡§£ ‡•™: ‡§®‡§Æ‡•Ç‡§®‡§æ ‡§õ‡§µ‡§ø‡§π‡§∞‡•Ç‡§Æ‡§æ ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§£ ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç\n",
    "\n",
    "‡§á‡§®‡•ç‡§ü‡§∞‡§®‡•á‡§ü‡§¨‡§æ‡§ü ‡§ï‡•á‡§π‡•Ä ‡§õ‡§µ‡§ø‡§π‡§∞‡•Ç ‡§µ‡§∞‡•ç‡§ó‡•Ä‡§ï‡§∞‡§£ ‡§ó‡§∞‡•ç‡§®‡•á ‡§™‡•ç‡§∞‡§Ø‡§æ‡§∏ ‡§ó‡§∞‡•å‡§Ç!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample images to classify\n",
    "# These are from Unsplash (free stock photos)\n",
    "test_images = [\n",
    "    {\n",
    "        \"url\": \"https://images.unsplash.com/photo-1514888286974-6c03e2ca1dba?w=400\",\n",
    "        \"description\": \"A cat\"\n",
    "    },\n",
    "    {\n",
    "        \"url\": \"https://images.unsplash.com/photo-1552053831-71594a27632d?w=400\",\n",
    "        \"description\": \"A dog\"\n",
    "    },\n",
    "    {\n",
    "        \"url\": \"https://images.unsplash.com/photo-1511919884226-fd3cad34687c?w=400\",\n",
    "        \"description\": \"A car\"\n",
    "    },\n",
    "]\n",
    "\n",
    "print(f\"üß™ Testing on {len(test_images)} images...\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡•á‡§ï ‡§õ‡§µ‡§ø‡§ï‡•ã ‡§µ‡§∞‡•ç‡§ó‡•Ä‡§ï‡§∞‡§£ ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, img_data in enumerate(test_images, 1):\n",
    "    print(f\"\\nüì∏ Image {i}: {img_data['description']}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    try:\n",
    "        # Load image\n",
    "        img = load_image_from_url(img_data['url'])\n",
    "        \n",
    "        # Display image\n",
    "        display(img.resize((200, 200)))  # Show smaller version\n",
    "        \n",
    "        # Classify\n",
    "        results = classify_image(img)\n",
    "        \n",
    "        # Show predictions\n",
    "        print(\"\\nüéØ Top 5 Predictions:\")\n",
    "        for rank, (label, confidence) in enumerate(results, 1):\n",
    "            # Create a visual bar\n",
    "            bar_length = int(confidence * 50)\n",
    "            bar = \"‚ñà\" * bar_length\n",
    "            \n",
    "            print(f\"  {rank}. {label:20s} {confidence*100:5.2f}% {bar}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‡§ö‡§∞‡§£ ‡•´: ‡§Ü‡§´‡•ç‡§®‡•à ‡§§‡§∏‡•ç‡§µ‡•Ä‡§∞‡§π‡§∞‡•Ç ‡§™‡•ç‡§∞‡§Ø‡§æ‡§∏ ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç!\n",
    "\n",
    "‡§§‡§≤‡§ï‡•ã URL ‡§≤‡§æ‡§à ‡§§‡§™‡§æ‡§à‡§Ç ‡§µ‡§∞‡•ç‡§ó‡•Ä‡§ï‡§∞‡§£ ‡§ó‡§∞‡•ç‡§® ‡§ö‡§æ‡§π‡§®‡•Å‡§≠‡§è‡§ï‡•ã ‡§ï‡•Å‡§®‡•à ‡§™‡§®‡§ø ‡§§‡§∏‡•ç‡§µ‡•Ä‡§∞‡§ï‡•ã URL ‡§∏‡§Å‡§ó ‡§¨‡§¶‡§≤‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç‡•§\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try your own image!\n",
    "# Replace this URL with any image URL\n",
    "custom_image_url = \"https://images.unsplash.com/photo-1472491235688-bdc81a63246e?w=400\"  # A flower\n",
    "\n",
    "print(\"üñºÔ∏è  Classifying your custom image...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    # Load and show image\n",
    "    img = load_image_from_url(custom_image_url)\n",
    "    display(img.resize((300, 300)))\n",
    "    \n",
    "    # Classify\n",
    "    results = classify_image(img)\n",
    "    \n",
    "    # Show results\n",
    "    print(\"\\nüéØ Top 5 Predictions:\")\n",
    "    print(\"-\" * 70)\n",
    "    for rank, (label, confidence) in enumerate(results, 1):\n",
    "        bar_length = int(confidence * 50)\n",
    "        bar = \"‚ñà\" * bar_length\n",
    "        print(f\"  {rank}. {label:20s} {confidence*100:5.2f}% {bar}\")\n",
    "    \n",
    "    # Highlight top prediction\n",
    "    top_label, top_confidence = results[0]\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"\\nüèÜ Best guess: {top_label} ({top_confidence*100:.2f}% confident)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    print(\"   Make sure the URL points to a valid image!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° ‡§ï‡•á ‡§≠‡§Ø‡•ã?\n",
    "\n",
    "1. **‡§π‡§æ‡§Æ‡•Ä‡§≤‡•á ‡§™‡•ç‡§∞‡§ø-‡§ü‡•ç‡§∞‡•á‡§® ‡§ó‡§∞‡§ø‡§è‡§ï‡•ã ‡§Æ‡•ã‡§°‡•á‡§≤ ‡§≤‡•ã‡§° ‡§ó‡§∞‡•ç‡§Ø‡•å‡§Ç** - MobileNetV2 ‡§≤‡§æ‡§ñ‡•å‡§Ç ‡§§‡§∏‡•ç‡§¨‡§ø‡§∞‡§π‡§∞‡•Ç‡§Æ‡§æ ‡§™‡•ç‡§∞‡§∂‡§ø‡§ï‡•ç‡§∑‡§ø‡§§ ‡§ó‡§∞‡§ø‡§è‡§ï‡•ã ‡§•‡§ø‡§Ø‡•ã  \n",
    "2. **‡§π‡§æ‡§Æ‡•Ä‡§≤‡•á ‡§§‡§∏‡•ç‡§¨‡§ø‡§∞‡§π‡§∞‡•Ç ‡§™‡•ç‡§∞‡§ø-‡§™‡•ç‡§∞‡•ã‡§∏‡•á‡§∏ ‡§ó‡§∞‡•ç‡§Ø‡•å‡§Ç** - ‡§Æ‡•ã‡§°‡•á‡§≤‡§ï‡§æ ‡§≤‡§æ‡§ó‡§ø ‡§Ü‡§ï‡§æ‡§∞ ‡§™‡§∞‡§ø‡§µ‡§∞‡•ç‡§§‡§® ‡§ó‡§∞‡§ø‡§Ø‡•ã ‡§∞ ‡§´‡§∞‡•ç‡§Æ‡•ç‡§Ø‡§æ‡§ü ‡§ó‡§∞‡§ø‡§Ø‡•ã  \n",
    "3. **‡§Æ‡•ã‡§°‡•á‡§≤‡§≤‡•á ‡§≠‡§µ‡§ø‡§∑‡•ç‡§Ø‡§µ‡§æ‡§£‡•Ä ‡§ó‡§∞‡•ç‡§Ø‡•ã** - ‡§Ø‡§∏‡§≤‡•á 1000 ‡§µ‡§∏‡•ç‡§§‡•Å ‡§µ‡§∞‡•ç‡§ó‡§π‡§∞‡•Ç‡§ï‡•ã ‡§≤‡§æ‡§ó‡§ø ‡§∏‡§Æ‡•ç‡§≠‡§æ‡§µ‡§®‡§æ‡§π‡§∞‡•Ç ‡§â‡§§‡•ç‡§™‡§æ‡§¶‡§® ‡§ó‡§∞‡•ç‡§Ø‡•ã  \n",
    "4. **‡§π‡§æ‡§Æ‡•Ä‡§≤‡•á ‡§®‡§§‡§ø‡§ú‡§æ ‡§°‡§ø‡§ï‡•ã‡§° ‡§ó‡§∞‡•ç‡§Ø‡•å‡§Ç** - ‡§∏‡§Ç‡§ñ‡•ç‡§Ø‡§æ‡§π‡§∞‡•Ç‡§≤‡§æ‡§à ‡§Æ‡§æ‡§®‡§µ‡§≤‡•á ‡§¨‡•Å‡§ù‡•ç‡§® ‡§∏‡§ï‡§ø‡§®‡•á ‡§≤‡•á‡§¨‡§≤‡§Æ‡§æ ‡§™‡§∞‡§ø‡§µ‡§∞‡•ç‡§§‡§® ‡§ó‡§∞‡§ø‡§Ø‡•ã  \n",
    "\n",
    "### ‡§µ‡§ø‡§∂‡•ç‡§µ‡§æ‡§∏ ‡§∏‡•ç‡§ï‡•ã‡§∞ ‡§¨‡•Å‡§ù‡•ç‡§¶‡•à\n",
    "\n",
    "- **‡•Ø‡•¶-‡•ß‡•¶‡•¶%**: ‡§ß‡•á‡§∞‡•à ‡§µ‡§ø‡§∂‡•ç‡§µ‡§∏‡•ç‡§§ (‡§≤‡§ó‡§≠‡§ó ‡§™‡§ï‡•ç‡§ï‡§æ ‡§∏‡§π‡•Ä)  \n",
    "- **‡•≠‡•¶-‡•Ø‡•¶%**: ‡§µ‡§ø‡§∂‡•ç‡§µ‡§∏‡•ç‡§§ (‡§∏‡§æ‡§Ø‡§¶ ‡§∏‡§π‡•Ä)  \n",
    "- **‡•´‡•¶-‡•≠‡•¶%**: ‡§ï‡•á‡§π‡•Ä ‡§π‡§¶‡§∏‡§Æ‡•ç‡§Æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§∏‡•ç‡§§ (‡§∏‡§π‡•Ä ‡§π‡•Å‡§® ‡§∏‡§ï‡•ç‡§õ)  \n",
    "- **‡•´‡•¶% ‡§≠‡§®‡•ç‡§¶‡§æ ‡§ï‡§Æ**: ‡§ß‡•á‡§∞‡•à ‡§µ‡§ø‡§∂‡•ç‡§µ‡§∏‡•ç‡§§ ‡§õ‡•à‡§® (‡§Ö‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§)  \n",
    "\n",
    "### ‡§ï‡§ø‡§® ‡§≠‡§µ‡§ø‡§∑‡•ç‡§Ø‡§µ‡§æ‡§£‡•Ä‡§π‡§∞‡•Ç ‡§ó‡§≤‡§§ ‡§π‡•Å‡§® ‡§∏‡§ï‡•ç‡§õ‡§®‡•ç?\n",
    "\n",
    "- **‡§Ö‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§ï‡•ã‡§£ ‡§µ‡§æ ‡§™‡•ç‡§∞‡§ï‡§æ‡§∂** - ‡§Æ‡•ã‡§°‡•á‡§≤ ‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§§‡§∏‡•ç‡§¨‡§ø‡§∞‡§π‡§∞‡•Ç‡§Æ‡§æ ‡§™‡•ç‡§∞‡§∂‡§ø‡§ï‡•ç‡§∑‡§ø‡§§ ‡§ó‡§∞‡§ø‡§è‡§ï‡•ã ‡§•‡§ø‡§Ø‡•ã  \n",
    "- **‡§ß‡•á‡§∞‡•à ‡§µ‡§∏‡•ç‡§§‡•Å‡§π‡§∞‡•Ç** - ‡§Æ‡•ã‡§°‡•á‡§≤‡§≤‡•á ‡§è‡§ï ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§µ‡§∏‡•ç‡§§‡•Å ‡§Ö‡§™‡•á‡§ï‡•ç‡§∑‡§æ ‡§ó‡§∞‡•ç‡§õ  \n",
    "- **‡§¶‡•Å‡§∞‡•ç‡§≤‡§≠ ‡§µ‡§∏‡•ç‡§§‡•Å‡§π‡§∞‡•Ç** - ‡§Æ‡•ã‡§°‡•á‡§≤‡§≤‡•á ‡§ï‡•á‡§µ‡§≤ 1000 ‡§µ‡§∞‡•ç‡§ó‡§π‡§∞‡•Ç ‡§Æ‡§æ‡§§‡•ç‡§∞ ‡§ö‡§ø‡§®‡•ç‡§õ  \n",
    "- **‡§ï‡§Æ ‡§ó‡•Å‡§£‡§∏‡•ç‡§§‡§∞‡§ï‡•ã ‡§§‡§∏‡•ç‡§¨‡§ø‡§∞** - ‡§ß‡§Æ‡§ø‡§≤‡•ã ‡§µ‡§æ ‡§™‡§ø‡§ï‡•ç‡§∏‡•á‡§≤‡•á‡§ü‡•á‡§° ‡§§‡§∏‡•ç‡§¨‡§ø‡§∞‡§π‡§∞‡•Ç ‡§ï‡§†‡§ø‡§® ‡§π‡•Å‡§®‡•ç‡§õ‡§®‡•ç  \n",
    "\n",
    "---  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ ‡§Ü‡§ó‡§æ‡§Æ‡•Ä ‡§ï‡§¶‡§Æ‡§π‡§∞‡•Ç\n",
    "\n",
    "1. **‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§§‡§∏‡•ç‡§¨‡§ø‡§∞‡§π‡§∞‡•Ç ‡§™‡•ç‡§∞‡§Ø‡§æ‡§∏ ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç:**\n",
    "   - [Unsplash](https://unsplash.com) ‡§Æ‡§æ ‡§§‡§∏‡•ç‡§¨‡§ø‡§∞‡§π‡§∞‡•Ç ‡§ñ‡•ã‡§ú‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç\n",
    "   - ‡§¶‡§æ‡§Ø‡§æ‡§Å-‡§ï‡•ç‡§≤‡§ø‡§ï ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç ‚Üí \"Copy image address\" ‡§ó‡§∞‡•á‡§∞ URL ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç\n",
    "\n",
    "2. **‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§£ ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç:**\n",
    "   - ‡§Ö‡§Æ‡•Ç‡§∞‡•ç‡§§ ‡§ï‡§≤‡§æ‡§∏‡§Å‡§ó ‡§ï‡•á ‡§π‡•Å‡§®‡•ç‡§õ?\n",
    "   - ‡§ï‡•á ‡§Ø‡§∏‡§≤‡•á ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§ï‡•ã‡§£‡§¨‡§æ‡§ü ‡§µ‡§∏‡•ç‡§§‡•Å‡§π‡§∞‡•Ç ‡§ö‡§ø‡§®‡•ç‡§® ‡§∏‡§ï‡•ç‡§õ?\n",
    "   - ‡§Ø‡§∏‡§≤‡•á ‡§ß‡•á‡§∞‡•à ‡§µ‡§∏‡•ç‡§§‡•Å‡§π‡§∞‡•Ç‡§≤‡§æ‡§à ‡§ï‡§∏‡§∞‡•Ä ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§æ‡§™‡§® ‡§ó‡§∞‡•ç‡§õ?\n",
    "\n",
    "3. **‡§•‡§™ ‡§ú‡§æ‡§®‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç:**\n",
    "   - [Computer Vision ‡§™‡§æ‡§†‡§π‡§∞‡•Ç](../lessons/4-ComputerVision/README.md) ‡§Ö‡§®‡•ç‡§µ‡•á‡§∑‡§£ ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç\n",
    "   - ‡§Ü‡§´‡•ç‡§®‡•ã ‡§§‡§∏‡•ç‡§¨‡§ø‡§∞ ‡§µ‡§∞‡•ç‡§ó‡•Ä‡§ï‡§∞‡§£‡§ï‡§∞‡•ç‡§§‡§æ ‡§™‡•ç‡§∞‡§∂‡§ø‡§ï‡•ç‡§∑‡§£ ‡§ó‡§∞‡•ç‡§® ‡§∏‡§ø‡§ï‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç\n",
    "   - CNNs (Convolutional Neural Networks) ‡§ï‡§∏‡§∞‡•Ä ‡§ï‡§æ‡§Æ ‡§ó‡§∞‡•ç‡§õ‡§®‡•ç ‡§¨‡•Å‡§ù‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ ‡§¨‡§ß‡§æ‡§à ‡§õ!\n",
    "\n",
    "‡§§‡§™‡§æ‡§à‡§Ç‡§≤‡•á ‡§Ö‡§§‡•ç‡§Ø‡§æ‡§ß‡•Å‡§®‡§ø‡§ï ‡§®‡•ç‡§Ø‡•Ç‡§∞‡§≤ ‡§®‡•á‡§ü‡§µ‡§∞‡•ç‡§ï ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ó‡§∞‡•á‡§∞ ‡§§‡§∏‡•ç‡§¨‡§ø‡§∞ ‡§µ‡§∞‡•ç‡§ó‡•Ä‡§ï‡§∞‡§£‡§ï‡§∞‡•ç‡§§‡§æ ‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§£ ‡§ó‡§∞‡•ç‡§®‡•Å‡§≠‡§Ø‡•ã!\n",
    "\n",
    "‡§Ø‡§π‡•Ä ‡§™‡•ç‡§∞‡§µ‡§ø‡§ß‡§ø‡§≤‡•á ‡§®‡§ø‡§Æ‡•ç‡§®‡§≤‡§æ‡§à ‡§∂‡§ï‡•ç‡§§‡§ø ‡§¶‡§ø‡§®‡•ç‡§õ:\n",
    "- Google Photos (‡§§‡§™‡§æ‡§à‡§Ç‡§ï‡§æ ‡§§‡§∏‡•ç‡§¨‡§ø‡§∞‡§π‡§∞‡•Ç ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§ø‡§§ ‡§ó‡§∞‡•ç‡§¶‡•à)\n",
    "- ‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ ‡§ï‡§æ‡§∞‡§π‡§∞‡•Ç (‡§µ‡§∏‡•ç‡§§‡•Å‡§π‡§∞‡•Ç ‡§ö‡§ø‡§®‡•ç‡§¶‡•à)\n",
    "- ‡§ö‡§ø‡§ï‡§ø‡§§‡•ç‡§∏‡§æ ‡§®‡§ø‡§¶‡§æ‡§® (X-rays ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§ó‡§∞‡•ç‡§¶‡•à)\n",
    "- ‡§ó‡•Å‡§£‡§∏‡•ç‡§§‡§∞ ‡§®‡§ø‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§£ (‡§§‡•ç‡§∞‡•Å‡§ü‡§ø‡§π‡§∞‡•Ç ‡§™‡§§‡•ç‡§§‡§æ ‡§≤‡§ó‡§æ‡§â‡§Å‡§¶‡•à)\n",
    "\n",
    "‡§Ö‡§®‡•ç‡§µ‡•á‡§∑‡§£ ‡§∞ ‡§∏‡§ø‡§ï‡§æ‡§á ‡§ú‡§æ‡§∞‡•Ä ‡§∞‡§æ‡§ñ‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç! üöÄ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**‡§Ö‡§∏‡•ç‡§µ‡•Ä‡§ï‡§∞‡§£**:  \n‡§Ø‡•ã ‡§¶‡§∏‡•ç‡§§‡§æ‡§µ‡•á‡§ú‡§º AI ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶ ‡§∏‡•á‡§µ‡§æ [Co-op Translator](https://github.com/Azure/co-op-translator) ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ó‡§∞‡•Ä ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶ ‡§ó‡§∞‡§ø‡§è‡§ï‡•ã ‡§π‡•ã‡•§ ‡§π‡§æ‡§Æ‡•Ä ‡§Ø‡§•‡§æ‡§∏‡§Æ‡•ç‡§≠‡§µ ‡§∏‡§ü‡•Ä‡§ï‡§§‡§æ ‡§∏‡•Å‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§ó‡§∞‡•ç‡§® ‡§™‡•ç‡§∞‡§Ø‡§æ‡§∏ ‡§ó‡§∞‡•ç‡§õ‡•å‡§Ç, ‡§§‡§∞ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§ß‡•ç‡§Ø‡§æ‡§® ‡§¶‡§ø‡§®‡•Å‡§π‡•ã‡§∏‡•ç ‡§ï‡§ø ‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶‡§π‡§∞‡•Ç‡§Æ‡§æ ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø‡§π‡§∞‡•Ç ‡§µ‡§æ ‡§Ö‡§∂‡•Å‡§¶‡•ç‡§ß‡§§‡§æ‡§π‡§∞‡•Ç ‡§π‡•Å‡§® ‡§∏‡§ï‡•ç‡§õ‡§®‡•ç‡•§ ‡§Ø‡§∏‡§ï‡•ã ‡§Æ‡•Ç‡§≤ ‡§≠‡§æ‡§∑‡§æ‡§Æ‡§æ ‡§∞‡§π‡•á‡§ï‡•ã ‡§Æ‡•Ç‡§≤ ‡§¶‡§∏‡•ç‡§§‡§æ‡§µ‡•á‡§ú‡§º‡§≤‡§æ‡§à ‡§Ü‡§ß‡§ø‡§ï‡§æ‡§∞‡§ø‡§ï ‡§∏‡•ç‡§∞‡•ã‡§§ ‡§Æ‡§æ‡§®‡§ø‡§®‡•Å‡§™‡§∞‡•ç‡§õ‡•§ ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä‡§ï‡§æ ‡§≤‡§æ‡§ó‡§ø, ‡§µ‡•ç‡§Ø‡§æ‡§µ‡§∏‡§æ‡§Ø‡§ø‡§ï ‡§Æ‡§æ‡§®‡§µ ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶ ‡§∏‡§ø‡§´‡§æ‡§∞‡§ø‡§∏ ‡§ó‡§∞‡§ø‡§®‡•ç‡§õ‡•§ ‡§Ø‡§∏ ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶‡§ï‡•ã ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡§¨‡§æ‡§ü ‡§â‡§§‡•ç‡§™‡§®‡•ç‡§® ‡§ï‡•Å‡§®‡•à ‡§™‡§®‡§ø ‡§ó‡§≤‡§§‡§´‡§π‡§Æ‡•Ä ‡§µ‡§æ ‡§ó‡§≤‡§§ ‡§µ‡•ç‡§Ø‡§æ‡§ñ‡•ç‡§Ø‡§æ‡§ï‡•ã ‡§≤‡§æ‡§ó‡§ø ‡§π‡§æ‡§Æ‡•Ä ‡§ú‡§ø‡§Æ‡•ç‡§Æ‡•á‡§µ‡§æ‡§∞ ‡§π‡•Å‡§®‡•á ‡§õ‡•à‡§®‡•å‡§Ç‡•§\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "coopTranslator": {
   "original_hash": "1d472141d9df46b751542b3c29f88677",
   "translation_date": "2025-10-03T11:43:07+00:00",
   "source_file": "examples/03-image-classifier.ipynb",
   "language_code": "ne"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}