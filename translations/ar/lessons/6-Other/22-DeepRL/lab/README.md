<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7bd8dc72040e98e35e7225e34058cd4e",
  "translation_date": "2025-08-26T10:16:23+00:00",
  "source_file": "lessons/6-Other/22-DeepRL/lab/README.md",
  "language_code": "ar"
}
-->
## البيئة

يتكون بيئة Mountain Car من سيارة محاصرة داخل وادٍ. هدفك هو القفز خارج الوادي والوصول إلى العلم. الإجراءات التي يمكنك القيام بها هي التسارع إلى اليسار، أو إلى اليمين، أو عدم القيام بأي شيء. يمكنك مراقبة موقع السيارة على المحور x، وسرعتها.

## بدء الدفتر

ابدأ المختبر بفتح [MountainCar.ipynb](../../../../../../lessons/6-Other/22-DeepRL/lab/MountainCar.ipynb)

## الفائدة المستخلصة

يجب أن تتعلم خلال هذا المختبر أن تبني خوارزميات التعلم المعزز (RL) لبيئة جديدة غالبًا ما يكون بسيطًا جدًا، لأن OpenAI Gym لديه نفس الواجهة لجميع البيئات، والخوارزميات بشكل عام لا تعتمد بشكل كبير على طبيعة البيئة. يمكنك حتى إعادة هيكلة كود Python بطريقة تسمح بتمرير أي بيئة إلى خوارزمية التعلم المعزز كمعامل.

**إخلاء المسؤولية**:  
تم ترجمة هذا المستند باستخدام خدمة الترجمة بالذكاء الاصطناعي [Co-op Translator](https://github.com/Azure/co-op-translator). بينما نسعى لتحقيق الدقة، يرجى العلم أن الترجمات الآلية قد تحتوي على أخطاء أو معلومات غير دقيقة. يجب اعتبار المستند الأصلي بلغته الأصلية المصدر الموثوق. للحصول على معلومات حاسمة، يُوصى بالاستعانة بترجمة بشرية احترافية. نحن غير مسؤولين عن أي سوء فهم أو تفسيرات خاطئة تنشأ عن استخدام هذه الترجمة.