<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6522312ff835796ca34136a9462fafb2",
  "translation_date": "2025-09-23T09:35:57+00:00",
  "source_file": "lessons/5-NLP/19-NER/README.md",
  "language_code": "da"
}
-->
# Navngiven Enhedsgenkendelse

Indtil nu har vi prim√¶rt fokuseret p√• √©n NLP-opgave - klassifikation. Men der findes ogs√• andre NLP-opgaver, som kan l√∏ses med neurale netv√¶rk. En af disse opgaver er **[Navngiven Enhedsgenkendelse](https://wikipedia.org/wiki/Named-entity_recognition)** (NER), som handler om at genkende specifikke enheder i tekst, s√•som steder, personnavne, dato-tidsintervaller, kemiske formler og s√• videre.

## [Quiz f√∏r lektionen](https://ff-quizzes.netlify.app/en/ai/quiz/37)

## Eksempel p√• brug af NER

Forestil dig, at du vil udvikle en chatbot, der fungerer som Amazon Alexa eller Google Assistant. Intelligente chatbots arbejder ved at *forst√•*, hvad brugeren √∏nsker, ved at udf√∏re tekstklassifikation p√• den indtastede s√¶tning. Resultatet af denne klassifikation kaldes **intent**, som afg√∏r, hvad chatbotten skal g√∏re.

<img alt="Bot NER" src="images/bot-ner.png" width="50%"/>

> Billede af forfatteren

Men en bruger kan ogs√• angive nogle parametre som en del af s√¶tningen. For eksempel, n√•r hun sp√∏rger om vejret, kan hun specificere en lokation eller dato. En bot skal kunne forst√• disse enheder og udfylde parameterfelterne korrekt, f√∏r den udf√∏rer handlingen. Det er pr√¶cis her, NER kommer ind i billedet.

> ‚úÖ Et andet eksempel kunne v√¶re [analyse af videnskabelige medicinske artikler](https://soshnikov.com/science/analyzing-medical-papers-with-azure-and-text-analytics-for-health/). En af de vigtigste ting, vi skal kigge efter, er specifikke medicinske termer, s√•som sygdomme og medicinske stoffer. Mens et lille antal sygdomme sandsynligvis kan udtr√¶kkes ved hj√¶lp af substring-s√∏gning, kr√¶ver mere komplekse enheder, s√•som kemiske forbindelser og medicinnavne, en mere avanceret tilgang.

## NER som Tokenklassifikation

NER-modeller er i bund og grund **tokenklassifikationsmodeller**, fordi vi for hver af input-tokens skal afg√∏re, om den tilh√∏rer en enhed eller ej, og hvis den g√∏r - hvilken enhedsklasse den tilh√∏rer.

Overvej f√∏lgende titel p√• en artikel:

**Tricuspidalklap-regurgitation** og **lithiumcarbonat** **toksicitet** hos et nyf√∏dt sp√¶dbarn.

Enhederne her er:

* Tricuspidalklap-regurgitation er en sygdom (`DIS`)
* Lithiumcarbonat er et kemisk stof (`CHEM`)
* Toksicitet er ogs√• en sygdom (`DIS`)

Bem√¶rk, at √©n enhed kan str√¶kke sig over flere tokens. Og som i dette tilf√¶lde skal vi skelne mellem to p√• hinanden f√∏lgende enheder. Derfor er det almindeligt at bruge to klasser for hver enhed - √©n, der angiver det f√∏rste token i enheden (ofte bruges pr√¶fikset `B-` for **b**egyndelse), og en anden for forts√¶ttelsen af en enhed (`I-`, for **i**ndre token). Vi bruger ogs√• `O` som en klasse til at repr√¶sentere alle **o**vrige tokens. Denne form for tokenm√¶rkning kaldes [BIO-m√¶rkning](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)) (eller IOB). N√•r det er m√¶rket, vil vores titel se s√•dan ud:

Token | Tag
------|-----
Tricuspidalklap | B-DIS
regurgitation | I-DIS
og | O
lithium | B-CHEM
carbonat | I-CHEM
toksicitet | B-DIS
hos | O
et | O
nyf√∏dt | O
sp√¶dbarn | O
. | O

Da vi skal opbygge en √©n-til-√©n-korrespondance mellem tokens og klasser, kan vi tr√¶ne en h√∏jreorienteret **mange-til-mange** neuralt netv√¶rksmodel fra dette billede:

![Billede, der viser almindelige m√∏nstre for rekurrente neurale netv√¶rk.](../../../../../translated_images/unreasonable-effectiveness-of-rnn.541ead816778f42dce6c42d8a56c184729aa2378d059b851be4ce12b993033df.da.jpg)

> *Billede fra [denne blogpost](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) af [Andrej Karpathy](http://karpathy.github.io/). NER-tokenklassifikationsmodeller svarer til den h√∏jreorienterede netv√¶rksarkitektur p√• dette billede.*

## Tr√¶ning af NER-modeller

Da en NER-model i bund og grund er en tokenklassifikationsmodel, kan vi bruge RNN'er, som vi allerede er bekendt med, til denne opgave. I dette tilf√¶lde vil hver blok af det rekurrente netv√¶rk returnere token-ID'et. Den f√∏lgende eksempel-notebook viser, hvordan man tr√¶ner LSTM til tokenklassifikation.

## ‚úçÔ∏è Eksempel-notebooks: NER

Forts√¶t din l√¶ring i den f√∏lgende notebook:

* [NER med TensorFlow](NER-TF.ipynb)

## Konklusion

En NER-model er en **tokenklassifikationsmodel**, hvilket betyder, at den kan bruges til at udf√∏re tokenklassifikation. Dette er en meget almindelig opgave inden for NLP, som hj√¶lper med at genkende specifikke enheder i tekst, herunder steder, navne, datoer og mere.

## üöÄ Udfordring

Fuldf√∏r opgaven, der er linket nedenfor, for at tr√¶ne en model til navngiven enhedsgenkendelse af medicinske termer, og pr√∏v den derefter p√• et andet datas√¶t.

## [Quiz efter lektionen](https://ff-quizzes.netlify.app/en/ai/quiz/38)

## Gennemgang & Selvstudie

L√¶s blogindl√¶gget [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) og f√∏lg med i afsnittet om yderligere l√¶sning i den artikel for at uddybe din viden.

## [Opgave](lab/README.md)

I opgaven for denne lektion skal du tr√¶ne en model til genkendelse af medicinske enheder. Du kan starte med at tr√¶ne en LSTM-model som beskrevet i denne lektion og derefter forts√¶tte med at bruge BERT-transformermodel. L√¶s [instruktionerne](lab/README.md) for at f√• alle detaljer.

---

