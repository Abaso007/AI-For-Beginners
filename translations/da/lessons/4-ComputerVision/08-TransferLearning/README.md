<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "717775c4050ccbffbe0c961ad8bf7bf7",
  "translation_date": "2025-08-28T15:14:57+00:00",
  "source_file": "lessons/4-ComputerVision/08-TransferLearning/README.md",
  "language_code": "da"
}
-->
# Forudtr√¶nede netv√¶rk og transfer learning

Tr√¶ning af CNN'er kan tage meget tid, og der kr√¶ves en stor m√¶ngde data til denne opgave. Meget af tiden bruges dog p√• at l√¶re de bedste lavniveaufiltre, som et netv√¶rk kan bruge til at udtr√¶kke m√∏nstre fra billeder. Et naturligt sp√∏rgsm√•l opst√•r - kan vi bruge et neuralt netv√¶rk, der er tr√¶net p√• √©n datas√¶t, og tilpasse det til at klassificere forskellige billeder uden at kr√¶ve en fuld tr√¶ningsproces?

## [Pre-lecture quiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/108)

Denne tilgang kaldes **transfer learning**, fordi vi overf√∏rer noget viden fra √©n neuralt netv√¶rksmodel til en anden. I transfer learning starter vi typisk med en forudtr√¶net model, som er blevet tr√¶net p√• et stort billeddatas√¶t, s√•som **ImageNet**. Disse modeller kan allerede g√∏re et godt stykke arbejde med at udtr√¶kke forskellige funktioner fra generiske billeder, og i mange tilf√¶lde kan det give gode resultater blot at bygge en klassifikator oven p√• de udtrukne funktioner.

> ‚úÖ Transfer learning er et begreb, du ogs√• finder i andre akademiske felter, s√•som uddannelse. Det refererer til processen med at tage viden fra √©t omr√•de og anvende det p√• et andet.

## Forudtr√¶nede modeller som feature-ekstraktorer

De konvolutionelle netv√¶rk, vi har talt om i det foreg√•ende afsnit, indeholder en r√¶kke lag, som hver is√¶r skal udtr√¶kke nogle funktioner fra billedet, startende med lavniveau pixelkombinationer (s√•som horisontale/vertikale linjer eller streger) og op til h√∏jere niveau kombinationer af funktioner, der svarer til ting som et √∏je eller en flamme. Hvis vi tr√¶ner CNN p√• et tilstr√¶kkeligt stort datas√¶t af generiske og diverse billeder, b√∏r netv√¶rket l√¶re at udtr√¶kke disse f√¶lles funktioner.

B√•de Keras og PyTorch indeholder funktioner til nemt at indl√¶se forudtr√¶nede neurale netv√¶rksv√¶gte for nogle almindelige arkitekturer, hvoraf de fleste er tr√¶net p√• ImageNet-billeder. De mest anvendte er beskrevet p√• siden [CNN Architectures](../07-ConvNets/CNN_Architectures.md) fra den tidligere lektion. Is√¶r kan du overveje at bruge en af f√∏lgende:

* **VGG-16/VGG-19**, som er relativt simple modeller, der stadig giver god n√∏jagtighed. Ofte er det en god id√© at starte med VGG for at se, hvordan transfer learning fungerer.
* **ResNet** er en familie af modeller foresl√•et af Microsoft Research i 2015. De har flere lag og kr√¶ver derfor flere ressourcer.
* **MobileNet** er en familie af modeller med reduceret st√∏rrelse, velegnet til mobile enheder. Brug dem, hvis du har begr√¶nsede ressourcer og kan ofre lidt n√∏jagtighed.

Her er eksempler p√• funktioner udtrukket fra et billede af en kat af VGG-16-netv√¶rket:

![Features extracted by VGG-16](../../../../../translated_images/features.6291f9c7ba3a0b951af88fc9864632b9115365410765680680d30c927dd67354.da.png)

## Cats vs. Dogs Dataset

I dette eksempel vil vi bruge et datas√¶t med [Cats and Dogs](https://www.microsoft.com/download/details.aspx?id=54765&WT.mc_id=academic-77998-cacaste), som er meget t√¶t p√• et virkelighedsn√¶rt billedklassifikationsscenarie.

## ‚úçÔ∏è √òvelse: Transfer Learning

Lad os se transfer learning i aktion i de tilsvarende notebooks:

* [Transfer Learning - PyTorch](TransferLearningPyTorch.ipynb)
* [Transfer Learning - TensorFlow](TransferLearningTF.ipynb)

## Visualisering af Adversarial Cat

Et forudtr√¶net neuralt netv√¶rk indeholder forskellige m√∏nstre i sin *hjerne*, inklusive forestillinger om **den ideelle kat** (s√•vel som den ideelle hund, den ideelle zebra osv.). Det kunne v√¶re interessant p√• en eller anden m√•de at **visualisere dette billede**. Det er dog ikke simpelt, fordi m√∏nstrene er spredt over netv√¶rkets v√¶gte og ogs√• organiseret i en hierarkisk struktur.

En tilgang, vi kan tage, er at starte med et tilf√¶ldigt billede og derefter fors√∏ge at bruge **gradient descent optimering** til at justere det billede p√• en s√•dan m√•de, at netv√¶rket begynder at tro, at det er en kat.

![Image Optimization Loop](../../../../../translated_images/ideal-cat-loop.999fbb8ff306e044f997032f4eef9152b453e6a990e449bbfb107de2493cc37e.da.png)

Men hvis vi g√∏r dette, vil vi modtage noget, der ligner tilf√¶ldig st√∏j. Dette skyldes, at *der er mange m√•der at f√• netv√¶rket til at tro, at inputbilledet er en kat*, inklusive nogle, der ikke giver mening visuelt. Selvom disse billeder indeholder mange m√∏nstre, der er typiske for en kat, er der intet, der begr√¶nser dem til at v√¶re visuelt genkendelige.

For at forbedre resultatet kan vi tilf√∏je et andet led til tab-funktionen, som kaldes **variation loss**. Det er en metric, der viser, hvor ens nabopixels i billedet er. Ved at minimere variation loss bliver billedet glattere og fjerner st√∏j - hvilket afsl√∏rer mere visuelt tiltalende m√∏nstre. Her er et eksempel p√• s√•danne "ideelle" billeder, der klassificeres som kat og zebra med h√∏j sandsynlighed:

![Ideal Cat](../../../../../translated_images/ideal-cat.203dd4597643d6b0bd73038b87f9c0464322725e3a06ab145d25d4a861c70592.da.png) | ![Ideal Zebra](../../../../../translated_images/ideal-zebra.7f70e8b54ee15a7a314000bb5df38a6cfe086ea04d60df4d3ef313d046b98a2b.da.png)
-----|-----
 *Ideel kat* | *Ideel zebra*

En lignende tilgang kan bruges til at udf√∏re s√•kaldte **adversarial attacks** p√• et neuralt netv√¶rk. Antag, at vi vil narre et neuralt netv√¶rk og f√• en hund til at ligne en kat. Hvis vi tager et billede af en hund, som netv√¶rket genkender som en hund, kan vi derefter justere det lidt ved hj√¶lp af gradient descent optimering, indtil netv√¶rket begynder at klassificere det som en kat:

![Picture of a Dog](../../../../../translated_images/original-dog.8f68a67d2fe0911f33041c0f7fce8aa4ea919f9d3917ec4b468298522aeb6356.da.png) | ![Picture of a dog classified as a cat](../../../../../translated_images/adversarial-dog.d9fc7773b0142b89752539bfbf884118de845b3851c5162146ea0b8809fc820f.da.png)
-----|-----
*Originalt billede af en hund* | *Billede af en hund klassificeret som en kat*

Se koden for at genskabe resultaterne ovenfor i f√∏lgende notebook:

* [Ideal and Adversarial Cat - TensorFlow](AdversarialCat_TF.ipynb)

## Konklusion

Ved hj√¶lp af transfer learning kan du hurtigt sammens√¶tte en klassifikator til en brugerdefineret objektklassifikationsopgave og opn√• h√∏j n√∏jagtighed. Du kan se, at mere komplekse opgaver, som vi l√∏ser nu, kr√¶ver h√∏jere computerkraft og ikke let kan l√∏ses p√• CPU'en. I den n√¶ste enhed vil vi fors√∏ge at bruge en mere letv√¶gtsimplementering til at tr√¶ne den samme model ved hj√¶lp af lavere computerressourcer, hvilket resulterer i kun lidt lavere n√∏jagtighed.

## üöÄ Udfordring

I de medf√∏lgende notebooks er der noter nederst om, hvordan transfer learning fungerer bedst med nogenlunde lignende tr√¶ningsdata (m√•ske en ny type dyr). Lav nogle eksperimenter med helt nye typer billeder for at se, hvor godt eller d√•rligt dine transfer learning-modeller klarer sig.

## [Post-lecture quiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/208)

## Gennemgang & Selvstudie

L√¶s [TrainingTricks.md](TrainingTricks.md) for at uddybe din viden om andre m√•der at tr√¶ne dine modeller p√•.

## [Opgave](lab/README.md)

I denne lab vil vi bruge det virkelighedsn√¶re [Oxford-IIIT](https://www.robots.ox.ac.uk/~vgg/data/pets/) pets datas√¶t med 35 racer af katte og hunde, og vi vil bygge en transfer learning klassifikator.

---

**Ansvarsfraskrivelse**:  
Dette dokument er blevet oversat ved hj√¶lp af AI-overs√¶ttelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selvom vi bestr√¶ber os p√• at opn√• n√∏jagtighed, skal du v√¶re opm√¶rksom p√•, at automatiserede overs√¶ttelser kan indeholde fejl eller un√∏jagtigheder. Det originale dokument p√• dets oprindelige sprog b√∏r betragtes som den autoritative kilde. For kritisk information anbefales professionel menneskelig overs√¶ttelse. Vi er ikke ansvarlige for eventuelle misforst√•elser eller fejltolkninger, der m√•tte opst√• som f√∏lge af brugen af denne overs√¶ttelse.