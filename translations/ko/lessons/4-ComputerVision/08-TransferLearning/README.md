<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "717775c4050ccbffbe0c961ad8bf7bf7",
  "translation_date": "2025-08-24T21:31:08+00:00",
  "source_file": "lessons/4-ComputerVision/08-TransferLearning/README.md",
  "language_code": "ko"
}
-->
# 사전 학습된 네트워크와 전이 학습

CNN을 훈련시키는 데는 많은 시간이 걸리며, 이를 위해 많은 데이터가 필요합니다. 하지만 대부분의 시간은 네트워크가 이미지를 통해 패턴을 추출할 수 있는 최적의 저수준 필터를 학습하는 데 소비됩니다. 여기서 자연스럽게 이런 질문이 떠오릅니다. 한 데이터셋에서 훈련된 신경망을 사용하여 완전한 훈련 과정 없이 다른 이미지를 분류하도록 적응시킬 수 있을까요?

## [사전 강의 퀴즈](https://ff-quizzes.netlify.app/en/ai/quiz/15)

이 접근법은 **전이 학습**이라고 불리며, 한 신경망 모델에서 다른 모델로 지식을 전이하는 것을 의미합니다. 전이 학습에서는 일반적으로 **ImageNet**과 같은 대규모 이미지 데이터셋에서 훈련된 사전 학습 모델을 시작점으로 사용합니다. 이러한 모델은 이미 일반적인 이미지에서 다양한 특징을 추출하는 데 능숙하며, 많은 경우 이러한 추출된 특징 위에 분류기를 구축하는 것만으로도 좋은 결과를 얻을 수 있습니다.

> ✅ 전이 학습은 교육과 같은 다른 학문 분야에서도 발견되는 용어입니다. 이는 한 영역에서 얻은 지식을 다른 영역에 적용하는 과정을 의미합니다.

## 사전 학습된 모델을 특징 추출기로 사용하기

이전 섹션에서 다룬 컨볼루션 네트워크는 여러 층으로 구성되어 있으며, 각 층은 이미지에서 특징을 추출하도록 설계되었습니다. 저수준 픽셀 조합(예: 수평/수직 선 또는 획)에서 시작하여, 더 높은 수준의 특징 조합(예: 불꽃의 눈과 같은 것)에 이르기까지 말입니다. 충분히 크고 다양한 이미지 데이터셋에서 CNN을 훈련시키면 네트워크는 이러한 공통된 특징을 추출하는 방법을 학습할 수 있습니다.

Keras와 PyTorch는 대부분 ImageNet 이미지로 훈련된 일반적인 아키텍처에 대해 사전 학습된 신경망 가중치를 쉽게 로드할 수 있는 기능을 제공합니다. 가장 자주 사용되는 모델은 이전 강의의 [CNN 아키텍처](../07-ConvNets/CNN_Architectures.md) 페이지에서 설명되어 있습니다. 특히 다음 모델 중 하나를 고려해볼 수 있습니다:

* **VGG-16/VGG-19**: 비교적 간단한 모델로 여전히 좋은 정확도를 제공합니다. 전이 학습이 어떻게 작동하는지 확인하기 위해 VGG를 첫 시도로 사용하는 것이 좋은 선택일 수 있습니다.
* **ResNet**: Microsoft Research에서 2015년에 제안한 모델 계열로, 더 많은 층을 가지고 있어 더 많은 자원이 필요합니다.
* **MobileNet**: 크기가 줄어든 모델 계열로, 모바일 장치에 적합합니다. 자원이 부족하고 약간의 정확도를 희생할 수 있다면 사용해보세요.

다음은 VGG-16 네트워크가 고양이 사진에서 추출한 특징의 예입니다:

![VGG-16이 추출한 특징](../../../../../translated_images/features.6291f9c7ba3a0b951af88fc9864632b9115365410765680680d30c927dd67354.ko.png)

## 고양이와 개 데이터셋

이 예제에서는 [고양이와 개](https://www.microsoft.com/download/details.aspx?id=54765&WT.mc_id=academic-77998-cacaste) 데이터셋을 사용합니다. 이는 실제 이미지 분류 시나리오와 매우 유사합니다.

## ✍️ 연습: 전이 학습

다음 노트북에서 전이 학습이 실제로 어떻게 작동하는지 확인해보세요:

* [전이 학습 - PyTorch](../../../../../lessons/4-ComputerVision/08-TransferLearning/TransferLearningPyTorch.ipynb)
* [전이 학습 - TensorFlow](../../../../../lessons/4-ComputerVision/08-TransferLearning/TransferLearningTF.ipynb)

## 이상적인 고양이 시각화하기

사전 학습된 신경망은 **이상적인 고양이**(이상적인 개, 이상적인 얼룩말 등)에 대한 개념을 포함하여 다양한 패턴을 *뇌* 안에 가지고 있습니다. 이러한 이미지를 **시각화**하는 것은 흥미로울 것입니다. 하지만 이는 간단하지 않습니다. 패턴이 네트워크 가중치 전체에 퍼져 있고 계층적 구조로 조직되어 있기 때문입니다.

우리가 취할 수 있는 한 가지 접근법은 무작위 이미지를 시작점으로 사용한 다음 **경사 하강 최적화** 기법을 사용하여 네트워크가 해당 이미지를 고양이라고 생각하도록 이미지를 조정하는 것입니다.

![이미지 최적화 루프](../../../../../translated_images/ideal-cat-loop.999fbb8ff306e044f997032f4eef9152b453e6a990e449bbfb107de2493cc37e.ko.png)

하지만 이렇게 하면 무작위 노이즈와 매우 유사한 결과를 얻게 됩니다. 이는 *네트워크가 입력 이미지를 고양이라고 생각하도록 만드는 방법이 많기 때문*이며, 그중에는 시각적으로 의미가 없는 방법도 포함됩니다. 이러한 이미지는 고양이에 일반적인 많은 패턴을 포함하고 있지만, 시각적으로 뚜렷하게 보이도록 제한하는 요소가 없습니다.

결과를 개선하기 위해 **변동 손실**이라는 또 다른 항목을 손실 함수에 추가할 수 있습니다. 이는 이미지의 인접 픽셀이 얼마나 유사한지를 보여주는 메트릭입니다. 변동 손실을 최소화하면 이미지가 더 부드러워지고 노이즈가 제거되어 더 시각적으로 매력적인 패턴이 드러납니다. 다음은 고양이와 얼룩말로 높은 확률로 분류된 "이상적인" 이미지의 예입니다:

![이상적인 고양이](../../../../../translated_images/ideal-cat.203dd4597643d6b0bd73038b87f9c0464322725e3a06ab145d25d4a861c70592.ko.png) | ![이상적인 얼룩말](../../../../../translated_images/ideal-zebra.7f70e8b54ee15a7a314000bb5df38a6cfe086ea04d60df4d3ef313d046b98a2b.ko.png)
-----|-----
 *이상적인 고양이* | *이상적인 얼룩말*

유사한 접근법은 신경망에 대한 **적대적 공격**을 수행하는 데도 사용할 수 있습니다. 예를 들어, 개를 고양이처럼 보이게 만들어 신경망을 속이고 싶다고 가정해봅시다. 네트워크가 개로 인식하는 개의 이미지를 가져와 경사 하강 최적화를 사용하여 네트워크가 이를 고양이로 분류할 때까지 약간 조정할 수 있습니다:

![개 사진](../../../../../translated_images/original-dog.8f68a67d2fe0911f33041c0f7fce8aa4ea919f9d3917ec4b468298522aeb6356.ko.png) | ![고양이로 분류된 개 사진](../../../../../translated_images/adversarial-dog.d9fc7773b0142b89752539bfbf884118de845b3851c5162146ea0b8809fc820f.ko.png)
-----|-----
*원래 개 사진* | *고양이로 분류된 개 사진*

위 결과를 재현하는 코드는 다음 노트북에서 확인할 수 있습니다:

* [이상적인 고양이와 적대적 고양이 - TensorFlow](../../../../../lessons/4-ComputerVision/08-TransferLearning/AdversarialCat_TF.ipynb)

## 결론

전이 학습을 사용하면 사용자 정의 객체 분류 작업을 위한 분류기를 빠르게 구성하고 높은 정확도를 달성할 수 있습니다. 이제 우리가 해결하려는 더 복잡한 작업은 더 높은 계산 능력을 요구하며 CPU에서 쉽게 해결할 수 없습니다. 다음 단원에서는 동일한 모델을 더 낮은 계산 자원을 사용하여 훈련하는 경량 구현을 시도해볼 것이며, 이는 약간 낮은 정확도를 초래합니다.

## 🚀 도전 과제

동반 노트북의 하단에는 전이 학습이 어느 정도 유사한 훈련 데이터(예: 새로운 종류의 동물)와 가장 잘 작동한다는 내용이 있습니다. 완전히 새로운 유형의 이미지를 사용하여 실험을 진행하며 전이 학습 모델이 얼마나 잘 또는 못 작동하는지 확인해보세요.

## [강의 후 퀴즈](https://ff-quizzes.netlify.app/en/ai/quiz/16)

## 복습 및 자기 학습

[TrainingTricks.md](TrainingTricks.md)를 읽고 모델을 훈련시키는 다른 방법에 대한 지식을 심화하세요.

## [과제](lab/README.md)

이 실습에서는 35종의 고양이와 개 품종이 포함된 실제 [Oxford-IIIT](https://www.robots.ox.ac.uk/~vgg/data/pets/) 애완동물 데이터셋을 사용하여 전이 학습 분류기를 구축할 것입니다.

**면책 조항**:  
이 문서는 AI 번역 서비스 [Co-op Translator](https://github.com/Azure/co-op-translator)를 사용하여 번역되었습니다. 정확성을 위해 최선을 다하고 있으나, 자동 번역에는 오류나 부정확성이 포함될 수 있습니다. 원본 문서의 원어 버전을 권위 있는 출처로 간주해야 합니다. 중요한 정보에 대해서는 전문적인 인간 번역을 권장합니다. 이 번역 사용으로 인해 발생하는 오해나 잘못된 해석에 대해 당사는 책임을 지지 않습니다.