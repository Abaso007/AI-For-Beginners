<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "437c988596e751072e41a5aad3fcc5d9",
  "translation_date": "2025-08-24T21:23:09+00:00",
  "source_file": "lessons/7-Ethics/README.md",
  "language_code": "ko"
}
-->
# 윤리적이고 책임 있는 AI

이 과정을 거의 마쳤습니다. 이제 AI가 데이터를 통해 관계를 찾고 인간 행동의 일부를 재현하는 모델을 훈련시키는 여러 수학적 방법에 기반하고 있다는 것을 명확히 이해하셨기를 바랍니다. 현재 시점에서 AI는 데이터를 통해 패턴을 추출하고 새로운 문제를 해결하는 데 적용할 수 있는 매우 강력한 도구로 간주됩니다.

## [강의 전 퀴즈](https://white-water-09ec41f0f.azurestaticapps.net/quiz/5/)

하지만, 공상과학 소설에서는 AI가 인류에게 위험을 초래하는 이야기를 자주 접할 수 있습니다. 이러한 이야기들은 대개 AI가 인간에 대항하기로 결정하는 어떤 형태의 반란을 중심으로 전개됩니다. 이는 AI가 감정을 가지고 있거나 개발자가 예측하지 못한 결정을 내릴 수 있다는 것을 암시합니다.

이 과정에서 배운 AI는 단순히 대규모 행렬 연산에 불과합니다. 이는 우리의 문제를 해결하는 데 도움을 주는 매우 강력한 도구이며, 다른 강력한 도구와 마찬가지로 선한 목적과 악한 목적 모두에 사용될 수 있습니다. 중요한 점은 AI가 *오용*될 수 있다는 것입니다.

## 책임 있는 AI의 원칙

AI의 우발적 또는 의도적인 오용을 방지하기 위해, Microsoft는 중요한 [책임 있는 AI의 원칙](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-77998-cacaste)을 제시합니다. 다음 개념들이 이러한 원칙을 뒷받침합니다:

* **공정성**은 *모델 편향*이라는 중요한 문제와 관련이 있습니다. 이는 편향된 데이터를 사용하여 모델을 훈련시킬 때 발생할 수 있습니다. 예를 들어, 특정 사람이 소프트웨어 개발자 직업을 얻을 확률을 예측하려고 할 때, 훈련 데이터셋이 남성 중심으로 편향되어 있을 가능성이 높기 때문에 모델이 남성을 더 선호할 가능성이 있습니다. 우리는 훈련 데이터를 신중히 균형 있게 조정하고 모델을 조사하여 편향을 방지하며, 모델이 더 관련성 높은 특징을 고려하도록 해야 합니다.
* **신뢰성과 안전성**. AI 모델은 본질적으로 실수를 할 수 있습니다. 신경망은 확률을 반환하며, 우리는 이를 고려하여 결정을 내려야 합니다. 모든 모델은 일정한 정밀도와 재현율을 가지고 있으며, 잘못된 조언이 초래할 수 있는 피해를 예방하기 위해 이를 이해해야 합니다.
* **프라이버시와 보안**은 AI와 관련된 특정한 함의를 가지고 있습니다. 예를 들어, 모델을 훈련시키기 위해 데이터를 사용할 때, 이 데이터는 모델에 어느 정도 "통합"됩니다. 한편으로는 보안과 프라이버시가 강화되지만, 다른 한편으로는 모델이 어떤 데이터를 기반으로 훈련되었는지 기억해야 합니다.
* **포용성**은 AI를 사람을 대체하기 위해 만드는 것이 아니라, 사람을 보조하고 우리의 작업을 더 창의적으로 만들기 위해 만든다는 것을 의미합니다. 이는 공정성과도 관련이 있습니다. 대표성이 부족한 커뮤니티를 다룰 때, 우리가 수집하는 대부분의 데이터셋은 편향될 가능성이 높으며, 이러한 커뮤니티가 포함되고 AI에 의해 올바르게 처리되도록 해야 합니다.
* **투명성**. 이는 AI가 사용되고 있다는 사실을 항상 명확히 하는 것을 포함합니다. 또한 가능한 경우, *해석 가능한* AI 시스템을 사용하는 것을 목표로 합니다.
* **책임성**. AI 모델이 어떤 결정을 내릴 때, 그 결정에 대한 책임이 누구에게 있는지 항상 명확하지 않을 수 있습니다. 우리는 AI 결정의 책임이 어디에 있는지 이해해야 합니다. 대부분의 경우 중요한 결정을 내리는 과정에 인간을 포함시켜 실제 사람들이 책임을 지도록 해야 합니다.

## 책임 있는 AI를 위한 도구

Microsoft는 [책임 있는 AI 도구 상자](https://github.com/microsoft/responsible-ai-toolbox)를 개발했으며, 여기에는 다음과 같은 도구들이 포함되어 있습니다:

* Interpretability Dashboard (InterpretML)
* Fairness Dashboard (FairLearn)
* Error Analysis Dashboard
* Responsible AI Dashboard, 여기에는 다음이 포함됩니다:

   - EconML - 가상 시나리오를 다루는 인과 분석 도구
   - DiCE - 반사실 분석 도구로, 모델의 결정을 변경하기 위해 어떤 특징을 수정해야 하는지 확인할 수 있음

AI 윤리에 대한 추가 정보를 원하시면, 과제와 함께 제공되는 머신 러닝 커리큘럼의 [이 강의](https://github.com/microsoft/ML-For-Beginners/tree/main/1-Introduction/3-fairness?WT.mc_id=academic-77998-cacaste)를 방문해 보세요.

## 복습 및 자기 학습

책임 있는 AI에 대해 더 배우고 싶다면, 이 [학습 경로](https://docs.microsoft.com/learn/modules/responsible-ai-principles/?WT.mc_id=academic-77998-cacaste)를 확인하세요.

## [강의 후 퀴즈](https://white-water-09ec41f0f.azurestaticapps.net/quiz/6/)

**면책 조항**:  
이 문서는 AI 번역 서비스 [Co-op Translator](https://github.com/Azure/co-op-translator)를 사용하여 번역되었습니다. 정확성을 위해 노력하고 있지만, 자동 번역에는 오류나 부정확성이 포함될 수 있습니다. 원본 문서를 해당 언어로 작성된 상태에서 권위 있는 자료로 간주해야 합니다. 중요한 정보의 경우, 전문적인 인간 번역을 권장합니다. 이 번역 사용으로 인해 발생하는 오해나 잘못된 해석에 대해 당사는 책임을 지지 않습니다.