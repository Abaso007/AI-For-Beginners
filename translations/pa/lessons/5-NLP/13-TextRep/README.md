<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "4522e22e150be0845e03aa41209a39d5",
  "translation_date": "2025-08-26T08:26:42+00:00",
  "source_file": "lessons/5-NLP/13-TextRep/README.md",
  "language_code": "pa"
}
-->
# ਟੈਕਸਟ ਨੂੰ ਟੈਂਸਰ ਵਜੋਂ ਦਰਸਾਉਣਾ

## [ਪ੍ਰੀ-ਲੈਕਚਰ ਕਵਿਜ਼](https://ff-quizzes.netlify.app/en/ai/quiz/25)

## ਟੈਕਸਟ ਕਲਾਸੀਫਿਕੇਸ਼ਨ

ਇਸ ਸੈਕਸ਼ਨ ਦੇ ਪਹਿਲੇ ਹਿੱਸੇ ਦੌਰਾਨ, ਅਸੀਂ **ਟੈਕਸਟ ਕਲਾਸੀਫਿਕੇਸ਼ਨ** ਟਾਸਕ 'ਤੇ ਧਿਆਨ ਦੇਵਾਂਗੇ। ਅਸੀਂ [AG News](https://www.kaggle.com/amananandrai/ag-news-classification-dataset) ਡਾਟਾਸੈਟ ਦੀ ਵਰਤੋਂ ਕਰਾਂਗੇ, ਜਿਸ ਵਿੱਚ ਹੇਠਾਂ ਦਿੱਤੇ ਜਿਹੇ ਖ਼ਬਰਾਂ ਦੇ ਲੇਖ ਸ਼ਾਮਲ ਹਨ:

* ਸ਼੍ਰੇਣੀ: ਸਾਇ/ਟੈਕ
* ਸਿਰਲੇਖ: Ky. ਕੰਪਨੀ ਨੇ ਪੈਪਟਾਈਡਸ ਦਾ ਅਧਿਐਨ ਕਰਨ ਲਈ ਗ੍ਰਾਂਟ ਜਿੱਤੀ (AP)
* ਬਾਡੀ: AP - ਲੂਈਵਿਲ ਯੂਨੀਵਰਸਿਟੀ ਦੇ ਰਸਾਇਣ ਵਿਗਿਆਨ ਦੇ ਖੋਜਕਰਤਾ ਦੁਆਰਾ ਸਥਾਪਿਤ ਇੱਕ ਕੰਪਨੀ ਨੇ ਵਿਕਾਸ ਲਈ ਗ੍ਰਾਂਟ ਜਿੱਤੀ...

ਸਾਡਾ ਲਕਸ਼ ਖ਼ਬਰਾਂ ਦੇ ਲੇਖ ਨੂੰ ਟੈਕਸਟ ਦੇ ਆਧਾਰ 'ਤੇ ਇੱਕ ਸ਼੍ਰੇਣੀ ਵਿੱਚ ਵੰਡਣਾ ਹੋਵੇਗਾ।

## ਟੈਕਸਟ ਨੂੰ ਦਰਸਾਉਣਾ

ਜੇਕਰ ਅਸੀਂ ਨੈਚਰਲ ਲੈਂਗਵੇਜ ਪ੍ਰੋਸੈਸਿੰਗ (NLP) ਟਾਸਕ ਨੂੰ ਨਿਊਰਲ ਨੈਟਵਰਕ ਨਾਲ ਹੱਲ ਕਰਨਾ ਚਾਹੁੰਦੇ ਹਾਂ, ਤਾਂ ਸਾਨੂੰ ਟੈਕਸਟ ਨੂੰ ਟੈਂਸਰ ਵਜੋਂ ਦਰਸਾਉਣ ਦਾ ਕੋਈ ਤਰੀਕਾ ਲੋੜੀਂਦਾ ਹੈ। ਕੰਪਿਊਟਰ ਪਹਿਲਾਂ ਹੀ ਟੈਕਸਟ ਦੇ ਅੱਖਰਾਂ ਨੂੰ ਅੰਕਾਂ ਵਜੋਂ ਦਰਸਾਉਂਦੇ ਹਨ ਜੋ ਤੁਹਾਡੇ ਸਕ੍ਰੀਨ 'ਤੇ ਫੌਂਟਸ ਨਾਲ ਮੈਪ ਹੁੰਦੇ ਹਨ, ASCII ਜਾਂ UTF-8 ਵਰਗੀਆਂ ਐਨਕੋਡਿੰਗ ਦੀ ਵਰਤੋਂ ਕਰਦੇ ਹੋਏ।

<img alt="ਇੱਕ ਚਿੱਤਰ ਜੋ ਇੱਕ ਅੱਖਰ ਨੂੰ ASCII ਅਤੇ ਬਾਈਨਰੀ ਪ੍ਰਤੀਨਿਧਤਾ ਨਾਲ ਮੈਪ ਕਰਦਾ ਹੈ" src="images/ascii-character-map.png" width="50%"/>

> [ਚਿੱਤਰ ਸਰੋਤ](https://www.seobility.net/en/wiki/ASCII)

ਇਨਸਾਨਾਂ ਵਜੋਂ, ਅਸੀਂ ਸਮਝਦੇ ਹਾਂ ਕਿ ਹਰ ਅੱਖਰ **ਕੀ ਦਰਸਾਉਂਦਾ ਹੈ**, ਅਤੇ ਸਾਰੇ ਅੱਖਰ ਇਕੱਠੇ ਹੋ ਕੇ ਵਾਕ ਦੇ ਸ਼ਬਦ ਬਣਾਉਂਦੇ ਹਨ। ਹਾਲਾਂਕਿ, ਕੰਪਿਊਟਰ ਆਪਣੇ ਆਪ ਇਸ ਤਰ੍ਹਾਂ ਦੀ ਸਮਝ ਨਹੀਂ ਰੱਖਦੇ, ਅਤੇ ਨਿਊਰਲ ਨੈਟਵਰਕ ਨੂੰ ਟ੍ਰੇਨਿੰਗ ਦੌਰਾਨ ਅਰਥ ਸਿੱਖਣਾ ਪੈਂਦਾ ਹੈ।

ਇਸ ਲਈ, ਅਸੀਂ ਟੈਕਸਟ ਨੂੰ ਦਰਸਾਉਣ ਲਈ ਵੱਖ-ਵੱਖ ਤਰੀਕੇ ਵਰਤ ਸਕਦੇ ਹਾਂ:

* **ਕਿਰਦਾਰ-ਪੱਧਰ ਦੀ ਪ੍ਰਤੀਨਿਧਤਾ**, ਜਦੋਂ ਅਸੀਂ ਟੈਕਸਟ ਨੂੰ ਹਰ ਅੱਖਰ ਨੂੰ ਇੱਕ ਅੰਕ ਵਜੋਂ ਮੰਨ ਕੇ ਦਰਸਾਉਂਦੇ ਹਾਂ। ਜੇਕਰ ਸਾਡੇ ਟੈਕਸਟ ਕੋਰਪਸ ਵਿੱਚ *C* ਵੱਖ-ਵੱਖ ਅੱਖਰ ਹਨ, ਤਾਂ ਸ਼ਬਦ *Hello* ਨੂੰ 5x*C* ਟੈਂਸਰ ਵਜੋਂ ਦਰਸਾਇਆ ਜਾਵੇਗਾ। ਹਰ ਅੱਖਰ ਇੱਕ-ਹਾਟ ਐਨਕੋਡਿੰਗ ਵਿੱਚ ਟੈਂਸਰ ਕਾਲਮ ਦੇ ਅਨੁਸਾਰ ਹੋਵੇਗਾ।
* **ਸ਼ਬਦ-ਪੱਧਰ ਦੀ ਪ੍ਰਤੀਨਿਧਤਾ**, ਜਿਸ ਵਿੱਚ ਅਸੀਂ ਆਪਣੇ ਟੈਕਸਟ ਵਿੱਚ ਸਾਰੇ ਸ਼ਬਦਾਂ ਦੀ ਇੱਕ **ਵਰਡ ਕੋਸ਼** ਬਣਾਉਂਦੇ ਹਾਂ, ਅਤੇ ਫਿਰ ਸ਼ਬਦਾਂ ਨੂੰ ਇੱਕ-ਹਾਟ ਐਨਕੋਡਿੰਗ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਦਰਸਾਉਂਦੇ ਹਾਂ। ਇਹ ਤਰੀਕਾ ਕੁਝ ਹੱਦ ਤੱਕ ਬਿਹਤਰ ਹੈ, ਕਿਉਂਕਿ ਹਰ ਅੱਖਰ ਆਪਣੇ ਆਪ ਵਿੱਚ ਬਹੁਤ ਜ਼ਿਆਦਾ ਅਰਥ ਨਹੀਂ ਰੱਖਦਾ, ਅਤੇ ਇਸ ਲਈ ਉੱਚ-ਪੱਧਰੀ ਸੈਮੈਂਟਿਕ ਧਾਰਨਾਵਾਂ - ਸ਼ਬਦਾਂ - ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਅਸੀਂ ਨਿਊਰਲ ਨੈਟਵਰਕ ਲਈ ਕੰਮ ਸੌਖਾ ਕਰ ਦਿੰਦੇ ਹਾਂ। ਹਾਲਾਂਕਿ, ਵੱਡੇ ਡਿਕਸ਼ਨਰੀ ਆਕਾਰ ਦੇ ਕਾਰਨ, ਸਾਨੂੰ ਉੱਚ-ਮਾਪਦੰਡ ਵਾਲੇ sparse ਟੈਂਸਰਾਂ ਨਾਲ ਨਜਿੱਠਣਾ ਪੈਂਦਾ ਹੈ।

ਕਿਸੇ ਵੀ ਪ੍ਰਤੀਨਿਧਤਾ ਦੇ ਮਾਮਲੇ ਵਿੱਚ, ਸਾਨੂੰ ਪਹਿਲਾਂ ਟੈਕਸਟ ਨੂੰ **ਟੋਕਨਜ਼** ਦੀ ਲੜੀ ਵਿੱਚ ਬਦਲਣਾ ਪੈਂਦਾ ਹੈ, ਇੱਕ ਟੋਕਨ ਜਾਂ ਤਾਂ ਇੱਕ ਅੱਖਰ, ਇੱਕ ਸ਼ਬਦ, ਜਾਂ ਕਈ ਵਾਰ ਇੱਕ ਸ਼ਬਦ ਦਾ ਹਿੱਸਾ ਹੁੰਦਾ ਹੈ। ਫਿਰ, ਅਸੀਂ ਟੋਕਨ ਨੂੰ ਇੱਕ ਅੰਕ ਵਿੱਚ ਬਦਲਦੇ ਹਾਂ, ਆਮ ਤੌਰ 'ਤੇ **ਵਰਡ ਕੋਸ਼** ਦੀ ਵਰਤੋਂ ਕਰਦੇ ਹੋਏ, ਅਤੇ ਇਹ ਅੰਕ ਇੱਕ-ਹਾਟ ਐਨਕੋਡਿੰਗ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਨਿਊਰਲ ਨੈਟਵਰਕ ਵਿੱਚ ਫੀਡ ਕੀਤਾ ਜਾ ਸਕਦਾ ਹੈ।

## N-Grams

ਕੁਦਰਤੀ ਭਾਸ਼ਾ ਵਿੱਚ, ਸ਼ਬਦਾਂ ਦਾ ਸਹੀ ਅਰਥ ਸਿਰਫ ਸੰਦਰਭ ਵਿੱਚ ਹੀ ਨਿਰਧਾਰਤ ਕੀਤਾ ਜਾ ਸਕਦਾ ਹੈ। ਉਦਾਹਰਣ ਲਈ, *neural network* ਅਤੇ *fishing network* ਦੇ ਅਰਥ ਪੂਰੀ ਤਰ੍ਹਾਂ ਵੱਖਰੇ ਹਨ। ਇਸਨੂੰ ਧਿਆਨ ਵਿੱਚ ਰੱਖਣ ਦੇ ਤਰੀਕਿਆਂ ਵਿੱਚੋਂ ਇੱਕ ਹੈ ਕਿ ਅਸੀਂ ਆਪਣੇ ਮਾਡਲ ਨੂੰ ਸ਼ਬਦਾਂ ਦੇ ਜੋੜਿਆਂ 'ਤੇ ਬਣਾਈਏ, ਅਤੇ ਸ਼ਬਦ ਜੋੜਿਆਂ ਨੂੰ ਵੱਖਰੇ ਵਰਡ ਕੋਸ਼ ਟੋਕਨਜ਼ ਵਜੋਂ ਮੰਨਿਆ ਜਾਵੇ। ਇਸ ਤਰੀਕੇ ਨਾਲ, ਵਾਕ *I like to go fishing* ਹੇਠਾਂ ਦਿੱਤੇ ਟੋਕਨਜ਼ ਦੀ ਲੜੀ ਵਜੋਂ ਦਰਸਾਇਆ ਜਾਵੇਗਾ: *I like*, *like to*, *to go*, *go fishing*। ਇਸ ਤਰੀਕੇ ਨਾਲ ਸਮੱਸਿਆ ਇਹ ਹੈ ਕਿ ਡਿਕਸ਼ਨਰੀ ਦਾ ਆਕਾਰ ਕਾਫ਼ੀ ਵੱਧ ਜਾਂਦਾ ਹੈ, ਅਤੇ *go fishing* ਅਤੇ *go shopping* ਵਰਗੇ ਜੋੜੇ ਵੱਖਰੇ ਟੋਕਨਜ਼ ਦੁਆਰਾ ਦਰਸਾਏ ਜਾਂਦੇ ਹਨ, ਜੋ ਕਿ ਕੋਈ ਵੀ ਸੈਮੈਂਟਿਕ ਸਮਾਨਤਾ ਸਾਂਝੀ ਨਹੀਂ ਕਰਦੇ, ਭਾਵੇਂ ਕਿ ਕ੍ਰਿਆ ਇੱਕੋ ਹੀ ਹੈ।

ਕਈ ਮਾਮਲਿਆਂ ਵਿੱਚ, ਅਸੀਂ tri-grams -- ਤਿੰਨ ਸ਼ਬਦਾਂ ਦੇ ਜੋੜੇ -- ਦੀ ਵਰਤੋਂ ਕਰਨ ਬਾਰੇ ਵੀ ਸੋਚ ਸਕਦੇ ਹਾਂ। ਇਸ ਤਰੀਕੇ ਨੂੰ ਅਕਸਰ **n-grams** ਕਿਹਾ ਜਾਂਦਾ ਹੈ। ਇਹ ਵੀ ਸਮਝਦਾਰ ਹੈ ਕਿ n-grams ਨੂੰ ਕਿਰਦਾਰ-ਪੱਧਰ ਦੀ ਪ੍ਰਤੀਨਿਧਤਾ ਨਾਲ ਵਰਤਿਆ ਜਾਵੇ, ਜਿਸ ਵਿੱਚ n-grams ਲਗਭਗ ਵੱਖ-ਵੱਖ ਸਿਲੇਬਲਾਂ ਨੂੰ ਦਰਸਾਉਂਦੇ ਹਨ।

## Bag-of-Words ਅਤੇ TF/IDF

ਜਦੋਂ ਅਸੀਂ ਟੈਕਸਟ ਕਲਾਸੀਫਿਕੇਸ਼ਨ ਵਰਗੇ ਟਾਸਕ ਹੱਲ ਕਰਦੇ ਹਾਂ, ਤਾਂ ਸਾਨੂੰ ਟੈਕਸਟ ਨੂੰ ਇੱਕ ਫਿਕਸਡ-ਸਾਈਜ਼ ਵੇਕਟਰ ਦੁਆਰਾ ਦਰਸਾਉਣ ਦੀ ਲੋੜ ਹੁੰਦੀ ਹੈ, ਜਿਸਨੂੰ ਅਸੀਂ ਅੰਤਮ ਡੈਂਸ ਕਲਾਸੀਫਾਇਰ ਵਿੱਚ ਇਨਪੁਟ ਵਜੋਂ ਵਰਤਾਂਗੇ। ਇਸਦਾ ਸਭ ਤੋਂ ਸੌਖਾ ਤਰੀਕਾ ਇਹ ਹੈ ਕਿ ਸਾਰੇ ਵਿਅਕਤੀਗਤ ਸ਼ਬਦ ਪ੍ਰਤੀਨਿਧਤਾਵਾਂ ਨੂੰ ਜੋੜ ਦਿੱਤਾ ਜਾਵੇ। ਜੇਕਰ ਅਸੀਂ ਹਰ ਸ਼ਬਦ ਦੀ ਇੱਕ-ਹਾਟ ਐਨਕੋਡਿੰਗ ਨੂੰ ਜੋੜੀਏ, ਤਾਂ ਅਸੀਂ ਫ੍ਰੀਕਵੈਂਸੀਜ਼ ਦੇ ਇੱਕ ਵੇਕਟਰ 'ਤੇ ਪਹੁੰਚਾਂਗੇ, ਜੋ ਦਿਖਾਉਂਦਾ ਹੈ ਕਿ ਹਰ ਸ਼ਬਦ ਟੈਕਸਟ ਵਿੱਚ ਕਿੰਨੀ ਵਾਰ ਆਉਂਦਾ ਹੈ। ਟੈਕਸਟ ਦੀ ਇਸ ਤਰ੍ਹਾਂ ਦੀ ਪ੍ਰਤੀਨਿਧਤਾ ਨੂੰ **bag of words** (BoW) ਕਿਹਾ ਜਾਂਦਾ ਹੈ।

<img src="images/bow.png" width="90%"/>

> ਲੇਖਕ ਦੁਆਰਾ ਚਿੱਤਰ

BoW ਅਸਲ ਵਿੱਚ ਦਰਸਾਉਂਦਾ ਹੈ ਕਿ ਕਿਹੜੇ ਸ਼ਬਦ ਟੈਕਸਟ ਵਿੱਚ ਆਉਂਦੇ ਹਨ ਅਤੇ ਕਿਹੜੀਆਂ ਮਾਤਰਾਵਾਂ ਵਿੱਚ, ਜੋ ਕਿ ਅਕਸਰ ਇਹ ਦਰਸਾਉਣ ਲਈ ਇੱਕ ਵਧੀਆ ਸੰਕੇਤ ਹੁੰਦਾ ਹੈ ਕਿ ਟੈਕਸਟ ਕਿਸ ਬਾਰੇ ਹੈ। ਉਦਾਹਰਣ ਲਈ, ਰਾਜਨੀਤੀ 'ਤੇ ਖ਼ਬਰਾਂ ਦੇ ਲੇਖ ਵਿੱਚ ਸੰਭਾਵਨਾ ਹੈ ਕਿ *president* ਅਤੇ *country* ਵਰਗੇ ਸ਼ਬਦ ਸ਼ਾਮਲ ਹੋਣਗੇ, ਜਦਕਿ ਵਿਗਿਆਨਕ ਪ੍ਰਕਾਸ਼ਨ ਵਿੱਚ *collider*, *discovered* ਆਦਿ ਵਰਗੇ ਸ਼ਬਦ ਹੋ ਸਕਦੇ ਹਨ। ਇਸ ਤਰ੍ਹਾਂ, ਸ਼ਬਦਾਂ ਦੀਆਂ ਮਾਤਰਾਵਾਂ ਕਈ ਮਾਮਲਿਆਂ ਵਿੱਚ ਟੈਕਸਟ ਦੇ ਸਮੱਗਰੀ ਦੇ ਬਾਰੇ ਇੱਕ ਵਧੀਆ ਸੰਕੇਤ ਹੋ ਸਕਦੀਆਂ ਹਨ।

BoW ਨਾਲ ਸਮੱਸਿਆ ਇਹ ਹੈ ਕਿ ਕੁਝ ਆਮ ਸ਼ਬਦ, ਜਿਵੇਂ ਕਿ *and*, *is*, ਆਦਿ ਜ਼ਿਆਦਾਤਰ ਟੈਕਸਟ ਵਿੱਚ ਆਉਂਦੇ ਹਨ, ਅਤੇ ਉਹ ਸਭ ਤੋਂ ਉੱਚੀਆਂ ਮਾਤਰਾਵਾਂ ਰੱਖਦੇ ਹਨ, ਜੋ ਸੱਚਮੁੱਚ ਮਹੱਤਵਪੂਰਨ ਸ਼ਬਦਾਂ ਨੂੰ ਛੁਪਾ ਦਿੰਦੇ ਹਨ। ਅਸੀਂ ਉਹਨਾਂ ਸ਼ਬਦਾਂ ਦੀ ਮਹੱਤਤਾ ਨੂੰ ਘਟਾ ਸਕਦੇ ਹਾਂ ਜੇਕਰ ਅਸੀਂ ਪੂਰੇ ਦਸਤਾਵੇਜ਼ ਸੰਗ੍ਰਹਿ ਵਿੱਚ ਸ਼ਬਦਾਂ ਦੇ ਆਵਿਰਤੀ ਦਰ ਨੂੰ ਧਿਆਨ ਵਿੱਚ ਰੱਖੀਏ। ਇਹ TF/IDF ਤਰੀਕੇ ਦੇ ਪਿੱਛੇ ਮੁੱਖ ਵਿਚਾਰ ਹੈ, ਜਿਸਨੂੰ ਇਸ ਪਾਠ ਨਾਲ ਜੁੜੇ ਨੋਟਬੁੱਕਸ ਵਿੱਚ ਵਧੇਰੇ ਵਿਸਥਾਰ ਨਾਲ ਕਵਰ ਕੀਤਾ ਗਿਆ ਹੈ।

ਹਾਲਾਂਕਿ, ਇਹਨਾਂ ਤਰੀਕਿਆਂ ਵਿੱਚੋਂ ਕੋਈ ਵੀ ਟੈਕਸਟ ਦੇ **ਸੈਮੈਂਟਿਕਸ** ਨੂੰ ਪੂਰੀ ਤਰ੍ਹਾਂ ਧਿਆਨ ਵਿੱਚ ਨਹੀਂ ਰੱਖ ਸਕਦਾ। ਸਾਨੂੰ ਇਸ ਲਈ ਹੋਰ ਸ਼ਕਤੀਸ਼ਾਲੀ ਨਿਊਰਲ ਨੈਟਵਰਕ ਮਾਡਲਾਂ ਦੀ ਲੋੜ ਹੈ, ਜਿਸ ਬਾਰੇ ਅਸੀਂ ਇਸ ਸੈਕਸ਼ਨ ਵਿੱਚ ਬਾਅਦ ਵਿੱਚ ਚਰਚਾ ਕਰਾਂਗੇ।

## ✍️ ਅਭਿਆਸ: ਟੈਕਸਟ ਪ੍ਰਤੀਨਿਧਤਾ

ਹੇਠਾਂ ਦਿੱਤੇ ਨੋਟਬੁੱਕਸ ਵਿੱਚ ਆਪਣੀ ਸਿੱਖਿਆ ਜਾਰੀ ਰੱਖੋ:

* [ਪਾਈਟਾਰਚ ਨਾਲ ਟੈਕਸਟ ਪ੍ਰਤੀਨਿਧਤਾ](../../../../../lessons/5-NLP/13-TextRep/TextRepresentationPyTorch.ipynb)
* [ਟੈਂਸਰਫਲੋ ਨਾਲ ਟੈਕਸਟ ਪ੍ਰਤੀਨਿਧਤਾ](../../../../../lessons/5-NLP/13-TextRep/TextRepresentationTF.ipynb)

## ਨਿਸਕਰਸ਼

ਅਜੇ ਤੱਕ, ਅਸੀਂ ਉਹ ਤਕਨੀਕਾਂ ਪੜ੍ਹੀਆਂ ਹਨ ਜੋ ਵੱਖ-ਵੱਖ ਸ਼ਬਦਾਂ ਨੂੰ ਆਵਿਰਤੀ ਵਜ਼ਨ ਦੇ ਸਕਦੀਆਂ ਹਨ। ਹਾਲਾਂਕਿ, ਇਹ ਅਰਥ ਜਾਂ ਕ੍ਰਮ ਨੂੰ ਦਰਸਾਉਣ ਵਿੱਚ ਅਸਮਰੱਥ ਹਨ। ਪ੍ਰਸਿੱਧ ਭਾਸ਼ਾਵਿਦ ਜੇ. ਆਰ. ਫਰਥ ਨੇ 1935 ਵਿੱਚ ਕਿਹਾ ਸੀ, "ਸ਼ਬਦ ਦਾ ਪੂਰਾ ਅਰਥ ਹਮੇਸ਼ਾ ਸੰਦਰਭਕ ਹੁੰਦਾ ਹੈ, ਅਤੇ ਸੰਦਰਭ ਤੋਂ ਬਿਨਾਂ ਅਰਥ ਦਾ ਕੋਈ ਅਧਿਐਨ ਗੰਭੀਰਤਾ ਨਾਲ ਨਹੀਂ ਲਿਆ ਜਾ ਸਕਦਾ।" ਅਸੀਂ ਇਸ ਕੋਰਸ ਵਿੱਚ ਬਾਅਦ ਵਿੱਚ ਸਿੱਖਾਂਗੇ ਕਿ ਭਾਸ਼ਾ ਮਾਡਲਿੰਗ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਟੈਕਸਟ ਤੋਂ ਸੰਦਰਭਕ ਜਾਣਕਾਰੀ ਕਿਵੇਂ ਕੈਪਚਰ ਕੀਤੀ ਜਾ ਸਕਦੀ ਹੈ।

## 🚀 ਚੈਲੈਂਜ

Bag-of-words ਅਤੇ ਵੱਖ-ਵੱਖ ਡਾਟਾ ਮਾਡਲਾਂ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਕੁਝ ਹੋਰ ਅਭਿਆਸ ਕਰਨ ਦੀ ਕੋਸ਼ਿਸ਼ ਕਰੋ। ਤੁਸੀਂ ਇਸ [Kaggle ਮੁਕਾਬਲੇ](https://www.kaggle.com/competitions/word2vec-nlp-tutorial/overview/part-1-for-beginners-bag-of-words) ਤੋਂ ਪ੍ਰੇਰਿਤ ਹੋ ਸਕਦੇ ਹੋ।

## [ਪੋਸਟ-ਲੈਕਚਰ ਕਵਿਜ਼](https://ff-quizzes.netlify.app/en/ai/quiz/26)

## ਸਮੀਖਿਆ ਅਤੇ ਸਵੈ ਅਧਿਐਨ

[ਮਾਈਕਰੋਸਾਫਟ ਲਰਨ](https://docs.microsoft.com/learn/modules/intro-natural-language-processing-pytorch/?WT.mc_id=academic-77998-cacaste) 'ਤੇ ਟੈਕਸਟ ਐਮਬੈਡਿੰਗ ਅਤੇ bag-of-words ਤਕਨੀਕਾਂ ਨਾਲ ਆਪਣੀਆਂ ਹੁਨਰਾਂ ਦਾ ਅਭਿਆਸ ਕਰੋ।

## [ਅਸਾਈਨਮੈਂਟ: ਨੋਟਬੁੱਕਸ](assignment.md)

**ਅਸਵੀਕਰਤਾ**:  
ਇਹ ਦਸਤਾਵੇਜ਼ AI ਅਨੁਵਾਦ ਸੇਵਾ [Co-op Translator](https://github.com/Azure/co-op-translator) ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਅਨੁਵਾਦ ਕੀਤਾ ਗਿਆ ਹੈ। ਜਦੋਂ ਕਿ ਅਸੀਂ ਸਹੀ ਹੋਣ ਦਾ ਯਤਨ ਕਰਦੇ ਹਾਂ, ਕਿਰਪਾ ਕਰਕੇ ਧਿਆਨ ਦਿਓ ਕਿ ਸਵੈਚਾਲਿਤ ਅਨੁਵਾਦਾਂ ਵਿੱਚ ਗਲਤੀਆਂ ਜਾਂ ਅਸੁਚੱਜੇਪਣ ਹੋ ਸਕਦੇ ਹਨ। ਮੂਲ ਦਸਤਾਵੇਜ਼, ਜੋ ਇਸਦੀ ਮੂਲ ਭਾਸ਼ਾ ਵਿੱਚ ਹੈ, ਨੂੰ ਅਧਿਕਾਰਤ ਸਰੋਤ ਮੰਨਿਆ ਜਾਣਾ ਚਾਹੀਦਾ ਹੈ। ਮਹੱਤਵਪੂਰਨ ਜਾਣਕਾਰੀ ਲਈ, ਪੇਸ਼ੇਵਰ ਮਨੁੱਖੀ ਅਨੁਵਾਦ ਦੀ ਸਿਫਾਰਸ਼ ਕੀਤੀ ਜਾਂਦੀ ਹੈ। ਇਸ ਅਨੁਵਾਦ ਦੀ ਵਰਤੋਂ ਤੋਂ ਪੈਦਾ ਹੋਣ ਵਾਲੇ ਕਿਸੇ ਵੀ ਗਲਤਫਹਿਮੀ ਜਾਂ ਗਲਤ ਵਿਆਖਿਆ ਲਈ ਅਸੀਂ ਜ਼ਿੰਮੇਵਾਰ ਨਹੀਂ ਹਾਂ।