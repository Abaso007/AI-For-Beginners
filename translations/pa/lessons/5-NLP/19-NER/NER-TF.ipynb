{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ਨਾਂਦਿਤ ਇਕਾਈ ਪਛਾਣ (NER)\n",
    "\n",
    "ਇਹ ਨੋਟਬੁੱਕ [AI for Beginners Curriculum](http://aka.ms/ai-beginners) ਤੋਂ ਹੈ।\n",
    "\n",
    "ਇਸ ਉਦਾਹਰਨ ਵਿੱਚ, ਅਸੀਂ ਸਿੱਖਾਂਗੇ ਕਿ [Annotated Corpus for Named Entity Recognition](https://www.kaggle.com/datasets/abhinavwalia95/entity-annotated-corpus) ਡੇਟਾਸੈੱਟ ਤੋਂ Kaggle 'ਤੇ NER ਮਾਡਲ ਨੂੰ ਕਿਵੇਂ ਟ੍ਰੇਨ ਕਰਨਾ ਹੈ। ਅੱਗੇ ਵਧਣ ਤੋਂ ਪਹਿਲਾਂ, ਕਿਰਪਾ ਕਰਕੇ [ner_dataset.csv](https://www.kaggle.com/datasets/abhinavwalia95/entity-annotated-corpus?resource=download&select=ner_dataset.csv) ਫਾਈਲ ਨੂੰ ਮੌਜੂਦਾ ਡਾਇਰੈਕਟਰੀ ਵਿੱਚ ਡਾਊਨਲੋਡ ਕਰੋ।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ਡਾਟਾਸੈੱਟ ਤਿਆਰ ਕਰਨਾ\n",
    "\n",
    "ਅਸੀਂ ਡਾਟਾਸੈੱਟ ਨੂੰ ਇੱਕ ਡਾਟਾਫਰੇਮ ਵਿੱਚ ਪੜ੍ਹਨ ਨਾਲ ਸ਼ੁਰੂ ਕਰਾਂਗੇ। ਜੇ ਤੁਸੀਂ Pandas ਦੀ ਵਰਤੋਂ ਬਾਰੇ ਹੋਰ ਜਾਣਨਾ ਚਾਹੁੰਦੇ ਹੋ, ਤਾਂ ਸਾਡੇ [Data Science for Beginners](http://aka.ms/datascience-beginners) ਵਿੱਚ [ਡਾਟਾ ਪ੍ਰੋਸੈਸਿੰਗ ਦੇ ਪਾਠ](https://github.com/microsoft/Data-Science-For-Beginners/tree/main/2-Working-With-Data/07-python) 'ਤੇ ਜਾਓ।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1          NaN             of   IN   O\n",
       "2          NaN  demonstrators  NNS   O\n",
       "3          NaN           have  VBP   O\n",
       "4          NaN        marched  VBN   O"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ner_dataset.csv',encoding='unicode-escape')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ਆਓ ਵਿਲੱਖਣ ਟੈਗ ਪ੍ਰਾਪਤ ਕਰੀਏ ਅਤੇ ਲੁੱਕਅੱਪ ਡਿਕਸ਼ਨਰੀ ਬਣਾਈਏ ਜੋ ਅਸੀਂ ਟੈਗ ਨੂੰ ਕਲਾਸ ਨੰਬਰਾਂ ਵਿੱਚ ਤਬਦੀਲ ਕਰਨ ਲਈ ਵਰਤ ਸਕੀਏ:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O', 'B-geo', 'B-gpe', 'B-per', 'I-geo', 'B-org', 'I-org', 'B-tim',\n",
       "       'B-art', 'I-art', 'I-per', 'I-gpe', 'I-tim', 'B-nat', 'B-eve',\n",
       "       'I-eve', 'I-nat'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = df.Tag.unique()\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'O'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2tag = dict(enumerate(tags))\n",
    "tag2id = { v : k for k,v in id2tag.items() }\n",
    "\n",
    "id2tag[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ਹੁਣ ਸਾਨੂੰ ਸ਼ਬਦਾਵਲੀ ਨਾਲ ਵੀ ਇਹੀ ਕਰਨਾ ਹੈ। ਸੌਖੇਪਣ ਲਈ, ਅਸੀਂ ਸ਼ਬਦਾਵਲੀ ਨੂੰ ਬਿਨਾਂ ਸ਼ਬਦਾਂ ਦੀ ਆਵ੍ਰਿਤੀ ਨੂੰ ਧਿਆਨ ਵਿੱਚ ਲਿਆਂਦੇ ਬਣਾਵਾਂਗੇ; ਅਸਲ ਜ਼ਿੰਦਗੀ ਵਿੱਚ ਤੁਸੀਂ Keras ਵੈਕਟਰਾਈਜ਼ਰ ਦੀ ਵਰਤੋਂ ਕਰ ਸਕਦੇ ਹੋ ਅਤੇ ਸ਼ਬਦਾਂ ਦੀ ਗਿਣਤੀ ਨੂੰ ਸੀਮਿਤ ਕਰ ਸਕਦੇ ਹੋ।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(df['Word'].apply(lambda x: x.lower()))\n",
    "id2word = { i+1 : v for i,v in enumerate(vocab) }\n",
    "id2word[0] = '<UNK>'\n",
    "vocab.add('<UNK>')\n",
    "word2id = { v : k for k,v in id2word.items() }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ਅਸੀਂ ਸਿਖਲਾਈ ਲਈ ਵਾਕਾਂ ਦਾ ਡੇਟਾਸੈੱਟ ਬਣਾਉਣ ਦੀ ਲੋੜ ਹੈ। ਆਓ ਅਸਲ ਡੇਟਾਸੈੱਟ ਵਿੱਚੋਂ ਗੁਜ਼ਰ ਕੇ ਸਾਰੇ ਵੱਖ-ਵੱਖ ਵਾਕਾਂ ਨੂੰ `X` (ਸ਼ਬਦਾਂ ਦੀਆਂ ਸੂਚੀਆਂ) ਅਤੇ `Y` (ਟੋਕਨ ਦੀ ਸੂਚੀ) ਵਿੱਚ ਵੰਡ ਲਈਏ:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = [],[]\n",
    "s,t = [],[]\n",
    "for i,row in df[['Sentence #','Word','Tag']].iterrows():\n",
    "    if pd.isna(row['Sentence #']):\n",
    "        s.append(row['Word'])\n",
    "        t.append(row['Tag'])\n",
    "    else:\n",
    "        if len(s)>0:\n",
    "            X.append(s)\n",
    "            Y.append(t)\n",
    "        s,t = [row['Word']],[row['Tag']]\n",
    "X.append(s)\n",
    "Y.append(t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([10386,\n",
       "  23515,\n",
       "  4134,\n",
       "  29620,\n",
       "  7954,\n",
       "  13583,\n",
       "  21193,\n",
       "  12222,\n",
       "  27322,\n",
       "  18258,\n",
       "  5815,\n",
       "  15880,\n",
       "  5355,\n",
       "  25242,\n",
       "  31327,\n",
       "  18258,\n",
       "  27067,\n",
       "  23515,\n",
       "  26444,\n",
       "  14412,\n",
       "  358,\n",
       "  26551,\n",
       "  5011,\n",
       "  30558],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vectorize(seq):\n",
    "    return [word2id[x.lower()] for x in seq]\n",
    "\n",
    "def tagify(seq):\n",
    "    return [tag2id[x] for x in seq]\n",
    "\n",
    "Xv = list(map(vectorize,X))\n",
    "Yv = list(map(tagify,Y))\n",
    "\n",
    "Xv[0], Yv[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ਸਰਲਤਾ ਲਈ, ਅਸੀਂ ਸਾਰੀਆਂ ਵਾਕਾਂ ਨੂੰ ਵੱਧ ਤੋਂ ਵੱਧ ਲੰਬਾਈ ਤੱਕ 0 ਟੋਕਨ ਨਾਲ ਭਰ ਦਿਆਂਗੇ। ਅਸਲ ਜ਼ਿੰਦਗੀ ਵਿੱਚ, ਅਸੀਂ ਹੋਰ ਚਤੁਰਾਈ ਭਰੀ ਰਣਨੀਤੀ ਵਰਤਣਾ ਚਾਹਾਂਗੇ ਅਤੇ ਸਿਰਫ਼ ਇੱਕ ਮਿਨੀਬੈਚ ਦੇ ਅੰਦਰ ਕ੍ਰਮਾਂ ਨੂੰ ਭਰਨਾ ਚਾਹਾਂਗੇ।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = keras.preprocessing.sequence.pad_sequences(Xv,padding='post')\n",
    "Y_data = keras.preprocessing.sequence.pad_sequences(Yv,padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ਟੋਕਨ ਵਰਗੀਕਰਨ ਨੈੱਟਵਰਕ ਦੀ ਪਰਿਭਾਸ਼ਾ\n",
    "\n",
    "ਅਸੀਂ ਟੋਕਨ ਵਰਗੀਕਰਨ ਲਈ ਦੋ-ਪਰਤਾਂ ਵਾਲੇ ਬਿਡਾਇਰੈਕਸ਼ਨਲ LSTM ਨੈੱਟਵਰਕ ਦੀ ਵਰਤੋਂ ਕਰਾਂਗੇ। ਆਖਰੀ LSTM ਪਰਤ ਦੇ ਹਰ ਆਉਟਪੁੱਟ 'ਤੇ ਡੈਂਸ ਵਰਗੀਕਰਨ ਲਾਗੂ ਕਰਨ ਲਈ, ਅਸੀਂ `TimeDistributed` ਕਨਸਟਰਕਸ਼ਨ ਦੀ ਵਰਤੋਂ ਕਰਾਂਗੇ, ਜੋ LSTM ਦੇ ਹਰ ਕਦਮ 'ਤੇ ਇੱਕੋ ਜਿਹੇ ਡੈਂਸ ਪਰਤ ਨੂੰ ਦੁਹਰਾਉਂਦਾ ਹੈ:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 104, 300)          9545400   \n",
      "                                                                 \n",
      " bidirectional_6 (Bidirectio  (None, 104, 200)         320800    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_7 (Bidirectio  (None, 104, 200)         240800    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDis  (None, 104, 17)          3417      \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,110,417\n",
      "Trainable params: 10,110,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "maxlen = X_data.shape[1]\n",
    "vocab_size = len(vocab)\n",
    "num_tags = len(tags)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Embedding(vocab_size, 300, input_length=maxlen),\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(units=100, activation='tanh', return_sequences=True)),\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(units=100, activation='tanh', return_sequences=True)),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(num_tags, activation='softmax'))\n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ਇੱਥੇ ਧਿਆਨ ਦਿਓ ਕਿ ਅਸੀਂ ਆਪਣੇ ਡਾਟਾਸੈੱਟ ਲਈ `maxlen` ਸਪਸ਼ਟ ਤੌਰ 'ਤੇ ਨਿਰਧਾਰਤ ਕਰ ਰਹੇ ਹਾਂ - ਜੇਕਰ ਅਸੀਂ ਚਾਹੁੰਦੇ ਹਾਂ ਕਿ ਨੈੱਟਵਰਕ ਵੱਖ-ਵੱਖ ਲੰਬਾਈ ਵਾਲੀਆਂ ਲੜੀਆਂ ਨੂੰ ਸੰਭਾਲ ਸਕੇ, ਤਾਂ ਸਾਨੂੰ ਨੈੱਟਵਰਕ ਨੂੰ ਨਿਰਧਾਰਤ ਕਰਦੇ ਸਮੇਂ ਕੁਝ ਹੋਰ ਚੁਸਤ ਹੋਣਾ ਪਵੇਗਾ।\n",
    "\n",
    "ਚਲੋ ਹੁਣ ਮਾਡਲ ਨੂੰ ਟ੍ਰੇਨ ਕਰਦੇ ਹਾਂ। ਗਤੀ ਨੂੰ ਤੇਜ਼ ਕਰਨ ਲਈ, ਅਸੀਂ ਸਿਰਫ ਇੱਕ epoch ਲਈ ਟ੍ਰੇਨ ਕਰਾਂਗੇ, ਪਰ ਤੁਸੀਂ ਲੰਬੇ ਸਮੇਂ ਲਈ ਟ੍ਰੇਨ ਕਰਨ ਦੀ ਕੋਸ਼ਿਸ਼ ਕਰ ਸਕਦੇ ਹੋ। ਇਸ ਤੋਂ ਇਲਾਵਾ, ਤੁਸੀਂ ਡਾਟਾਸੈੱਟ ਦੇ ਕੁਝ ਹਿੱਸੇ ਨੂੰ ਟ੍ਰੇਨਿੰਗ ਡਾਟਾਸੈੱਟ ਵਜੋਂ ਵੱਖ ਕਰ ਸਕਦੇ ਹੋ, ਤਾਂ ਜੋ ਵੈਲੀਡੇਸ਼ਨ ਐਕ੍ਯੂਰੇਸੀ ਦਾ ਅਧਿਐਨ ਕੀਤਾ ਜਾ ਸਕੇ।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1499/1499 [==============================] - 740s 488ms/step - loss: 0.0667 - acc: 0.9841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16f0bb2a310>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_data,Y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ਨਤੀਜੇ ਦੀ ਜਾਂਚ\n",
    "\n",
    "ਆਓ ਹੁਣ ਦੇਖੀਏ ਕਿ ਸਾਡਾ ਐਨਟੀਟੀ ਪਛਾਣ ਮਾਡਲ ਇੱਕ ਨਮੂਨਾ ਵਾਕ 'ਤੇ ਕਿਵੇਂ ਕੰਮ ਕਰਦਾ ਹੈ:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'John Smith went to Paris to attend a conference in cancer development institute'\n",
    "words = sent.lower().split()\n",
    "v = keras.preprocessing.sequence.pad_sequences([[word2id[x] for x in words]],padding='post',maxlen=maxlen)\n",
    "res = model(v)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "john -> B-per\n",
      "smith -> I-per\n",
      "went -> O\n",
      "to -> O\n",
      "paris -> B-geo\n",
      "to -> O\n",
      "attend -> O\n",
      "a -> O\n",
      "conference -> O\n",
      "in -> O\n",
      "cancer -> B-org\n",
      "development -> I-org\n",
      "institute -> I-org\n"
     ]
    }
   ],
   "source": [
    "r = np.argmax(res.numpy(),axis=1)\n",
    "for i,w in zip(r,words):\n",
    "    print(f\"{w} -> {id2tag[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ਮੁੱਖ ਗੱਲ\n",
    "\n",
    "ਇੱਕ ਸਧਾਰਨ LSTM ਮਾਡਲ ਵੀ NER ਵਿੱਚ ਠੀਕ ਨਤੀਜੇ ਦਿਖਾਉਂਦਾ ਹੈ। ਹਾਲਾਂਕਿ, ਹੋਰ ਵਧੀਆ ਨਤੀਜੇ ਪ੍ਰਾਪਤ ਕਰਨ ਲਈ, ਤੁਸੀਂ ਵੱਡੇ ਪੂਰਵ-ਪ੍ਰਸ਼ਿਕਸ਼ਿਤ ਭਾਸ਼ਾ ਮਾਡਲਾਂ ਜਿਵੇਂ ਕਿ BERT ਦੀ ਵਰਤੋਂ ਕਰ ਸਕਦੇ ਹੋ। Huggingface Transformers ਲਾਇਬ੍ਰੇਰੀ ਦੀ ਵਰਤੋਂ ਕਰਕੇ NER ਲਈ BERT ਨੂੰ ਪ੍ਰਸ਼ਿਕਸ਼ਿਤ ਕਰਨ ਦੀ ਵਿਵਰਣਾ [ਇੱਥੇ](https://huggingface.co/course/chapter7/2?fw=pt) ਦਿੱਤੀ ਗਈ ਹੈ।\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**ਅਸਵੀਕਰਤੀ**:  \nਇਹ ਦਸਤਾਵੇਜ਼ AI ਅਨੁਵਾਦ ਸੇਵਾ [Co-op Translator](https://github.com/Azure/co-op-translator) ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਅਨੁਵਾਦ ਕੀਤਾ ਗਿਆ ਹੈ। ਜਦੋਂ ਕਿ ਅਸੀਂ ਸਹੀ ਹੋਣ ਦਾ ਯਤਨ ਕਰਦੇ ਹਾਂ, ਕਿਰਪਾ ਕਰਕੇ ਧਿਆਨ ਦਿਓ ਕਿ ਸਵੈਚਾਲਿਤ ਅਨੁਵਾਦਾਂ ਵਿੱਚ ਗਲਤੀਆਂ ਜਾਂ ਅਸੁੱਤੀਆਂ ਹੋ ਸਕਦੀਆਂ ਹਨ। ਇਸ ਦੀ ਮੂਲ ਭਾਸ਼ਾ ਵਿੱਚ ਲਿਖਿਆ ਦਸਤਾਵੇਜ਼ ਪ੍ਰਮਾਣਿਕ ਸਰੋਤ ਮੰਨਿਆ ਜਾਣਾ ਚਾਹੀਦਾ ਹੈ। ਮਹੱਤਵਪੂਰਨ ਜਾਣਕਾਰੀ ਲਈ, ਪੇਸ਼ੇਵਰ ਮਨੁੱਖੀ ਅਨੁਵਾਦ ਦੀ ਸਿਫਾਰਸ਼ ਕੀਤੀ ਜਾਂਦੀ ਹੈ। ਇਸ ਅਨੁਵਾਦ ਦੇ ਪ੍ਰਯੋਗ ਤੋਂ ਪੈਦਾ ਹੋਣ ਵਾਲੇ ਕਿਸੇ ਵੀ ਗਲਤਫਹਿਮੀ ਜਾਂ ਗਲਤ ਵਿਆਖਿਆ ਲਈ ਅਸੀਂ ਜ਼ਿੰਮੇਵਾਰ ਨਹੀਂ ਹਾਂ।  \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16af2a8bbb083ea23e5e41c7f5787656b2ce26968575d8763f2c4b17f9cd711f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "254d25052dcca4ef84f59a05f2935bdc",
   "translation_date": "2025-08-28T09:32:38+00:00",
   "source_file": "lessons/5-NLP/19-NER/NER-TF.ipynb",
   "language_code": "pa"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}