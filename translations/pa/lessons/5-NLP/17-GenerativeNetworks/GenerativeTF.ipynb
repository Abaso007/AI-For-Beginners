{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ਜਨਰੇਟਿਵ ਨੈਟਵਰਕਸ\n",
    "\n",
    "ਰਿਕਰੰਟ ਨਿਊਰਲ ਨੈਟਵਰਕਸ (RNNs) ਅਤੇ ਉਨ੍ਹਾਂ ਦੇ ਗੇਟਡ ਸੈੱਲ ਵੈਰੀਐਂਟਸ ਜਿਵੇਂ ਕਿ ਲਾਂਗ ਸ਼ਾਰਟ ਟਰਮ ਮੈਮੋਰੀ ਸੈੱਲਸ (LSTMs) ਅਤੇ ਗੇਟਡ ਰਿਕਰੰਟ ਯੂਨਿਟਸ (GRUs) ਨੇ ਭਾਸ਼ਾ ਮਾਡਲਿੰਗ ਲਈ ਇੱਕ ਮਕੈਨਿਜ਼ਮ ਮੁਹੱਈਆ ਕਰਵਾਇਆ, ਯਾਨੀ ਇਹ ਸ਼ਬਦਾਂ ਦੀ ਕ੍ਰਮਵਾਰਤਾ ਸਿੱਖ ਸਕਦੇ ਹਨ ਅਤੇ ਕ੍ਰਮ ਵਿੱਚ ਅਗਲੇ ਸ਼ਬਦ ਦੀ ਭਵਿੱਖਵਾਣੀ ਕਰ ਸਕਦੇ ਹਨ। ਇਸ ਨਾਲ ਸਾਨੂੰ RNNs ਨੂੰ **ਜਨਰੇਟਿਵ ਕੰਮਾਂ** ਲਈ ਵਰਤਣ ਦੀ ਆਗਿਆ ਮਿਲਦੀ ਹੈ, ਜਿਵੇਂ ਕਿ ਆਮ ਪਾਠ ਜਨਰੇਸ਼ਨ, ਮਸ਼ੀਨ ਅਨੁਵਾਦ, ਅਤੇ ਇੱਥੋਂ ਤੱਕ ਕਿ ਚਿੱਤਰ ਕੈਪਸ਼ਨਿੰਗ।\n",
    "\n",
    "ਪਿਛਲੇ ਯੂਨਿਟ ਵਿੱਚ ਚਰਚਾ ਕੀਤੀ ਗਈ RNN ਆਰਕੀਟੈਕਚਰ ਵਿੱਚ, ਹਰ RNN ਯੂਨਿਟ ਨੇ ਅਗਲਾ ਹਿਡਨ ਸਟੇਟ ਇੱਕ ਆਉਟਪੁਟ ਵਜੋਂ ਤਿਆਰ ਕੀਤਾ। ਹਾਲਾਂਕਿ, ਅਸੀਂ ਹਰ ਰਿਕਰੰਟ ਯੂਨਿਟ ਵਿੱਚ ਇੱਕ ਹੋਰ ਆਉਟਪੁਟ ਵੀ ਸ਼ਾਮਲ ਕਰ ਸਕਦੇ ਹਾਂ, ਜੋ ਸਾਨੂੰ ਇੱਕ **ਕ੍ਰਮ** (ਜੋ ਮੂਲ ਕ੍ਰਮ ਦੇ ਬਰਾਬਰ ਲੰਬਾਈ ਵਾਲਾ ਹੈ) ਆਉਟਪੁਟ ਕਰਨ ਦੀ ਆਗਿਆ ਦਿੰਦਾ ਹੈ। ਇਸ ਤੋਂ ਇਲਾਵਾ, ਅਸੀਂ RNN ਯੂਨਿਟਸ ਦੀ ਵਰਤੋਂ ਕਰ ਸਕਦੇ ਹਾਂ ਜੋ ਹਰ ਕਦਮ 'ਤੇ ਇਨਪੁਟ ਸਵੀਕਾਰ ਨਹੀਂ ਕਰਦੇ, ਸਗੋਂ ਸਿਰਫ਼ ਕੁਝ ਸ਼ੁਰੂਆਤੀ ਸਟੇਟ ਵੈਕਟਰ ਲੈਂਦੇ ਹਨ ਅਤੇ ਫਿਰ ਆਉਟਪੁਟ ਦਾ ਇੱਕ ਕ੍ਰਮ ਤਿਆਰ ਕਰਦੇ ਹਨ।\n",
    "\n",
    "ਇਸ ਨੋਟਬੁੱਕ ਵਿੱਚ, ਅਸੀਂ ਸਧਾਰਨ ਜਨਰੇਟਿਵ ਮਾਡਲਾਂ 'ਤੇ ਧਿਆਨ ਕੇਂਦਰਿਤ ਕਰਾਂਗੇ ਜੋ ਸਾਨੂੰ ਪਾਠ ਤਿਆਰ ਕਰਨ ਵਿੱਚ ਮਦਦ ਕਰਦੇ ਹਨ। ਸਧਾਰਨਤਾ ਲਈ, ਆਓ ਇੱਕ **ਕਿਰਦਾਰ-ਪੱਧਰੀ ਨੈਟਵਰਕ** ਬਣਾਈਏ, ਜੋ ਅੱਖਰ ਦਰ ਅੱਖਰ ਪਾਠ ਤਿਆਰ ਕਰਦਾ ਹੈ। ਟ੍ਰੇਨਿੰਗ ਦੌਰਾਨ, ਸਾਨੂੰ ਕੁਝ ਪਾਠ ਕੋਰਪਸ ਲੈਣਾ ਪਵੇਗਾ ਅਤੇ ਇਸਨੂੰ ਅੱਖਰ ਕ੍ਰਮਾਂ ਵਿੱਚ ਵੰਡਣਾ ਪਵੇਗਾ।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "\n",
    "ds_train, ds_test = tfds.load('ag_news_subset').values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ਕਿਰਦਾਰ ਸ਼ਬਦਾਵਲੀ ਬਣਾਉਣਾ\n",
    "\n",
    "ਕਿਰਦਾਰ-ਪੱਧਰ ਦੀ ਜਨਰੇਟਿਵ ਨੈੱਟਵਰਕ ਬਣਾਉਣ ਲਈ, ਸਾਨੂੰ ਪੂਰੇ ਪਾਠ ਨੂੰ ਸ਼ਬਦਾਂ ਦੀ ਬਜਾਏ ਵਿਅਕਤੀਗਤ ਅੱਖਰਾਂ ਵਿੱਚ ਵੰਡਣਾ ਪਵੇਗਾ। `TextVectorization` ਲੇਅਰ, ਜਿਸਦਾ ਅਸੀਂ ਪਹਿਲਾਂ ਇਸਤੇਮਾਲ ਕਰ ਰਹੇ ਸਾਂ, ਇਹ ਕੰਮ ਨਹੀਂ ਕਰ ਸਕਦੀ, ਇਸ ਲਈ ਸਾਡੇ ਕੋਲ ਦੋ ਵਿਕਲਪ ਹਨ:\n",
    "\n",
    "* ਪਾਠ ਨੂੰ ਮੈਨੁਅਲ ਤੌਰ 'ਤੇ ਲੋਡ ਕਰਨਾ ਅਤੇ 'ਹੱਥੋਂ' ਟੋਕਨਾਈਜ਼ੇਸ਼ਨ ਕਰਨਾ, ਜਿਵੇਂ ਕਿ [ਇਸ ਅਧਿਕਾਰਤ Keras ਉਦਾਹਰਨ](https://keras.io/examples/generative/lstm_character_level_text_generation/) ਵਿੱਚ ਦਿਖਾਇਆ ਗਿਆ ਹੈ।\n",
    "* ਕਿਰਦਾਰ-ਪੱਧਰ ਦੀ ਟੋਕਨਾਈਜ਼ੇਸ਼ਨ ਲਈ `Tokenizer` ਕਲਾਸ ਦਾ ਇਸਤੇਮਾਲ ਕਰਨਾ।\n",
    "\n",
    "ਅਸੀਂ ਦੂਜੇ ਵਿਕਲਪ ਨਾਲ ਚੱਲਾਂਗੇ। `Tokenizer` ਨੂੰ ਸ਼ਬਦਾਂ ਵਿੱਚ ਟੋਕਨਾਈਜ਼ ਕਰਨ ਲਈ ਵੀ ਵਰਤਿਆ ਜਾ ਸਕਦਾ ਹੈ, ਇਸ ਲਈ ਕੋਈ ਵੀ ਆਸਾਨੀ ਨਾਲ ਕਿਰਦਾਰ-ਪੱਧਰ ਤੋਂ ਸ਼ਬਦ-ਪੱਧਰ ਦੀ ਟੋਕਨਾਈਜ਼ੇਸ਼ਨ ਵਿੱਚ ਬਦਲ ਸਕਦਾ ਹੈ।\n",
    "\n",
    "ਕਿਰਦਾਰ-ਪੱਧਰ ਦੀ ਟੋਕਨਾਈਜ਼ੇਸ਼ਨ ਕਰਨ ਲਈ, ਸਾਨੂੰ `char_level=True` ਪੈਰਾਮੀਟਰ ਪਾਸ ਕਰਨਾ ਪਵੇਗਾ:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(x):\n",
    "    return x['title']+' '+x['description']\n",
    "\n",
    "def tupelize(x):\n",
    "    return (extract_text(x),x['label'])\n",
    "\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True,lower=False)\n",
    "tokenizer.fit_on_texts([x['title'].numpy().decode('utf-8') for x in ds_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ਅਸੀਂ ਇੱਕ ਖਾਸ ਟੋਕਨ ਦੀ ਵਰਤੋਂ ਕਰਨੀ ਚਾਹੁੰਦੇ ਹਾਂ ਜੋ **ਅਨੁਕ੍ਰਮ ਦੇ ਅੰਤ** ਨੂੰ ਦਰਸਾਉਂਦਾ ਹੈ, ਜਿਸਨੂੰ ਅਸੀਂ `<eos>` ਕਹਾਂਗੇ। ਆਓ ਇਸਨੂੰ ਹੱਥੋਂ ਸ਼ਬਦਾਵਲੀ ਵਿੱਚ ਸ਼ਾਮਲ ਕਰੀਏ:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eos_token = len(tokenizer.word_index)+1\n",
    "tokenizer.word_index['<eos>'] = eos_token\n",
    "\n",
    "vocab_size = eos_token + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[48, 2, 10, 10, 5, 44, 1, 25, 5, 8, 10, 13, 78]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences(['Hello, world!'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ਜਨਰੇਟਿਵ RNN ਨੂੰ ਸਿਰਲੇਖ ਬਣਾਉਣ ਲਈ ਟ੍ਰੇਨ ਕਰਨਾ\n",
    "\n",
    "ਅਸੀਂ RNN ਨੂੰ ਖ਼ਬਰਾਂ ਦੇ ਸਿਰਲੇਖ ਬਣਾਉਣ ਲਈ ਇਸ ਤਰੀਕੇ ਨਾਲ ਟ੍ਰੇਨ ਕਰਾਂਗੇ। ਹਰ ਕਦਮ 'ਤੇ, ਅਸੀਂ ਇੱਕ ਸਿਰਲੇਖ ਲਵਾਂਗੇ, ਜਿਸਨੂੰ RNN ਵਿੱਚ ਫੀਡ ਕੀਤਾ ਜਾਵੇਗਾ, ਅਤੇ ਹਰ ਇਨਪੁਟ ਅੱਖਰ ਲਈ ਅਸੀਂ ਨੈੱਟਵਰਕ ਨੂੰ ਅਗਲਾ ਆਉਟਪੁਟ ਅੱਖਰ ਜਨਰੇਟ ਕਰਨ ਲਈ ਕਹਾਂਗੇ:\n",
    "\n",
    "![ਇੱਕ ਉਦਾਹਰਣ RNN 'HELLO' ਸ਼ਬਦ ਦੀ ਜਨਰੇਸ਼ਨ ਦਿਖਾਉਂਦੀ ਤਸਵੀਰ।](../../../../../translated_images/rnn-generate.56c54afb52f9781d63a7c16ea9c1b86cb70e6e1eae6a742b56b7b37468576b17.pa.png)\n",
    "\n",
    "ਸਾਡੇ ਕ੍ਰਮ ਦੇ ਆਖਰੀ ਅੱਖਰ ਲਈ, ਅਸੀਂ ਨੈੱਟਵਰਕ ਨੂੰ `<eos>` ਟੋਕਨ ਜਨਰੇਟ ਕਰਨ ਲਈ ਕਹਾਂਗੇ।\n",
    "\n",
    "ਜਨਰੇਟਿਵ RNN ਵਿੱਚ ਮੁੱਖ ਫਰਕ, ਜੋ ਅਸੀਂ ਇੱਥੇ ਵਰਤ ਰਹੇ ਹਾਂ, ਇਹ ਹੈ ਕਿ ਅਸੀਂ RNN ਦੇ ਹਰ ਕਦਮ ਤੋਂ ਆਉਟਪੁਟ ਲਵਾਂਗੇ, ਨਾ ਕਿ ਸਿਰਫ਼ ਆਖਰੀ ਸੈੱਲ ਤੋਂ। ਇਹ `return_sequences` ਪੈਰਾਮੀਟਰ ਨੂੰ RNN ਸੈੱਲ ਵਿੱਚ ਸੈਟ ਕਰਕੇ ਹਾਸਲ ਕੀਤਾ ਜਾ ਸਕਦਾ ਹੈ।\n",
    "\n",
    "ਇਸ ਤਰ੍ਹਾਂ, ਟ੍ਰੇਨਿੰਗ ਦੌਰਾਨ, ਨੈੱਟਵਰਕ ਲਈ ਇਨਪੁਟ ਕੁਝ ਲੰਬਾਈ ਦੇ ਐਨਕੋਡ ਕੀਤੇ ਅੱਖਰਾਂ ਦੀ ਲੜੀ ਹੋਵੇਗੀ, ਅਤੇ ਆਉਟਪੁਟ ਉਸੇ ਲੰਬਾਈ ਦੀ ਲੜੀ ਹੋਵੇਗੀ, ਪਰ ਇੱਕ ਤੱਤ ਨਾਲ ਸ਼ਿਫਟ ਕੀਤੀ ਹੋਈ ਅਤੇ `<eos>` ਨਾਲ ਖਤਮ ਕੀਤੀ ਹੋਈ। ਮਿਨੀਬੈਚ ਵਿੱਚ ਕਈ ਇਸ ਤਰ੍ਹਾਂ ਦੀਆਂ ਲੜੀਆਂ ਸ਼ਾਮਲ ਹੋਣਗੀਆਂ, ਅਤੇ ਸਾਰੀਆਂ ਲੜੀਆਂ ਨੂੰ ਇਕਸਾਰ ਕਰਨ ਲਈ ਸਾਨੂੰ **ਪੈਡਿੰਗ** ਦੀ ਲੋੜ ਹੋਵੇਗੀ।\n",
    "\n",
    "ਆਓ ਅਜਿਹੀਆਂ ਫੰਕਸ਼ਨ ਬਣਾਈਏ ਜੋ ਸਾਡੇ ਲਈ ਡੇਟਾਸੈਟ ਨੂੰ ਬਦਲਣਗੇ। ਕਿਉਂਕਿ ਅਸੀਂ ਮਿਨੀਬੈਚ ਪੱਧਰ 'ਤੇ ਲੜੀਆਂ ਨੂੰ ਪੈਡ ਕਰਨਾ ਚਾਹੁੰਦੇ ਹਾਂ, ਅਸੀਂ ਪਹਿਲਾਂ `.batch()` ਕਾਲ ਕਰਕੇ ਡੇਟਾਸੈਟ ਨੂੰ ਬੈਚ ਕਰਾਂਗੇ, ਅਤੇ ਫਿਰ ਇਸਨੂੰ ਬਦਲਣ ਲਈ `map` ਕਰਾਂਗੇ। ਇਸ ਲਈ, ਬਦਲਾਅ ਫੰਕਸ਼ਨ ਪੂਰੇ ਮਿਨੀਬੈਚ ਨੂੰ ਇੱਕ ਪੈਰਾਮੀਟਰ ਵਜੋਂ ਲਵੇਗਾ:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_batch(x):\n",
    "    x = [t.numpy().decode('utf-8') for t in x]\n",
    "    z = tokenizer.texts_to_sequences(x)\n",
    "    z = tf.keras.preprocessing.sequence.pad_sequences(z)\n",
    "    return tf.one_hot(z,vocab_size), tf.one_hot(tf.concat([z[:,1:],tf.constant(eos_token,shape=(len(z),1))],axis=1),vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ਕੁਝ ਮਹੱਤਵਪੂਰਨ ਗੱਲਾਂ ਜੋ ਅਸੀਂ ਇੱਥੇ ਕਰਦੇ ਹਾਂ:\n",
    "* ਅਸੀਂ ਪਹਿਲਾਂ ਸਟ੍ਰਿੰਗ ਟੈਂਸਰ ਤੋਂ ਅਸਲ ਟੈਕਸਟ ਨਿਕਾਲਦੇ ਹਾਂ\n",
    "* `text_to_sequences` ਸਟ੍ਰਿੰਗਜ਼ ਦੀ ਲਿਸਟ ਨੂੰ ਇੰਟੀਜਰ ਟੈਂਸਰਜ਼ ਦੀ ਲਿਸਟ ਵਿੱਚ ਬਦਲਦਾ ਹੈ\n",
    "* `pad_sequences` ਉਹ ਟੈਂਸਰਜ਼ ਨੂੰ ਉਨ੍ਹਾਂ ਦੀ ਵੱਧ ਤੋਂ ਵੱਧ ਲੰਬਾਈ ਤੱਕ ਪੈਡ ਕਰਦਾ ਹੈ\n",
    "* ਅਸੀਂ ਆਖਿਰ ਵਿੱਚ ਸਾਰੇ ਅੱਖਰਾਂ ਨੂੰ ਇੱਕ-ਹਾਟ ਐਨਕੋਡ ਕਰਦੇ ਹਾਂ, ਅਤੇ ਸ਼ਿਫਟਿੰਗ ਅਤੇ `<eos>` ਨੂੰ ਸ਼ਾਮਲ ਕਰਦੇ ਹਾਂ। ਜਲਦੀ ਹੀ ਅਸੀਂ ਦੇਖਾਂਗੇ ਕਿ ਸਾਨੂੰ ਇੱਕ-ਹਾਟ-ਐਨਕੋਡ ਕੀਤੇ ਅੱਖਰਾਂ ਦੀ ਲੋੜ ਕਿਉਂ ਹੈ\n",
    "\n",
    "ਹਾਲਾਂਕਿ, ਇਹ ਫੰਕਸ਼ਨ **Pythonic** ਹੈ, ਅਰਥਾਤ ਇਹ ਨੂੰ Tensorflow ਦੇ ਗਣਨਾਤਮਕ ਗ੍ਰਾਫ ਵਿੱਚ ਸਵੈਚਾਲਿਤ ਤੌਰ 'ਤੇ ਤਬਦੀਲ ਨਹੀਂ ਕੀਤਾ ਜਾ ਸਕਦਾ। ਜੇਕਰ ਅਸੀਂ ਇਸ ਫੰਕਸ਼ਨ ਨੂੰ ਸਿੱਧੇ `Dataset.map` ਫੰਕਸ਼ਨ ਵਿੱਚ ਵਰਤਣ ਦੀ ਕੋਸ਼ਿਸ਼ ਕਰਦੇ ਹਾਂ ਤਾਂ ਅਸੀਂ ਗਲਤੀਆਂ ਪ੍ਰਾਪਤ ਕਰਾਂਗੇ। ਸਾਨੂੰ ਇਸ Pythonic ਕਾਲ ਨੂੰ `py_function` ਰੈਪਰ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਘੇਰਨਾ ਪਵੇਗਾ:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_batch_fn(x):\n",
    "    x = x['title']\n",
    "    a,b = tf.py_function(title_batch,inp=[x],Tout=(tf.float32,tf.float32))\n",
    "    return a,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **ਨੋਟ**: ਪਾਇਥਨਿਕ ਅਤੇ ਟੈਂਸਰਫਲੋ ਟ੍ਰਾਂਸਫਾਰਮੇਸ਼ਨ ਫੰਕਸ਼ਨਾਂ ਵਿੱਚ ਅੰਤਰ ਕਰਨਾ ਕਈ ਵਾਰ ਥੋੜ੍ਹਾ ਜਟਿਲ ਲੱਗ ਸਕਦਾ ਹੈ, ਅਤੇ ਤੁਸੀਂ ਸੋਚ ਰਹੇ ਹੋ ਸਕਦੇ ਹੋ ਕਿ ਅਸੀਂ ਡਾਟਾਸੈਟ ਨੂੰ `fit` ਨੂੰ ਪਾਸ ਕਰਨ ਤੋਂ ਪਹਿਲਾਂ ਸਧਾਰਨ ਪਾਇਥਨ ਫੰਕਸ਼ਨਾਂ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਕਿਉਂ ਨਹੀਂ ਬਦਲਦੇ। ਹਾਲਾਂਕਿ ਇਹ ਜ਼ਰੂਰ ਕੀਤਾ ਜਾ ਸਕਦਾ ਹੈ, ਪਰ `Dataset.map` ਦੀ ਵਰਤੋਂ ਕਰਨ ਦਾ ਇੱਕ ਵੱਡਾ ਫਾਇਦਾ ਹੈ, ਕਿਉਂਕਿ ਡਾਟਾ ਟ੍ਰਾਂਸਫਾਰਮੇਸ਼ਨ ਪਾਈਪਲਾਈਨ ਟੈਂਸਰਫਲੋ ਕੰਪਿਊਟੇਸ਼ਨਲ ਗ੍ਰਾਫ ਦੀ ਵਰਤੋਂ ਕਰਦੀ ਹੈ, ਜੋ GPU ਗਣਨਾਵਾਂ ਦਾ ਲਾਭ ਲੈਂਦੀ ਹੈ ਅਤੇ CPU/GPU ਦੇ ਵਿਚਕਾਰ ਡਾਟਾ ਪਾਸ ਕਰਨ ਦੀ ਲੋੜ ਨੂੰ ਘਟਾਉਂਦੀ ਹੈ।\n",
    "\n",
    "ਹੁਣ ਅਸੀਂ ਆਪਣਾ ਜਨਰੇਟਰ ਨੈਟਵਰਕ ਬਣਾਉਣ ਅਤੇ ਟ੍ਰੇਨਿੰਗ ਸ਼ੁਰੂ ਕਰਨ ਦੇ ਯੋਗ ਹਾਂ। ਇਹ ਕਿਸੇ ਵੀ ਰੀਕਰਨਟ ਸੈੱਲ 'ਤੇ ਆਧਾਰਿਤ ਹੋ ਸਕਦਾ ਹੈ ਜਿਸ ਬਾਰੇ ਅਸੀਂ ਪਿਛਲੇ ਯੂਨਿਟ ਵਿੱਚ ਚਰਚਾ ਕੀਤੀ ਸੀ (ਸਧਾਰਨ, LSTM ਜਾਂ GRU)। ਸਾਡੇ ਉਦਾਹਰਨ ਵਿੱਚ ਅਸੀਂ LSTM ਦੀ ਵਰਤੋਂ ਕਰਾਂਗੇ।\n",
    "\n",
    "ਕਿਉਂਕਿ ਨੈਟਵਰਕ ਅੱਖਰਾਂ ਨੂੰ ਇਨਪੁਟ ਵਜੋਂ ਲੈਂਦਾ ਹੈ, ਅਤੇ ਸ਼ਬਦਾਵਲੀ ਦਾ ਆਕਾਰ ਕਾਫ਼ੀ ਛੋਟਾ ਹੈ, ਸਾਨੂੰ ਐਮਬੈਡਿੰਗ ਲੇਅਰ ਦੀ ਲੋੜ ਨਹੀਂ ਹੈ। ਇੱਕ-ਹਾਟ-ਇਨਕੋਡ ਕੀਤੇ ਇਨਪੁਟ ਨੂੰ ਸਿੱਧੇ LSTM ਸੈੱਲ ਵਿੱਚ ਭੇਜਿਆ ਜਾ ਸਕਦਾ ਹੈ। ਆਉਟਪੁਟ ਲੇਅਰ ਇੱਕ `Dense` ਕਲਾਸੀਫਾਇਰ ਹੋਵੇਗਾ ਜੋ LSTM ਦੇ ਆਉਟਪੁਟ ਨੂੰ ਇੱਕ-ਹਾਟ-ਇਨਕੋਡ ਟੋਕਨ ਨੰਬਰਾਂ ਵਿੱਚ ਬਦਲੇਗਾ।\n",
    "\n",
    "ਇਸ ਦੇ ਇਲਾਵਾ, ਕਿਉਂਕਿ ਅਸੀਂ ਵੈਰੀਏਬਲ-ਲੰਬਾਈ ਵਾਲੀਆਂ ਸੀਕਵੈਂਸਾਂ ਨਾਲ ਡੀਲ ਕਰ ਰਹੇ ਹਾਂ, ਅਸੀਂ `Masking` ਲੇਅਰ ਦੀ ਵਰਤੋਂ ਕਰ ਸਕਦੇ ਹਾਂ ਜੋ ਸਟ੍ਰਿੰਗ ਦੇ ਪੈਡ ਕੀਤੇ ਹਿੱਸੇ ਨੂੰ ਅਣਡਿੱਠਾ ਕਰ ਦੇਵੇ। ਇਹ ਸਖ਼ਤ ਤੌਰ 'ਤੇ ਲੋੜੀਂਦਾ ਨਹੀਂ ਹੈ, ਕਿਉਂਕਿ ਅਸੀਂ `<eos>` ਟੋਕਨ ਤੋਂ ਅੱਗੇ ਵਾਲੀ ਹਰ ਚੀਜ਼ ਵਿੱਚ ਬਹੁਤ ਜ਼ਿਆਦਾ ਦਿਲਚਸਪੀ ਨਹੀਂ ਰੱਖਦੇ, ਪਰ ਅਸੀਂ ਇਸ ਲੇਅਰ ਦੀ ਕਿਸਮ ਨਾਲ ਕੁਝ ਤਜਰਬਾ ਪ੍ਰਾਪਤ ਕਰਨ ਲਈ ਇਸਦੀ ਵਰਤੋਂ ਕਰਾਂਗੇ। `input_shape` `(None, vocab_size)` ਹੋਵੇਗਾ, ਜਿੱਥੇ `None` ਵੈਰੀਏਬਲ ਲੰਬਾਈ ਵਾਲੀ ਸੀਕਵੈਂਸ ਨੂੰ ਦਰਸਾਉਂਦਾ ਹੈ, ਅਤੇ ਆਉਟਪੁਟ ਸ਼ੇਪ ਵੀ `(None, vocab_size)` ਹੈ, ਜਿਵੇਂ ਕਿ ਤੁਸੀਂ `summary` ਤੋਂ ਵੇਖ ਸਕਦੇ ਹੋ।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking (Masking)            (None, None, 84)          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, None, 128)         109056    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, None, 84)          10836     \n",
      "=================================================================\n",
      "Total params: 119,892\n",
      "Trainable params: 119,892\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "15000/15000 [==============================] - 229s 15ms/step - loss: 1.5385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa40c1245e0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Masking(input_shape=(None,vocab_size)),\n",
    "    keras.layers.LSTM(128,return_sequences=True),\n",
    "    keras.layers.Dense(vocab_size,activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy')\n",
    "\n",
    "model.fit(ds_train.batch(8).map(title_batch_fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ਆਉਟਪੁੱਟ ਤਿਆਰ ਕਰਨਾ\n",
    "\n",
    "ਹੁਣ ਜਦੋਂ ਕਿ ਅਸੀਂ ਮਾਡਲ ਨੂੰ ਟ੍ਰੇਨ ਕਰ ਲਿਆ ਹੈ, ਅਸੀਂ ਇਸਨੂੰ ਕੁਝ ਆਉਟਪੁੱਟ ਤਿਆਰ ਕਰਨ ਲਈ ਵਰਤਣਾ ਚਾਹੁੰਦੇ ਹਾਂ। ਸਭ ਤੋਂ ਪਹਿਲਾਂ, ਸਾਨੂੰ ਟੋਕਨ ਨੰਬਰਾਂ ਦੀ ਲੜੀ ਦੁਆਰਾ ਦਰਸਾਏ ਗਏ ਟੈਕਸਟ ਨੂੰ ਡਿਕੋਡ ਕਰਨ ਦਾ ਇੱਕ ਤਰੀਕਾ ਚਾਹੀਦਾ ਹੈ। ਇਸ ਲਈ, ਅਸੀਂ `tokenizer.sequences_to_texts` ਫੰਕਸ਼ਨ ਦੀ ਵਰਤੋਂ ਕਰ ਸਕਦੇ ਹਾਂ; ਹਾਲਾਂਕਿ, ਇਹ ਕਿਰਦਾਰ-ਪੱਧਰ ਟੋਕਨਾਈਜ਼ੇਸ਼ਨ ਨਾਲ ਚੰਗਾ ਕੰਮ ਨਹੀਂ ਕਰਦਾ। ਇਸ ਲਈ ਅਸੀਂ ਟੋਕਨਾਈਜ਼ਰ ਤੋਂ ਟੋਕਨ ਦਾ ਇੱਕ ਡਿਕਸ਼ਨਰੀ (ਜਿਸਨੂੰ `word_index` ਕਿਹਾ ਜਾਂਦਾ ਹੈ) ਲੈਣਗੇ, ਇੱਕ ਰਿਵਰਸ ਮੈਪ ਬਣਾਉਣਗੇ, ਅਤੇ ਆਪਣਾ ਡਿਕੋਡਿੰਗ ਫੰਕਸ਼ਨ ਲਿਖਾਂਗੇ:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_map = {val:key for key, val in tokenizer.word_index.items()}\n",
    "\n",
    "def decode(x):\n",
    "    return ''.join([reverse_map[t] for t in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ਚਲੋ ਹੁਣ ਜਨਰੇਸ਼ਨ ਕਰਦੇ ਹਾਂ। ਅਸੀਂ ਕੁਝ ਸਤਰ `start` ਨਾਲ ਸ਼ੁਰੂ ਕਰਾਂਗੇ, ਇਸਨੂੰ ਇੱਕ ਕ੍ਰਮ `inp` ਵਿੱਚ ਐਨਕੋਡ ਕਰਾਂਗੇ, ਅਤੇ ਫਿਰ ਹਰ ਕਦਮ 'ਤੇ ਅਸੀਂ ਆਪਣਾ ਨੈਟਵਰਕ ਕਾਲ ਕਰਾਂਗੇ ਤਾਂ ਜੋ ਅਗਲਾ ਅੱਖਰ ਪਤਾ ਲਗਾਇਆ ਜਾ ਸਕੇ।\n",
    "\n",
    "ਨੈਟਵਰਕ ਦਾ ਆਉਟਪੁੱਟ `out` ਇੱਕ ਵੇਕਟਰ ਹੁੰਦਾ ਹੈ ਜਿਸ ਵਿੱਚ `vocab_size` ਤੱਤ ਹੁੰਦੇ ਹਨ ਜੋ ਹਰ ਟੋਕਨ ਦੀ ਸੰਭਾਵਨਾ ਦਰਸਾਉਂਦੇ ਹਨ। ਅਸੀਂ `argmax` ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਸਭ ਤੋਂ ਸੰਭਾਵਿਤ ਟੋਕਨ ਨੰਬਰ ਲੱਭ ਸਕਦੇ ਹਾਂ। ਫਿਰ ਅਸੀਂ ਇਸ ਅੱਖਰ ਨੂੰ ਜਨਰੇਟ ਕੀਤੇ ਟੋਕਨ ਦੀ ਸੂਚੀ ਵਿੱਚ ਸ਼ਾਮਲ ਕਰਦੇ ਹਾਂ ਅਤੇ ਜਨਰੇਸ਼ਨ ਜਾਰੀ ਰੱਖਦੇ ਹਾਂ। ਇੱਕ ਅੱਖਰ ਜਨਰੇਟ ਕਰਨ ਦੀ ਇਹ ਪ੍ਰਕਿਰਿਆ `size` ਵਾਰ ਦੁਹਰਾਈ ਜਾਂਦੀ ਹੈ ਤਾਂ ਜੋ ਲੋੜੀਂਦੇ ਅੱਖਰਾਂ ਦੀ ਗਿਣਤੀ ਜਨਰੇਟ ਕੀਤੀ ਜਾ ਸਕੇ, ਅਤੇ ਜਦੋਂ `eos_token` ਮਿਲਦਾ ਹੈ ਤਾਂ ਅਸੀਂ ਜਲਦੀ ਰੋਕ ਦਿੰਦੇ ਹਾਂ।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Today #39;s lead to strike for the strike for the strike for the strike (AFP)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate(model,size=100,start='Today '):\n",
    "        inp = tokenizer.texts_to_sequences([start])[0]\n",
    "        chars = inp\n",
    "        for i in range(size):\n",
    "            out = model(tf.expand_dims(tf.one_hot(inp,vocab_size),0))[0][-1]\n",
    "            nc = tf.argmax(out)\n",
    "            if nc==eos_token:\n",
    "                break\n",
    "            chars.append(nc.numpy())\n",
    "            inp = inp+[nc]\n",
    "        return decode(chars)\n",
    "    \n",
    "generate(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ਟ੍ਰੇਨਿੰਗ ਦੌਰਾਨ ਆਉਟਪੁੱਟ ਸੈਂਪਲ ਕਰਨਾ\n",
    "\n",
    "ਕਿਉਂਕਿ ਸਾਡੇ ਕੋਲ *ਸਹੀਤਾ* ਵਰਗੇ ਕੋਈ ਲਾਭਦਾਇਕ ਮਾਪਦੰਡ ਨਹੀਂ ਹਨ, ਸਾਨੂੰ ਇਹ ਦੇਖਣ ਦਾ ਇੱਕੋ ਤਰੀਕਾ ਹੈ ਕਿ ਸਾਡਾ ਮਾਡਲ ਬਿਹਤਰ ਹੋ ਰਿਹਾ ਹੈ ਜਾਂ ਨਹੀਂ, **ਟ੍ਰੇਨਿੰਗ ਦੌਰਾਨ ਜਨਰੇਟ ਕੀਤੇ ਸਟਰਿੰਗ ਨੂੰ ਸੈਂਪਲ ਕਰਨਾ**। ਇਸ ਨੂੰ ਕਰਨ ਲਈ, ਅਸੀਂ **ਕਾਲਬੈਕਸ** ਵਰਤਾਂਗੇ, ਜ਼ਿਆਨੀ ਉਹ ਫੰਕਸ਼ਨ ਜੋ ਅਸੀਂ `fit` ਫੰਕਸ਼ਨ ਨੂੰ ਪਾਸ ਕਰ ਸਕਦੇ ਹਾਂ ਅਤੇ ਜੋ ਟ੍ਰੇਨਿੰਗ ਦੌਰਾਨ ਸਮਯਸਮਯ ਤੇ ਕਾਲ ਕੀਤੇ ਜਾਣਗੇ।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "15000/15000 [==============================] - 226s 15ms/step - loss: 1.2703\n",
      "Today #39;s a lead in the company for the strike\n",
      "Epoch 2/3\n",
      "15000/15000 [==============================] - 227s 15ms/step - loss: 1.2057\n",
      "Today #39;s the Market Service on Security Start (AP)\n",
      "Epoch 3/3\n",
      "15000/15000 [==============================] - 226s 15ms/step - loss: 1.1752\n",
      "Today #39;s a line on the strike to start for the start\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa40c74e3d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling_callback = keras.callbacks.LambdaCallback(\n",
    "  on_epoch_end = lambda batch, logs: print(generate(model))\n",
    ")\n",
    "\n",
    "model.fit(ds_train.batch(8).map(title_batch_fn),callbacks=[sampling_callback],epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ਇਹ ਉਦਾਹਰਨ ਪਹਿਲਾਂ ਹੀ ਕਾਫ਼ੀ ਵਧੀਆ ਟੈਕਸਟ ਤਿਆਰ ਕਰਦਾ ਹੈ, ਪਰ ਇਸਨੂੰ ਕਈ ਤਰੀਕਿਆਂ ਨਾਲ ਹੋਰ ਬਿਹਤਰ ਬਣਾਇਆ ਜਾ ਸਕਦਾ ਹੈ:\n",
    "\n",
    "* **ਹੋਰ ਟੈਕਸਟ**। ਅਸੀਂ ਸਿਰਫ਼ ਸਿਰਲੇਖਾਂ ਨੂੰ ਆਪਣੇ ਕੰਮ ਲਈ ਵਰਤਿਆ ਹੈ, ਪਰ ਤੁਸੀਂ ਪੂਰੇ ਟੈਕਸਟ ਨਾਲ ਅਨੁਭਵ ਕਰਨਾ ਚਾਹੋਗੇ। ਯਾਦ ਰੱਖੋ ਕਿ RNNs ਲੰਬੇ ਕ੍ਰਮਾਂ ਨੂੰ ਸੰਭਾਲਣ ਵਿੱਚ ਬਹੁਤ ਵਧੀਆ ਨਹੀਂ ਹੁੰਦੇ, ਇਸ ਲਈ ਇਹ ਸਮਝਦਾਰੀ ਹੈ ਕਿ ਜਾਂ ਤਾਂ ਉਨ੍ਹਾਂ ਨੂੰ ਛੋਟੇ ਵਾਕਾਂ ਵਿੱਚ ਵੰਡਿਆ ਜਾਵੇ, ਜਾਂ ਹਮੇਸ਼ਾ ਕਿਸੇ ਪੂਰਵ-ਨਿਰਧਾਰਤ ਮੁੱਲ `num_chars` (ਕਹੋ, 256) ਦੇ ਫਿਕਸ ਕ੍ਰਮ ਦੀ ਲੰਬਾਈ 'ਤੇ ਟ੍ਰੇਨ ਕੀਤਾ ਜਾਵੇ। ਤੁਸੀਂ ਉਪਰੋਕਤ ਉਦਾਹਰਨ ਨੂੰ ਇਸ ਤਰ੍ਹਾਂ ਦੀ ਆਰਚਿਟੈਕਚਰ ਵਿੱਚ ਬਦਲਣ ਦੀ ਕੋਸ਼ਿਸ਼ ਕਰ ਸਕਦੇ ਹੋ, [ਅਧਿਕਾਰਕ Keras ਟਿਊਟੋਰਿਅਲ](https://keras.io/examples/generative/lstm_character_level_text_generation/) ਨੂੰ ਪ੍ਰੇਰਣਾ ਵਜੋਂ ਵਰਤਦੇ ਹੋਏ।\n",
    "\n",
    "* **ਮਲਟੀਲੇਅਰ LSTM**। 2 ਜਾਂ 3 LSTM ਸੈਲ ਲੇਅਰਾਂ ਦੀ ਕੋਸ਼ਿਸ਼ ਕਰਨਾ ਸਮਝਦਾਰੀ ਹੈ। ਜਿਵੇਂ ਅਸੀਂ ਪਿਛਲੇ ਯੂਨਿਟ ਵਿੱਚ ਜ਼ਿਕਰ ਕੀਤਾ ਸੀ, LSTM ਦੀ ਹਰ ਲੇਅਰ ਟੈਕਸਟ ਤੋਂ ਕੁਝ ਪੈਟਰਨ ਕੱਢਦੀ ਹੈ, ਅਤੇ ਕਿਰਦਾਰ-ਸਤਰ ਜਨਰੇਟਰ ਦੇ ਮਾਮਲੇ ਵਿੱਚ ਅਸੀਂ ਉਮੀਦ ਕਰ ਸਕਦੇ ਹਾਂ ਕਿ ਹੇਠਲੀ LSTM ਲੇਅਰ ਅੱਖਰਾਂ ਨੂੰ ਕੱਢਣ ਲਈ ਜ਼ਿੰਮੇਵਾਰ ਹੋਵੇਗੀ, ਅਤੇ ਉੱਚੀ ਲੇਅਰਾਂ - ਸ਼ਬਦ ਅਤੇ ਸ਼ਬਦ ਸੰਯੋਜਨਾਂ ਲਈ। ਇਹ ਸਿਰਫ਼ LSTM ਕੰਸਟ੍ਰਕਟਰ ਨੂੰ ਲੇਅਰਾਂ ਦੀ ਗਿਣਤੀ-ਪੈਰਾਮੀਟਰ ਪਾਸ ਕਰਕੇ ਲਾਗੂ ਕੀਤਾ ਜਾ ਸਕਦਾ ਹੈ।\n",
    "\n",
    "* ਤੁਸੀਂ **GRU ਯੂਨਿਟਾਂ** ਨਾਲ ਅਨੁਭਵ ਕਰਨ ਦੀ ਕੋਸ਼ਿਸ਼ ਕਰ ਸਕਦੇ ਹੋ ਅਤੇ ਵੇਖ ਸਕਦੇ ਹੋ ਕਿ ਕਿਹੜੇ ਵਧੀਆ ਪ੍ਰਦਰਸ਼ਨ ਕਰਦੇ ਹਨ, ਅਤੇ **ਵੱਖ-ਵੱਖ ਛੁਪੇ ਹੋਏ ਲੇਅਰ ਸਾਈਜ਼ਾਂ** ਨਾਲ। ਬਹੁਤ ਵੱਡਾ ਛੁਪਾ ਲੇਅਰ ਅਤਿ-ਫਿਟਿੰਗ ਦਾ ਕਾਰਨ ਬਣ ਸਕਦਾ ਹੈ (ਉਦਾਹਰਨ ਲਈ, ਨੈਟਵਰਕ ਸਹੀ ਟੈਕਸਟ ਸਿੱਖ ਲਵੇਗਾ), ਅਤੇ ਛੋਟਾ ਸਾਈਜ਼ ਚੰਗੇ ਨਤੀਜੇ ਨਹੀਂ ਦੇ ਸਕਦਾ।\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ਨਰਮ ਟੈਕਸਟ ਜਨਰੇਸ਼ਨ ਅਤੇ ਟੈਂਪਰੇਚਰ\n",
    "\n",
    "ਪਿਛਲੀ ਵਿਆਖਿਆ ਵਿੱਚ `generate`, ਅਸੀਂ ਹਮੇਸ਼ਾ ਉਹ ਅੱਖਰ ਲੈਂਦੇ ਸੀ ਜਿਸਦੀ ਸੰਭਾਵਨਾ ਸਭ ਤੋਂ ਉੱਚੀ ਹੁੰਦੀ ਸੀ, ਇਸਨੂੰ ਜਨਰੇਟ ਕੀਤੇ ਗਏ ਟੈਕਸਟ ਵਿੱਚ ਅਗਲਾ ਅੱਖਰ ਬਣਾਉਣ ਲਈ। ਇਸ ਦਾ ਨਤੀਜਾ ਇਹ ਸੀ ਕਿ ਟੈਕਸਟ ਅਕਸਰ \"ਚੱਕਰ\" ਵਿੱਚ ਫਸ ਜਾਂਦਾ ਸੀ ਅਤੇ ਵਾਰ-ਵਾਰ ਉਹੀ ਅੱਖਰ ਕ੍ਰਮ ਦੁਹਰਾਇਆ ਜਾਂਦਾ ਸੀ, ਜਿਵੇਂ ਇਸ ਉਦਾਹਰਨ ਵਿੱਚ:\n",
    "```\n",
    "today of the second the company and a second the company ...\n",
    "```\n",
    "\n",
    "ਪਰ ਜੇ ਅਸੀਂ ਅਗਲੇ ਅੱਖਰ ਲਈ ਸੰਭਾਵਨਾ ਵੰਡ ਨੂੰ ਦੇਖੀਏ, ਤਾਂ ਇਹ ਹੋ ਸਕਦਾ ਹੈ ਕਿ ਕੁਝ ਸਭ ਤੋਂ ਉੱਚੀਆਂ ਸੰਭਾਵਨਾਵਾਂ ਵਿੱਚ ਜ਼ਿਆਦਾ ਫਰਕ ਨਾ ਹੋਵੇ, ਜਿਵੇਂ ਕਿ ਇੱਕ ਅੱਖਰ ਦੀ ਸੰਭਾਵਨਾ 0.2 ਹੋ ਸਕਦੀ ਹੈ, ਦੂਜੇ ਦੀ 0.19, ਆਦਿ। ਉਦਾਹਰਨ ਲਈ, ਜਦੋਂ ਅੱਖਰ ਕ੍ਰਮ '*play*' ਵਿੱਚ ਅਗਲੇ ਅੱਖਰ ਦੀ ਭਾਲ ਕਰਦੇ ਹਾਂ, ਤਾਂ ਅਗਲਾ ਅੱਖਰ ਬਰਾਬਰ ਹੀ ਸਪੇਸ ਹੋ ਸਕਦਾ ਹੈ ਜਾਂ **e** (ਜਿਵੇਂ ਸ਼ਬਦ *player* ਵਿੱਚ)।\n",
    "\n",
    "ਇਸ ਤੋਂ ਸਾਨੂੰ ਇਹ ਨਤੀਜਾ ਕੱਢਣ ਨੂੰ ਮਿਲਦਾ ਹੈ ਕਿ ਹਮੇਸ਼ਾ ਸਭ ਤੋਂ ਉੱਚੀ ਸੰਭਾਵਨਾ ਵਾਲੇ ਅੱਖਰ ਨੂੰ ਚੁਣਨਾ \"ਨਿਆਂਪੂਰਨ\" ਨਹੀਂ ਹੈ, ਕਿਉਂਕਿ ਦੂਜੀ ਸਭ ਤੋਂ ਉੱਚੀ ਸੰਭਾਵਨਾ ਵਾਲੇ ਅੱਖਰ ਨੂੰ ਚੁਣਨਾ ਵੀ ਸਾਰਥਕ ਟੈਕਸਟ ਤੱਕ ਲੈ ਜਾ ਸਕਦਾ ਹੈ। ਇਹ ਜ਼ਿਆਦਾ ਸਮਝਦਾਰੀ ਵਾਲੀ ਗੱਲ ਹੈ ਕਿ ਨੈੱਟਵਰਕ ਆਉਟਪੁੱਟ ਦੁਆਰਾ ਦਿੱਤੀ ਗਈ ਸੰਭਾਵਨਾ ਵੰਡ ਤੋਂ **ਨਮੂਨਾ ਲਿਆ ਜਾਵੇ**।\n",
    "\n",
    "ਇਹ ਨਮੂਨਾ `np.multinomial` ਫੰਕਸ਼ਨ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਲਿਆ ਜਾ ਸਕਦਾ ਹੈ, ਜੋ ਕਿ ਇਸੇ ਨੂੰ ਕਿਹਾ ਜਾਂਦਾ ਹੈ **ਮਲਟੀਨੋਮਿਅਲ ਵੰਡ**। ਇੱਕ ਫੰਕਸ਼ਨ ਜੋ ਇਸ ਤਰ੍ਹਾਂ ਦੇ **ਨਰਮ** ਟੈਕਸਟ ਜਨਰੇਸ਼ਨ ਨੂੰ ਲਾਗੂ ਕਰਦਾ ਹੈ, ਹੇਠਾਂ ਦਿੱਤਾ ਗਿਆ ਹੈ:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Temperature = 0.3\n",
      "Today #39;s strike #39; to start at the store return\n",
      "On Sunday PO to Be Data Profit Up (Reuters)\n",
      "Moscow, SP wins straight to the Microsoft #39;s control of the space start\n",
      "President olding of the blast start for the strike to pay &lt;b&gt;...&lt;/b&gt;\n",
      "Little red riding hood ficed to the spam countered in European &lt;b&gt;...&lt;/b&gt;\n",
      "\n",
      "--- Temperature = 0.8\n",
      "Today countie strikes ryder missile faces food market blut\n",
      "On Sunday collores lose-toppy of sale of Bullment in &lt;b&gt;...&lt;/b&gt;\n",
      "Moscow, IBM Diffeiting in Afghan Software Hotels (Reuters)\n",
      "President Ol Luster for Profit Peaced Raised (AP)\n",
      "Little red riding hood dace on depart talks #39; bank up\n",
      "\n",
      "--- Temperature = 1.0\n",
      "Today wits House buiting debate fixes #39; supervice stake again\n",
      "On Sunday arling digital poaching In for level\n",
      "Moscow, DS Up 7, Top Proble Protest Caprey Mamarian Strike\n",
      "President teps help of roubler stepted lessabul-Dhalitics (AFP)\n",
      "Little red riding hood signs on cash in Carter-youb\n",
      "\n",
      "--- Temperature = 1.3\n",
      "Today wits flawer ro, pSIA figat's co DroftwavesIs Talo up\n",
      "On Sunday hround elitwing wint EU Powerburlinetien\n",
      "Moscow, Bazz #39;s sentries olymen winnelds' next for Olympite Huc?\n",
      "President lost securitys from power Elections in Smiltrials\n",
      "Little red riding hood vides profit, exponituity, profitmainalist-at said listers\n",
      "\n",
      "--- Temperature = 1.8\n",
      "Today #39;It: He deat: N.KA Asside\n",
      "On Sunday i arry Par aldeup patient Wo stele1\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-db32367a0feb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n--- Temperature = {i}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_soft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-db32367a0feb>\u001b[0m in \u001b[0;36mgenerate_soft\u001b[0;34m(model, size, start, temperature)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mchars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Today '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'On Sunday '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Moscow, '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'President '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Little red riding hood '\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-3f5fa6130b1d>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreverse_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-3f5fa6130b1d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreverse_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "def generate_soft(model,size=100,start='Today ',temperature=1.0):\n",
    "        inp = tokenizer.texts_to_sequences([start])[0]\n",
    "        chars = inp\n",
    "        for i in range(size):\n",
    "            out = model(tf.expand_dims(tf.one_hot(inp,vocab_size),0))[0][-1]\n",
    "            probs = tf.exp(tf.math.log(out)/temperature).numpy().astype(np.float64)\n",
    "            probs = probs/np.sum(probs)\n",
    "            nc = np.argmax(np.random.multinomial(1,probs,1))\n",
    "            if nc==eos_token:\n",
    "                break\n",
    "            chars.append(nc)\n",
    "            inp = inp+[nc]\n",
    "        return decode(chars)\n",
    "\n",
    "words = ['Today ','On Sunday ','Moscow, ','President ','Little red riding hood ']\n",
    "    \n",
    "for i in [0.3,0.8,1.0,1.3,1.8]:\n",
    "    print(f\"\\n--- Temperature = {i}\")\n",
    "    for j in range(5):\n",
    "        print(generate_soft(model,size=300,start=words[j],temperature=i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ਅਸੀਂ ਇੱਕ ਹੋਰ ਪੈਰਾਮੀਟਰ ਪੇਸ਼ ਕੀਤਾ ਹੈ ਜਿਸਨੂੰ **ਤਾਪਮਾਨ** ਕਿਹਾ ਜਾਂਦਾ ਹੈ, ਜੋ ਇਹ ਦਰਸਾਉਣ ਲਈ ਵਰਤਿਆ ਜਾਂਦਾ ਹੈ ਕਿ ਸਾਨੂੰ ਸਭ ਤੋਂ ਉੱਚੀ ਸੰਭਾਵਨਾ ਨਾਲ ਕਿੰਨਾ ਕੜਾਈ ਨਾਲ ਚਿਪਕਣਾ ਚਾਹੀਦਾ ਹੈ। ਜੇ ਤਾਪਮਾਨ 1.0 ਹੈ, ਤਾਂ ਅਸੀਂ ਨਿਆਇਕ ਮਲਟੀਨੋਮਿਅਲ ਸੈਂਪਲਿੰਗ ਕਰਦੇ ਹਾਂ, ਅਤੇ ਜਦੋਂ ਤਾਪਮਾਨ ਅਨੰਤ ਵੱਲ ਜਾਂਦਾ ਹੈ - ਸਾਰੀਆਂ ਸੰਭਾਵਨਾਵਾਂ ਬਰਾਬਰ ਹੋ ਜਾਂਦੀਆਂ ਹਨ, ਅਤੇ ਅਸੀਂ ਅਗਲਾ ਅੱਖਰ ਬੇਤਰਤੀਬੀ ਨਾਲ ਚੁਣਦੇ ਹਾਂ। ਹੇਠਾਂ ਦਿੱਤੇ ਉਦਾਹਰਨ ਵਿੱਚ ਅਸੀਂ ਦੇਖ ਸਕਦੇ ਹਾਂ ਕਿ ਜਦੋਂ ਅਸੀਂ ਤਾਪਮਾਨ ਨੂੰ ਬਹੁਤ ਜ਼ਿਆਦਾ ਵਧਾਉਂਦੇ ਹਾਂ ਤਾਂ ਪਾਠ ਬੇਮਤਲਬ ਹੋ ਜਾਂਦਾ ਹੈ, ਅਤੇ ਜਦੋਂ ਇਹ 0 ਦੇ ਨੇੜੇ ਹੋ ਜਾਂਦਾ ਹੈ ਤਾਂ ਇਹ \"ਚੱਕਰਦਾਰ\" ਕਠੋਰ-ਉਤਪੰਨ ਪਾਠ ਵਰਗਾ ਲੱਗਦਾ ਹੈ।\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**ਅਸਵੀਕਰਤੀ**:  \nਇਹ ਦਸਤਾਵੇਜ਼ AI ਅਨੁਵਾਦ ਸੇਵਾ [Co-op Translator](https://github.com/Azure/co-op-translator) ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਅਨੁਵਾਦ ਕੀਤਾ ਗਿਆ ਹੈ। ਜਦੋਂ ਕਿ ਅਸੀਂ ਸਹੀ ਹੋਣ ਦਾ ਯਤਨ ਕਰਦੇ ਹਾਂ, ਕਿਰਪਾ ਕਰਕੇ ਧਿਆਨ ਦਿਓ ਕਿ ਸਵੈਚਾਲਿਤ ਅਨੁਵਾਦਾਂ ਵਿੱਚ ਗਲਤੀਆਂ ਜਾਂ ਅਸੁੱਛਤਾਵਾਂ ਹੋ ਸਕਦੀਆਂ ਹਨ। ਇਸ ਦੀ ਮੂਲ ਭਾਸ਼ਾ ਵਿੱਚ ਮੌਜੂਦ ਮੂਲ ਦਸਤਾਵੇਜ਼ ਨੂੰ ਅਧਿਕਾਰਤ ਸਰੋਤ ਮੰਨਿਆ ਜਾਣਾ ਚਾਹੀਦਾ ਹੈ। ਮਹੱਤਵਪੂਰਨ ਜਾਣਕਾਰੀ ਲਈ, ਪੇਸ਼ੇਵਰ ਮਨੁੱਖੀ ਅਨੁਵਾਦ ਦੀ ਸਿਫਾਰਸ਼ ਕੀਤੀ ਜਾਂਦੀ ਹੈ। ਇਸ ਅਨੁਵਾਦ ਦੇ ਪ੍ਰਯੋਗ ਤੋਂ ਪੈਦਾ ਹੋਣ ਵਾਲੇ ਕਿਸੇ ਵੀ ਗਲਤਫਹਮੀਆਂ ਜਾਂ ਗਲਤ ਵਿਆਖਿਆਵਾਂ ਲਈ ਅਸੀਂ ਜ਼ਿੰਮੇਵਾਰ ਨਹੀਂ ਹਾਂ।  \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16af2a8bbb083ea23e5e41c7f5787656b2ce26968575d8763f2c4b17f9cd711f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "coopTranslator": {
   "original_hash": "9fbb7d5fda708537649f71f5f646fcde",
   "translation_date": "2025-08-28T09:14:30+00:00",
   "source_file": "lessons/5-NLP/17-GenerativeNetworks/GenerativeTF.ipynb",
   "language_code": "pa"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}