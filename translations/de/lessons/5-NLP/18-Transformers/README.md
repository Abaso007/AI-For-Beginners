<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7e617f0b8de85a43957a853aba09bfeb",
  "translation_date": "2025-08-24T10:18:00+00:00",
  "source_file": "lessons/5-NLP/18-Transformers/README.md",
  "language_code": "de"
}
-->
# Aufmerksamkeitsmechanismen und Transformer

## [Quiz vor der Vorlesung](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/118)

Eines der wichtigsten Probleme im Bereich der NLP ist die **maschinelle √úbersetzung**, eine wesentliche Aufgabe, die Tools wie Google Translate zugrunde liegt. In diesem Abschnitt konzentrieren wir uns auf die maschinelle √úbersetzung oder allgemeiner auf jede *Sequence-to-Sequence*-Aufgabe (auch **Satztransduktion** genannt).

Mit RNNs wird Sequence-to-Sequence durch zwei rekurrente Netzwerke implementiert, wobei ein Netzwerk, der **Encoder**, eine Eingabesequenz in einen versteckten Zustand zusammenfasst, w√§hrend ein anderes Netzwerk, der **Decoder**, diesen versteckten Zustand in ein √ºbersetztes Ergebnis entfaltet. Es gibt jedoch einige Probleme bei diesem Ansatz:

* Der Endzustand des Encoder-Netzwerks hat Schwierigkeiten, sich an den Anfang eines Satzes zu erinnern, was zu einer schlechten Modellqualit√§t bei langen S√§tzen f√ºhrt.
* Alle W√∂rter in einer Sequenz haben den gleichen Einfluss auf das Ergebnis. In der Realit√§t haben jedoch bestimmte W√∂rter in der Eingabesequenz oft mehr Einfluss auf die sequentiellen Ausgaben als andere.

**Aufmerksamkeitsmechanismen** bieten eine M√∂glichkeit, den kontextuellen Einfluss jedes Eingabevektors auf jede Ausgabewahrscheinlichkeit des RNN zu gewichten. Dies wird durch die Erstellung von Abk√ºrzungen zwischen den Zwischenzust√§nden des Eingabe-RNN und des Ausgabe-RNN umgesetzt. Auf diese Weise ber√ºcksichtigen wir bei der Generierung des Ausgabesymbols y<sub>t</sub> alle versteckten Eingabezust√§nde h<sub>i</sub>, mit unterschiedlichen Gewichtungskoeffizienten Œ±<sub>t,i</sub>.

![Bild eines Encoder/Decoder-Modells mit einer additiven Aufmerksamkeits-Schicht](../../../../../lessons/5-NLP/18-Transformers/images/encoder-decoder-attention.png)

> Das Encoder-Decoder-Modell mit additivem Aufmerksamkeitsmechanismus aus [Bahdanau et al., 2015](https://arxiv.org/pdf/1409.0473.pdf), zitiert aus [diesem Blogbeitrag](https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html)

Die Aufmerksamkeitsmatrix {Œ±<sub>i,j</sub>} w√ºrde den Grad darstellen, in dem bestimmte Eingabew√∂rter bei der Generierung eines bestimmten Wortes in der Ausgabesequenz eine Rolle spielen. Unten ist ein Beispiel f√ºr eine solche Matrix:

![Bild eines Beispiel-Alignments, gefunden von RNNsearch-50, entnommen aus Bahdanau - arviz.org](../../../../../lessons/5-NLP/18-Transformers/images/bahdanau-fig3.png)

> Abbildung aus [Bahdanau et al., 2015](https://arxiv.org/pdf/1409.0473.pdf) (Fig.3)

Aufmerksamkeitsmechanismen sind verantwortlich f√ºr viele der aktuellen oder nahezu aktuellen Spitzenleistungen in der NLP. Das Hinzuf√ºgen von Aufmerksamkeit erh√∂ht jedoch die Anzahl der Modellparameter erheblich, was zu Skalierungsproblemen mit RNNs f√ºhrte. Eine wichtige Einschr√§nkung bei der Skalierung von RNNs ist, dass die rekurrente Natur der Modelle es schwierig macht, das Training zu batchen und zu parallelisieren. In einem RNN muss jedes Element einer Sequenz in der Reihenfolge verarbeitet werden, was bedeutet, dass es nicht leicht parallelisiert werden kann.

![Encoder Decoder mit Aufmerksamkeit](../../../../../lessons/5-NLP/18-Transformers/images/EncDecAttention.gif)

> Abbildung aus [Googles Blog](https://research.googleblog.com/2016/09/a-neural-network-for-machine.html)

Die Einf√ºhrung von Aufmerksamkeitsmechanismen in Kombination mit dieser Einschr√§nkung f√ºhrte zur Entwicklung der heute bekannten und genutzten Transformer-Modelle wie BERT und Open-GPT3, die den aktuellen Stand der Technik darstellen.

## Transformer-Modelle

Eine der Hauptideen hinter Transformern ist es, die sequentielle Natur von RNNs zu vermeiden und ein Modell zu schaffen, das w√§hrend des Trainings parallelisierbar ist. Dies wird durch die Implementierung von zwei Ideen erreicht:

* Positionskodierung
* Verwendung des Selbstaufmerksamkeitsmechanismus, um Muster zu erfassen, anstatt RNNs (oder CNNs) zu verwenden (deshalb hei√üt das Papier, das Transformer einf√ºhrt, *[Attention is all you need](https://arxiv.org/abs/1706.03762)*).

### Positionskodierung/-einbettung

Die Idee der Positionskodierung ist folgende:  
1. Bei der Verwendung von RNNs wird die relative Position der Tokens durch die Anzahl der Schritte dargestellt und muss daher nicht explizit dargestellt werden.  
2. Sobald wir jedoch zu Aufmerksamkeit wechseln, m√ºssen wir die relativen Positionen der Tokens innerhalb einer Sequenz kennen.  
3. Um Positionskodierung zu erhalten, erg√§nzen wir unsere Sequenz von Tokens mit einer Sequenz von Token-Positionen in der Sequenz (d.h. einer Sequenz von Zahlen 0,1, ...).  
4. Wir mischen dann die Token-Position mit einem Token-Einbettungsvektor. Um die Position (Ganzzahl) in einen Vektor zu transformieren, k√∂nnen wir verschiedene Ans√§tze verwenden:

* Trainierbare Einbettung, √§hnlich wie Token-Einbettung. Dies ist der Ansatz, den wir hier betrachten. Wir wenden Einbettungsschichten sowohl auf Tokens als auch auf ihre Positionen an, was zu Einbettungsvektoren derselben Dimensionen f√ºhrt, die wir dann zusammen addieren.  
* Feste Positionskodierungsfunktion, wie im urspr√ºnglichen Papier vorgeschlagen.

<img src="images/pos-embedding.png" width="50%"/>

> Bild vom Autor

Das Ergebnis, das wir mit Positionskodierung erhalten, bettet sowohl das urspr√ºngliche Token als auch seine Position innerhalb einer Sequenz ein.

### Multi-Head Selbstaufmerksamkeit

Als N√§chstes m√ºssen wir einige Muster innerhalb unserer Sequenz erfassen. Um dies zu tun, verwenden Transformer einen **Selbstaufmerksamkeitsmechanismus**, der im Wesentlichen Aufmerksamkeit ist, die auf dieselbe Sequenz als Eingabe und Ausgabe angewendet wird. Die Anwendung von Selbstaufmerksamkeit erm√∂glicht es uns, den **Kontext** innerhalb des Satzes zu ber√ºcksichtigen und zu sehen, welche W√∂rter miteinander in Beziehung stehen. Zum Beispiel erm√∂glicht es uns zu sehen, welche W√∂rter durch Koreferenzen wie *es* referenziert werden, und auch den Kontext zu ber√ºcksichtigen:

![](../../../../../lessons/5-NLP/18-Transformers/images/CoreferenceResolution.png)

> Bild aus dem [Google Blog](https://research.googleblog.com/2017/08/transformer-novel-neural-network.html)

In Transformern verwenden wir **Multi-Head Attention**, um dem Netzwerk die F√§higkeit zu geben, verschiedene Arten von Abh√§ngigkeiten zu erfassen, z. B. langfristige vs. kurzfristige Wortbeziehungen, Koreferenz vs. etwas anderes usw.

[TensorFlow Notebook](../../../../../lessons/5-NLP/18-Transformers/TransformersTF.ipynb) enth√§lt weitere Details zur Implementierung von Transformer-Schichten.

### Encoder-Decoder Aufmerksamkeit

In Transformern wird Aufmerksamkeit an zwei Stellen verwendet:

* Um Muster innerhalb des Eingabetextes mit Selbstaufmerksamkeit zu erfassen  
* Um Sequenz√ºbersetzung durchzuf√ºhren - dies ist die Aufmerksamkeits-Schicht zwischen Encoder und Decoder.

Encoder-Decoder Aufmerksamkeit ist der Aufmerksamkeitsmechanismus, der in RNNs verwendet wird, wie zu Beginn dieses Abschnitts beschrieben. Dieses animierte Diagramm erkl√§rt die Rolle der Encoder-Decoder Aufmerksamkeit.

![Animiertes GIF, das zeigt, wie die Bewertungen in Transformer-Modellen durchgef√ºhrt werden.](../../../../../lessons/5-NLP/18-Transformers/images/transformer-animated-explanation.gif)

Da jede Eingabeposition unabh√§ngig auf jede Ausgabeposition abgebildet wird, k√∂nnen Transformer besser parallelisieren als RNNs, was viel gr√∂√üere und ausdrucksst√§rkere Sprachmodelle erm√∂glicht. Jeder Aufmerksamkeitskopf kann verwendet werden, um verschiedene Beziehungen zwischen W√∂rtern zu lernen, was die nachgelagerten Aufgaben der nat√ºrlichen Sprachverarbeitung verbessert.

## BERT

**BERT** (Bidirectional Encoder Representations from Transformers) ist ein sehr gro√ües mehrschichtiges Transformer-Netzwerk mit 12 Schichten f√ºr *BERT-base* und 24 f√ºr *BERT-large*. Das Modell wird zun√§chst auf einem gro√üen Textkorpus (Wikipedia + B√ºcher) mit un√ºberwachtem Training (Vorhersage maskierter W√∂rter in einem Satz) vortrainiert. W√§hrend des Vortrainings absorbiert das Modell signifikante Sprachverst√§ndnisf√§higkeiten, die dann mit anderen Datens√§tzen durch Feinabstimmung genutzt werden k√∂nnen. Dieser Prozess wird als **Transfer Learning** bezeichnet.

![Bild von http://jalammar.github.io/illustrated-bert/](../../../../../lessons/5-NLP/18-Transformers/images/jalammarBERT-language-modeling-masked-lm.png)

> Bild [Quelle](http://jalammar.github.io/illustrated-bert/)

## ‚úçÔ∏è √úbungen: Transformer

Setzen Sie Ihr Lernen in den folgenden Notebooks fort:

* [Transformer in PyTorch](../../../../../lessons/5-NLP/18-Transformers/TransformersPyTorch.ipynb)  
* [Transformer in TensorFlow](../../../../../lessons/5-NLP/18-Transformers/TransformersTF.ipynb)  

## Fazit

In dieser Lektion haben Sie Transformer und Aufmerksamkeitsmechanismen kennengelernt, die wesentliche Werkzeuge im NLP-Werkzeugkasten sind. Es gibt viele Variationen von Transformer-Architekturen, darunter BERT, DistilBERT, BigBird, OpenGPT3 und mehr, die fein abgestimmt werden k√∂nnen. Das [HuggingFace-Paket](https://github.com/huggingface/) bietet ein Repository f√ºr das Training vieler dieser Architekturen mit sowohl PyTorch als auch TensorFlow.

## üöÄ Herausforderung

## [Quiz nach der Vorlesung](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/218)

## √úberpr√ºfung & Selbststudium

* [Blogbeitrag](https://mchromiak.github.io/articles/2017/Sep/12/Transformer-Attention-is-all-you-need/), der das klassische [Attention is all you need](https://arxiv.org/abs/1706.03762)-Papier √ºber Transformer erkl√§rt.  
* [Eine Serie von Blogbeitr√§gen](https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452) √ºber Transformer, die die Architektur im Detail erkl√§ren.  

## [Aufgabe](assignment.md)  

**Haftungsausschluss**:  
Dieses Dokument wurde mit dem KI-√úbersetzungsdienst [Co-op Translator](https://github.com/Azure/co-op-translator) √ºbersetzt. Obwohl wir uns um Genauigkeit bem√ºhen, weisen wir darauf hin, dass automatisierte √úbersetzungen Fehler oder Ungenauigkeiten enthalten k√∂nnen. Das Originaldokument in seiner urspr√ºnglichen Sprache sollte als ma√ügebliche Quelle betrachtet werden. F√ºr kritische Informationen wird eine professionelle menschliche √úbersetzung empfohlen. Wir √ºbernehmen keine Haftung f√ºr Missverst√§ndnisse oder Fehlinterpretationen, die aus der Nutzung dieser √úbersetzung entstehen.