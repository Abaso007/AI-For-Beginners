<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "d7f8a25ff13cfe9f4cd671cc23351fad",
  "translation_date": "2025-08-24T09:34:07+00:00",
  "source_file": "lessons/4-ComputerVision/12-Segmentation/README.md",
  "language_code": "de"
}
-->
# Segmentierung

Wir haben zuvor √ºber Objekterkennung gelernt, die es uns erm√∂glicht, Objekte in einem Bild durch Vorhersage ihrer *Bounding Boxes* zu lokalisieren. F√ºr einige Aufgaben ben√∂tigen wir jedoch nicht nur Bounding Boxes, sondern auch eine pr√§zisere Objektlokalisierung. Diese Aufgabe nennt man **Segmentierung**.

## [Pre-lecture quiz](https://ff-quizzes.netlify.app/en/ai/quiz/23)

Segmentierung kann als **Pixelklassifikation** betrachtet werden, bei der f√ºr **jeden** Pixel des Bildes seine Klasse vorhergesagt werden muss (*Hintergrund* ist dabei eine der Klassen). Es gibt zwei Hauptalgorithmen f√ºr die Segmentierung:

* **Semantische Segmentierung** gibt nur die Klasse des Pixels an und unterscheidet nicht zwischen verschiedenen Objekten derselben Klasse.
* **Instanzsegmentierung** teilt Klassen in verschiedene Instanzen auf.

Bei der Instanzsegmentierung sind diese Schafe unterschiedliche Objekte, w√§hrend bei der semantischen Segmentierung alle Schafe durch eine Klasse repr√§sentiert werden.

<img src="images/instance_vs_semantic.jpeg" width="50%">

> Bild aus [diesem Blogbeitrag](https://nirmalamurali.medium.com/image-classification-vs-semantic-segmentation-vs-instance-segmentation-625c33a08d50)

Es gibt verschiedene neuronale Architekturen f√ºr die Segmentierung, aber sie haben alle dieselbe Struktur. In gewisser Weise √§hnelt sie dem Autoencoder, den Sie zuvor kennengelernt haben, aber anstatt das urspr√ºngliche Bild zu rekonstruieren, ist unser Ziel, eine **Maske** zu rekonstruieren. Eine Segmentierungsnetzwerk hat daher folgende Bestandteile:

* **Encoder** extrahiert Merkmale aus dem Eingabebild.
* **Decoder** transformiert diese Merkmale in das **Maskenbild**, mit derselben Gr√∂√üe und einer Anzahl von Kan√§len, die der Anzahl der Klassen entspricht.

<img src="images/segm.png" width="80%">

> Bild aus [dieser Publikation](https://arxiv.org/pdf/2001.05566.pdf)

Besonders erw√§hnenswert ist die Verlustfunktion, die f√ºr die Segmentierung verwendet wird. Bei klassischen Autoencodern m√ºssen wir die √Ñhnlichkeit zwischen zwei Bildern messen, wof√ºr wir den mittleren quadratischen Fehler (MSE) verwenden k√∂nnen. Bei der Segmentierung repr√§sentiert jeder Pixel im Zielmaskenbild die Klassennummer (one-hot-encoded entlang der dritten Dimension), daher m√ºssen wir Verlustfunktionen verwenden, die speziell f√ºr Klassifikationen geeignet sind - Kreuzentropieverlust, gemittelt √ºber alle Pixel. Wenn die Maske bin√§r ist, wird der **bin√§re Kreuzentropieverlust** (BCE) verwendet.

> ‚úÖ One-Hot-Encoding ist eine Methode, um eine Klassenbezeichnung in einen Vektor mit einer L√§nge zu kodieren, die der Anzahl der Klassen entspricht. Schauen Sie sich [diesen Artikel](https://datagy.io/sklearn-one-hot-encode/) zu dieser Technik an.

## Segmentierung in der medizinischen Bildgebung

In dieser Lektion werden wir die Segmentierung in Aktion sehen, indem wir ein Netzwerk trainieren, um menschliche N√§vi (auch bekannt als Muttermale) auf medizinischen Bildern zu erkennen. Wir verwenden die <a href="https://www.fc.up.pt/addi/ph2%20database.html">PH<sup>2</sup>-Datenbank</a> mit Dermatoskopiebildern als Bildquelle. Dieses Datenset enth√§lt 200 Bilder von drei Klassen: typischer N√§vus, atypischer N√§vus und Melanom. Alle Bilder enthalten auch eine entsprechende **Maske**, die den N√§vus umrei√üt.

> ‚úÖ Diese Technik ist besonders geeignet f√ºr diese Art der medizinischen Bildgebung, aber welche anderen Anwendungen in der realen Welt k√∂nnten Sie sich vorstellen?

<img alt="navi" src="images/navi.png"/>

> Bild aus der PH<sup>2</sup>-Datenbank

Wir werden ein Modell trainieren, um jeden N√§vus vom Hintergrund zu segmentieren.

## ‚úçÔ∏è √úbungen: Semantische Segmentierung

√ñffnen Sie die untenstehenden Notebooks, um mehr √ºber verschiedene Architekturen der semantischen Segmentierung zu erfahren, mit ihnen zu arbeiten und sie in Aktion zu sehen.

* [Semantische Segmentierung Pytorch](../../../../../lessons/4-ComputerVision/12-Segmentation/SemanticSegmentationPytorch.ipynb)
* [Semantische Segmentierung TensorFlow](../../../../../lessons/4-ComputerVision/12-Segmentation/SemanticSegmentationTF.ipynb)

## [Post-lecture quiz](https://ff-quizzes.netlify.app/en/ai/quiz/24)

## Fazit

Segmentierung ist eine sehr leistungsstarke Technik f√ºr die Bildklassifikation, die √ºber Bounding Boxes hinausgeht und eine Klassifikation auf Pixelebene erm√∂glicht. Sie wird unter anderem in der medizinischen Bildgebung eingesetzt.

## üöÄ Herausforderung

Die Segmentierung des K√∂rpers ist nur eine der h√§ufigen Aufgaben, die wir mit Bildern von Menschen durchf√ºhren k√∂nnen. Andere wichtige Aufgaben umfassen **Skelett-Erkennung** und **Posenerkennung**. Probieren Sie die [OpenPose](https://github.com/CMU-Perceptual-Computing-Lab/openpose)-Bibliothek aus, um zu sehen, wie Posenerkennung verwendet werden kann.

## R√ºckblick & Selbststudium

Dieser [Wikipedia-Artikel](https://wikipedia.org/wiki/Image_segmentation) bietet einen guten √úberblick √ºber die verschiedenen Anwendungen dieser Technik. Informieren Sie sich selbst √ºber die Teilbereiche der Instanzsegmentierung und der Panoptischen Segmentierung in diesem Forschungsfeld.

## [Aufgabe](lab/README.md)

In diesem Labor versuchen Sie die **Segmentierung des menschlichen K√∂rpers** mit dem [Segmentation Full Body MADS Dataset](https://www.kaggle.com/datasets/tapakah68/segmentation-full-body-mads-dataset) von Kaggle.

**Haftungsausschluss**:  
Dieses Dokument wurde mit dem KI-√úbersetzungsdienst [Co-op Translator](https://github.com/Azure/co-op-translator) √ºbersetzt. Obwohl wir uns um Genauigkeit bem√ºhen, beachten Sie bitte, dass automatisierte √úbersetzungen Fehler oder Ungenauigkeiten enthalten k√∂nnen. Das Originaldokument in seiner urspr√ºnglichen Sprache sollte als ma√ügebliche Quelle betrachtet werden. F√ºr kritische Informationen wird eine professionelle menschliche √úbersetzung empfohlen. Wir √ºbernehmen keine Haftung f√ºr Missverst√§ndnisse oder Fehlinterpretationen, die sich aus der Nutzung dieser √úbersetzung ergeben.