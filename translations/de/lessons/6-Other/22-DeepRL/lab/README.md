<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7bd8dc72040e98e35e7225e34058cd4e",
  "translation_date": "2025-08-24T09:39:10+00:00",
  "source_file": "lessons/6-Other/22-DeepRL/lab/README.md",
  "language_code": "de"
}
-->
## Die Umgebung

Die Mountain Car-Umgebung besteht aus einem Auto, das in einem Tal gefangen ist. Dein Ziel ist es, aus dem Tal herauszuspringen und die Fahne zu erreichen. Die Aktionen, die du ausführen kannst, sind: nach links beschleunigen, nach rechts beschleunigen oder nichts tun. Du kannst die Position des Autos entlang der x-Achse und die Geschwindigkeit beobachten.

## Start-Notebook

Beginne das Lab, indem du [MountainCar.ipynb](../../../../../../lessons/6-Other/22-DeepRL/lab/MountainCar.ipynb) öffnest.

## Erkenntnis

Während dieses Labs solltest du lernen, dass die Anpassung von RL-Algorithmen an eine neue Umgebung oft recht unkompliziert ist, da OpenAI Gym für alle Umgebungen dieselbe Schnittstelle bietet und die Algorithmen im Allgemeinen nicht stark von der Art der Umgebung abhängen. Du kannst den Python-Code sogar so umstrukturieren, dass jede Umgebung als Parameter an den RL-Algorithmus übergeben werden kann.

**Haftungsausschluss**:  
Dieses Dokument wurde mit dem KI-Übersetzungsdienst [Co-op Translator](https://github.com/Azure/co-op-translator) übersetzt. Obwohl wir uns um Genauigkeit bemühen, weisen wir darauf hin, dass automatisierte Übersetzungen Fehler oder Ungenauigkeiten enthalten können. Das Originaldokument in seiner ursprünglichen Sprache sollte als maßgebliche Quelle betrachtet werden. Für kritische Informationen wird eine professionelle menschliche Übersetzung empfohlen. Wir übernehmen keine Haftung für Missverständnisse oder Fehlinterpretationen, die aus der Nutzung dieser Übersetzung entstehen.