{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einfacher Bildklassifikator\n",
    "\n",
    "Dieses Notebook zeigt, wie man Bilder mit einem vortrainierten neuronalen Netzwerk klassifiziert.\n",
    "\n",
    "**Was Sie lernen werden:**\n",
    "- Wie man ein vortrainiertes Modell l√§dt und verwendet\n",
    "- Bildvorverarbeitung\n",
    "- Vorhersagen f√ºr Bilder treffen\n",
    "- Verst√§ndnis von Vertrauenswerten\n",
    "\n",
    "**Anwendungsfall:** Objekte in Bildern identifizieren (wie \"Katze\", \"Hund\", \"Auto\" usw.)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 1: Erforderliche Bibliotheken importieren\n",
    "\n",
    "Lassen Sie uns die ben√∂tigten Tools importieren. Keine Sorge, wenn Sie noch nicht alles davon verstehen!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# TensorFlow for deep learning\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.applications import MobileNetV2\n",
    "    from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, decode_predictions\n",
    "    print(\"‚úÖ TensorFlow loaded successfully!\")\n",
    "    print(f\"   Version: {tf.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå Please install TensorFlow: pip install tensorflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 2: Vortrainiertes Modell laden\n",
    "\n",
    "Wir verwenden **MobileNetV2**, ein neuronales Netzwerk, das bereits mit Millionen von Bildern trainiert wurde.\n",
    "\n",
    "Das nennt man **Transfer Learning** ‚Äì die Nutzung eines Modells, das von jemand anderem trainiert wurde!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üì¶ Loading pre-trained MobileNetV2 model...\")\n",
    "print(\"   This may take a minute on first run (downloading weights)...\")\n",
    "\n",
    "# Load the model\n",
    "# include_top=True means we use the classification layer\n",
    "# weights='imagenet' means it was trained on ImageNet dataset\n",
    "model = MobileNetV2(weights='imagenet', include_top=True)\n",
    "\n",
    "print(\"‚úÖ Model loaded!\")\n",
    "print(f\"   The model can recognize 1000 different object categories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 3: Hilfsfunktionen\n",
    "\n",
    "Lassen Sie uns Funktionen erstellen, um Bilder f√ºr unser Modell zu laden und vorzubereiten.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_from_url(url):\n",
    "    \"\"\"\n",
    "    Load an image from a URL.\n",
    "    \n",
    "    Args:\n",
    "        url: Web address of the image\n",
    "        \n",
    "    Returns:\n",
    "        PIL Image object\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    return img\n",
    "\n",
    "\n",
    "def prepare_image(img):\n",
    "    \"\"\"\n",
    "    Prepare an image for the model.\n",
    "    \n",
    "    Steps:\n",
    "    1. Resize to 224x224 (model's expected size)\n",
    "    2. Convert to array\n",
    "    3. Add batch dimension\n",
    "    4. Preprocess for MobileNetV2\n",
    "    \n",
    "    Args:\n",
    "        img: PIL Image\n",
    "        \n",
    "    Returns:\n",
    "        Preprocessed image array\n",
    "    \"\"\"\n",
    "    # Resize to 224x224 pixels\n",
    "    img = img.resize((224, 224))\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    img_array = np.array(img)\n",
    "    \n",
    "    # Add batch dimension (model expects multiple images)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    # Preprocess for MobileNetV2\n",
    "    img_array = preprocess_input(img_array)\n",
    "    \n",
    "    return img_array\n",
    "\n",
    "\n",
    "def classify_image(img):\n",
    "    \"\"\"\n",
    "    Classify an image and return top predictions.\n",
    "    \n",
    "    Args:\n",
    "        img: PIL Image\n",
    "        \n",
    "    Returns:\n",
    "        List of (class_name, confidence) tuples\n",
    "    \"\"\"\n",
    "    # Prepare the image\n",
    "    img_array = prepare_image(img)\n",
    "    \n",
    "    # Make prediction\n",
    "    predictions = model.predict(img_array, verbose=0)\n",
    "    \n",
    "    # Decode predictions to human-readable labels\n",
    "    # top=5 means we get the top 5 most likely classes\n",
    "    decoded = decode_predictions(predictions, top=5)[0]\n",
    "    \n",
    "    # Convert to simpler format\n",
    "    results = [(label, float(confidence)) for (_, label, confidence) in decoded]\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"‚úÖ Helper functions ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 4: Testen mit Beispielbildern\n",
    "\n",
    "Lass uns einige Bilder aus dem Internet klassifizieren!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample images to classify\n",
    "# These are from Unsplash (free stock photos)\n",
    "test_images = [\n",
    "    {\n",
    "        \"url\": \"https://images.unsplash.com/photo-1514888286974-6c03e2ca1dba?w=400\",\n",
    "        \"description\": \"A cat\"\n",
    "    },\n",
    "    {\n",
    "        \"url\": \"https://images.unsplash.com/photo-1552053831-71594a27632d?w=400\",\n",
    "        \"description\": \"A dog\"\n",
    "    },\n",
    "    {\n",
    "        \"url\": \"https://images.unsplash.com/photo-1511919884226-fd3cad34687c?w=400\",\n",
    "        \"description\": \"A car\"\n",
    "    },\n",
    "]\n",
    "\n",
    "print(f\"üß™ Testing on {len(test_images)} images...\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klassifizieren Sie jedes Bild\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, img_data in enumerate(test_images, 1):\n",
    "    print(f\"\\nüì∏ Image {i}: {img_data['description']}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    try:\n",
    "        # Load image\n",
    "        img = load_image_from_url(img_data['url'])\n",
    "        \n",
    "        # Display image\n",
    "        display(img.resize((200, 200)))  # Show smaller version\n",
    "        \n",
    "        # Classify\n",
    "        results = classify_image(img)\n",
    "        \n",
    "        # Show predictions\n",
    "        print(\"\\nüéØ Top 5 Predictions:\")\n",
    "        for rank, (label, confidence) in enumerate(results, 1):\n",
    "            # Create a visual bar\n",
    "            bar_length = int(confidence * 50)\n",
    "            bar = \"‚ñà\" * bar_length\n",
    "            \n",
    "            print(f\"  {rank}. {label:20s} {confidence*100:5.2f}% {bar}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 5: Probieren Sie Ihre eigenen Bilder aus!\n",
    "\n",
    "Ersetzen Sie die untenstehende URL durch eine beliebige Bild-URL, die Sie klassifizieren m√∂chten.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try your own image!\n",
    "# Replace this URL with any image URL\n",
    "custom_image_url = \"https://images.unsplash.com/photo-1472491235688-bdc81a63246e?w=400\"  # A flower\n",
    "\n",
    "print(\"üñºÔ∏è  Classifying your custom image...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    # Load and show image\n",
    "    img = load_image_from_url(custom_image_url)\n",
    "    display(img.resize((300, 300)))\n",
    "    \n",
    "    # Classify\n",
    "    results = classify_image(img)\n",
    "    \n",
    "    # Show results\n",
    "    print(\"\\nüéØ Top 5 Predictions:\")\n",
    "    print(\"-\" * 70)\n",
    "    for rank, (label, confidence) in enumerate(results, 1):\n",
    "        bar_length = int(confidence * 50)\n",
    "        bar = \"‚ñà\" * bar_length\n",
    "        print(f\"  {rank}. {label:20s} {confidence*100:5.2f}% {bar}\")\n",
    "    \n",
    "    # Highlight top prediction\n",
    "    top_label, top_confidence = results[0]\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"\\nüèÜ Best guess: {top_label} ({top_confidence*100:.2f}% confident)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    print(\"   Make sure the URL points to a valid image!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° Was ist gerade passiert?\n",
    "\n",
    "1. **Wir haben ein vortrainiertes Modell geladen** - MobileNetV2 wurde mit Millionen von Bildern trainiert.  \n",
    "2. **Wir haben Bilder vorverarbeitet** - Sie wurden f√ºr das Modell passend skaliert und formatiert.  \n",
    "3. **Das Modell hat Vorhersagen getroffen** - Es hat Wahrscheinlichkeiten f√ºr 1000 Objektklassen ausgegeben.  \n",
    "4. **Wir haben die Ergebnisse dekodiert** - Zahlen wurden in menschenlesbare Labels umgewandelt.  \n",
    "\n",
    "### Verst√§ndnis der Vertrauenswerte\n",
    "\n",
    "- **90-100%**: Sehr sicher (fast garantiert korrekt)  \n",
    "- **70-90%**: Sicher (wahrscheinlich korrekt)  \n",
    "- **50-70%**: Etwas sicher (k√∂nnte korrekt sein)  \n",
    "- **Unter 50%**: Nicht sehr sicher (unsicher)  \n",
    "\n",
    "### Warum k√∂nnten Vorhersagen falsch sein?\n",
    "\n",
    "- **Ungew√∂hnlicher Winkel oder Beleuchtung** - Das Modell wurde mit typischen Fotos trainiert.  \n",
    "- **Mehrere Objekte** - Das Modell erwartet ein Hauptobjekt.  \n",
    "- **Seltene Objekte** - Das Modell kennt nur 1000 Kategorien.  \n",
    "- **Schlechte Bildqualit√§t** - Verschwommene oder verpixelte Bilder sind schwieriger zu erkennen.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ N√§chste Schritte\n",
    "\n",
    "1. **Probieren Sie verschiedene Bilder aus:**\n",
    "   - Finden Sie Bilder auf [Unsplash](https://unsplash.com)\n",
    "   - Rechtsklick ‚Üí ‚ÄûBildadresse kopieren‚Äú, um die URL zu erhalten\n",
    "\n",
    "2. **Experimentieren:**\n",
    "   - Was passiert mit abstrakter Kunst?\n",
    "   - Kann es Objekte aus verschiedenen Blickwinkeln erkennen?\n",
    "   - Wie geht es mit mehreren Objekten um?\n",
    "\n",
    "3. **Mehr erfahren:**\n",
    "   - Erkunden Sie [Computer Vision Lektionen](../lessons/4-ComputerVision/README.md)\n",
    "   - Lernen Sie, Ihren eigenen Bildklassifikator zu trainieren\n",
    "   - Verstehen Sie, wie CNNs (Convolutional Neural Networks) funktionieren\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ Herzlichen Gl√ºckwunsch!\n",
    "\n",
    "Sie haben gerade einen Bildklassifikator mit einem hochmodernen neuronalen Netzwerk erstellt!\n",
    "\n",
    "Diese Technik wird verwendet f√ºr:\n",
    "- Google Fotos (Organisieren Ihrer Bilder)\n",
    "- Selbstfahrende Autos (Objekterkennung)\n",
    "- Medizinische Diagnosen (Analyse von R√∂ntgenbildern)\n",
    "- Qualit√§tskontrolle (Erkennung von Defekten)\n",
    "\n",
    "Bleiben Sie neugierig und lernen Sie weiter! üöÄ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Haftungsausschluss**:  \nDieses Dokument wurde mit dem KI-√úbersetzungsdienst [Co-op Translator](https://github.com/Azure/co-op-translator) √ºbersetzt. Obwohl wir uns um Genauigkeit bem√ºhen, weisen wir darauf hin, dass automatisierte √úbersetzungen Fehler oder Ungenauigkeiten enthalten k√∂nnen. Das Originaldokument in seiner urspr√ºnglichen Sprache sollte als ma√ügebliche Quelle betrachtet werden. F√ºr kritische Informationen wird eine professionelle menschliche √úbersetzung empfohlen. Wir √ºbernehmen keine Haftung f√ºr Missverst√§ndnisse oder Fehlinterpretationen, die aus der Nutzung dieser √úbersetzung entstehen.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "coopTranslator": {
   "original_hash": "1d472141d9df46b751542b3c29f88677",
   "translation_date": "2025-10-03T11:37:36+00:00",
   "source_file": "examples/03-image-classifier.ipynb",
   "language_code": "de"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}