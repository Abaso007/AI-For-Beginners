<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "0c84b280e654e05ed658023021a6a975",
  "translation_date": "2025-09-23T13:11:05+00:00",
  "source_file": "lessons/1-Intro/README.md",
  "language_code": "ja"
}
-->
# AIの概要

![AIの概要内容をスケッチした画像](../../../../translated_images/ai-intro.bf28d1ac4235881c096f0ffdb320ba4102940eafcca4e9d7a55a03914361f8f3.ja.png)

> スケッチノート: [Tomomi Imura](https://twitter.com/girlie_mac)

## [講義前のクイズ](https://ff-quizzes.netlify.app/en/ai/quiz/1)

**人工知能（AI）**は、コンピュータが知的な振る舞いを示す方法を研究する、非常に興味深い科学分野です。例えば、人間が得意とすることをコンピュータに行わせることを目指します。

もともとコンピュータは、[チャールズ・バベッジ](https://en.wikipedia.org/wiki/Charles_Babbage)によって、明確に定義された手順（アルゴリズム）に従って数値を操作するために発明されました。現代のコンピュータは、19世紀に提案された元のモデルよりもはるかに高度ですが、依然として制御された計算という同じアイデアに基づいています。そのため、目標を達成するために必要な手順を正確に知っていれば、コンピュータをプログラムして何かを行わせることが可能です。

![人物の写真](../../../../translated_images/dsh_age.d212a30d4e54fb5f68b94a624aad64bc086124bcbbec9561ae5bd5da661e22d8.ja.png)

> 写真: [Vickie Soshnikova](http://twitter.com/vickievalerie)

> ✅ 写真から人物の年齢を定義することは、明確にプログラムすることができないタスクです。なぜなら、私たちが頭の中でその数字を思いつく方法を正確に説明することができないからです。

---

しかし、明確に解決方法がわからないタスクも存在します。例えば、写真から人物の年齢を判断することを考えてみてください。私たちは、さまざまな年齢の人々の例をたくさん見てきたため、これを学習することができますが、どのようにしてそれを行うのかを明確に説明することはできませんし、コンピュータにそれをプログラムすることもできません。このようなタスクこそが、**人工知能（AI）**の関心の対象となるものです。

✅ コンピュータに任せることでAIの恩恵を受けられるタスクを考えてみましょう。金融、医療、芸術の分野を考慮してみてください。これらの分野は今日、AIからどのような恩恵を受けているでしょうか？

## 弱いAIと強いAI

弱いAI | 強いAI
---------------------------------------|-------------------------------------
弱いAIは、特定のタスクや限定されたタスクのために設計・訓練されたAIシステムを指します。|強いAI、または人工汎用知能（AGI）は、人間レベルの知性と理解を持つAIシステムを指します。
これらのAIシステムは一般的な知性を持っているわけではなく、定義されたタスクを実行することに特化していますが、真の理解や意識は欠けています。|これらのAIシステムは、人間が行えるあらゆる知的タスクを実行し、異なる領域に適応し、意識や自己認識の形を持つ能力を持っています。
弱いAIの例には、SiriやAlexaのような仮想アシスタント、ストリーミングサービスで使用される推薦アルゴリズム、特定の顧客サービスタスクに設計されたチャットボットなどがあります。|強いAIを達成することはAI研究の長期的な目標であり、幅広いタスクやコンテキストにわたって推論、学習、理解、適応できるAIシステムの開発が必要です。
弱いAIは非常に専門的であり、その限定された領域を超えた人間のような認知能力や一般的な問題解決能力を持っていません。|強いAIは現在理論的な概念であり、このレベルの汎用知能に到達したAIシステムは存在していません。

詳細については、**[人工汎用知能](https://en.wikipedia.org/wiki/Artificial_general_intelligence)** (AGI) を参照してください。

## 知能の定義とチューリングテスト

**[知能](https://en.wikipedia.org/wiki/Intelligence)**という用語を扱う際の問題の1つは、この用語に明確な定義がないことです。知能が**抽象的思考**や**自己認識**に関連していると主張することはできますが、適切に定義することはできません。

![猫の写真](../../../../translated_images/photo-cat.8c8e8fb760ffe45725c5b9f6b0d954e9bf114475c01c55adf0303982851b7eae.ja.jpg)

> [写真](https://unsplash.com/photos/75715CVEJhI) by [Amber Kipp](https://unsplash.com/@sadmax) from Unsplash

*知能*という用語の曖昧さを理解するために、「猫は知能を持っているか？」という質問に答えてみてください。この質問に対する答えは人によって異なる傾向があり、この主張が真実かどうかを証明する普遍的に受け入れられるテストはありません。そして、もしそのようなテストがあると思うなら、あなたの猫にIQテストを受けさせてみてください...

✅ 知能をどのように定義するかについて1分間考えてみてください。迷路を解いて食べ物にたどり着けるカラスは知能を持っているでしょうか？子供は知能を持っているでしょうか？

---

AGIについて話す際には、真に知的なシステムを作成したかどうかを判断する方法が必要です。[アラン・チューリング](https://en.wikipedia.org/wiki/Alan_Turing)は、**[チューリングテスト](https://en.wikipedia.org/wiki/Turing_test)**と呼ばれる方法を提案しました。これは知能の定義としても機能します。このテストでは、与えられたシステムを本質的に知的なもの、つまり実際の人間と比較します。自動比較はコンピュータプログラムによって回避される可能性があるため、人間の尋問者を使用します。したがって、人間がテキストベースの対話で実際の人間とコンピュータシステムを区別できない場合、そのシステムは知的であると見なされます。

> [Eugene Goostman](https://en.wikipedia.org/wiki/Eugene_Goostman)というチャットボットは、2014年にサンクトペテルブルクで開発され、巧妙な人格トリックを使用してチューリングテストに近づきました。このボットは、13歳のウクライナ人少年であると事前に宣言し、知識の欠如やテキストの矛盾を説明しました。このボットは5分間の対話の後、審査員の30％を人間だと信じさせました。これは、チューリングが2000年までに機械が達成できると信じていた指標です。しかし、これが知的なシステムを作成したことを示しているわけでも、コンピュータシステムが人間の尋問者を欺いたことを示しているわけでもありません。実際には、システムが人間を欺いたのではなく、ボットの作成者が人間を欺いたのです！

✅ チャットボットに人間と話していると思い込まされたことはありますか？それはどのようにしてあなたを納得させましたか？

## AIへの異なるアプローチ

コンピュータを人間のように振る舞わせたい場合、コンピュータ内で私たちの思考方法を何らかの形でモデル化する必要があります。そのため、人間が知的である理由を理解しようとする必要があります。

> 機械に知能をプログラムするためには、私たち自身の意思決定プロセスがどのように機能しているかを理解する必要があります。少し自己内省をしてみると、無意識に行われるプロセス（例: 猫と犬を区別すること）と、推論を伴うプロセスがあることに気付くでしょう。

この問題には2つのアプローチがあります：

トップダウンアプローチ（記号的推論） | ボトムアップアプローチ（ニューラルネットワーク）
---------------------------------------|-------------------------------------
トップダウンアプローチは、人間が問題を解決するために推論する方法をモデル化します。これには、人間から**知識**を抽出し、それをコンピュータが読み取れる形式で表現することが含まれます。また、コンピュータ内で**推論**をモデル化する方法を開発する必要があります。|ボトムアップアプローチは、人間の脳の構造をモデル化します。脳は**ニューロン**と呼ばれる多数の単純なユニットで構成されています。各ニューロンは入力の加重平均のように機能し、**トレーニングデータ**を提供することで、ニューロンのネットワークを訓練して有用な問題を解決できるようにします。

その他のアプローチもあります：

* **創発的**、**シナジー的**、または**マルチエージェントアプローチ**は、多数の単純なエージェントの相互作用によって複雑な知的行動が得られるという事実に基づいています。[進化的サイバネティクス](https://en.wikipedia.org/wiki/Global_brain#Evolutionary_cybernetics)によれば、知能はより単純な反応的行動から、*メタシステム移行*の過程で*創発*することができます。

* **進化的アプローチ**または**遺伝的アルゴリズム**は、進化の原則に基づいた最適化プロセスです。

これらのアプローチについては後の講義で取り上げますが、今は主にトップダウンとボトムアップの2つの方向に焦点を当てます。

### トップダウンアプローチ

**トップダウンアプローチ**では、私たちの推論をモデル化しようとします。推論する際に自分の思考を追うことができるため、このプロセスを形式化してコンピュータ内にプログラムすることができます。これを**記号的推論**と呼びます。

人々は意思決定プロセスを導くいくつかのルールを頭の中に持っている傾向があります。例えば、医師が患者を診断する際、患者が発熱していることに気付き、それによって体内で炎症が起きている可能性があると推測するかもしれません。医師は特定の問題に対して多くのルールを適用することで最終的な診断を導き出すことができます。

このアプローチは**知識表現**と**推論**に大きく依存しています。人間の専門家から知識を抽出することは最も難しい部分かもしれません。なぜなら、医師は多くの場合、特定の診断を導き出す理由を正確に知らないことがあるからです。時には、明確な思考なしに解決策が頭に浮かぶこともあります。写真から人物の年齢を判断するようなタスクは、知識を操作することに全く還元できない場合もあります。

### ボトムアップアプローチ

一方で、私たちの脳内の最も単純な要素であるニューロンをモデル化しようとすることもできます。コンピュータ内に**人工ニューラルネットワーク**を構築し、例を与えることで問題を解決する方法を教えることができます。このプロセスは、新生児が観察を通じて周囲について学ぶ方法に似ています。

✅ 赤ちゃんが学ぶ方法について少し調べてみてください。赤ちゃんの脳の基本的な要素は何でしょうか？

> | 機械学習については？         |      |
> |--------------|-----------|
> | データに基づいて問題を解決する方法をコンピュータが学習する人工知能の一部は**機械学習**と呼ばれます。このコースでは古典的な機械学習を扱いません。別の[機械学習入門](http://aka.ms/ml-beginners)カリキュラムを参照してください。 |   ![機械学習入門](../../../../translated_images/ml-for-beginners.9e4fed176fd5817d7d1f7d358302515186579cbf09b2a6c5bd8092b345da7f22.ja.png)    |

## AIの簡単な歴史

人工知能は20世紀半ばに分野として始まりました。当初は記号的推論が主流のアプローチであり、専門家システムのような重要な成功をもたらしました。専門家システムは、限定された問題領域で専門家として行動できるコンピュータプログラムです。しかし、このアプローチがうまくスケールしないことがすぐに明らかになりました。専門家から知識を抽出し、それをコンピュータに表現し、その知識ベースを正確に保つことは非常に複雑で、多くの場合実用的ではないほど高価であることが判明しました。このため、1970年代にはいわゆる[AIの冬](https://en.wikipedia.org/wiki/AI_winter)が訪れました。

<img alt="AIの簡単な歴史" src="images/history-of-ai.png" width="70%"/>

> 画像: [Dmitry Soshnikov](http://soshnikov.com)

時が経つにつれて、コンピュータリソースが安価になり、より多くのデータが利用可能になったため、ニューラルネットワークアプローチが多くの分野で人間と競争する上で優れた性能を示し始めました。例えば、コンピュータビジョンや音声理解などです。過去10年間で、人工知能という用語は主にニューラルネットワークの同義語として使用されてきました。なぜなら、私たちが耳にするAIの成功のほとんどがそれに基づいているからです。

チェスをプレイするコンピュータプログラムの作成におけるアプローチの変化を観察することができます：

* 初期のチェスプログラムは探索に基づいていました。プログラムは、次の数手の間に相手の可能な手を明示的に推定し、数手で達成できる最適な位置に基づいて最適な手を選択しました。これにより、いわゆる[アルファベータ刈り込み](https://en.wikipedia.org/wiki/Alpha%E2%80%93beta_pruning)探索アルゴリズムが開発されました。
* 探索戦略は、探索空間が限られているゲームの終盤ではうまく機能しますが、ゲームの序盤では探索空間が非常に広く、既存の人間プレイヤー間の試合から学習することでアルゴリズムを改善することができます。その後の実験では、いわゆる[ケースベース推論](https://en.wikipedia.org/wiki/Case-based_reasoning)が採用されました。プログラムは、ゲームの現在の位置に非常に似たケースを知識ベースで探しました。
* 人間プレイヤーに勝つ現代のプログラムは、ニューラルネットワークと[強化学習](https://en.wikipedia.org/wiki/Reinforcement_learning)に基づいています。これらのプログラムは、自分自身と長時間プレイし、自分のミスから学ぶことでプレイ方法を学びます。これは、人間がチェスを学ぶ方法に非常に似ています。ただし、コンピュータプログラムははるかに短い時間で多くのゲームをプレイできるため、はるかに速く学習できます。

✅ AIがプレイした他のゲームについて少し調べてみてください。

同様に、「話すプログラム」（チューリングテストに合格する可能性があるもの）を作成するアプローチの変化を見ることができます：

* この種の初期のプログラム、例えば[Eliza](https://en.wikipedia.org/wiki/ELIZA)は、非常に単純な文法規則と入力文を質問に再構成することに基づいていました。
* 現代のアシスタント、例えばCortana、Siri、Google Assistantは、音声をテキストに変換し、意図を認識するためにニューラルネットワークを使用し、必要なアクションを実行するために推論や明示的なアルゴリズムを使用するハイブリッドシステムです。
* 将来的には、完全なニューラルベースのモデルが
> Dmitry Soshnikovによる画像、[写真](https://unsplash.com/photos/r8LmVbUKgns)は[Marina Abrosimova](https://unsplash.com/@abrosimova_marina_foto)によるもの、Unsplashより

## 最近のAI研究

ニューラルネットワーク研究の急成長は2010年頃から始まりました。この頃、大規模な公開データセットが利用可能になったのがきっかけです。約1400万枚の注釈付き画像を含む膨大な画像コレクションである[ImageNet](https://en.wikipedia.org/wiki/ImageNet)は、[ImageNet Large Scale Visual Recognition Challenge](https://image-net.org/challenges/LSVRC/)の誕生を促しました。

![ILSVRCの精度](../../../../lessons/1-Intro/images/ilsvrc.gif)

> [Dmitry Soshnikov](http://soshnikov.com)による画像

2012年には、[畳み込みニューラルネットワーク](../4-ComputerVision/07-ConvNets/README.md)が初めて画像分類に使用され、分類エラー率が大幅に低下しました（約30%から16.4%へ）。2015年には、Microsoft ResearchのResNetアーキテクチャが[人間レベルの精度を達成](https://doi.org/10.1109/ICCV.2015.123)しました。

それ以来、ニューラルネットワークは多くのタスクで非常に成功を収めています。

---

年 | 人間と同等の精度達成
-----|--------
2015 | [画像分類](https://doi.org/10.1109/ICCV.2015.123)
2016 | [会話型音声認識](https://arxiv.org/abs/1610.05256)
2018 | [自動機械翻訳](https://arxiv.org/abs/1803.05567)（中国語から英語）
2020 | [画像キャプション生成](https://arxiv.org/abs/2009.13682)

ここ数年で、BERTやGPT-3のような大規模言語モデルの大きな成功を目の当たりにしました。これが可能になった主な理由は、一般的なテキストデータが豊富に存在し、それを利用してモデルがテキストの構造や意味を捉えることができるからです。これにより、一般的なテキストコレクションでモデルを事前学習し、その後特定のタスクに特化させることが可能になりました。このコースの後半で[自然言語処理](../5-NLP/README.md)についてさらに学びます。

## 🚀 チャレンジ

インターネットを巡り、AIが最も効果的に使用されていると思う分野を探してください。それは地図アプリでしょうか、それとも音声認識サービスやビデオゲームでしょうか？そのシステムがどのように構築されたかを調査してください。

## [講義後のクイズ](https://ff-quizzes.netlify.app/en/ai/quiz/2)

## 復習と自己学習

[このレッスン](https://github.com/microsoft/ML-For-Beginners/tree/main/1-Introduction/2-history-of-ML)を読んで、AIとMLの歴史を復習してください。このレッスンや冒頭のスケッチノートから要素を1つ選び、それを深く調査して、その進化を支えた文化的背景を理解してください。

**課題**: [ゲームジャム](assignment.md)

---

