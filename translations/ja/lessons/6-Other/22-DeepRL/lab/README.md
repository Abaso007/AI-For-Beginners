<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7bd8dc72040e98e35e7225e34058cd4e",
  "translation_date": "2025-08-24T21:14:04+00:00",
  "source_file": "lessons/6-Other/22-DeepRL/lab/README.md",
  "language_code": "ja"
}
-->
## 環境

Mountain Carの環境は、谷底に閉じ込められた車で構成されています。目標は谷を飛び越えて旗に到達することです。実行できるアクションは、左に加速する、右に加速する、または何もしないの3つです。観測できるのは、車のx軸上の位置と速度です。

## ノートブックの開始

[MountainCar.ipynb](../../../../../../lessons/6-Other/22-DeepRL/lab/MountainCar.ipynb)を開いてラボを開始してください。

## 学びのポイント

このラボを通じて学ぶべきことは、新しい環境にRLアルゴリズムを適用することはしばしば非常に簡単であるということです。これは、OpenAI Gymがすべての環境に対して同じインターフェースを提供しているためです。また、アルゴリズム自体は環境の性質に大きく依存しません。Pythonコードを再構築して、任意の環境をRLアルゴリズムにパラメータとして渡せるようにすることも可能です。

**免責事項**:  
この文書は、AI翻訳サービス [Co-op Translator](https://github.com/Azure/co-op-translator) を使用して翻訳されています。正確性を追求しておりますが、自動翻訳には誤りや不正確な部分が含まれる可能性があることをご承知ください。元の言語で記載された文書が正式な情報源とみなされるべきです。重要な情報については、専門の人間による翻訳を推奨します。この翻訳の使用に起因する誤解や誤解釈について、当方は責任を負いません。