<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "0b306c04f5337b6e7430e5c0b16bb5c0",
  "translation_date": "2025-08-24T21:07:56+00:00",
  "source_file": "lessons/4-ComputerVision/09-Autoencoders/README.md",
  "language_code": "ja"
}
-->
# オートエンコーダー

CNNをトレーニングする際の問題の一つは、大量のラベル付きデータが必要になることです。画像分類の場合、画像を異なるクラスに分ける必要があり、これは手作業で行う必要があります。

## [事前講義クイズ](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/109)

しかし、CNNの特徴抽出器をトレーニングする際に、生データ（ラベルなしデータ）を使用したい場合があります。これを**自己教師あり学習**と呼びます。ラベルの代わりに、トレーニング画像をネットワークの入力と出力の両方として使用します。**オートエンコーダー**の主なアイデアは、入力画像を**潜在空間**（通常は小さなサイズのベクトル）に変換する**エンコーダーネットワーク**を持ち、その後、元の画像を再構築することを目指す**デコーダーネットワーク**を使用することです。

> ✅ [オートエンコーダー](https://wikipedia.org/wiki/Autoencoder)は「ラベルなしデータの効率的なコーディングを学習するために使用される人工ニューラルネットワークの一種」です。

オートエンコーダーをトレーニングする際、元の画像から可能な限り多くの情報を正確に再構築するためにキャプチャしようとするため、ネットワークは入力画像の意味を捉える最適な**埋め込み**を見つけようとします。

![オートエンコーダーの図](../../../../../translated_images/autoencoder_schema.5e6fc9ad98a5eb6197f3513cf3baf4dfbe1389a6ae74daebda64de9f1c99f142.ja.jpg)

> 画像提供：[Kerasブログ](https://blog.keras.io/building-autoencoders-in-keras.html)

## オートエンコーダーの使用シナリオ

元の画像を再構築すること自体はあまり有用ではないように思えますが、オートエンコーダーが特に役立ついくつかのシナリオがあります：

* **画像の次元を下げて可視化する**、または**画像埋め込みをトレーニングする**。通常、オートエンコーダーはPCAよりも良い結果をもたらします。これは、画像の空間的な性質や階層的な特徴を考慮するためです。
* **ノイズ除去**、つまり画像からノイズを取り除くこと。ノイズは多くの無駄な情報を含むため、オートエンコーダーは比較的小さな潜在空間にすべてを収めることができず、画像の重要な部分のみをキャプチャします。ノイズ除去器をトレーニングする際には、元の画像を使用し、人工的にノイズを追加した画像をオートエンコーダーの入力として使用します。
* **超解像**、画像の解像度を向上させること。高解像度の画像を使用し、低解像度の画像をオートエンコーダーの入力として使用します。
* **生成モデル**。オートエンコーダーをトレーニングした後、デコーダー部分を使用してランダムな潜在ベクトルから新しいオブジェクトを作成することができます。

## 変分オートエンコーダー (VAE)

従来のオートエンコーダーは、入力データの次元を何らかの方法で削減し、入力画像の重要な特徴を見つけます。しかし、潜在ベクトルはあまり意味を持たないことがよくあります。例えば、MNISTデータセットを例にとると、異なる潜在ベクトルがどの数字に対応するかを理解するのは簡単ではありません。近い潜在ベクトルが必ずしも同じ数字に対応するわけではないからです。

一方で、*生成*モデルをトレーニングするには、潜在空間を理解する方が望ましいです。このアイデアが**変分オートエンコーダー** (VAE) につながります。

VAEは、潜在パラメータの*統計分布*、いわゆる**潜在分布**を予測することを学習するオートエンコーダーです。例えば、潜在ベクトルが平均z<sub>mean</sub>と標準偏差z<sub>sigma</sub>（どちらも次元dのベクトル）を持つ正規分布に従うようにしたい場合があります。VAEのエンコーダーはこれらのパラメータを予測し、デコーダーはこの分布からランダムなベクトルを取り出してオブジェクトを再構築します。

まとめると：

 * 入力ベクトルから`z_mean`と`z_log_sigma`を予測します（標準偏差そのものではなく、その対数を予測します）
 * 分布N(z<sub>mean</sub>,exp(z<sub>log_sigma</sub>))からベクトル`sample`をサンプリングします
 * デコーダーは`sample`を入力ベクトルとして使用して元の画像をデコードしようとします

 <img src="images/vae.png" width="50%">

> 画像提供：[Isaak Dykemanのブログ記事](https://ijdykeman.github.io/ml/2016/12/21/cvae.html)

変分オートエンコーダーは、2つの部分からなる複雑な損失関数を使用します：

* **再構築損失**は、再構築された画像がターゲットにどれだけ近いかを示す損失関数です（平均二乗誤差、MSEなど）。通常のオートエンコーダーと同じ損失関数です。
* **KL損失**は、潜在変数分布が正規分布に近い状態を維持することを保証します。[Kullback-Leiblerダイバージェンス](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained)という概念に基づいており、2つの統計分布がどれだけ似ているかを推定する指標です。

VAEの重要な利点の一つは、潜在ベクトルをサンプリングする分布が分かっているため、新しい画像を比較的簡単に生成できることです。例えば、MNISTで2次元の潜在ベクトルを使用してVAEをトレーニングした場合、潜在ベクトルの成分を変化させることで異なる数字を得ることができます：

<img alt="vaemnist" src="images/vaemnist.png" width="50%"/>

> 画像提供：[Dmitry Soshnikov](http://soshnikov.com)

画像がどのように互いにブレンドされるかを観察してください。潜在パラメータ空間の異なる部分から潜在ベクトルを取得し始めると、画像が変化していきます。この空間を2次元で可視化することもできます：

<img alt="vaemnist cluster" src="images/vaemnist-diag.png" width="50%"/> 

> 画像提供：[Dmitry Soshnikov](http://soshnikov.com)

## ✍️ 演習：オートエンコーダー

以下の対応するノートブックでオートエンコーダーについてさらに学びましょう：

* [TensorFlowでのオートエンコーダー](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb)
* [PyTorchでのオートエンコーダー](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoEncodersPyTorch.ipynb)

## オートエンコーダーの特性

* **データ特化型** - トレーニングした画像の種類にのみ適しています。例えば、花の超解像ネットワークをトレーニングした場合、ポートレートにはうまく機能しません。これは、ネットワークがトレーニングデータセットから学習した特徴を使用して細かい詳細を取り込むことで高解像度画像を生成するためです。
* **損失あり** - 再構築された画像は元の画像と同じではありません。損失の性質はトレーニング中に使用される*損失関数*によって定義されます。
* **ラベルなしデータ**で動作します。

## [事後講義クイズ](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/209)

## 結論

このレッスンでは、AI研究者が利用できるさまざまな種類のオートエンコーダーについて学びました。それらを構築する方法や、画像を再構築するための使用方法について学びました。また、VAEについて学び、それを使用して新しい画像を生成する方法も学びました。

## 🚀 チャレンジ

このレッスンでは、画像にオートエンコーダーを使用する方法について学びました。しかし、音楽にも使用できます！Magentaプロジェクトの[MusicVAE](https://magenta.tensorflow.org/music-vae)プロジェクトをチェックしてみてください。このプロジェクトでは、オートエンコーダーを使用して音楽を再構築する方法を学習します。このライブラリを使用して[実験](https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/Multitrack_MusicVAE.ipynb)を行い、何が作れるか試してみてください。

## [事後講義クイズ](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/208)

## 復習と自己学習

参考として、以下のリソースでオートエンコーダーについてさらに学びましょう：

* [Kerasでオートエンコーダーを構築する](https://blog.keras.io/building-autoencoders-in-keras.html)
* [NeuroHiveのブログ記事](https://neurohive.io/ru/osnovy-data-science/variacionnyj-avtojenkoder-vae/)
* [変分オートエンコーダーの解説](https://kvfrans.com/variational-autoencoders-explained/)
* [条件付き変分オートエンコーダー](https://ijdykeman.github.io/ml/2016/12/21/cvae.html)

## 課題

[TensorFlowを使用したこのノートブック](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb)の最後に「タスク」があります - これを課題として使用してください。

**免責事項**:  
この文書は、AI翻訳サービス [Co-op Translator](https://github.com/Azure/co-op-translator) を使用して翻訳されています。正確性を追求しておりますが、自動翻訳には誤りや不正確な部分が含まれる可能性があります。元の言語で記載された文書を正式な情報源としてお考えください。重要な情報については、専門の人間による翻訳を推奨します。この翻訳の使用に起因する誤解や誤解釈について、当社は責任を負いません。