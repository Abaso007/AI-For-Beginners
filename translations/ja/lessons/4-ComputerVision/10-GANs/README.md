<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f07c85bbf05a1f67505da98f4ecc124c",
  "translation_date": "2025-08-24T21:08:44+00:00",
  "source_file": "lessons/4-ComputerVision/10-GANs/README.md",
  "language_code": "ja"
}
-->
# 敵対的生成ネットワーク (Generative Adversarial Networks)

前のセクションでは、**生成モデル**について学びました。これは、トレーニングデータセットに似た新しい画像を生成できるモデルです。VAEは生成モデルの良い例でした。

## [事前クイズ](https://ff-quizzes.netlify.app/en/ai/quiz/19)

しかし、VAEを使って合理的な解像度の絵画のような本当に意味のあるものを生成しようとすると、トレーニングがうまく収束しないことがわかります。このようなケースでは、生成モデルに特化した別のアーキテクチャである**敵対的生成ネットワーク (Generative Adversarial Networks, GANs)** を学ぶ必要があります。

GANの主なアイデアは、2つのニューラルネットワークを互いに競わせながらトレーニングすることです。

<img src="images/gan_architecture.png" width="70%"/>

> 画像提供: [Dmitry Soshnikov](http://soshnikov.com)

> ✅ 用語解説:
> * **Generator (生成器)**: ランダムなベクトルを入力として受け取り、画像を生成するネットワーク
> * **Discriminator (識別器)**: 画像を入力として受け取り、それがトレーニングデータセットからの実際の画像か、生成器によって生成された画像かを判定するネットワーク。本質的には画像分類器です。

### 識別器 (Discriminator)

識別器のアーキテクチャは、通常の画像分類ネットワークと大差ありません。最も単純な場合、完全結合型の分類器として設計できますが、通常は[畳み込みネットワーク](../07-ConvNets/README.md)が使用されます。

> ✅ 畳み込みネットワークに基づくGANは、[DCGAN](https://arxiv.org/pdf/1511.06434.pdf) と呼ばれます。

CNNベースの識別器は以下のような層で構成されます: 複数の畳み込み+プーリング層（空間サイズを縮小）と、1つ以上の完全結合層で「特徴ベクトル」を取得し、最終的に2値分類器を構築します。

> ✅ 「プーリング」とは、画像のサイズを縮小する技術です。「プーリング層は、ある層のニューロンクラスターの出力を次の層の1つのニューロンに結合することで、データの次元を削減します。」 - [出典](https://wikipedia.org/wiki/Convolutional_neural_network#Pooling_layers)

### 生成器 (Generator)

生成器は少し複雑です。識別器を逆にしたものと考えることができます。潜在ベクトル（特徴ベクトルの代わり）から始まり、完全結合層で必要なサイズ/形状に変換し、その後に逆畳み込み+アップスケーリングを行います。これは[オートエンコーダ](../09-Autoencoders/README.md)の*デコーダ*部分に似ています。

> ✅ 畳み込み層が画像を走査する線形フィルタとして実装されるため、逆畳み込みは本質的に畳み込みと似ており、同じ層のロジックを使用して実装できます。

<img src="images/gan_arch_detail.png" width="70%"/>

> 画像提供: [Dmitry Soshnikov](http://soshnikov.com)

### GANのトレーニング

GANが**敵対的**と呼ばれるのは、生成器と識別器の間で常に競争が行われるためです。この競争を通じて、生成器と識別器の両方が改善され、ネットワークはより良い画像を生成する方法を学びます。

トレーニングは2つのステージで行われます:

* **識別器のトレーニング**: このタスクは比較的簡単です。生成器によって生成された画像のバッチを生成し、それにラベル0（偽画像）を付け、入力データセットからの画像バッチ（ラベル1、実画像）を使用します。これにより*識別器の損失*を取得し、バックプロパゲーションを行います。
* **生成器のトレーニング**: これは少し複雑です。生成器の期待出力が直接的にはわからないためです。生成器と識別器を組み合わせたGAN全体にランダムベクトルを入力し、結果が1（実画像に対応）になることを期待します。このステップでは識別器のパラメータを固定し（この段階では識別器をトレーニングしない）、バックプロパゲーションを行います。

このプロセス中、生成器と識別器の損失は大幅には減少しません。理想的には、両方のネットワークが改善されることに対応して損失が振動するはずです。

## ✍️ 演習: GANs

* [TensorFlow/KerasでのGANノートブック](../../../../../lessons/4-ComputerVision/10-GANs/GANTF.ipynb)
* [PyTorchでのGANノートブック](../../../../../lessons/4-ComputerVision/10-GANs/GANPyTorch.ipynb)

### GANトレーニングの問題点

GANは特にトレーニングが難しいことで知られています。以下はいくつかの問題点です:

* **モード崩壊**: 生成器が1つの成功した画像を生成することを学び、それが識別器を騙すだけで、さまざまな画像を生成しない現象。
* **ハイパーパラメータへの感度**: GANが全く収束しない場合があり、学習率を突然下げることで収束することがあります。
* **生成器と識別器のバランスを保つ**: 多くの場合、識別器の損失が比較的早くゼロに近づき、生成器がそれ以上トレーニングできなくなることがあります。これを克服するために、生成器と識別器に異なる学習率を設定したり、識別器の損失がすでに低い場合は識別器のトレーニングをスキップすることが考えられます。
* **高解像度のトレーニング**: オートエンコーダと同様の問題で、畳み込みネットワークの層が多すぎるとアーティファクトが発生します。この問題は、まず低解像度の画像で数層をトレーニングし、その後層を「アンロック」または追加する**プログレッシブグローイング**で解決されることが多いです。また、層間に追加の接続を設け、複数の解像度を同時にトレーニングする方法もあります。詳細はこの[Multi-Scale Gradient GANs 論文](https://arxiv.org/abs/1903.06048)を参照してください。

## スタイル転送 (Style Transfer)

GANは芸術的な画像を生成するのに優れた方法です。もう1つ興味深い技術が**スタイル転送**です。これは1つの**コンテンツ画像**を取り、別のスタイルで描き直す技術で、**スタイル画像**のフィルタを適用します。

その仕組みは以下の通りです:
* ランダムなノイズ画像（またはコンテンツ画像）から始めますが、理解を簡単にするためにランダムノイズから始める方が良いです。
* 目標は、コンテンツ画像とスタイル画像の両方に近い画像を作成することです。これは2つの損失関数によって決定されます:
   - **コンテンツ損失**: 現在の画像とコンテンツ画像からCNNのいくつかの層で抽出された特徴に基づいて計算されます。
   - **スタイル損失**: 現在の画像とスタイル画像の間で、グラム行列を使用して巧妙に計算されます（詳細は[例ノートブック](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)を参照）。
* 画像を滑らかにし、ノイズを除去するために、隣接するピクセル間の平均距離を計算する**変動損失**も導入します。
* 主な最適化ループでは、勾配降下法（または他の最適化アルゴリズム）を使用して現在の画像を調整し、3つの損失の加重和である総損失を最小化します。

## ✍️ 例: [スタイル転送](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)

## [事後クイズ](https://ff-quizzes.netlify.app/en/ai/quiz/20)

## 結論

このレッスンでは、GANとそのトレーニング方法について学びました。また、このタイプのニューラルネットワークが直面する特有の課題と、それを克服するためのいくつかの戦略についても学びました。

## 🚀 チャレンジ

[スタイル転送ノートブック](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)を実行し、自分の画像を使用してみましょう。

## 復習と自己学習

参考として、以下のリソースでGANについてさらに学んでください:

* Marco Pasini, [10 Lessons I Learned Training GANs for one Year](https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628)
* [StyleGAN](https://en.wikipedia.org/wiki/StyleGAN): 検討すべき事実上のGANアーキテクチャ
* [Azure MLを使用したGANによる生成アートの作成](https://soshnikov.com/scienceart/creating-generative-art-using-gan-on-azureml/)

## 課題

このレッスンに関連する2つのノートブックのいずれかを再訪し、自分の画像でGANを再トレーニングしてください。どのようなものが作れるでしょうか？

**免責事項**:  
この文書は、AI翻訳サービス [Co-op Translator](https://github.com/Azure/co-op-translator) を使用して翻訳されています。正確性を期すよう努めておりますが、自動翻訳には誤りや不正確な部分が含まれる可能性があります。元の言語で記載された原文が公式な情報源と見なされるべきです。重要な情報については、専門の人間による翻訳を推奨します。本翻訳の使用に起因する誤解や誤認について、当方は一切の責任を負いません。