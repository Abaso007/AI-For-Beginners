<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "2f7b97b375358cb51a1e098df306bf73",
  "translation_date": "2025-08-24T21:10:24+00:00",
  "source_file": "lessons/4-ComputerVision/07-ConvNets/CNN_Architectures.md",
  "language_code": "ja"
}
-->
# よく知られたCNNアーキテクチャ

### VGG-16

VGG-16は、2014年にImageNetのトップ5分類で92.7%の精度を達成したネットワークです。そのレイヤー構造は以下の通りです：

![ImageNet Layers](../../../../../translated_images/vgg-16-arch1.d901a5583b3a51baeaab3e768567d921e5d54befa46e1e642616c5458c934028.ja.jpg)

ご覧の通り、VGGは伝統的なピラミッド型アーキテクチャを採用しており、畳み込み層とプーリング層が順番に並んでいます。

![ImageNet Pyramid](../../../../../translated_images/vgg-16-arch.64ff2137f50dd49fdaa786e3f3a975b3f22615efd13efb19c5d22f12e01451a1.ja.jpg)

> 画像出典: [Researchgate](https://www.researchgate.net/figure/Vgg16-model-structure-To-get-the-VGG-NIN-model-we-replace-the-2-nd-4-th-6-th-7-th_fig2_335194493)

### ResNet

ResNetは、2015年にMicrosoft Researchによって提案されたモデルファミリーです。ResNetの主なアイデアは、**残差ブロック**を使用することです：

<img src="images/resnet-block.png" width="300"/>

> 画像出典: [この論文](https://arxiv.org/pdf/1512.03385.pdf)

アイデンティティパススルーを使用する理由は、レイヤーが**前のレイヤーの結果と残差ブロックの出力との差分**を予測するようにするためです。このため「残差」という名前が付けられています。これらのブロックは非常に学習しやすく、数百ものブロックを持つネットワークを構築することが可能です（最も一般的なバリエーションはResNet-52、ResNet-101、ResNet-152です）。

また、このネットワークはデータセットに応じてその複雑さを調整できると考えることもできます。ネットワークの学習を開始したばかりのときは、重みの値が小さく、ほとんどの信号がアイデンティティ層を通過します。学習が進み、重みが大きくなるにつれて、ネットワークパラメータの重要性が増し、ネットワークは必要な表現力を調整して、トレーニング画像を正しく分類できるようになります。

### Google Inception

Google Inceptionアーキテクチャは、このアイデアをさらに一歩進め、各ネットワーク層を複数の異なるパスの組み合わせとして構築します：

<img src="images/inception.png" width="400"/>

> 画像出典: [Researchgate](https://www.researchgate.net/figure/Inception-module-with-dimension-reductions-left-and-schema-for-Inception-ResNet-v1_fig2_355547454)

ここで、1x1畳み込みの役割を強調する必要があります。一見すると、1x1フィルターで画像を処理することに意味がないように思えるかもしれません。しかし、畳み込みフィルターは複数の深さチャネル（元々はRGBカラー、後の層では異なるフィルターのチャネル）でも機能することを思い出してください。1x1畳み込みは、異なる学習可能な重みを使用してこれらの入力チャネルを混ぜ合わせるために使用されます。また、チャネル次元でのダウンサンプリング（プーリング）としても見ることができます。

このテーマについては[こちらのブログ記事](https://medium.com/analytics-vidhya/talented-mr-1x1-comprehensive-look-at-1x1-convolution-in-deep-learning-f6b355825578)や[元論文](https://arxiv.org/pdf/1312.4400.pdf)が参考になります。

### MobileNet

MobileNetは、モバイルデバイスに適した小型のモデルファミリーです。リソースが限られており、多少の精度を犠牲にしても良い場合に使用します。これらのモデルの主なアイデアは、**深さ方向分離可能畳み込み**と呼ばれるもので、空間的な畳み込みと深さチャネルに対する1x1畳み込みの組み合わせで畳み込みフィルターを表現します。これにより、パラメータ数が大幅に削減され、ネットワークのサイズが小さくなり、少ないデータでの学習も容易になります。

[MobileNetに関する良いブログ記事](https://medium.com/analytics-vidhya/image-classification-with-mobilenet-cc6fbb2cd470)はこちらです。

## 結論

このユニットでは、コンピュータビジョンのニューラルネットワーク、つまり畳み込みネットワークの基本概念を学びました。画像分類、物体検出、さらには画像生成ネットワークを支える実際のアーキテクチャは、すべてCNNに基づいており、レイヤー数が多く、いくつかの追加の学習トリックが加えられています。

## 🚀 チャレンジ

付属のノートブックには、精度を向上させる方法についてのメモがあります。いくつかの実験を行い、より高い精度を達成できるか試してみてください。

## [講義後のクイズ](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/207)

## 復習と自己学習

CNNは主にコンピュータビジョンのタスクで使用されますが、固定サイズのパターンを抽出するのに適しているため、他の用途にも利用できます。例えば、音声を扱う場合、音声信号内の特定のパターンを探すためにCNNを使用することが考えられます。この場合、フィルターは1次元（このCNNは1D-CNNと呼ばれます）になります。また、3D-CNNを使用して、ビデオ内の特定のイベントのような多次元空間の特徴を抽出することもあります。CNNが時間の経過に伴う特徴の変化パターンを捉えることができるのです。他のタスクでCNNがどのように使用されるかについて復習と自己学習を行ってください。

## [課題](lab/README.md)

このラボでは、異なる猫と犬の品種を分類するタスクに取り組みます。これらの画像はMNISTデータセットよりも複雑で、次元が高く、クラス数も10以上あります。

**免責事項**:  
この文書は、AI翻訳サービス [Co-op Translator](https://github.com/Azure/co-op-translator) を使用して翻訳されています。正確性を追求しておりますが、自動翻訳には誤りや不正確な部分が含まれる可能性があることをご承知ください。元の言語で記載された文書が正式な情報源とみなされるべきです。重要な情報については、専門の人間による翻訳を推奨します。この翻訳の使用に起因する誤解や誤解釈について、当方は一切の責任を負いません。