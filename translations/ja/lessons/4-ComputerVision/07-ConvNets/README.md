<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "088837b42b7d99198bf62db8a42411e0",
  "translation_date": "2025-08-24T21:10:02+00:00",
  "source_file": "lessons/4-ComputerVision/07-ConvNets/README.md",
  "language_code": "ja"
}
-->
# 畳み込みニューラルネットワーク (CNN)

これまでに、ニューラルネットワークが画像処理に非常に優れていることを見てきました。たとえ1層のパーセプトロンであっても、MNISTデータセットの手書き数字をある程度の精度で認識できることが分かっています。しかし、MNISTデータセットは非常に特殊で、すべての数字が画像の中心に配置されているため、タスクが簡単になっています。

## [講義前クイズ](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/107)

現実世界では、画像内の正確な位置に関係なく、写真の中の物体を認識できることが求められます。コンピュータビジョンは一般的な分類とは異なります。なぜなら、写真の中で特定の物体を見つけようとする際、特定の**パターン**やその組み合わせを探すために画像をスキャンするからです。例えば、猫を探す場合、まず水平線を探してヒゲを形成し、その後、特定のヒゲの組み合わせが実際に猫の写真であることを示すかもしれません。特定のパターンの相対的な位置や存在が重要であり、画像上の正確な位置はそれほど重要ではありません。

パターンを抽出するために、**畳み込みフィルタ**という概念を使用します。ご存知の通り、画像は2次元の行列、または色の深さを持つ3次元テンソルで表されます。フィルタを適用するとは、比較的小さな**フィルタカーネル**行列を使用し、元の画像の各ピクセルに対して隣接する点との加重平均を計算することを意味します。これは、小さなウィンドウが画像全体をスライドし、フィルタカーネル行列の重みに従ってすべてのピクセルを平均化するようなものと考えることができます。

![垂直エッジフィルタ](../../../../../translated_images/filter-vert.b7148390ca0bc356ddc7e55555d2481819c1e86ddde9dce4db5e71a69d6f887f.ja.png) | ![水平エッジフィルタ](../../../../../translated_images/filter-horiz.59b80ed4feb946efbe201a7fe3ca95abb3364e266e6fd90820cb893b4d3a6dda.ja.png)
----|----

> 画像提供: Dmitry Soshnikov

例えば、MNISTの数字に3x3の垂直エッジフィルタと水平エッジフィルタを適用すると、元の画像で垂直および水平のエッジがある場所が強調されます（例: 高い値が得られる）。したがって、これら2つのフィルタはエッジを「探す」ために使用できます。同様に、他の低レベルのパターンを探すための異なるフィルタを設計することも可能です。

> [Leung-Malikフィルタバンクの画像](https://www.robots.ox.ac.uk/~vgg/research/texclass/filters.html)

しかし、フィルタを手動で設計してパターンを抽出することもできますが、ネットワークを設計してパターンを自動的に学習させることも可能です。これがCNNの主要なアイデアの1つです。

## CNNの主要なアイデア

CNNが動作する仕組みは、以下の重要なアイデアに基づいています:

* 畳み込みフィルタはパターンを抽出できる
* フィルタを自動的に学習するようにネットワークを設計できる
* 元の画像だけでなく、高レベルの特徴においても同じアプローチを使用してパターンを見つけることができる。したがって、CNNの特徴抽出は、低レベルのピクセルの組み合わせから始まり、画像の部分の高レベルの組み合わせに至るまで、特徴の階層構造で機能する。

![階層的特徴抽出](../../../../../translated_images/FeatureExtractionCNN.d9b456cbdae7cb643fde3032b81b2940e3cf8be842e29afac3f482725ba7f95c.ja.png)

> 画像提供: [Hislop-Lynchの論文](https://www.semanticscholar.org/paper/Computer-vision-based-pedestrian-trajectory-Hislop-Lynch/26e6f74853fc9bbb7487b06dc2cf095d36c9021d)、[研究内容](https://dl.acm.org/doi/abs/10.1145/1553374.1553453)に基づく

## ✍️ 演習: 畳み込みニューラルネットワーク

畳み込みニューラルネットワークがどのように機能するのか、またトレーニング可能なフィルタをどのように実現できるのかを、以下のノートブックを通じて学びましょう:

* [畳み込みニューラルネットワーク - PyTorch](../../../../../lessons/4-ComputerVision/07-ConvNets/ConvNetsPyTorch.ipynb)
* [畳み込みニューラルネットワーク - TensorFlow](../../../../../lessons/4-ComputerVision/07-ConvNets/ConvNetsTF.ipynb)

## ピラミッドアーキテクチャ

画像処理に使用されるほとんどのCNNは、いわゆるピラミッドアーキテクチャに従っています。元の画像に適用される最初の畳み込み層は、通常、比較的少ない数のフィルタ（8～16）を持ち、水平/垂直の線やストロークなどの異なるピクセルの組み合わせに対応します。次のレベルでは、ネットワークの空間的次元を縮小し、フィルタの数を増やします。これにより、単純な特徴のより多くの組み合わせが可能になります。各層を進むにつれて、最終的な分類器に近づくにつれ、画像の空間的次元は減少し、フィルタの数は増加します。

例として、2014年にImageNetのトップ5分類で92.7%の精度を達成したVGG-16のアーキテクチャを見てみましょう:

![ImageNetの層](../../../../../translated_images/vgg-16-arch1.d901a5583b3a51baeaab3e768567d921e5d54befa46e1e642616c5458c934028.ja.jpg)

![ImageNetのピラミッド](../../../../../translated_images/vgg-16-arch.64ff2137f50dd49fdaa786e3f3a975b3f22615efd13efb19c5d22f12e01451a1.ja.jpg)

> 画像提供: [Researchgate](https://www.researchgate.net/figure/Vgg16-model-structure-To-get-the-VGG-NIN-model-we-replace-the-2-nd-4-th-6-th-7-th_fig2_335194493)

## よく知られたCNNアーキテクチャ

[よく知られたCNNアーキテクチャについてさらに学びましょう](CNN_Architectures.md)

**免責事項**:  
この文書は、AI翻訳サービス [Co-op Translator](https://github.com/Azure/co-op-translator) を使用して翻訳されています。正確性を追求しておりますが、自動翻訳には誤りや不正確な部分が含まれる可能性があります。元の言語で記載された文書を正式な情報源としてお考えください。重要な情報については、専門の人間による翻訳を推奨します。この翻訳の使用に起因する誤解や誤解釈について、当方は一切の責任を負いません。