{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prosty Klasyfikator Obraz√≥w\n",
    "\n",
    "Ten notebook pokazuje, jak klasyfikowaƒá obrazy za pomocƒÖ wstƒôpnie wytrenowanej sieci neuronowej.\n",
    "\n",
    "**Czego siƒô nauczysz:**\n",
    "- Jak za≈Çadowaƒá i u≈ºywaƒá wstƒôpnie wytrenowanego modelu\n",
    "- Przetwarzanie obraz√≥w\n",
    "- Dokonywanie predykcji na obrazach\n",
    "- Zrozumienie wynik√≥w pewno≈õci\n",
    "\n",
    "**Przypadek u≈ºycia:** Identyfikacja obiekt√≥w na obrazach (np. \"kot\", \"pies\", \"samoch√≥d\" itd.)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Krok 1: Importowanie wymaganych bibliotek\n",
    "\n",
    "Zaimportujmy potrzebne narzƒôdzia. Nie martw siƒô, je≈õli jeszcze nie rozumiesz wszystkich!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# TensorFlow for deep learning\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.applications import MobileNetV2\n",
    "    from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, decode_predictions\n",
    "    print(\"‚úÖ TensorFlow loaded successfully!\")\n",
    "    print(f\"   Version: {tf.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå Please install TensorFlow: pip install tensorflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Krok 2: Za≈Çaduj wstƒôpnie wytrenowany model\n",
    "\n",
    "U≈ºyjemy **MobileNetV2**, sieci neuronowej ju≈º wytrenowanej na milionach obraz√≥w.\n",
    "\n",
    "To nazywa siƒô **Transfer Learning** - korzystanie z modelu wytrenowanego przez kogo≈õ innego!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üì¶ Loading pre-trained MobileNetV2 model...\")\n",
    "print(\"   This may take a minute on first run (downloading weights)...\")\n",
    "\n",
    "# Load the model\n",
    "# include_top=True means we use the classification layer\n",
    "# weights='imagenet' means it was trained on ImageNet dataset\n",
    "model = MobileNetV2(weights='imagenet', include_top=True)\n",
    "\n",
    "print(\"‚úÖ Model loaded!\")\n",
    "print(f\"   The model can recognize 1000 different object categories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Krok 3: Funkcje pomocnicze\n",
    "\n",
    "Stw√≥rzmy funkcje do ≈Çadowania i przygotowywania obraz√≥w dla naszego modelu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_from_url(url):\n",
    "    \"\"\"\n",
    "    Load an image from a URL.\n",
    "    \n",
    "    Args:\n",
    "        url: Web address of the image\n",
    "        \n",
    "    Returns:\n",
    "        PIL Image object\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    return img\n",
    "\n",
    "\n",
    "def prepare_image(img):\n",
    "    \"\"\"\n",
    "    Prepare an image for the model.\n",
    "    \n",
    "    Steps:\n",
    "    1. Resize to 224x224 (model's expected size)\n",
    "    2. Convert to array\n",
    "    3. Add batch dimension\n",
    "    4. Preprocess for MobileNetV2\n",
    "    \n",
    "    Args:\n",
    "        img: PIL Image\n",
    "        \n",
    "    Returns:\n",
    "        Preprocessed image array\n",
    "    \"\"\"\n",
    "    # Resize to 224x224 pixels\n",
    "    img = img.resize((224, 224))\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    img_array = np.array(img)\n",
    "    \n",
    "    # Add batch dimension (model expects multiple images)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    # Preprocess for MobileNetV2\n",
    "    img_array = preprocess_input(img_array)\n",
    "    \n",
    "    return img_array\n",
    "\n",
    "\n",
    "def classify_image(img):\n",
    "    \"\"\"\n",
    "    Classify an image and return top predictions.\n",
    "    \n",
    "    Args:\n",
    "        img: PIL Image\n",
    "        \n",
    "    Returns:\n",
    "        List of (class_name, confidence) tuples\n",
    "    \"\"\"\n",
    "    # Prepare the image\n",
    "    img_array = prepare_image(img)\n",
    "    \n",
    "    # Make prediction\n",
    "    predictions = model.predict(img_array, verbose=0)\n",
    "    \n",
    "    # Decode predictions to human-readable labels\n",
    "    # top=5 means we get the top 5 most likely classes\n",
    "    decoded = decode_predictions(predictions, top=5)[0]\n",
    "    \n",
    "    # Convert to simpler format\n",
    "    results = [(label, float(confidence)) for (_, label, confidence) in decoded]\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"‚úÖ Helper functions ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Krok 4: Testowanie na przyk≈Çadowych obrazach\n",
    "\n",
    "Spr√≥bujmy sklasyfikowaƒá kilka obraz√≥w z internetu!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample images to classify\n",
    "# These are from Unsplash (free stock photos)\n",
    "test_images = [\n",
    "    {\n",
    "        \"url\": \"https://images.unsplash.com/photo-1514888286974-6c03e2ca1dba?w=400\",\n",
    "        \"description\": \"A cat\"\n",
    "    },\n",
    "    {\n",
    "        \"url\": \"https://images.unsplash.com/photo-1552053831-71594a27632d?w=400\",\n",
    "        \"description\": \"A dog\"\n",
    "    },\n",
    "    {\n",
    "        \"url\": \"https://images.unsplash.com/photo-1511919884226-fd3cad34687c?w=400\",\n",
    "        \"description\": \"A car\"\n",
    "    },\n",
    "]\n",
    "\n",
    "print(f\"üß™ Testing on {len(test_images)} images...\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klasyfikuj Ka≈ºdy Obraz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, img_data in enumerate(test_images, 1):\n",
    "    print(f\"\\nüì∏ Image {i}: {img_data['description']}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    try:\n",
    "        # Load image\n",
    "        img = load_image_from_url(img_data['url'])\n",
    "        \n",
    "        # Display image\n",
    "        display(img.resize((200, 200)))  # Show smaller version\n",
    "        \n",
    "        # Classify\n",
    "        results = classify_image(img)\n",
    "        \n",
    "        # Show predictions\n",
    "        print(\"\\nüéØ Top 5 Predictions:\")\n",
    "        for rank, (label, confidence) in enumerate(results, 1):\n",
    "            # Create a visual bar\n",
    "            bar_length = int(confidence * 50)\n",
    "            bar = \"‚ñà\" * bar_length\n",
    "            \n",
    "            print(f\"  {rank}. {label:20s} {confidence*100:5.2f}% {bar}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Krok 5: Wypr√≥buj w≈Çasne obrazy!\n",
    "\n",
    "Zamie≈Ñ poni≈ºszy URL na dowolny URL obrazu, kt√≥ry chcesz sklasyfikowaƒá.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try your own image!\n",
    "# Replace this URL with any image URL\n",
    "custom_image_url = \"https://images.unsplash.com/photo-1472491235688-bdc81a63246e?w=400\"  # A flower\n",
    "\n",
    "print(\"üñºÔ∏è  Classifying your custom image...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    # Load and show image\n",
    "    img = load_image_from_url(custom_image_url)\n",
    "    display(img.resize((300, 300)))\n",
    "    \n",
    "    # Classify\n",
    "    results = classify_image(img)\n",
    "    \n",
    "    # Show results\n",
    "    print(\"\\nüéØ Top 5 Predictions:\")\n",
    "    print(\"-\" * 70)\n",
    "    for rank, (label, confidence) in enumerate(results, 1):\n",
    "        bar_length = int(confidence * 50)\n",
    "        bar = \"‚ñà\" * bar_length\n",
    "        print(f\"  {rank}. {label:20s} {confidence*100:5.2f}% {bar}\")\n",
    "    \n",
    "    # Highlight top prediction\n",
    "    top_label, top_confidence = results[0]\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"\\nüèÜ Best guess: {top_label} ({top_confidence*100:.2f}% confident)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    print(\"   Make sure the URL points to a valid image!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° Co siƒô w≈Ça≈õnie wydarzy≈Ço?\n",
    "\n",
    "1. **Za≈Çadowali≈õmy wstƒôpnie wytrenowany model** - MobileNetV2 zosta≈Ç wytrenowany na milionach obraz√≥w\n",
    "2. **Przetworzyli≈õmy obrazy** - Zmienili≈õmy ich rozmiar i sformatowali≈õmy je dla modelu\n",
    "3. **Model dokona≈Ç predykcji** - Wyprowadzi≈Ç prawdopodobie≈Ñstwa dla 1000 klas obiekt√≥w\n",
    "4. **Zdekodowali≈õmy wyniki** - Przekszta≈Çcili≈õmy liczby na czytelne dla cz≈Çowieka etykiety\n",
    "\n",
    "### Zrozumienie wynik√≥w pewno≈õci\n",
    "\n",
    "- **90-100%**: Bardzo pewny (niemal na pewno poprawny)\n",
    "- **70-90%**: Pewny (prawdopodobnie poprawny)\n",
    "- **50-70%**: ≈örednio pewny (mo≈ºe byƒá poprawny)\n",
    "- **Poni≈ºej 50%**: Ma≈Ço pewny (niepewny)\n",
    "\n",
    "### Dlaczego predykcje mogƒÖ byƒá b≈Çƒôdne?\n",
    "\n",
    "- **Nietypowy kƒÖt lub o≈õwietlenie** - Model by≈Ç trenowany na typowych zdjƒôciach\n",
    "- **Wiele obiekt√≥w** - Model oczekuje jednego g≈Ç√≥wnego obiektu\n",
    "- **Rzadkie obiekty** - Model zna tylko 1000 kategorii\n",
    "- **Niska jako≈õƒá obrazu** - Rozmazane lub pikselowe obrazy sƒÖ trudniejsze do analizy\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Kolejne kroki\n",
    "\n",
    "1. **Wypr√≥buj r√≥≈ºne obrazy:**\n",
    "   - Znajd≈∫ obrazy na [Unsplash](https://unsplash.com)\n",
    "   - Kliknij prawym przyciskiem myszy ‚Üí ‚ÄûKopiuj adres obrazu‚Äù, aby uzyskaƒá URL\n",
    "\n",
    "2. **Eksperymentuj:**\n",
    "   - Co siƒô dzieje z abstrakcyjnƒÖ sztukƒÖ?\n",
    "   - Czy potrafi rozpoznaƒá obiekty z r√≥≈ºnych perspektyw?\n",
    "   - Jak radzi sobie z wieloma obiektami?\n",
    "\n",
    "3. **Dowiedz siƒô wiƒôcej:**\n",
    "   - Odkryj [lekcje o widzeniu komputerowym](../lessons/4-ComputerVision/README.md)\n",
    "   - Naucz siƒô trenowaƒá w≈Çasny klasyfikator obraz√≥w\n",
    "   - Zrozum, jak dzia≈ÇajƒÖ CNN (Konwolucyjne Sieci Neuronowe)\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ Gratulacje!\n",
    "\n",
    "W≈Ça≈õnie stworzy≈Çe≈õ klasyfikator obraz√≥w, wykorzystujƒÖc najnowocze≈õniejszƒÖ sieƒá neuronowƒÖ!\n",
    "\n",
    "Ta sama technika jest wykorzystywana w:\n",
    "- Google Photos (organizacja zdjƒôƒá)\n",
    "- Samochodach autonomicznych (rozpoznawanie obiekt√≥w)\n",
    "- Diagnostyce medycznej (analiza zdjƒôƒá rentgenowskich)\n",
    "- Kontroli jako≈õci (wykrywanie wad)\n",
    "\n",
    "Kontynuuj eksploracjƒô i naukƒô! üöÄ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Zastrze≈ºenie**:  \nTen dokument zosta≈Ç przet≈Çumaczony za pomocƒÖ us≈Çugi t≈Çumaczeniowej AI [Co-op Translator](https://github.com/Azure/co-op-translator). Chocia≈º dok≈Çadamy wszelkich stara≈Ñ, aby t≈Çumaczenie by≈Ço precyzyjne, prosimy pamiƒôtaƒá, ≈ºe automatyczne t≈Çumaczenia mogƒÖ zawieraƒá b≈Çƒôdy lub nie≈õcis≈Ço≈õci. Oryginalny dokument w jego rodzimym jƒôzyku powinien byƒá uznawany za wiarygodne ≈∫r√≥d≈Ço. W przypadku informacji krytycznych zaleca siƒô skorzystanie z profesjonalnego t≈Çumaczenia wykonanego przez cz≈Çowieka. Nie ponosimy odpowiedzialno≈õci za jakiekolwiek nieporozumienia lub b≈Çƒôdne interpretacje wynikajƒÖce z korzystania z tego t≈Çumaczenia.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "coopTranslator": {
   "original_hash": "1d472141d9df46b751542b3c29f88677",
   "translation_date": "2025-10-03T11:45:13+00:00",
   "source_file": "examples/03-image-classifier.ipynb",
   "language_code": "pl"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}