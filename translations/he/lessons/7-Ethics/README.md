<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "437c988596e751072e41a5aad3fcc5d9",
  "translation_date": "2025-08-28T19:42:03+00:00",
  "source_file": "lessons/7-Ethics/README.md",
  "language_code": "he"
}
-->
# בינה מלאכותית אתית ואחראית

אתם כמעט מסיימים את הקורס הזה, ואני מקווה שעד עכשיו ברור לכם שבינה מלאכותית מבוססת על מספר שיטות מתמטיות פורמליות שמאפשרות לנו למצוא קשרים בנתונים ולאמן מודלים לשחזר היבטים מסוימים של התנהגות אנושית. בנקודה זו בהיסטוריה, אנו רואים בבינה מלאכותית כלי רב עוצמה לחילוץ תבניות מנתונים וליישום התבניות הללו לפתרון בעיות חדשות.

## [שאלון לפני ההרצאה](https://white-water-09ec41f0f.azurestaticapps.net/quiz/5/)

עם זאת, במדע בדיוני אנו רואים לעיתים קרובות סיפורים שבהם בינה מלאכותית מהווה סכנה לאנושות. בדרך כלל, סיפורים אלו מתמקדים במרד כלשהו של הבינה המלאכותית, כאשר היא מחליטה להתעמת עם בני האדם. הדבר מרמז שלבינה מלאכותית יש סוג של רגשות או שהיא יכולה לקבל החלטות שלא נצפו על ידי המפתחים שלה.

הסוג של בינה מלאכותית שלמדנו עליו בקורס הזה אינו יותר מאשר חישובים מתמטיים מורכבים. זהו כלי רב עוצמה שיכול לעזור לנו לפתור בעיות, וכמו כל כלי רב עוצמה - ניתן להשתמש בו למטרות טובות או רעות. חשוב לציין, שהוא יכול גם להיות *מנוצל לרעה*.

## עקרונות הבינה המלאכותית האחראית

כדי להימנע משימוש שגוי או מכוון בבינה מלאכותית, מיקרוסופט מציגה את [עקרונות הבינה המלאכותית האחראית](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-77998-cacaste). העקרונות הללו מבוססים על המושגים הבאים:

* **הוגנות** קשורה לבעיה החשובה של *הטיות במודל*, שיכולות להיגרם משימוש בנתונים מוטים לאימון. לדוגמה, כאשר אנו מנסים לחזות את הסיכוי של אדם לקבל עבודה כמפתח תוכנה, המודל עשוי להעדיף גברים - פשוט כי מערך הנתונים לאימון היה כנראה מוטה כלפי קהל גברי. עלינו לאזן בזהירות את נתוני האימון ולחקור את המודל כדי להימנע מהטיות, ולוודא שהמודל מתחשב בתכונות רלוונטיות יותר.
* **אמינות ובטיחות**. מטבעם, מודלים של בינה מלאכותית יכולים לטעות. רשת עצבית מחזירה הסתברויות, ועלינו לקחת זאת בחשבון בעת קבלת החלטות. לכל מודל יש דיוק ושליפה מסוימים, ועלינו להבין זאת כדי למנוע נזק שעלול להיגרם מעצה שגויה.
* **פרטיות ואבטחה** כוללות השלכות ייחודיות לבינה מלאכותית. לדוגמה, כאשר אנו משתמשים בנתונים מסוימים לאימון מודל, הנתונים הללו הופכים במידה מסוימת ל"מוטמעים" במודל. מצד אחד, זה מגביר את האבטחה והפרטיות, ומצד שני - עלינו לזכור אילו נתונים שימשו לאימון המודל.
* **הכללה** פירושה שאנו לא בונים בינה מלאכותית כדי להחליף אנשים, אלא כדי להעצים אנשים ולהפוך את עבודתנו ליצירתית יותר. זה גם קשור להוגנות, כי כאשר אנו מתמודדים עם קהילות שאינן מיוצגות מספיק, רוב מערכי הנתונים שאנו אוספים עשויים להיות מוטים, ועלינו לוודא שהקהילות הללו נכללות ומטופלות כראוי על ידי הבינה המלאכותית.
* **שקיפות**. זה כולל לוודא שאנו תמיד ברורים לגבי השימוש בבינה מלאכותית. בנוסף, בכל מקום אפשרי, אנו רוצים להשתמש במערכות בינה מלאכותית שהן *ניתנות לפרשנות*.
* **אחריות**. כאשר מודלים של בינה מלאכותית מקבלים החלטות מסוימות, לא תמיד ברור מי אחראי להחלטות הללו. עלינו לוודא שאנו מבינים היכן טמונה האחריות להחלטות של הבינה המלאכותית. ברוב המקרים נרצה לשלב בני אדם בתהליך קבלת ההחלטות החשובות, כך שאנשים אמיתיים יישאו באחריות.

## כלים לבינה מלאכותית אחראית

מיקרוסופט פיתחה את [Responsible AI Toolbox](https://github.com/microsoft/responsible-ai-toolbox) הכולל סט של כלים:

* לוח מחוונים לפרשנות (InterpretML)
* לוח מחוונים להוגנות (FairLearn)
* לוח מחוונים לניתוח שגיאות
* לוח מחוונים לבינה מלאכותית אחראית הכולל:

   - EconML - כלי לניתוח סיבתי, המתמקד בשאלות "מה אם"
   - DiCE - כלי לניתוח נגד-עובדתי שמאפשר לראות אילו תכונות יש לשנות כדי להשפיע על החלטת המודל

למידע נוסף על אתיקה בבינה מלאכותית, בקרו ב[שיעור הזה](https://github.com/microsoft/ML-For-Beginners/tree/main/1-Introduction/3-fairness?WT.mc_id=academic-77998-cacaste) בתוכנית הלימודים של למידת מכונה הכוללת משימות.

## סקירה ולמידה עצמית

עברו על [מסלול הלמידה](https://docs.microsoft.com/learn/modules/responsible-ai-principles/?WT.mc_id=academic-77998-cacaste) הזה כדי ללמוד עוד על בינה מלאכותית אחראית.

## [שאלון לאחר ההרצאה](https://white-water-09ec41f0f.azurestaticapps.net/quiz/6/)

---

**כתב ויתור**:  
מסמך זה תורגם באמצעות שירות תרגום מבוסס בינה מלאכותית [Co-op Translator](https://github.com/Azure/co-op-translator). למרות שאנו שואפים לדיוק, יש לקחת בחשבון שתרגומים אוטומטיים עשויים להכיל שגיאות או אי דיוקים. המסמך המקורי בשפתו המקורית צריך להיחשב כמקור סמכותי. עבור מידע קריטי, מומלץ להשתמש בתרגום מקצועי על ידי אדם. איננו נושאים באחריות לאי הבנות או לפרשנויות שגויות הנובעות משימוש בתרגום זה.