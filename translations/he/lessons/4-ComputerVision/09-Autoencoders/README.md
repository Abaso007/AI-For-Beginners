<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "0b306c04f5337b6e7430e5c0b16bb5c0",
  "translation_date": "2025-08-28T19:34:57+00:00",
  "source_file": "lessons/4-ComputerVision/09-Autoencoders/README.md",
  "language_code": "he"
}
-->
# אוטואנקודרים

בעת אימון רשתות CNN, אחת הבעיות היא הצורך בכמות גדולה של נתונים מתויגים. במקרה של סיווג תמונות, יש להפריד תמונות לקבוצות שונות, מה שדורש מאמץ ידני.

## [שאלון לפני השיעור](https://ff-quizzes.netlify.app/en/ai/quiz/17)

עם זאת, ייתכן שנרצה להשתמש בנתונים גולמיים (לא מתויגים) כדי לאמן CNN לחילוץ מאפיינים, מה שנקרא **למידה עצמית-מונחית**. במקום תוויות, נשתמש בתמונות אימון הן כקלט והן כפלט של הרשת. הרעיון המרכזי של **אוטואנקודר** הוא שיהיה לנו **רשת מקודדת** שממירה תמונת קלט למרחב **לטנטי** (בדרך כלל וקטור בגודל קטן יותר), ואז **רשת מפענחת**, שמטרתה לשחזר את התמונה המקורית.

> ✅ [אוטואנקודר](https://wikipedia.org/wiki/Autoencoder) הוא "סוג של רשת עצבית מלאכותית המשמשת ללמידת קידודים יעילים של נתונים לא מתויגים."

מכיוון שאנו מאמנים אוטואנקודר כדי ללכוד כמה שיותר מידע מהתמונה המקורית לצורך שחזור מדויק, הרשת מנסה למצוא את ה**הטמעה** הטובה ביותר של תמונות הקלט כדי ללכוד את המשמעות.

![AutoEncoder Diagram](../../../../../translated_images/autoencoder_schema.5e6fc9ad98a5eb6197f3513cf3baf4dfbe1389a6ae74daebda64de9f1c99f142.he.jpg)

> תמונה מתוך [בלוג Keras](https://blog.keras.io/building-autoencoders-in-keras.html)

## תרחישים לשימוש באוטואנקודרים

למרות ששחזור תמונות מקוריות לא נראה שימושי בפני עצמו, ישנם כמה תרחישים שבהם אוטואנקודרים מועילים במיוחד:

* **הורדת ממדיות של תמונות לצורך ויזואליזציה** או **אימון הטמעות תמונה**. בדרך כלל אוטואנקודרים נותנים תוצאות טובות יותר מ-PCA, מכיוון שהם לוקחים בחשבון את הטבע המרחבי של תמונות ואת המאפיינים ההיררכיים.
* **הסרת רעשים**, כלומר הסרת רעש מהתמונה. מכיוון שרעש נושא מידע חסר תועלת רב, האוטואנקודר אינו יכול להתאים את כולו למרחב הלטנטי הקטן יחסית, ולכן הוא לוכד רק את החלק החשוב של התמונה. בעת אימון מסירי רעשים, אנו מתחילים עם תמונות מקוריות ומשתמשים בתמונות עם רעש מלאכותי כתמונות קלט לאוטואנקודר.
* **שיפור רזולוציה**, הגדלת רזולוציית תמונה. אנו מתחילים עם תמונות ברזולוציה גבוהה ומשתמשים בתמונה ברזולוציה נמוכה כקלט לאוטואנקודר.
* **מודלים גנרטיביים**. לאחר שאנו מאמנים את האוטואנקודר, ניתן להשתמש בחלק המפענח כדי ליצור אובייקטים חדשים החל מוקטורים לטנטיים אקראיים.

## אוטואנקודרים וריאציוניים (VAE)

אוטואנקודרים מסורתיים מפחיתים את ממדי נתוני הקלט בצורה כלשהי, ומגלים את המאפיינים החשובים של תמונות הקלט. עם זאת, וקטורים לטנטיים לעיתים קרובות אינם הגיוניים. במילים אחרות, אם ניקח את מאגר הנתונים MNIST כדוגמה, להבין אילו ספרות תואמות לוקטורים לטנטיים שונים זו משימה לא פשוטה, מכיוון שוקטורים לטנטיים קרובים לא בהכרח תואמים לאותן ספרות.

לעומת זאת, כדי לאמן מודלים *גנרטיביים* עדיף שיהיה לנו הבנה כלשהי של המרחב הלטנטי. רעיון זה מוביל אותנו ל**אוטואנקודר וריאציוני** (VAE).

VAE הוא אוטואנקודר שלומד לחזות *התפלגות סטטיסטית* של הפרמטרים הלטנטיים, מה שנקרא **התפלגות לטנטית**. לדוגמה, ייתכן שנרצה שוקטורים לטנטיים יהיו מופצים נורמלית עם ממוצע z<sub>mean</sub> וסטיית תקן z<sub>sigma</sub> (גם הממוצע וגם סטיית התקן הם וקטורים בעלי ממדיות מסוימת d). המקודד ב-VAE לומד לחזות את הפרמטרים הללו, ואז המפענח לוקח וקטור אקראי מההתפלגות הזו כדי לשחזר את האובייקט.

לסיכום:

* מתוך וקטור הקלט, אנו חוזים `z_mean` ו-`z_log_sigma` (במקום לחזות את סטיית התקן עצמה, אנו חוזים את הלוגריתם שלה)
* אנו דוגמים וקטור `sample` מההתפלגות N(z<sub>mean</sub>,exp(z<sub>log\_sigma</sub>))
* המפענח מנסה לפענח את התמונה המקורית באמצעות `sample` כוקטור קלט

<img src="images/vae.png" width="50%">

> תמונה מתוך [פוסט בבלוג](https://ijdykeman.github.io/ml/2016/12/21/cvae.html) מאת יצחק דייקמן

אוטואנקודרים וריאציוניים משתמשים בפונקציית הפסד מורכבת שמורכבת משני חלקים:

* **הפסד שחזור** הוא פונקציית הפסד שמראה עד כמה התמונה המשוחזרת קרובה ליעד (זה יכול להיות שגיאת ריבועים ממוצעת, או MSE). זו אותה פונקציית הפסד כמו באוטואנקודרים רגילים.
* **KL loss**, שמבטיח שהתפלגות המשתנים הלטנטיים תישאר קרובה להתפלגות נורמלית. זה מבוסס על מושג [סטיית קולבק-לייבלר](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained) - מדד להערכת הדמיון בין שתי התפלגויות סטטיסטיות.

יתרון חשוב של VAEs הוא שהם מאפשרים לנו ליצור תמונות חדשות יחסית בקלות, מכיוון שאנו יודעים מאיזו התפלגות לדגום וקטורים לטנטיים. לדוגמה, אם אנו מאמנים VAE עם וקטור לטנטי דו-ממדי על MNIST, אנו יכולים לשנות את רכיבי הוקטור הלטנטי כדי לקבל ספרות שונות:

<img alt="vaemnist" src="images/vaemnist.png" width="50%"/>

> תמונה מאת [דמיטרי סושניקוב](http://soshnikov.com)

שימו לב כיצד התמונות מתמזגות זו בזו, כאשר אנו מתחילים לקבל וקטורים לטנטיים מחלקים שונים של מרחב הפרמטרים הלטנטיים. אנו יכולים גם להמחיש את המרחב הזה ב-2D:

<img alt="vaemnist cluster" src="images/vaemnist-diag.png" width="50%"/> 

> תמונה מאת [דמיטרי סושניקוב](http://soshnikov.com)

## ✍️ תרגילים: אוטואנקודרים

למדו עוד על אוטואנקודרים במחברות הבאות:

* [אוטואנקודרים ב-TensorFlow](AutoencodersTF.ipynb)
* [אוטואנקודרים ב-PyTorch](AutoEncodersPyTorch.ipynb)

## תכונות של אוטואנקודרים

* **ספציפיים לנתונים** - הם עובדים היטב רק עם סוג התמונות שעליהן אומנו. לדוגמה, אם נאמן רשת לשיפור רזולוציה על פרחים, היא לא תעבוד היטב על דיוקנאות. זאת מכיוון שהרשת יכולה לייצר תמונה ברזולוציה גבוהה על ידי לקיחת פרטים עדינים ממאפיינים שנלמדו ממאגר הנתונים.
* **מאבדים מידע** - התמונה המשוחזרת אינה זהה לתמונה המקורית. אופי האובדן מוגדר על ידי *פונקציית הפסד* שנעשה בה שימוש במהלך האימון.
* עובדים עם **נתונים לא מתויגים**

## [שאלון לאחר השיעור](https://ff-quizzes.netlify.app/en/ai/quiz/18)

## סיכום

בשיעור זה, למדתם על סוגים שונים של אוטואנקודרים הזמינים למדען הבינה המלאכותית. למדתם כיצד לבנות אותם וכיצד להשתמש בהם לשחזור תמונות. כמו כן, למדתם על VAE וכיצד להשתמש בו ליצירת תמונות חדשות.

## 🚀 אתגר

בשיעור זה, למדתם על שימוש באוטואנקודרים לתמונות. אך ניתן להשתמש בהם גם למוזיקה! בדקו את פרויקט Magenta [MusicVAE](https://magenta.tensorflow.org/music-vae), שמשתמש באוטואנקודרים כדי ללמוד לשחזר מוזיקה. ערכו [ניסויים](https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/Multitrack_MusicVAE.ipynb) עם הספרייה הזו כדי לראות מה תוכלו ליצור.

## [שאלון לאחר השיעור](https://ff-quizzes.netlify.app/en/ai/quiz/16)

## סקירה ולימוד עצמי

לקריאה נוספת, למדו עוד על אוטואנקודרים במשאבים הבאים:

* [בניית אוטואנקודרים ב-Keras](https://blog.keras.io/building-autoencoders-in-keras.html)
* [פוסט בבלוג NeuroHive](https://neurohive.io/ru/osnovy-data-science/variacionnyj-avtojenkoder-vae/)
* [הסבר על אוטואנקודרים וריאציוניים](https://kvfrans.com/variational-autoencoders-explained/)
* [אוטואנקודרים וריאציוניים מותנים](https://ijdykeman.github.io/ml/2016/12/21/cvae.html)

## משימה

בסוף [המחברת הזו ב-TensorFlow](AutoencodersTF.ipynb), תמצאו 'משימה' - השתמשו בה כמשימה שלכם.

---

**כתב ויתור**:  
מסמך זה תורגם באמצעות שירות תרגום מבוסס בינה מלאכותית [Co-op Translator](https://github.com/Azure/co-op-translator). למרות שאנו שואפים לדיוק, יש לקחת בחשבון שתרגומים אוטומטיים עשויים להכיל שגיאות או אי-דיוקים. המסמך המקורי בשפתו המקורית נחשב למקור הסמכותי. למידע קריטי, מומלץ להשתמש בתרגום מקצועי על ידי מתרגם אנושי. איננו נושאים באחריות לכל אי-הבנה או פרשנות שגויה הנובעת משימוש בתרגום זה.  