<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f07c85bbf05a1f67505da98f4ecc124c",
  "translation_date": "2025-08-28T19:37:42+00:00",
  "source_file": "lessons/4-ComputerVision/10-GANs/README.md",
  "language_code": "he"
}
-->
# רשתות גנרטיביות מתחרות

בפרק הקודם למדנו על **מודלים גנרטיביים**: מודלים שיכולים ליצור תמונות חדשות הדומות לאלו שבמערך הנתונים של האימון. VAE היה דוגמה טובה למודל גנרטיבי.

## [שאלון לפני השיעור](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/110)

עם זאת, אם ננסה ליצור משהו באמת משמעותי, כמו ציור ברזולוציה סבירה, באמצעות VAE, נראה שהאימון לא מתכנס היטב. לשימוש כזה, כדאי ללמוד על ארכיטקטורה אחרת שמיועדת במיוחד למודלים גנרטיביים - **רשתות גנרטיביות מתחרות**, או GANs.

הרעיון המרכזי של GAN הוא להפעיל שתי רשתות נוירונים שמתאמנות אחת נגד השנייה:

<img src="images/gan_architecture.png" width="70%"/>

> תמונה מאת [Dmitry Soshnikov](http://soshnikov.com)

> ✅ קצת אוצר מילים:
> * **Generator** הוא רשת שמקבלת וקטור אקראי ומייצרת תמונה כתוצאה
> * **Discriminator** הוא רשת שמקבלת תמונה, והיא צריכה לקבוע האם זו תמונה אמיתית (ממערך הנתונים של האימון) או שהיא נוצרה על ידי ה-Generator. למעשה, מדובר בסיווג תמונה.

### Discriminator

הארכיטקטורה של ה-Discriminator אינה שונה מרשת סיווג תמונות רגילה. במקרה הפשוט ביותר, היא יכולה להיות מסווג מבוסס שכבות מחוברות, אך סביר להניח שהיא תהיה [רשת קונבולוציה](../07-ConvNets/README.md).

> ✅ GAN המבוסס על רשתות קונבולוציה נקרא [DCGAN](https://arxiv.org/pdf/1511.06434.pdf)

Discriminator מבוסס CNN מורכב מהשכבות הבאות: מספר שכבות קונבולוציה+Pooling (עם ירידה בגודל המרחבי) ואחת או יותר שכבות מחוברות ליצירת "וקטור תכונות", מסווג בינארי סופי.

> ✅ 'Pooling' בהקשר זה הוא טכניקה שמקטינה את גודל התמונה. "שכבות Pooling מקטינות את ממדי הנתונים על ידי שילוב התוצאות של קבוצות נוירונים בשכבה אחת לנוירון יחיד בשכבה הבאה." - [מקור](https://wikipedia.org/wiki/Convolutional_neural_network#Pooling_layers)

### Generator

ה-Generator מעט יותר מורכב. ניתן להתייחס אליו כאל Discriminator הפוך. החל מוקטור סמוי (במקום וקטור תכונות), יש לו שכבה מחוברת שממירה אותו לגודל/צורה הנדרשים, ואחריה שכבות דה-קונבולוציה+הגדלה. זה דומה לחלק ה-*decoder* של [Autoencoder](../09-Autoencoders/README.md).

> ✅ מכיוון ששכבת הקונבולוציה מיושמת כמסנן ליניארי שעובר על התמונה, דה-קונבולוציה דומה למעשה לקונבולוציה וניתן ליישם אותה באמצעות אותה לוגיקה של שכבה.

<img src="images/gan_arch_detail.png" width="70%"/>

> תמונה מאת [Dmitry Soshnikov](http://soshnikov.com)

### אימון ה-GAN

GANs נקראים **מתחרים** מכיוון שיש תחרות מתמדת בין ה-Generator ל-Discriminator. במהלך התחרות הזו, שניהם משתפרים, וכך הרשת לומדת לייצר תמונות טובות יותר ויותר.

האימון מתבצע בשני שלבים:

* **אימון ה-Discriminator**. משימה זו די פשוטה: אנו מייצרים אצווה של תמונות באמצעות ה-Generator, מסמנים אותן כ-0 (תמונה מזויפת), ולוקחים אצווה של תמונות ממערך הנתונים (עם תווית 1, תמונה אמיתית). אנו מקבלים *Discriminator loss* ומבצעים Backprop.
* **אימון ה-Generator**. זה מעט יותר מורכב, מכיוון שאיננו יודעים את התוצאה הצפויה עבור ה-Generator ישירות. אנו לוקחים את כל רשת ה-GAN שמורכבת מ-Generator ואחריו Discriminator, מזינים אותה עם וקטורים אקראיים, ומצפים שהתוצאה תהיה 1 (תמונות אמיתיות). אנו מקפיאים את הפרמטרים של ה-Discriminator (איננו רוצים לאמן אותו בשלב זה) ומבצעים Backprop.

במהלך התהליך הזה, ה-Loss של ה-Generator וה-Discriminator אינם יורדים באופן משמעותי. במצב אידיאלי, הם אמורים להתנדנד, מה שמעיד על שיפור ביצועי שתי הרשתות.

## ✍️ תרגילים: GANs

* [מחברת GAN ב-TensorFlow/Keras](GANTF.ipynb)
* [מחברת GAN ב-PyTorch](GANPyTorch.ipynb)

### בעיות באימון GAN

GANs ידועים כקשים במיוחד לאימון. הנה כמה בעיות:

* **Mode Collapse**. הכוונה לכך שה-Generator לומד לייצר תמונה אחת מוצלחת שמטעה את ה-Discriminator, ולא מגוון של תמונות שונות.
* **רגישות להיפר-פרמטרים**. לעיתים ניתן לראות ש-GAN לא מתכנס כלל, ואז פתאום שינוי קטן בקצב הלמידה מוביל להתכנסות.
* שמירה על **איזון** בין ה-Generator ל-Discriminator. במקרים רבים ה-Loss של ה-Discriminator יכול לרדת לאפס יחסית מהר, מה שגורם ל-Generator לא להיות מסוגל להתאמן יותר. כדי להתגבר על כך, ניתן לנסות להגדיר קצבי למידה שונים עבור ה-Generator וה-Discriminator, או לדלג על אימון ה-Discriminator אם ה-Loss כבר נמוך מדי.
* אימון עבור **רזולוציה גבוהה**. בעיה זו דומה לבעיה עם Autoencoders, והיא נגרמת מכך ששחזור שכבות רבות של רשת קונבולוציה מוביל לארטיפקטים. בעיה זו נפתרת בדרך כלל באמצעות **גדילה פרוגרסיבית**, שבה תחילה מאמנים כמה שכבות על תמונות ברזולוציה נמוכה, ואז "משחררים" או מוסיפים שכבות. פתרון נוסף הוא הוספת חיבורים נוספים בין שכבות ואימון מספר רזולוציות בו-זמנית - ראו את [מאמר Multi-Scale Gradient GANs](https://arxiv.org/abs/1903.06048) לפרטים.

## העברת סגנון

GANs הם דרך מצוינת לייצר תמונות אמנותיות. טכניקה מעניינת נוספת היא **העברת סגנון**, שבה לוקחים תמונת **תוכן** אחת ומציירים אותה מחדש בסגנון שונה, תוך שימוש במסננים מתמונת **סגנון**.

כך זה עובד:
* מתחילים עם תמונת רעש אקראית (או עם תמונת תוכן, אך לצורך הבנה קל יותר להתחיל מרעש אקראי)
* המטרה היא ליצור תמונה שתהיה קרובה הן לתמונת התוכן והן לתמונת הסגנון. זה נקבע על ידי שתי פונקציות Loss:
   - **Content loss** מחושב על בסיס התכונות שמופקות על ידי ה-CNN בשכבות מסוימות מהתמונה הנוכחית ותמונת התוכן
   - **Style loss** מחושב בין התמונה הנוכחית לתמונת הסגנון בצורה חכמה באמצעות מטריצות Gram (פרטים נוספים ב-[מחברת הדוגמה](StyleTransfer.ipynb))
* כדי להפוך את התמונה לחלקה יותר ולהסיר רעש, מוסיפים גם **Variation loss**, שמחשב את המרחק הממוצע בין פיקסלים שכנים
* לולאת האופטימיזציה הראשית מתאימה את התמונה הנוכחית באמצעות ירידת גרדיאנט (או אלגוריתם אופטימיזציה אחר) כדי למזער את ה-Loss הכולל, שהוא סכום משוקלל של כל שלושת ה-Lossים.

## ✍️ דוגמה: [העברת סגנון](StyleTransfer.ipynb)

## [שאלון אחרי השיעור](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/210)

## סיכום

בשיעור זה למדתם על GANs וכיצד לאמן אותם. כמו כן, למדתם על האתגרים המיוחדים שרשתות נוירונים מסוג זה יכולות להתמודד איתם, ועל אסטרטגיות להתגבר עליהם.

## 🚀 אתגר

עברו על [מחברת העברת סגנון](StyleTransfer.ipynb) תוך שימוש בתמונות שלכם.

## סקירה ולימוד עצמי

לקריאה נוספת על GANs, עיינו במשאבים הבאים:

* Marco Pasini, [10 Lessons I Learned Training GANs for one Year](https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628)
* [StyleGAN](https://en.wikipedia.org/wiki/StyleGAN), ארכיטקטורת GAN שכדאי לשקול
* [Creating Generative Art using GANs on Azure ML](https://soshnikov.com/scienceart/creating-generative-art-using-gan-on-azureml/)

## משימה

חזרו לאחת משתי המחברות הקשורות לשיעור זה ואמנו מחדש את ה-GAN על תמונות שלכם. מה תוכלו ליצור?

---

**כתב ויתור**:  
מסמך זה תורגם באמצעות שירות תרגום מבוסס בינה מלאכותית [Co-op Translator](https://github.com/Azure/co-op-translator). בעוד שאנו שואפים לדיוק, יש להיות מודעים לכך שתרגומים אוטומטיים עשויים להכיל שגיאות או אי דיוקים. המסמך המקורי בשפתו המקורית צריך להיחשב כמקור סמכותי. עבור מידע קריטי, מומלץ להשתמש בתרגום מקצועי על ידי אדם. איננו נושאים באחריות לאי הבנות או לפרשנויות שגויות הנובעות משימוש בתרגום זה.